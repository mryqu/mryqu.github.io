<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Mryqu's Notes</title><link>https://mryqu.github.io/post/</link><description>Recent content in Posts on Mryqu's Notes</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 31 Aug 2021 12:31:23 +0000</lastBuildDate><atom:link href="https://mryqu.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>MIUI12.5关闭充电提示音</title><link>https://mryqu.github.io/post/miui12.5%E5%85%B3%E9%97%AD%E5%85%85%E7%94%B5%E6%8F%90%E7%A4%BA%E9%9F%B3/</link><pubDate>Tue, 31 Aug 2021 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/miui12.5%E5%85%B3%E9%97%AD%E5%85%85%E7%94%B5%E6%8F%90%E7%A4%BA%E9%9F%B3/</guid><description>自从手机升级到MIUI12.5，原来关闭提示音就又出现了。
在“设置-声音与振动-更多声音设置”里面关闭了所有提示音，可是充电提示音依旧存在。上网一查，原来充电提示音变成不可配置的了。
下载Android SDK Platform-Tools ，执行adb程序无法找到任何设备。
C:\temp\platform-tools_r31.0.3-windows\platform-tools&amp;gt;adb devices List of devices attached 在手机上执行如下操作：
设置—我的设备—全部参数—连续点击MIUI版本直至提示开发者模式已打开 设置-更多设置-开发者选项-激活USB调试、USB调试（安全设置） 重新执行adb程序：
C:\temp\platform-tools_r31.0.3-windows\platform-tools&amp;gt;adb devices List of devices attached ******** device C:\temp\platform-tools_r31.0.3-windows\platform-tools&amp;gt;adb shell settings put global power_sounds_enabled 0 成功！</description></item><item><title>[GoLang] go get github.com/jessevdk/go-assets解决记录</title><link>https://mryqu.github.io/post/golang_go-get-go-assets/</link><pubDate>Fri, 19 Mar 2021 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/golang_go-get-go-assets/</guid><description>在我的Cenos服务器上无法获取go-assets，结果如下：
MRYQULAX&amp;gt; go get github.com/jessevdk/go-assets # cd .; git clone -- https://github.com/jessevdk/go-assets /users/mryqu/go/src/github.com/jessevdk/go-assets Cloning into &amp;#39;/users/mryqu/go/src/github.com/jessevdk/go-assets&amp;#39;... fatal: unable to access &amp;#39;https://github.com/jessevdk/go-assets/&amp;#39;: SSL connect error package github.com/jessevdk/go-assets: exit status 128 看了一下我的git版本是1.7.1，先升级一下试试吧。
export VER=&amp;#34;2.31.0&amp;#34; wget https://github.com/git/git/archive/v${VER}.tar.gz tar -xvf v${VER}.tar.gz rm -f v${VER}.tar.gz cd git-* make configure sudo ./configure --prefix=/usr sudo make sudo make install 升级完成后，还是无法获取go-assets。
调试一下ssh方式：
MRYQULAX&amp;gt; ssh -vT git@github.com OpenSSH_5.3p1, OpenSSL 1.0.0-fips 29 Mar 2010 debug1: Reading configuration data /users/mryqu/.ssh/config debug1: Reading configuration data /etc/ssh/ssh_config debug1: Applying options for * debug1: Connecting to github.</description></item><item><title>GoLang语言filepath.Clean功能在AIX脚本中的实现</title><link>https://mryqu.github.io/post/shell-substitutes-for-filepath.clean-of-golang/</link><pubDate>Tue, 23 Feb 2021 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/shell-substitutes-for-filepath.clean-of-golang/</guid><description>GoLang语言filepath包Clean函数功能如下：
Replace multiple Separator elements with a single one. Eliminate each . path name element (the current directory). Eliminate each inner .. path name element (the parent directory) along with the non-.. element that precedes it. Eliminate .. elements that begin a rooted path: that is, replace &amp;ldquo;/..&amp;rdquo; by &amp;ldquo;/&amp;rdquo; at the beginning of a path, assuming Separator is &amp;lsquo;/&amp;rsquo;. perl等价功能 File::Spec 模块的canonpath函数与GoLang语言filepath包Clean函数功能基本类似，都不进行文件系统物理检查仅完成路径逻辑清理。
No physical check on the filesystem, but a logical cleanup of a path.</description></item><item><title>在Centos上安装Perl LibXML库记录</title><link>https://mryqu.github.io/post/%E5%9C%A8centos%E4%B8%8A%E5%AE%89%E8%A3%85perl-libxml%E5%BA%93/</link><pubDate>Mon, 04 Jan 2021 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8centos%E4%B8%8A%E5%AE%89%E8%A3%85perl-libxml%E5%BA%93/</guid><description>一开始使用cpan安装，揍是不成功。
[root@mryqulax ~]# perldoc -m XML::LibXML No module found for &amp;#34;XML::LibXML&amp;#34;. [root@mryqulax ~]# perl -MCPAN -e shell Terminal does not support AddHistory. cpan shell -- CPAN exploration and modules installation (v1.9800) Enter &amp;#39;h&amp;#39; for help. cpan[1]&amp;gt; install XML::LibXML CPAN: Storable loaded ok (v2.20) Reading &amp;#39;/root/.cpan/Metadata&amp;#39; Database was generated on Sun, 24 Nov 2013 10:53:02 GMT CPAN: LWP::UserAgent loaded ok (v6.04) CPAN: Time::HiRes loaded ok (v1.9721) Fetching with LWP: ftp://cpan.cs.utah.edu/CPAN/authors/01mailrc.txt.gz Reading &amp;#39;/root/.</description></item><item><title>Shell之rev与tac</title><link>https://mryqu.github.io/post/shell-commands_rev-and-tac/</link><pubDate>Tue, 29 Dec 2020 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/shell-commands_rev-and-tac/</guid><description>今天想把一个文件内容反序输出，就找到了rev与tac这两个命令。
rev是对每一行内容进行反序，行序不变 tac是对行序反序, 每一行内容不变 mryqulax&amp;gt; cat test.log whoami 123 mryqulax&amp;gt; rev test.log imaohw 321 mryqulax&amp;gt; tac test.log 123 whoami</description></item><item><title>AIX操作笔记</title><link>https://mryqu.github.io/post/aix-notes/</link><pubDate>Wed, 23 Dec 2020 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/aix-notes/</guid><description>查看版本 TL（Technical Level）指 AIX 操作系统的技术版本（以前称为 ML, Maintenance Level），包括硬件、软件的新功能和传统的补丁。
SP( Service Pack) 指服务补丁版本，包括一些不能等到下一个TL推出的关键的补丁及非常有限的新硬件驱动。
$ oslevel -s 7100-04-04-1717 上例中oslevel -s显示结果为7100-04-04-1717，头四位系统版本，接下来两位为技术版本，之后两位为补丁版本，最后4位，前2位标识年份，后2位表示周。
7100-04-04-1717表示AIX7.1 TL版本04，SP版本04，这个版本是在2017年第17周进行的更新。
安装软件 在ftp://ftp.software.ibm.com/aix/freeSoftware/aixtoolbox/RPMS/ppc/ 查找到所需软件的链接，然后通过rpm进行安装。例如：
rpm -Uvh ftp://ftp.software.ibm.com/aix/freeSoftware/aixtoolbox/RPMS/ppc/curl/curl-7.9.3-2.aix4.3.ppc.rpm 查看系统指标 bindprocessor bindprocessor 用于将进程的内核线程绑定至处理器或取消绑定。
$ bindprocessor -q The available processors are: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 lparstat lparstat 报告逻辑分区（LPAR）相关信息和统计。</description></item><item><title>Shell读取文件修改时间并格式化输出</title><link>https://mryqu.github.io/post/shell%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4%E5%B9%B6%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA/</link><pubDate>Wed, 23 Dec 2020 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/shell%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4%E5%B9%B6%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA/</guid><description>最近有一些golang代码实现的功能需要移植到用于低版本AIX的korn shell上去。其中碰到了文件修改时间格式化问题。
通过下面的golang示例代码可知最后需要的是本地时间而不是UTC时间。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;os&amp;#34; &amp;#34;path/filepath&amp;#34; &amp;#34;time&amp;#34; ) // Infrastructrue var basedir string func init() { exe, err := os.Executable() if err != nil { os.Exit(1) } basedir = filepath.Dir(exe) } func main() { fmt.Printf(&amp;#34;now=%s\n&amp;#34;, time.Now().Format(&amp;#34;02Jan06:15:04:05&amp;#34;)) fmt.Printf(&amp;#34;now.UTC()=%s\n&amp;#34;, time.Now().UTC().Format(&amp;#34;02Jan06:15:04:05&amp;#34;)) fmt.Printf(&amp;#34;now.Local()=%s\n&amp;#34;, time.Now().Local().Format(&amp;#34;02Jan06:15:04:05&amp;#34;)) f, ferr := os.Lstat(basedir) if ferr != nil { fmt.Printf(&amp;#34;Unable to access %s. Skipping...\n&amp;#34;, basedir) os.Exit(1) } mode := f.Mode() if mode&amp;amp;os.ModeSymlink != 0 { fmt.</description></item><item><title>Shell逐行读取、解析并export变量实践</title><link>https://mryqu.github.io/post/shell%E9%80%90%E8%A1%8C%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%E5%B9%B6export%E5%8F%98%E9%87%8F%E5%AE%9E%E8%B7%B5/</link><pubDate>Tue, 15 Dec 2020 12:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/shell%E9%80%90%E8%A1%8C%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%E5%B9%B6export%E5%8F%98%E9%87%8F%E5%AE%9E%E8%B7%B5/</guid><description>setenv.yaml示例
MY_HOME: /local/install/myhome MY_JAVA_HOME: $MY_HOME/jre/bin test.ksh示例
#!/bin/ksh getCustEnv() { # 除了while read 也可以使用for var，但是需要更改IFS为换行符 cat setenv.yaml | while read line; do line=$(echo $line | grep -v &amp;#34;^\s*#&amp;#34; | grep &amp;#34;:&amp;#34;) if [ ! -z $line ]; then key=$(echo $line | cut -d: -f1 | sed -e &amp;#39;s/^\s*//&amp;#39; -e &amp;#39;s/\s*$//&amp;#39;) val=$(echo $line | cut -d: -f2 | sed -e &amp;#39;s/^\s*//&amp;#39; -e &amp;#39;s/\s*$//&amp;#39;) echo &amp;#34;line=$line&amp;#34; echo &amp;#34;key=$key&amp;#34; echo &amp;#34;val=$val&amp;#34; if [ ! -z $key ]; then echo &amp;#34;export $key=$val&amp;#34; # 不可以直接执行export，否则变量值还是字符串，例如MY_JAVA_HOME变量值仍为$MY_HOME/jre/bin，而不是/local/install/myhome/jre/bin eval export $key=$val # 变量的二次引用 这里${!</description></item><item><title>sed正则表达式捕获组实践</title><link>https://mryqu.github.io/post/sed%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%8D%95%E8%8E%B7%E7%BB%84%E5%AE%9E%E8%B7%B5/</link><pubDate>Fri, 04 Dec 2020 07:31:23 +0000</pubDate><guid>https://mryqu.github.io/post/sed%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%8D%95%E8%8E%B7%E7%BB%84%E5%AE%9E%E8%B7%B5/</guid><description>mryqu&amp;gt; cat test.txt Hello from=&amp;#34;Beijing&amp;#34; via=&amp;#34;Nanjing&amp;#34; to=&amp;#34;Shanghai&amp;#34;. test 123 mryqu&amp;gt; sed -e &amp;#39;s/^Hello.*from=&amp;#34;[^&amp;#34;]\+&amp;#34;.*$/abc/g&amp;#39; test.txt abc test 123 mryqu&amp;gt; sed -e &amp;#39;s/^Hello.*from=&amp;#34;\([^&amp;#34;]\+\)&amp;#34;.*$/\1/g&amp;#39; test.txt Beijing test 123 mryqu&amp;gt; sed -e &amp;#39;s/^\(Hello.*from=&amp;#34;\)\([^&amp;#34;]\+\)\(&amp;#34;.*\)$/\1********\3/g&amp;#39; test.txt Hello from=&amp;#34;********&amp;#34; via=&amp;#34;Nanjing&amp;#34; to=&amp;#34;Shanghai&amp;#34;. test 123 mryqu&amp;gt; sed -e &amp;#39;s/^\(Hello.*from=&amp;#34;\)\([^&amp;#34;]\+\)\(&amp;#34;.*\)$/\1********\3/g&amp;#39; -e &amp;#39;s/^\(Hello.*to=&amp;#34;\)\([^&amp;#34;]\+\)\(&amp;#34;.*\)$/\1********\3/g&amp;#39; test.txt Hello from=&amp;#34;********&amp;#34; via=&amp;#34;Nanjing&amp;#34; to=&amp;#34;********&amp;#34;. test 123 mryqu&amp;gt; 注：sed不支持非贪婪模式。
参考 Sed教程-正则表达式 grep、sed、awk、perl等对正则表达式的支持的差别 How to output only captured groups with sed?</description></item><item><title>Shell显示彩色文字</title><link>https://mryqu.github.io/post/shell%E6%98%BE%E7%A4%BA%E5%BD%A9%E8%89%B2%E6%96%87%E5%AD%97/</link><pubDate>Thu, 26 Nov 2020 08:25:00 +0000</pubDate><guid>https://mryqu.github.io/post/shell%E6%98%BE%E7%A4%BA%E5%BD%A9%E8%89%B2%E6%96%87%E5%AD%97/</guid><description>昨天学习一下如何使用shell在屏幕显示彩色文字。解决方案有两种：1. 转义字符 2. tput设置文本颜色。
在Linux上这两种方式都正常工作，在FreeBSD上第二种方式不起作用。
代码如下：
#!/bin/ksh println() { printf &amp;#34;%s\n&amp;#34; $* } ########################## # Solution 1 ########################## colorsEnabled() { if [ $TERM == &amp;#39;TERM&amp;#39; ] then return 0 fi return 1 } printlnColor() { c=$1 shift msg=$*; colorsEnabled if [ $? == 1 ] then printf &amp;#34;\033[0;%dm%s\033[0m\n&amp;#34; $c &amp;#34;$msg&amp;#34; else printf &amp;#34;%s\n&amp;#34; &amp;#34;$msg&amp;#34; fi } # Success printlnSuccess() { printlnColor 32 $* } # Warning printlnWarning() { printlnColor 33 $* } # Failure printlnFailure() { printlnColor 31 $* } # Verbose printlnVerbose() { printlnColor 35 $* } # Emphasis printlnEmphasis() { printlnColor 36 $* } # Note printlnNote() { printlnColor 37 $* } ########################## # Solution 2 ########################## println_color() { c=$1 shift msg=$*; tput setaf $c printf &amp;#34;%s\n&amp;#34; &amp;#34;$msg&amp;#34; tput sgr0 } # Success println_success() { println_color 2 $* } # Warning println_warning() { println_color 3 $* } # Failure println_failure() { println_color 1 $* } # Verbose println_verbose() { println_color 5 $* } # Emphasis println_emphasis() { println_color 6 $* } # Note println_note() { println_color 7 $* } printlnEmphasis hahaha 123 echo &amp;#34;=====================&amp;#34; println_emphasis hahaha 123 参考 ANSI Escape sequences Git shell coloring · GitHub tput</description></item><item><title>React-Redux Action链式调用</title><link>https://mryqu.github.io/post/react-redux-action%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8/</link><pubDate>Sun, 10 May 2020 06:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/react-redux-action%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8/</guid><description>在进行React-Redux实践时，碰到下面这样一个场景，执行一个UI操作需要链式次序分发多个Action。
例如，删除一个post时，需要通过axios删除选中的post，然后通过axios获取所有post以刷新post列表，最后将选中的post id设为空。 前两个action为异步action，后一个action为同步action。
下面就对我的实践进行一下总结。
实现 PostActions.js:
...... export const handleSelectIdChange = selectedId =&amp;gt; ({ type: types.UPDATE_SELECTED_ID, payload: { data: selectedId } }); ...... export const getPosts = () =&amp;gt; { return dispatch =&amp;gt; { dispatch(getPostsStarted()); return axios .get(&amp;#39;/api/posts&amp;#39;) .then(res =&amp;gt; { dispatch(getPostsSuccess(res.data)); }) .catch(err =&amp;gt; { dispatch(getPostsFailure(err.message)); }); }; } export const getPostsSuccess = posts =&amp;gt; ({ type: types.GET_POSTS_SUCCESS, payload: { data: posts } }); export const getPostsStarted = () =&amp;gt; ({ type: types.</description></item><item><title>ESLint和Prettier学习</title><link>https://mryqu.github.io/post/eslint%E5%92%8Cprettier%E5%AD%A6%E4%B9%A0/</link><pubDate>Fri, 01 May 2020 06:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/eslint%E5%92%8Cprettier%E5%AD%A6%E4%B9%A0/</guid><description>Devias Kit - React Admin Dashboard 使用了ESLint进行代码检测，使用Prettier进行代码格式化。
下面就其代码devias-io/react-material-dashboard 进行学习。
ESLint简介 ESLint 是一个用来识别ECMAScript/JavaScript并且按照规则给出报告的代码检测工具，使用它可以避免低级错误和统一代码的风格。如果每次在代码提交之前都进行一次ESLint代码检查，就不会因为某个字段未定义为undefined或null这样的错误而导致服务崩溃，可以有效的控制项目代码的质量。
在许多方面，它和 JSLint、JSHint 相似，除了少数的例外：
ESLint使用Espree解析JavaScript。 ESLint使用AST去分析代码中的模式。 ESLint是完全插件化的。 每一个规则都是一个插件并且你可以在运行时添加更多的规则。 Prettier简介 Prettier 是一个opinionated(有态度的)代码格式化工具，支持多种语言，可以和绝大多数编辑器集成，选项少。
什么是opinionated？就是有态度有倾向，尽量减少配置项，相反的意思是Unopinionated。 像Spring Boot也是宣称有态度的。
devias-io/react-material-dashboard开发环境依赖 &amp;#34;devDependencies&amp;#34;: { &amp;#34;eslint&amp;#34;: &amp;#34;5.16.0&amp;#34;, &amp;#34;eslint-plugin-prettier&amp;#34;: &amp;#34;^3.0.1&amp;#34;, &amp;#34;eslint-plugin-react&amp;#34;: &amp;#34;^7.12.4&amp;#34;, &amp;#34;prettier&amp;#34;: &amp;#34;^1.17.1&amp;#34;, &amp;#34;prettier-eslint&amp;#34;: &amp;#34;^8.8.2&amp;#34;, &amp;#34;prettier-eslint-cli&amp;#34;: &amp;#34;^4.7.1&amp;#34;, &amp;#34;typescript&amp;#34;: &amp;#34;^3.5.1&amp;#34; } ESLint包 是代码检测工具，Prettier包 是代码格式化工具。 ESLint既能完成传统的语法检测，也能检查风格是否符合要求。可以用ESLint完成一切工作，也可以结合ESLint完成代码格式化和错误检测。
其他包：
ESLint-plugin-React包：ESLint原生支持JSX，但ESLint并不支持React特定的JSX符号，所以要使用ESLint-plugin-React包； prettier-eslint包：prettier-eslint会先调用Prettier完成代码格式化，然后将执行eslint --fix按照配置进行语法修复； prettier-eslint-cli包：prettier-eslint的CLI； eslint-plugin-prettier包：作为ESLint的一个规则运行Prettier。 devias-io/react-material-dashboard 项目没有介绍怎么使用ESLint和Prettier。 如果使用prettier-eslint/prettier-eslint-cli，那就是次序使用Prettier和ESLint；如果使用eslint-plugin-prettier，就是Prettier作为ESLint的插件，在CLI仅仅使用ESLint，而ESLint会调用Prettier。
通过.eslintrc分析，ESLint仅使用了react插件，而没有prettier插件，而且ESLint规则里面也没有prettier，所以其实没有使用eslint-plugin-prettier包。
&amp;#34;plugins&amp;#34;: [ &amp;#34;react&amp;#34; ] CLI 上面的开发环境依赖所安装的包共有三个CLI可以使用：
.\node_modules\.bin\eslint -h .\node_modules\.bin\prettier -h .\node_modules\.bin\prettier-eslint -h Prettier配置 .</description></item><item><title>Gradle构建ReactJS前端实践</title><link>https://mryqu.github.io/post/gradle%E6%9E%84%E5%BB%BAreactjs%E5%89%8D%E7%AB%AF%E5%AE%9E%E8%B7%B5/</link><pubDate>Sat, 25 Apr 2020 12:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/gradle%E6%9E%84%E5%BB%BAreactjs%E5%89%8D%E7%AB%AF%E5%AE%9E%E8%B7%B5/</guid><description>frontend-maven-plugin使用介绍 Spring指南里面有个示例React.js and Spring Data REST ，技术架构为：
后端采用Spring Data Rest 前端采用React.js 构建工具为Maven 下面看一下其pom.xml构建前端的片段:
&amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;com.github.eirslett&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;frontend-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.6&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;installDirectory&amp;gt;target&amp;lt;/installDirectory&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;install node and npm&amp;lt;/id&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;install-node-and-npm&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;nodeVersion&amp;gt;v10.11.0&amp;lt;/nodeVersion&amp;gt; &amp;lt;npmVersion&amp;gt;6.4.1&amp;lt;/npmVersion&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;npm install&amp;lt;/id&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;npm&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;arguments&amp;gt;install&amp;lt;/arguments&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;webpack build&amp;lt;/id&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;webpack&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; frontend-maven-plugin 用于构建JavaScript部分：
install-node-and-npm命令将安装node.js及其包管理工具npm到target目录。 （这确保这些二进制文件不在源代码控制范围内并且能被clean命令清除）。 npm命令将执行使用参数install的npm二进制文件，它会安装定义在package.json内的模块。 webpack命令将执行webpack二进制文件，它会基于webpack.config.js打包所有JavaScript代码。 这些步骤依次运行，完成安装node.js、下载JavaScript模块、构建JS部分。
备选Gradle前端构建插件 frontend-maven-plugin 是专用于Maven的插件，在Gradle上并没有直接对应的插件。
我查找后，重点考察了下面两个插件：
Frontend Gradle plugin Gradle Plugin for Node Frontend Gradle plugin实践 代码修改 package.</description></item><item><title>Vue.js开发环境设置</title><link>https://mryqu.github.io/post/vue.js-dev-settings/</link><pubDate>Mon, 20 Apr 2020 06:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/vue.js-dev-settings/</guid><description>设置Node.js和NPM 升级Node(n不支持Windows操作系统)：
node -v #查看Node版本 npm cache clean -f #清除Node的缓存 npm install -g n #安装n工具，该工具是专门管理Node版本的工具 n stable #安装最新稳定的Node版本 升级NPM：
npm -v #查看NPM版本 npm install npm@latest -g #安装最新稳定的NPM版本 我在两台机器上安装了Node 12.16.2 TLS，其中一台机器上npm死活有问题，从Node 10.16版本开始总是报错verbose stack TypeError: Cannot read property 'resolve' of undefined。
最后在那台机器上重新安装了Node 10.15.3,才避免了问题。
安装Chrome插件Vue.js devtools 在vue-devtools github项目页面里找到Chrome插件网址，进行安装。 安装后，在Chrome开发者工具中可以看到Vue Tab并使用。
安装Vue CLI npm install -g @vue/cli 使用Vue CLI创建Vue项目 C:\ws&amp;gt;vue create hello-vue Vue CLI v4.3.1 ? Please pick a preset: default (babel, eslint) Vue CLI v4.</description></item><item><title>React.js开发环境设置</title><link>https://mryqu.github.io/post/react.js-dev-settings/</link><pubDate>Sun, 19 Apr 2020 12:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/react.js-dev-settings/</guid><description>设置Node.js和NPM 升级Node(n不支持Windows操作系统)：
node -v #查看Node版本 npm cache clean -f #清除Node的缓存 npm install -g n #安装n工具，该工具是专门管理Node版本的工具 n stable #安装最新稳定的Node版本 升级NPM：
npm -v #查看NPM版本 npm install npm@latest -g #安装最新稳定的NPM版本 我在两台机器上安装了Node 12.16.2 TLS，其中一台机器上npm死活有问题，从Node 10.16版本开始总是报错verbose stack TypeError: Cannot read property 'resolve' of undefined。
最后在那台机器上重新安装了Node 10.15.3,才避免了问题。
安装Chrome插件React Developer Tools 从Chrome Extensions上搜索React Developer Tools进行安装。
安装后，在Chrome开发者工具中可以看到React的Components和Profiler两个Tab并使用。
安装脚手架create-react-app npm install -g create-react-app 使用create-react-app创建React项目 C:\devpg&amp;gt;create-react-app hello-react Creating a new React app in C:\devpg\hello-react. Installing packages. This might take a couple of minutes.</description></item><item><title>前端框架对比资料</title><link>https://mryqu.github.io/post/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94%E8%B5%84%E6%96%99/</link><pubDate>Tue, 14 Apr 2020 06:06:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94%E8%B5%84%E6%96%99/</guid><description>资料如下：
Side by Side: SAPUI5 vs. React &amp;amp; Angular2 Vue: Comparison with Other Frameworks Angular 2 vs React: The Ultimate Dance Off React vs Angular vs Vue.js — What to choose in 2019? (updated) React.js与Vue.js：流行框架的比较 Reactjs vs. Vuejs React与Vue的对比 关于Vue.js和React.js，听听国外的开发者怎么说？ web前端技术框架选型参考 前端框架及组件库选型分析 前端架构师对于框架的技术选型</description></item><item><title>Gradle：解决error: unmappable character for encoding GBK</title><link>https://mryqu.github.io/post/gradle_%E8%A7%A3%E5%86%B3error-unmappable-character-for-encoding-gbk/</link><pubDate>Wed, 20 Nov 2019 21:15:17 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E8%A7%A3%E5%86%B3error-unmappable-character-for-encoding-gbk/</guid><description>在学习某个项目时，.\gradlew build总是遇到error: unmappable character for encoding GBK。至少确定源文件至少会是UTF8的，所以尝试设置文件编码格式来解决这个问题。
一般使用javac编译和java执行程序时，可以使用：
javac -encoding UTF-8 Test.java java -Dfile.encoding=UTF-8 Test 对于Gradle项目，可以设置gradlew.bat:
set DEFAULT_JVM_OPTS=&amp;#34;-Dfile.encoding=UTF-8&amp;#34; 对于IntelliJ Idea，可在配置文件vmoption文件底部添加一行：
-Dfile.encoding=UTF-8 经过上述尝试，问题依旧存在，仔细一看错误是发生在javadoc任务阶段，一个java文件注释中包含一个字符“ß”导致这个问题的出现。
在build.gradle文件中添加：
javadoc { options.encoding = &amp;#39;UTF-8&amp;#39; } 搞定！！！</description></item><item><title>[JS] 图算法实践</title><link>https://mryqu.github.io/post/js_%E5%9B%BE%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 18 Jul 2019 20:17:16 +0000</pubDate><guid>https://mryqu.github.io/post/js_%E5%9B%BE%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/</guid><description>最近需要用JavaScript处理图算法，没找到适合的库，就自己写一套玩玩。
Graph.js 仿照Graph.java写的，实现无向图API。
(function(){ return Graph = (function () { // create empty Graph with V vertices function Graph(V) { this._V = V; this._E = 0; this._adj = []; for(var i=0;i&amp;lt;V;i++) this._adj.push([]); } Object.defineProperty(Graph.prototype, &amp;#34;V&amp;#34;, { get: function () { return this._V; }, enumerable: true, configurable: true }); Object.defineProperty(Graph.prototype, &amp;#34;E&amp;#34;, { get: function () { return this._E; }, enumerable: true, configurable: true }); // Adds the undirected edge v-w to this graph.</description></item><item><title>[OpenUI5] 监控Model属性变动</title><link>https://mryqu.github.io/post/openui5_%E7%9B%91%E6%8E%A7model%E5%B1%9E%E6%80%A7%E5%8F%98%E5%8A%A8/</link><pubDate>Thu, 18 Jul 2019 06:36:28 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E7%9B%91%E6%8E%A7model%E5%B1%9E%E6%80%A7%E5%8F%98%E5%8A%A8/</guid><description>设计了某个OpenUI5控件，当对控件的某些子控件进行设置时，想监控模型的变动。
下面的代码完成了这样的功能：
该控件绑定路径为/someItems/{itemId}/objInfo 当控件下某些子控件修改设置，则路径为/someItems/{itemId}/objInfo的模型属性会发生变动 路径为/someItems/{itemId}/isModified的模型属性将被设置为true (function () { &amp;#34;use strict&amp;#34;; .... var PATH_PART_OBJINFO = &amp;#34;/objInfo&amp;#34;; var PATH_PART_ISMODIFIED = &amp;#34;/isModified&amp;#34;; SomeControl.extend(&amp;#34;com.yqu.MySomeControl&amp;#34;, { metadata: { properties: {}, publicMethods: [], events: {} }, rb: sap.ui.getCore().getLibraryResourceBundle(&amp;#34;com.yqu&amp;#34;), renderer: &amp;#34;SomeControlRenderer&amp;#34;, init: function() { .... }, onBeforeRendering: function() { if(SomeControl.prototype.onBeforeRendering) SomeControl.prototype.onBeforeRendering.apply(this, arguments); .... var context = this.getBindingContext(); if (!!context &amp;amp;&amp;amp; !!context.oModel &amp;amp;&amp;amp; !!context.sPath) { var binding = new sap.ui.model.Binding(context.oModel, &amp;#34;/&amp;#34;, context); binding.attachChange($.proxy(this._onDataModified, this)); } }, _onDataModified: function() { var context = this.</description></item><item><title>CTRL+C无法中断Git Bash中运行的Spring Boot程序</title><link>https://mryqu.github.io/post/ctrl_c%E6%97%A0%E6%B3%95%E4%B8%AD%E6%96%ADgitbash%E4%B8%AD%E8%BF%90%E8%A1%8C%E7%9A%84spring-boot%E7%A8%8B%E5%BA%8F/</link><pubDate>Fri, 12 Jul 2019 20:02:02 +0000</pubDate><guid>https://mryqu.github.io/post/ctrl_c%E6%97%A0%E6%B3%95%E4%B8%AD%E6%96%ADgitbash%E4%B8%AD%E8%BF%90%E8%A1%8C%E7%9A%84spring-boot%E7%A8%8B%E5%BA%8F/</guid><description>在Git Bash中通过gradle bootRun的方式运行Spring Boot程序，使用CTRL+C无法中断运行的程序，重启计算机才能重新运行Spring Boot程序。
忍了很久，最近查了查，发现是Msys2使用的MinTTY终端无法争取地将CTRL+C传递给应用导致的。
CTRL-C doesn&amp;rsquo;t interrupt the running process #684
CTRL-C doesn&amp;rsquo;t stop running app in Windows #773
Re: Ctrl-C and non-cygwin programs
Unable to use CTRL-C, &amp;rsquo;n&amp;rsquo; and &amp;lsquo;q&amp;rsquo; keyboard commands in Cygwin and Msys2 shells #112
Ctrl+C no longer kills running process in Git Bash
在最后一个帖子中查找到适用于我使用场景的workaround：
通过文件浏览器在Git目录中删除usr\bin\mintty.exe文件 重新运行Git Bash（或在文件浏览器中直接双击git-bash.exe) # 删除mintty前 $ echo $TERM xterm # 删除mintty后 $ echo $TERM cygwin</description></item><item><title>学习使用Minikube</title><link>https://mryqu.github.io/post/learning-minikube/</link><pubDate>Thu, 13 Jun 2019 06:12:34 +0000</pubDate><guid>https://mryqu.github.io/post/learning-minikube/</guid><description>在管理容器化应用方面，Kubernetes是目前最好的工具之一。而Minikube能够在macOS、Linux和Windows平台上实现一个本地Kubernetes集群，用于Kubernetes的学习。
Minikube是由Go语言实现，当前支持如下Kubernetes特性：
DNS NodePort ConfigMap和Secret 仪表盘 容器运行时: Docker、rkt、CRI-O和containerd 使能容器网络接口 Ingres 由上图可知，要使用Minikube，需要安装Minikube、kubectl和虚拟机。好在有Katacoda提供浏览器内的带有Kubernetes环境的免费虚拟终端，省却了安装这一步骤。
按照Kubernetes的Hello Minikube教程走了一遍。
minikube version; minikube start $ $ minikube version; minikube start minikube version: v0.28.2 Starting local Kubernetes v1.10.0 cluster... Starting VM... Getting VM IP address... Moving files into cluster... Setting up certs... Connecting to cluster... Setting up kubeconfig... Starting cluster components... Kubectl is now configured to use the cluster. Loading cached images from config file. $ $ minikube --help Minikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows.</description></item><item><title>玩一道正则表达式练习题</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E9%81%93%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%BB%83%E4%B9%A0%E9%A2%98/</link><pubDate>Sun, 02 Jun 2019 18:36:11 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E9%81%93%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%BB%83%E4%B9%A0%E9%A2%98/</guid><description>前一段时间在网上碰到一道题，要求进行用户名检查：
用户名长度要求最短6字符，最长16字符； 用户名可以由字母、数字和可选的一个连字号(-)组成； 用户名首字符必须为字母，末字符不可以是连字号。 这道题属于送分题，很容易写出下面的Java代码：
public class Username { public static int MIN_LEN = 6; public static int MAX_LEN = 16; public static boolean validate(String username) { if(username==null || username.length()&amp;lt;MIN_LEN || username.length()&amp;gt;MAX_LEN || !Character.isLetter(username.charAt(0))) return false; int hyphenNum = 0; for(int i=1;i&amp;lt;username.length();i++) { char ch = username.charAt(i); if (!Character.isLetterOrDigit(ch)) { if (ch==&amp;#39;-&amp;#39;) { if(i== username.length()-1 || ++hyphenNum&amp;gt;1) return false; } else return false; } } return true; } public static void main(String[] args) { String[] tests = new String[] { null, &amp;#34;mryqu123&amp;#34;, &amp;#34;mryqu-123&amp;#34;, &amp;#34;mryqu 123&amp;#34;, &amp;#34;mryqu123-&amp;#34;, &amp;#34;mryqu-123-bj&amp;#34;, &amp;#34;123mryqu&amp;#34;, &amp;#34;MryQu-123&amp;#34; }; for(String test:tests) { System.</description></item><item><title>使用Postman动态调试Salesforce API</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8postman%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95salesforce-api/</link><pubDate>Mon, 27 May 2019 06:12:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8postman%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95salesforce-api/</guid><description>在使用Postman调试Salesforce API时，觉得每次输入Access Token很low，应该充分利用它的脚本能力进行自动化。
创建环境变量 创建新环境变量： 设置环境变量： 选择环境变量： 创建OAuth集合 创建OAuth Collection：
创建Password Authorization请求：
Password Authorization请求头：
Password Authorization请求体：
Password Authorization响应脚本： 脚本用于将响应中信息写入ACCESS_TOKEN和INSTANCE_URL环境变量以用于后继API调用。
Server Authorization请求：
创建Export集合 创建Export Collection： 编辑Export Collection： 主要是让集合内请求共用Bearer Token。 获取版本： 脚本用于将响应中信息写入LATEST_VER_PATH环境变量以用于后继API调用。
注： 通过快捷键(CMD/CTRL + ALT + C)可以打开Postman应用的控制台。
获取资源： 获取对象列表： 获取对象元数据： 获取对象列信息： 脚本用于通过响应信息生成QUERY环境变量以用于SOQL查询API调用。
执行SOQL查询： 查询限额： 最后将环境变量和两个请求集合导出成JSON文件，可以共享给其他人使用。</description></item><item><title>体验Salesforce API</title><link>https://mryqu.github.io/post/%E4%BD%93%E9%AA%8Csalesforce-api/</link><pubDate>Tue, 21 May 2019 06:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%93%E9%AA%8Csalesforce-api/</guid><description>继前一博文[Salesforce dataLoader一览](/post/Salesforce dataLoader一览)，这次就开始体验一把Salesforce API了。
准备工作 通过developer.salesforce.com/signup获得Salesforce开发版 确保激活了API权限
创建connected app：scnydqTest1
获取scnydqTest1的sonsumer key和secret OAuth鉴权 Salesforce的OAuth鉴权支持三种流程：
web服务器流程：适用于服务器可以保存consumer secret 用户代理流程：适用于应用无法安全保存consumer secret 用户密码流程：应用使用用户凭证直接访问 OAuth鉴权之web服务器流程 验证按照Understanding the User-Agent OAuth Authentication Flow进行。
https://login.salesforce.com/services/oauth2/authorize?response_type=code&amp;amp;client_id={scnydqTest1_appConsumerKey}&amp;amp;redirect_uri=https%3A%2F%2Flogin.salesforce.com%2Fservices%2Foauth2%2Fsuccess 鉴权：
通过跳转URL获取code：
通过code、consumer key和consumer secret获取access token：
OAuth鉴权之用户代理流程 验证按照How Are Apps Authenticated with the Web Server OAuth Authentication Flow?进行。
https://login.salesforce.com/services/oauth2/authorize?response_type=token&amp;amp;client_id={scnydqTest1_appConsumerKey}&amp;amp;redirect_uri=https%3A%2F%2Flogin.salesforce.com%2Fservices%2Foauth2%2Fsuccess 认证： 鉴权：
通过跳转URL获取access_token：
返回URL为：
https://login.salesforce.com/services/oauth2/success#access_token=00D2v000000R9tt%21AXXXXXi.&amp;amp;instance_url=https%3A%2F%2Fap15.salesforce.com&amp;amp;id=https%3A%2F%2Flogin.salesforce.com%2Fid%2F00D2XXXXXC%2F005XXXXXL&amp;amp;issued_at=1XXXXX8&amp;amp;signature=iXXXXXI%3D&amp;amp;scope=id+api&amp;amp;token_type=Bearer OAuth鉴权之用户密码流程 验证按照Understanding the Username-Password OAuth Authentication Flow进行。
REST调用 此处走一下Salesforce官方的快速入门示例。
获取Salesforce版本 关于版本的介绍详见Apex Code Versions。
使用Salesforce版本获取可用资源 使用一个资源获取可用对象列表 获取一个对象的元数据描述 获取一个对象的列信息 执行SOQL查询获取Account记录的某些指定列的值 限额 REST API与SOAP API使用相同的数据模型和标准对象。REST API遵循SOAP API的限额。</description></item><item><title>Salesforce Data Loader一览</title><link>https://mryqu.github.io/post/salesforce-dataloader%E4%B8%80%E8%A7%88/</link><pubDate>Mon, 20 May 2019 06:00:05 +0000</pubDate><guid>https://mryqu.github.io/post/salesforce-dataloader%E4%B8%80%E8%A7%88/</guid><description>最近研究一下如何从Salesforce抓取数据，所以找到了dataloader.io和dataloader这两款软件进行学习。
dataloader.io dataloader.io是salesforce AppExchange上的应用。它分为免费版、专业版和企业版。
入口
认证
授权
主界面
导出 - 浏览对象 导出 - 选择列
导出 - 设置
导出 - 运行结果邮件
Data Loader Data Loader是Salesforce开源的一款桌面版数据连接器，基于Java语言，底层依赖Force Wsc和Patner API。 Data Loader有两种登陆方式：OAuth和Password Authentication。 OAuth认证 认证 授权 登陆成功 密码认证 注：
假设用户密码为mypwd，此处要输入的密码为用户密码和下面提到的Salesforce 安全标记组合，即mypwdXXXXXXXXXXXX。 此处Salesforce登陆URL为用户所在的实例地址。如果使用沙箱的话，则使用https://test.salesforce.com。 导出 导出 - 浏览对象 导出 - 选择列
导出 - 运行
导出 - 查看结果
其他Salesforce Data Loader Jitterbit Cloud Data Loader for Salesforce
Salesforce Connector - Mule 4
参考 Data Loader Guide
Data Loader help</description></item><item><title>初探Salesforce API</title><link>https://mryqu.github.io/post/%E5%88%9D%E6%8E%A2salesforce-api/</link><pubDate>Fri, 17 May 2019 06:00:05 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%9D%E6%8E%A2salesforce-api/</guid><description>最近研究一下如何从Salesforce抓取数据，首先看了一下几个ODBC driver。
DataDirect 文档 easysoft devart cdata 怎么没有Salesforce自家的驱动，都是第三方的。
再找找看，找到了Salesforce SOAP API Developer Guide和REST API Developer Guide。
既然有了SOAP/REST API，何必再看ODBC driver了。</description></item><item><title>升级Idea IntelliJ</title><link>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7idea-intellij/</link><pubDate>Thu, 21 Feb 2019 15:30:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7idea-intellij/</guid><description>上次重装机器时，看看自己用的IntelliJ是ideaIU-2016.3.5，而可以升级的最新版本是ideaIU-2018.3.3。犹豫了一下，害怕万一将来跟公司的插件、设置冲突没法用，就没敢升级那么大，只升到ideaIU-2016.3.8而已。
结果从已有项目导入Idea，不仅报错&amp;quot;Failed to notify progress listener.&amp;quot;，而且依赖库也找不到。上网查了查才发现ideaIU-2018.2之前的版本不支持Gradle 5。
好吧，升级到ideaIU-2018.3.4了。</description></item><item><title>使用了Widnows包管理器Chocolatey</title><link>https://mryqu.github.io/post/use-chocolatey/</link><pubDate>Mon, 14 Jan 2019 18:07:31 +0000</pubDate><guid>https://mryqu.github.io/post/use-chocolatey/</guid><description>系统由于升级微软安全补丁起不来了，在IT同事的帮助下重装了系统。
然后就开始重装大量软件，看到有些软件可以用Widnows包管理器Chocolatey安装，一时轻浮，按捺不住对新事物的向往，就装了Chocolatey。
通过Chocolatey安装了Gradle，后来IntelliJ问我Gradle装哪里了，我一时就蒙了。
想想Linux下的软件都不问，为啥到Windows就不成了？估计还是Linux下包管理是主流，判断依赖软件装没装直接先问deb/apt-get。
估计Windows下用Chocolatey的太少，不但人而且软件的习惯都还没培养起来。这是我的不对，赶紧自己搜出来“C:\ProgramData\chocolatey\lib\gradle\tools\gradle-5.1.1”应付交差了。</description></item><item><title>使用Packer创建基于Ubuntu的Vagrant Box</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8packer%E5%88%9B%E5%BB%BA%E5%9F%BA%E4%BA%8Eubuntu%E7%9A%84vagrant_box/</link><pubDate>Fri, 04 Jan 2019 06:07:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8packer%E5%88%9B%E5%BB%BA%E5%9F%BA%E4%BA%8Eubuntu%E7%9A%84vagrant_box/</guid><description>前一博客创建基于Ubuntu的Vagrant Box是手工完成的，这意味着每次实施后需要写出详细文档，以便于以后查档、定位问题或者更新。
持续交付和DevOps技术的快速进步和演化，使得基础设施的配置不得不频繁变化。基础设施即代码(IaC)是一种使用新的技术来构建和管理动态基础设施的方式。它把基础设施、工具和服务以及对基础设施的管理本身作为一个软件系统，采纳软件工程实践以结构化的安全的方式来管理对系统的变更。
Packer是由HashiCorp推出的一款轻量级镜像定义工具，用于从单一配置来源为多平台创建相同的机器映像。目前支持的平台包括Alicloud ECS、Amazon EC2、Azure、CloudStack、DigitalOcean、Docker、File、Google Cloud、Hetzner Cloud、Hper-V、LXC、LXD、NAVER Cloud、1&amp;amp;1、OpenStack、Oracle、Parallels、ProfitBricks、QEMU、Scaleway、Triton、VirtualBox和VMware。
配置好一个模版文件，用pakcer命令就可以按需构建机器镜像。也可以根据需求及时更改配置。 加入软件版本控制（主要用的是 Git）后，就可以很方便的追溯更改。
尝试了用Packer模板创建Ubuntu基于VirtualBox provider的Vagrant Box，日志如下：
C:\quTemp\PackerTest&amp;gt;REM set PACKER_LOG=1 C:\quTemp\PackerTest&amp;gt;packer build -var &amp;#34;mirror=c:/quTemp&amp;#34; -var &amp;#34;mirror_directory=PackerTest&amp;#34; ubuntu-14.04-amd64.json virtualbox-iso output will be in this color. ==&amp;gt; virtualbox-iso: Retrieving Guest additions virtualbox-iso: Using file in-place: file:///C:/quTools/Oracle/VirtualBox/VBoxGuestAdditions.iso ==&amp;gt; virtualbox-iso: Retrieving ISO virtualbox-iso: Using file in-place: file:///C:/quTemp/PackerTest/ubuntu-14.04.5-server-amd64.iso ==&amp;gt; virtualbox-iso: Starting HTTP server on port 8711 ==&amp;gt; virtualbox-iso: Creating virtual machine... ==&amp;gt; virtualbox-iso: Creating hard drive... ==&amp;gt; virtualbox-iso: Creating forwarded port mapping for communicator (SSH, WinRM, etc) (host port 3620) ==&amp;gt; virtualbox-iso: Executing custom VBoxManage commands.</description></item><item><title>创建基于Ubuntu的Vagrant Box</title><link>https://mryqu.github.io/post/%E5%88%9B%E5%BB%BA%E5%9F%BA%E4%BA%8Eubuntu%E7%9A%84vagrant_box/</link><pubDate>Wed, 02 Jan 2019 06:07:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%9B%E5%BB%BA%E5%9F%BA%E4%BA%8Eubuntu%E7%9A%84vagrant_box/</guid><description>学习一下创建Ubuntu基于VirtualBox provider的Vagrant Box。
准备环境 Vagrant VirtualBox 下载Ubuntu 14.04.5 LTS (Trusty Tahr)服务器版ISO文件 创建虚拟机 创建VirtualBox VM mryqu-ubuntu 内存1024MB 创建VMDK类型、自动分配的虚拟硬盘 安装Ubuntu 点击Setting，在Storage配置页的Controller:IDE中增加CD，选择所下载的Ubuntu ISO文件。然后启动虚拟机。 安装过程除了下列项之外使用默认选择：
Configure the network - Hostname: vagrant Set up users and passwords: vagrant/vagrant Encrypt your home directory? Select No Select your time zone: UTC Partitioning method: Guided – use entire disk and set up LVM When prompted which software to install, select OpenSSH server 安装成功后，会提示进行登陆。 使用vagrant用户登陆后，使用sudo su -切到root账号，重新同步安装包索引并更新安装包。
apt-get update apt-get upgrade 为vagrant用户设置无密码sudo vagrant用户每次执行sudo命令会要求输入密码。通过visudo命令在配置文件末增加vagrant ALL=(ALL) NOPASSWD:ALL并保存即可实现无密码sudo。</description></item><item><title>博客从Hexo转向Hugo</title><link>https://mryqu.github.io/post/replace-hexo-with-hugo-for-blog/</link><pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate><guid>https://mryqu.github.io/post/replace-hexo-with-hugo-for-blog/</guid><description>起因 使用Hexo构建我的博客网站，感觉功能丰富、插件齐全，使用的不能再爽。
但是我开始把我以前的新浪博客帖子搬家，就不美了。我就搬了自己原创的部分，总共六百多个帖子，总是内存溢出。
&amp;lt;--- Last few GCs ---&amp;gt; 17611169 ms: Mark-sweep 1389.3 (1404.7) -&amp;gt; 1388.2 (1406.7) MB, 529.2 / 0.0 ms [allocation failure] [GC in old space requested]. 17611746 ms: Mark-sweep 1388.2 (1406.7) -&amp;gt; 1388.2 (1406.7) MB, 577.3 / 0.0 ms [allocation failure] [GC in old space requested]. 17612313 ms: Mark-sweep 1388.2 (1406.7) -&amp;gt; 1395.2 (1403.7) MB, 566.6 / 0.0 ms [last resort gc]. 17612859 ms: Mark-sweep 1395.2 (1403.7) -&amp;gt; 1402.</description></item><item><title>Facebook的Page Access Token</title><link>https://mryqu.github.io/post/facebook%E7%9A%84pageaccesstoken/</link><pubDate>Tue, 30 Oct 2018 06:31:53 +0000</pubDate><guid>https://mryqu.github.io/post/facebook%E7%9A%84pageaccesstoken/</guid><description>忽然发现原本可用的Facebook App Access Token无法获取Page内容的，甚至是自己的主页，错误提示为：
&amp;ldquo;(#10) To use &amp;lsquo;Page Public Content Access&amp;rsquo;, your use of this endpoint must be reviewed and approved by Facebook. To submit this &amp;lsquo;Page Public Content Access&amp;rsquo; feature for review please read our documentation on reviewable features: https://developers.facebook.com/docs/apps/review.&amp;quot;。
注：我的App yquTest当前App版本为2.8。 祭出Access Token Tool武器，开始实验User Access Token。 发现结果如下：
使用Facebook App Access Token无法读取自己或他人的主页内容 使用Facebook User Access Token可以读取自己主页内容，但无法读取他人的主页内容 Facebook Page Access Token调查 获取自己多个主页的Page Access Toke 获取自己单个主页的Page Access Toke 使用Page Access Token获取自己的主页内容 尝试获取他人主页的Page Access Token 结果自然是嘿嘿嘿。</description></item><item><title>折腾openui5-sample-app之使用Yarn替换Bower</title><link>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8yarn%E6%9B%BF%E6%8D%A2bower/</link><pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate><guid>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8yarn%E6%9B%BF%E6%8D%A2bower/</guid><description>SAP/openui5-sample-app是使用npm下载依赖的后端开发和构建模块，使用bower下载依赖的前端openui5库。 在npm install的过程中提示&amp;quot;npm WARN deprecated bower@1.8.4: We don&amp;rsquo;t recommend using Bower for new projects. Please consider Yarn and Webpack or Parcel. You can read how to migrate legacy project here: https://bower.io/blog/2017/how-to-migrate-away-from-bower/&amp;quot;。 对于SAP这个小示例，区分前端和后端使用包管理器有点浪费！对于所有的依赖模块，可以要么使用npm，要么使用yarn。
删除bower_components和dist目录
安装yarn：
npm install yarn -g 去掉bower.json 不过其中依赖的openui5/packaged-sap.ui.core、openui5/packaged-sap.m、openui5/packaged-themelib_sap_belize仅仅bower能够获取，在npm仓库里是找不到的。
修改package.json
去除bower模块 去除postinstall脚本 增加@openui5/sap.m依赖 增加@openui5/sap.ui.core依赖 增加@openui5/themelib_sap_belize依赖 修改Gruntfile.js npm仓库里的@openui5/sap.m、@openui5/sap.ui.core、@openui5/themelib_sap_belize仅包含openui5/packaged-sap.ui.core、openui5/packaged-sap.m、openui5/packaged-themelib_sap_belize中resources的部分，而不包含test-resources的部分。 对于openui5_connect任务，我认为无需test-resources部分即可。 将openui5库的定位从bower_components目录下改为node_modules目录下的相应位置 构建测试 yarn grunt build grunt serve 参考 SAP/grunt-openui5
JS新包管理工具yarn和npm的对比与使用入门</description></item><item><title>折腾openui5-sample-app之使用npm镜像</title><link>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8npm%E9%95%9C%E5%83%8F/</link><pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate><guid>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8npm%E9%95%9C%E5%83%8F/</guid><description>学习了一下SAP/openui5-sample-app，看看SAP是如何使用构建前端的。 SAP/openui5-sample-app中npm安装模块是从https://www.npmjs.com/下载的，不知道从淘宝NPM镜像下载是否会快些。
对npm使用镜像有以下几种方式，这里我使用第三种：
通过config命令 npm config set registry https://registry.npm.taobao.org npm info underscore 命令行指定 npm --registry https://registry.npm.taobao.org info underscore 在.npmrc文件中指定 registry = https://registry.npm.taobao.org 结果，速度上没什么感觉，都不快！</description></item><item><title>[Spring] LDAP用户验证笔记</title><link>https://mryqu.github.io/post/spring_ldap%E7%94%A8%E6%88%B7%E9%AA%8C%E8%AF%81%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 13 Aug 2018 10:25:53 +0000</pubDate><guid>https://mryqu.github.io/post/spring_ldap%E7%94%A8%E6%88%B7%E9%AA%8C%E8%AF%81%E7%AC%94%E8%AE%B0/</guid><description>对Spring LDAP用户验证进行了学习，制作了时序图： LDAP身份验证的步骤为：
从客户端登录页面获得用户名和密码。 匿名或使用管理DN/密码绑定到LDAP服务器，通过登录用户名查询用户DN，如失败则报用户不存在。 使用用户DN和密码再次绑定到LDAP服务器，如果能成功绑定则验证成功，否则报用户密码错误。 参考 Spring Security Architecture
Spring Security Reference
Spring Security Project
GETTING STARTED: Authenticating a User with LDAP
GitHub: spring-guides/gs-authenticating-ldap</description></item><item><title>[JS] 导出数据到CSV文件</title><link>https://mryqu.github.io/post/js_%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%88%B0csv%E6%96%87%E4%BB%B6/</link><pubDate>Thu, 09 Aug 2018 14:25:53 +0000</pubDate><guid>https://mryqu.github.io/post/js_%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%88%B0csv%E6%96%87%E4%BB%B6/</guid><description>项目有可能要在HTML客户端上导出数据到CSV文件，先找找方案。
JS/jQuery方案 Export to CSV using jQuery and html Demo for StackOverflow Answer to the question: Export to CSV using jQuery and html 使用javascript下载页面中的表格数据 Exporting data from a web browser to a csv file using javascript. OpenUI5方案 GitHub: OpenUI5 Export Test Download the Model Data to a CSV/Excel file in UI5 Export sap.ui.table.Table as CSV Export To Excel customization in UI5</description></item><item><title>新博客mryqu.github.io开张！</title><link>https://mryqu.github.io/post/readme/</link><pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate><guid>https://mryqu.github.io/post/readme/</guid><description>我目前的博客位于新浪mryqu的博客，这个算是新窝吧。</description></item><item><title>新博客诞生记</title><link>https://mryqu.github.io/post/%E6%96%B0%E5%8D%9A%E5%AE%A2%E8%AF%9E%E7%94%9F%E8%AE%B0/</link><pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%96%B0%E5%8D%9A%E5%AE%A2%E8%AF%9E%E7%94%9F%E8%AE%B0/</guid><description>在新浪博客贴代码片段诸多不爽，技术文章也时常通不过莫名其妙的关键词审查。偶尔心动，就创建了https://github.com/mryqu/mryqu.github.io，立刻新博客就出来了。 感觉有点简陋，开始琢磨theme之类的东东，然后就陷入了Jekyll、Hexo、Pelican等工具的比较纠结中，最后选定了用Node.js编写的博客框架Hexo及主题hexo-theme-next。
安装Hexo 安装Hexo的前提条件是已经安装好了Node.js和NPM：
mryqu@mryqu MINGW64 /c/quTools $ node -v v6.9.5 mryqu@mryqu MINGW64 /c/quTools $ npm -v 3.10.10 安装Hexo：
mryqu@mryqu MINGW64 /c/quTools $ mkdir hexo mryqu@mryqu MINGW64 /c/quTools $ cd hexo mryqu@mryqu MINGW64 /c/quTools/hexo npm install -g hexo-cli mryqu@mryqu MINGW64 /c/quTools/hexo npm install hexo --save 创建博客 mryqu@mryqu MINGW64 /c/users/mryqu $ hexo init blog mryqu@mryqu MINGW64 /c/users/mryqu $ cd blog mryqu@mryqu MINGW64 /c/users/mryqu/blog $ git clone https://github.com/iissnan/hexo-theme-next themes/next mryqu@mryqu MINGW64 /c/users/mryqu/blog $ cd themes/next mryqu@mryqu MINGW64 /c/users/mryqu/blog/themes/next $ git tag -l mryqu@mryqu MINGW64 /c/users/mryqu/blog/themes/next $ git checkout tags/v5.</description></item><item><title>[Vagrant]学习VBoxManage定制</title><link>https://mryqu.github.io/post/vagrant_%E5%AD%A6%E4%B9%A0vboxmanage%E5%AE%9A%E5%88%B6/</link><pubDate>Thu, 26 Jul 2018 05:56:21 +0000</pubDate><guid>https://mryqu.github.io/post/vagrant_%E5%AD%A6%E4%B9%A0vboxmanage%E5%AE%9A%E5%88%B6/</guid><description>Vagrant Configuration - VBoxManage Customizations里面有讲到通过VBoxManage修改VirtualBox虚拟机。而VBoxManage modifyvm里面细致的介绍了所有设置。
VBoxManage modifyvm设置 接触过的VBoxManage modifyvm设置 下面就仔细研究一下我看到过的modifyvm设置：
# -*- mode: ruby -*- # vi: set ft=ruby : VAGRANTFILE_API_VERSION = &amp;#34;2&amp;#34; Vagrant.require_version &amp;#34;&amp;gt;= 1.6.3&amp;#34; Vagrant.configure(VAGRANTFILE_API_VERSION) do |config| config.vm.provider &amp;#34;virtualbox&amp;#34; do |vb| # --memory设置用来指定分配的内存，单位为MB # 可简写为vb.memory=8192 vb.customize [&amp;#39;modifyvm&amp;#39;, :id, &amp;#39;--memory&amp;#39;, &amp;#39;8192&amp;#39;] # --cpus设置用来指定虚拟机的虚拟CPU个数 # 可简写为vb.cpus=3 vb.customize [&amp;#39;modifyvm&amp;#39;, :id, &amp;#39;--cpus&amp;#39;, &amp;#39;3&amp;#39;] # --cpuexecutioncap &amp;lt;1-100&amp;gt;设置用来指定虚拟CPU可用的CPU时间比例。 # 值50意味无论VM使用多少个虚拟虚拟CPU，都不会超过宿主机CPU时间的一半。 vb.customize [&amp;#39;modifyvm&amp;#39;, :id, &amp;#39;--cpuexecutioncap&amp;#39;, &amp;#39;75&amp;#39;] # --natdnshostresolver&amp;lt;1-N&amp;gt; on|off用来指定NAT使用宿主机的解析机制处理DNS请求。 vb.customize [&amp;#39;modifyvm&amp;#39;, :id, &amp;#39;--natdnshostresolver1&amp;#39;, &amp;#39;on&amp;#39;] # --natdnsproxy&amp;lt;1-N&amp;gt; on|off用来指定NAT将所有客户机DNS请求代理到宿主机的DNS服务器。 vb.</description></item><item><title>[Vagrant] 学习一下Vagrant的Provider类型</title><link>https://mryqu.github.io/post/vagrant_%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%8Bvagrant%E7%9A%84provider%E7%B1%BB%E5%9E%8B/</link><pubDate>Wed, 25 Jul 2018 06:05:44 +0000</pubDate><guid>https://mryqu.github.io/post/vagrant_%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%8Bvagrant%E7%9A%84provider%E7%B1%BB%E5%9E%8B/</guid><description>偶尔动了心思，想自己装一个Wiki。就按照MediaWiki-Vagrant，装一个Vagrant版的MediaWiki玩玩。MediaWiki全球最著名的开源wiki程序，运行于PHP+MySQL环境。MediaWiki从2002年2月25日被作为维基百科全书的系统软件，并有大量其他应用实例。 顺手研究了一下mediawiki/vagrant项目的Vagrantfile文件，跟我们自己项目用的Vagrantfile仅仅配置了一个VirtualBox provider不同，它配置了VirtualBox、VMWare Fusion、Microsoft Hyper-V、LXC、Parallels和libvirt (KVM/QEMU)六种provider。 在Vagrant的网站上仅仅提及了默认的VirtualBox、VMware、Docker、Hyper-V四款provider。那到底Vagrant有多少provider类型呢？ 从Vagrant Cloud上可知有22种provider类型的Vagrant box镜像可供下载：
aws cloudstack digitalocean docker google hyperv libvirt lxc openstack parallels qemu rackspace softlayer veertu virtualbox vmware vmware_desktop vmware_fusion vmware_ovf vmware_workstation vsphere xenserver</description></item><item><title>[Spark] 使用Spark的REST服务Livy</title><link>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark%E7%9A%84rest%E6%9C%8D%E5%8A%A1livy/</link><pubDate>Tue, 17 Jul 2018 06:09:41 +0000</pubDate><guid>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark%E7%9A%84rest%E6%9C%8D%E5%8A%A1livy/</guid><description>Apache Livy简介 Apache Livy是由Cloudera Labs贡献的基于Apache Spark的开源REST服务，它不仅以REST的方式代替了Spark传统的处理交互方式，同时也提供企业应用中不可忽视的多用户，安全，以及容错的支持。其功能如下：- 拥有可用于多Spark作业或多客户端长时间运行的SparkContext；
同时管理多个SparkContext，并在集群（YARN / Mesos）而不是Livy服务器上运行它们，以实现良好的容错性和并发性； 可以通过预先编译好的JAR、代码片段或是java/scala客户端API将Spark作业提交到远端的Spark集群上执行。 建立测试环境 今天在GitHub: mryqu/vagrant-hadoop-hive-spark提交了add livy support，因此可以在Vagrant搭建的Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0虚拟机环境中使用Livy 0.5.0服务。 使用Livy的REST API 创建交互式会话 curl -X POST -d &amp;#39;{&amp;#34;kind&amp;#34;: &amp;#34;spark&amp;#34;}&amp;#39; -H &amp;#34;Content-Type: application/json&amp;#34; http://10.211.55.101:8998/sessions { &amp;#34;id&amp;#34;:0, &amp;#34;appId&amp;#34;:null, &amp;#34;owner&amp;#34;:null, &amp;#34;proxyUser&amp;#34;:null, &amp;#34;state&amp;#34;:&amp;#34;starting&amp;#34;, &amp;#34;kind&amp;#34;:&amp;#34;spark&amp;#34;, &amp;#34;appInfo&amp;#34;:{ &amp;#34;driverLogUrl&amp;#34;:null, &amp;#34;sparkUiUrl&amp;#34;:null }, &amp;#34;log&amp;#34;:[ &amp;#34;stdout: &amp;#34;, &amp;#34; stderr: &amp;#34; ] } 成功创建会话0，kind指定为spark，如果之后提交的代码中没有指定kind，则使用此处的会话默认kind。
查询交互式会话列表 curl http://10.211.55.101:8998/sessions { &amp;#34;from&amp;#34;:0, &amp;#34;total&amp;#34;:1, &amp;#34;sessions&amp;#34;:[ { &amp;#34;id&amp;#34;:0, &amp;#34;appId&amp;#34;:null, &amp;#34;owner&amp;#34;:null, &amp;#34;proxyUser&amp;#34;:null, &amp;#34;state&amp;#34;:&amp;#34;idle&amp;#34;, &amp;#34;kind&amp;#34;:&amp;#34;spark&amp;#34;, &amp;#34;appInfo&amp;#34;:{ &amp;#34;driverLogUrl&amp;#34;:null, &amp;#34;sparkUiUrl&amp;#34;:null }, &amp;#34;log&amp;#34;:[ &amp;#34;2018-07-18 03:19:16 INFO BlockManager:54 - Using org.</description></item><item><title>[Spark] SparkCatalogAPI使用</title><link>https://mryqu.github.io/post/spark_sparkcatalogapi%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 16 Jul 2018 06:12:39 +0000</pubDate><guid>https://mryqu.github.io/post/spark_sparkcatalogapi%E4%BD%BF%E7%94%A8/</guid><description>Catalog API简介 Spark中的DataSet和Dataframe API支持结构化分析。结构化分析的一个重要的方面是管理元数据。这些元数据可能是一些临时元数据（比如临时表）、SQLContext上注册的UDF以及持久化的元数据（比如Hivemeta store或者HCatalog）。 Spark2中添加了标准的API（称为catalog）来访问Spark SQL中的元数据。这个API既可以操作Spark SQL，也可以操作Hive元数据。
Catalog API使用 查询数据库 scala&amp;gt; spark.catalog.listDatabases.show(false) +-------+---------------------+----------------------------------------+ |name |description |locationUri | +-------+---------------------+----------------------------------------+ |default|Default Hive database|hdfs://10.211.55.101/user/hive/warehouse| +-------+---------------------+----------------------------------------+ scala&amp;gt; spark.catalog.currentDatabase res4: String = default 查询表 scala&amp;gt; spark.catalog.listTables.show(false) +----+--------+----------------------------------------+---------+-----------+ |name|database|description |tableType|isTemporary| +----+--------+----------------------------------------+---------+-----------+ |emp |default |null |MANAGED |false | |emp2|default |Imported by sqoop on 2018/07/10 04:23:26|MANAGED |false | |emp3|default |Imported by sqoop on 2018/07/10 06:13:17|MANAGED |false | |yqu1|default |null |MANAGED |false | |yqu2|default |null |MANAGED |false | +----+--------+----------------------------------------+---------+-----------+ 下面的示例用于创建不同TableType的表：</description></item><item><title>[Oozie] 遭遇ShareLib无法找到的问题</title><link>https://mryqu.github.io/post/oozie_%E9%81%AD%E9%81%87sharelib%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</link><pubDate>Fri, 13 Jul 2018 05:40:09 +0000</pubDate><guid>https://mryqu.github.io/post/oozie_%E9%81%AD%E9%81%87sharelib%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</guid><description>折腾几天，终于装好了Oozie 5.0.0，并且启动了Oozie守护进程。
vagrant@node1:~$ oozie admin -oozie http://10.211.55.101:11000/oozie -status log4j:WARN No appenders could be found for logger (org.apache.hadoop.security.authentication.client.KerberosAuthenticator). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. System mode: NORMAL 不过运行MapReduce demo总是出错，找不到Oozie的共享库，日志如下：
2018-07-12 04:45:50,228 WARN ActionStartXCommand:523 - SERVER[node1] USER[vagrant] GROUP[-] TOKEN[] APP[map-reduce-wf] JOB[0000001-XXXXXXXXXXXXXXX-oozie-root-W] ACTION[0000001-XXXXXXXXXXXXXXX-oozie-root-W@mr-node] Error starting action [mr-node]. ErrorType [FAILED], ErrorCode [It should never happen], Message [File /user/root/share/lib does not exist] org.apache.oozie.action.ActionExecutorException: File /user/root/share/lib does not exist at org.</description></item><item><title>[Spark] Spark读取HBase</title><link>https://mryqu.github.io/post/spark_spark%E8%AF%BB%E5%8F%96hbase/</link><pubDate>Thu, 12 Jul 2018 05:40:01 +0000</pubDate><guid>https://mryqu.github.io/post/spark_spark%E8%AF%BB%E5%8F%96hbase/</guid><description>Spark读取Hbase有以下几张方式：
Spark的JavaSparkContext.newAPIHadoopRDD / SparkContext.newAPIHadoopRDD方法 HBase的hbase-spark Hortonworks的Spark HBase Connector Cloudera labs的SparkOnHBase 本文就Spark自带的方法进行示范和演示。 HBase数据库 Spark范例 HelloSparkHBase.java import org.apache.spark.SparkContext; import org.apache.spark.api.java.JavaPairRDD; import org.apache.spark.api.java.JavaRDD; import org.apache.spark.api.java.JavaSparkContext; import org.apache.spark.sql.Dataset; import org.apache.spark.sql.Row; import org.apache.spark.sql.SparkSession; import org.apache.spark.api.java.function.Function; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.hbase.HBaseConfiguration; import org.apache.hadoop.hbase.TableName; import org.apache.hadoop.hbase.client.*; import org.apache.hadoop.hbase.mapreduce.TableInputFormat; import org.apache.hadoop.hbase.io.ImmutableBytesWritable; import org.apache.hadoop.hbase.util.Bytes; import scala.Tuple2; public class HelloSparkHBase { public static void main(String[] args) { try { Configuration conf = HBaseConfiguration.create(); conf.set(TableInputFormat.INPUT_TABLE, &amp;#34;student&amp;#34;); SparkSession spark = SparkSession .builder() .appName(&amp;#34; .</description></item><item><title>[Sqoop]尝试Sqoop</title><link>https://mryqu.github.io/post/sqoop_%E5%B0%9D%E8%AF%95sqoop/</link><pubDate>Wed, 11 Jul 2018 05:44:19 +0000</pubDate><guid>https://mryqu.github.io/post/sqoop_%E5%B0%9D%E8%AF%95sqoop/</guid><description>Sqoop简介 Apache Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(HDFS、Hive、HBase、Accumulo)与关系型数据库(MySQL、PostgreSQL、Oracle、Microsoft SQL、Netezza)间进行数据传输，例如可以将一个关系型数据库中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。
测试环境 在我使用GitHub: martinprobson/vagrant-hadoop-hive-spark通过Vagrant搭建的Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0虚拟机环境中已经安装了Sqoop，正好可以尝试一下。
使用 help命令 vagrant@node1:~$ sqoop help Warning: /usr/local/sqoop/../hbase does not exist! HBase imports will fail. Please set $HBASE_HOME to the root of your HBase installation. Warning: /usr/local/sqoop/../accumulo does not exist! Accumulo imports will fail. Please set $ACCUMULO_HOME to the root of your Accumulo installation. Warning: /usr/local/sqoop/../zookeeper does not exist! Accumulo imports will fail. Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.</description></item><item><title>[Zeppelin] 尝试Zeppelin</title><link>https://mryqu.github.io/post/zeppelin_%E5%B0%9D%E8%AF%95zeppelin/</link><pubDate>Tue, 10 Jul 2018 05:50:35 +0000</pubDate><guid>https://mryqu.github.io/post/zeppelin_%E5%B0%9D%E8%AF%95zeppelin/</guid><description>Zeppelin简介 Apache Zeppelin是一个让交互式数据分析变得可行的基于网页的开源框架。Zeppelin提供了数据捏取、发现、分析、可视化与协作等功能。 Zeppelin 是一个提供交互数据分析且基于Web的笔记本。方便你做出可数据驱动的、可交互且可协作的精美文档，并且支持多种语言，包括 Scala(使用 Apache Spark)、Python(Apache Spark)、SparkSQL、 Hive、 Markdown、Shell等等。
试验环境搭建 跟之前的博文[Spark] 使用Spark2.30读写Hive2.3.3一样，本文的环境继续使用GitHub: martinprobson/vagrant-hadoop-hive-spark通过Vagrant搭建了一个Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0的虚拟机环境。不过当前scripts/common.sh中ZEPPELIN_VERSION=0.7.2，而Zeppelin 0.7.2已不可访问，需要改成最新版0.8.0。 按照GitHub: martinprobson/vagrant-hadoop-hive-spark说明执行zeppelin-daemon.sh start，结果说权限不足，因此我只好兜一圈开启Zeppelin守护进程。
vagrant@node1:~$ zeppelin-daemon.sh start find: File system loop detected; ‘/home/ubuntu/zeppelin/zeppelin-0.8.0-bin-netinst’ is part of the same file system loop as ‘/home/ubuntu/zeppelin’. Pid dir doesn&amp;#39;t exist, create /home/ubuntu/zeppelin/run mkdir: cannot create directory ‘/home/ubuntu/zeppelin/run’: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.sh: line 187: /home/ubuntu/zeppelin/logs/zeppelin-vagrant-node1.out: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.sh: line 189: /home/ubuntu/zeppelin/logs/zeppelin-vagrant-node1.out: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.</description></item><item><title>[Oozie] Oozie构建问题</title><link>https://mryqu.github.io/post/oozie_oozie%E6%9E%84%E5%BB%BA%E9%97%AE%E9%A2%98/</link><pubDate>Thu, 05 Jul 2018 06:20:10 +0000</pubDate><guid>https://mryqu.github.io/post/oozie_oozie%E6%9E%84%E5%BB%BA%E9%97%AE%E9%A2%98/</guid><description>想定制Oozie构建，结果log4j总出错，移除了pig、sqoop和hive就好了。
root@node1:~# /vagrant/resources/oozie-5.0.0/bin/mkdistro.sh -DskipTests -Puber -Dhadoop.version=2.7.6 -Ptez -Dpig.version=0.17.0 -Dsqoop.version=1.4.7 -Dhive.version=2.3.3 -Dtez.version=0.9.1 ...... [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.7.0:testCompile (default-testCompile) on project oozie-core: Compilation failure: Compilation failure: [ERROR] /vagrant/resources/oozie-5.0.0/core/src/test/java/org/apache/oozie/sla/TestSLACalculatorMemory.java:[836,48] cannot find symbol [ERROR] symbol: method getLevel() [ERROR] location: variable firstLogEntry of type org.apache.log4j.spi.LoggingEvent [ERROR] /vagrant/resources/oozie-5.0.0/core/src/test/java/org/apache/oozie/sla/TestSLACalculatorMemory.java:[837,33] cannot find symbol [ERROR] symbol: method getMessage() [ERROR] location: variable firstLogEntry of type org.apache.log4j.spi.LoggingEvent [ERROR] /vagrant/resources/oozie-5.0.0/core/src/test/java/org/apache/oozie/sla/TestSLACalculatorMemory.java:[838,79] cannot find symbol [ERROR] symbol: method getLoggerName() [ERROR] location: variable firstLogEntry of type org.</description></item><item><title>[Spark] 使用Spark2.30读写MySQL</title><link>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99mysql/</link><pubDate>Wed, 04 Jul 2018 06:36:25 +0000</pubDate><guid>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99mysql/</guid><description>本博文是[Spark] 使用Spark2.30读写Hive2.3.3的姊妹篇，环境及Java项目也是使用上一博文中的。
Spark项目 目录结构 vagrant@node1:~/HelloSparkHive$ ls build build.gradle src vagrant@node1:~/HelloSparkHive$ rm -rf build vagrant@node1:~/HelloSparkHive$ tree . ├── build.gradle └── src └── main └── java └── com └── yqu └── sparkhive ├── HelloSparkHiveDriver.java └── HelloSparkMysqlDriver.java 6 directories, 3 files src/main/java/com/yqu/sparkhive/HelloSparkMysqlDriver.java 该范例加载Hive中的emp表，存储到MySQL的test数据库中，然后读取MySQL数据库加载emp表，由此完成MySQL读写示例。
package com.yqu.sparkhive; import org.apache.spark.sql.Dataset; import org.apache.spark.sql.Row; import org.apache.spark.sql.SparkSession; import java.io.File; import java.sql.*; public class HelloSparkMysqlDriver { private static boolean setup() { Connection conn = null; Statement stmt = null; try { Class.</description></item><item><title>[Spark] 使用Spark2.30读写Hive2.3.3</title><link>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99hive2.3.3/</link><pubDate>Tue, 03 Jul 2018 06:04:31 +0000</pubDate><guid>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99hive2.3.3/</guid><description>试验环境搭建 安装Spark环境 犯懒，直接使用GitHub: martinprobson/vagrant-hadoop-hive-spark通过Vagrant搭建了一个Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0的虚拟机环境。
在Hive上加载emp表 hive&amp;gt; create table emp (empno int, ename string, job string, mgr int, hiredate string, salary double, comm double, deptno int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &amp;#39;|&amp;#39; ; hive&amp;gt; LOAD DATA LOCAL INPATH &amp;#39;/usr/local/hive/examples/files/emp2.txt&amp;#39; OVERWRITE INTO TABLE emp; 安装Gradle 按照Gradle用户手册中的方式手工安装Gradle：
vagrant@node1:~$ export GRADLE_HOME=/opt/gradle/gradle-4.8.1 vagrant@node1:~$ export PATH=$PATH:$GRADLE_HOME/bin vagrant@node1:~$ gradle -v Welcome to Gradle 4.8.1! Here are the highlights of this release: - Dependency locking - Maven Publish and Ivy Publish plugins improved and marked stable - Incremental annotation processing enhancements - APIs to configure tasks at creation time For more details see https://docs.</description></item><item><title>[AWS] 安装AWSCLI</title><link>https://mryqu.github.io/post/aws_%E5%AE%89%E8%A3%85awscli/</link><pubDate>Mon, 02 Jul 2018 05:40:10 +0000</pubDate><guid>https://mryqu.github.io/post/aws_%E5%AE%89%E8%A3%85awscli/</guid><description>想玩玩AWS CLI，就从https://aws.amazon.com/cli/装了一个，但是一执行就是出LookupError: unknown encoding: cp65001错误，查了一下据说是Python2.7导致的。 首先去https://www.python.org/下载了最新的Python3.7.0。然后重新安装AWS CLI，依旧出错，只好卸载。 查看是否安装pip，结果发现没有。根据https://packaging.python.org/tutorials/installing-packages/中的提示下载了get-pip.py，执行python get-pip.py，成功安装好pip。
C:\&amp;gt;pip --version pip 10.0.1 from c:\users\mryqu\appdata\local\programs\python\python37-32\lib\site-packages\pip (python 3.7 最后使用pip安装AWS CLI:
C:\&amp;gt;pip install awscli Collecting awscli Downloading https://files.pythonhosted.org/packages/1b/1b/7446d52820533164965f7e7d08cee70b170c78fbbcbd0c7a11ccb9187be6/awscli-1.15.49-py2.py3-none-any.whl (1.3MB) 100% |████████████████████████████████| 1.3MB 6.6MB/s Collecting docutils&amp;gt;=0.10 (from awscli) Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB) 100% |████████████████████████████████| 552kB 3.3MB/s Collecting s3transfer&amp;lt;0.2.0,&amp;gt;=0.1.12 (from awscli) Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB 100% |████████████████████████████████| 61kB 787kB/s Collecting botocore==1.10.48 (from awscli) Downloading https://files.pythonhosted.org/packages/0b/56/44067a8f0cae5f33007e7cbdbaac67cbd9fa598c733ad25eb8f252288fe9/botocore-1.10.48-py2.py3-none-any.whl (4.4MB 100% |████████████████████████████████| 4.4MB 6.6MB/s Collecting PyYAML&amp;lt;=3.12,&amp;gt;=3.10 (from awscli) Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB) 100% |████████████████████████████████| 256kB 6.</description></item><item><title>使用Consul DNS接口</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8consuldns%E6%8E%A5%E5%8F%A3/</link><pubDate>Thu, 21 Jun 2018 06:08:53 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8consuldns%E6%8E%A5%E5%8F%A3/</guid><description>Consul提供了两个查询接口：HTTP和DNS。DNS接口允许应用程序在没有与consul高度集成的情况下使用服务发现。 以下面这个小Consul集群为例：
root@consul:/# /usr/bin/consul members Node Address Status Type Build Protocol DC configuration 172.17.0.7:8301 alive client X.Y.Z 2 dc1 consul 172.17.0.2:8301 alive server X.Y.Z 2 dc1 httpd 172.17.0.4:8301 alive client X.Y.Z 2 dc1 logon 172.17.0.8:8301 alive client X.Y.Z 2 dc1 postgres 172.17.0.3:8301 alive client X.Y.Z 2 dc1 rabbitmq 172.17.0.6:8301 alive client X.Y.Z 2 dc1 可以通过DNS接口以&amp;lt;dnode&amp;gt;.node[.datacenter].&amp;lt;domain&amp;gt;的形式查询节点地址，也可以[tag.]&amp;lt;dservice&amp;gt;.service[.datacenter].&amp;lt;domain&amp;gt;的形式查询服务地址。
root@httpd:/# dig @127.0.0.1 -p53 postgres.node.consul ANY ; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.5-9-Debian &amp;lt;&amp;lt;&amp;gt;&amp;gt; @127.0.0.1 -p53 postgres.node.consul ANY ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 57064 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;postgres.</description></item><item><title>Vagrant折腾记</title><link>https://mryqu.github.io/post/vagrant%E6%8A%98%E8%85%BE%E8%AE%B0/</link><pubDate>Tue, 19 Jun 2018 05:59:52 +0000</pubDate><guid>https://mryqu.github.io/post/vagrant%E6%8A%98%E8%85%BE%E8%AE%B0/</guid><description>自从用了OpenStack，真是很久没玩Vagrant。偶尔想用用，问题不断，废了一点功夫才解决。
遭遇VBoxManage.exe: error $ vagrant up Bringing machine &amp;#39;xdevimg&amp;#39; up with &amp;#39;virtualbox&amp;#39; provider... ==&amp;gt; xdevimg: Checking if box &amp;#39;devimage-ubuntu&amp;#39; is up to date... ==&amp;gt; xdevimg: A newer version of the box &amp;#39;devimage-ubuntu&amp;#39; is available! You currently ==&amp;gt; xdevimg: have version &amp;#39;0.13.0&amp;#39;. The latest is version &amp;#39;0.13.2&amp;#39;. Run ==&amp;gt; xdevimg: `vagrant box update` to update. ==&amp;gt; xdevimg: Clearing any previously set forwarded ports... ==&amp;gt; xdevimg: Clearing any previously set network interfaces... ==&amp;gt; xdevimg: Preparing network interfaces based on configuration.</description></item><item><title>服务发现产品对比</title><link>https://mryqu.github.io/post/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%BA%A7%E5%93%81%E5%AF%B9%E6%AF%94/</link><pubDate>Tue, 29 May 2018 05:56:16 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%BA%A7%E5%93%81%E5%AF%B9%E6%AF%94/</guid><description>首先就一些常见的服务发现产品进行下对比:
对比项[Consul](https://www.consul.io/) [GitHub](https://github.com/hashicorp/consul)[Zookeeper](https://zookeeper.apache.org/) [GitHub](https://github.com/apache/zookeeper)[Etcd](https://coreos.com/etcd/) [GitHub](https://github.com/coreos/etcd)Euerka [GitHub](https://github.com/Netflix/eureka)[Kubernetes](https://kubernetes.io/) [GitHub](https://github.com/kubernetes/kubernetes)**服务健康检查**[客户端可绑定 任意多个服务或 节点健康检查 (内存、磁盘)](https://www.consul.io/intro/index.html)[CS之间长连接 +连接心跳](http://zookeeper.apache.org/doc/current/zookeeperOver.html); [SS之间TCP KeepAlive](http://zookeeper.apache.org/doc/current/zookeeperAdmin.html)[连接心跳](https://coreos.com/etcd/docs/latest/tuning.html)[连接心跳注册、 其他可配支持](http://cloud.spring.io/spring-cloud-netflix/single/spring-cloud-netflix.html#_eureka_s_health_checks)**多数据中心**[内置WAN方案支持](https://www.consul.io/docs/internals/architecture.html)[中央Zookeeper集群, 通过Observer有限支持](https://zookeeper.apache.org/doc/current/zookeeperObservers.html)————**KV存储限制**上百MB上百MB （有时支持上GB）上GB——**线性化读取 原子读取**[是](https://www.consul.io/docs/agent/http.html#consistency)否[是](https://coreos.com/etcd/docs/latest/learning/api_guarantees.html#linearizability)——**事务**[字段比较、 锁、读、写](https://www.consul.io/api/txn.html)[版本审查、 写](https://zookeeper.apache.org/doc/current/api/org/apache/zookeeper/ZooKeeper.html#multi-java.lang.Iterable-)[字段比较、 读、写](https://coreos.com/etcd/docs/latest/learning/api.html#transaction)——**多版本并发控制 MVCC**————[支持](https://coreos.com/etcd/docs/latest/learning/data_model.html)——**watch支持/ 变化通知**[针对KV对、键前缀、 服务成员、服务实例、 节点列表、健康检查、 自定义用户事件等](https://www.consul.io/docs/agent/watches.html)[针对当前KV或目录; 单次](http://zookeeper.apache.org/doc/current/zookeeperProgrammers.html#ch_zkWatches)[针对过去或当前的键区间](https://coreos.com/etcd/docs/latest/learning/api.html#watch-streams)[针对app、 vipAddress 或实例](https://github.com/Netflix/eureka/wiki/Eureka-2.0-Client-Configuration-And-Use#using-the-interest-client)**一致性协议**[Raft](https://www.consul.io/docs/internals/consensus.html)[Zab（≈Paxos）](https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos)[Raft](https://github.com/coreos/etcd)——**CAP**[CP](https://www.consul.io/intro/vs/serf.html)[CP](https://www.elastic.co/blog/found-zookeeper-king-of-coordination)CP[AP](https://github.com/Netflix/eureka/wiki/Eureka-2.0-Architecture-Overview#cap-theorem)**成员动态更新**[支持](https://www.consul.io/docs/guides/servers.html)[>3.5.0](https://cwiki.apache.org/confluence/display/ZOOKEEPER/ClusterMembership)[支持](https://coreos.com/etcd/docs/latest/op-guide/runtime-configuration.html)[支持](https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance#configurability)**支持接口**[HTTP](https://www.consul.io/api/index.html)和[DNS](https://www.consul.io/docs/agent/dns.html)[客户端](https://cwiki.apache.org/confluence/display/ZOOKEEPER/ZKClientBindings)[HTTP](https://coreos.com/etcd/docs/latest/dev-guide/api_grpc_gateway.html)和gRPC[HTTP](https://github.com/Netflix/eureka/wiki/Eureka-REST-operations) ([Sidecar](https://cloud.spring.io/spring-cloud-netflix/multi/multi__polyglot_support_with_sidecar.html))**性能指标监控**[Metrics](https://www.consul.io/docs/agent/telemetry.html)—— (可通过[命令行](http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_zkCommands) 或[JMX](http://zookeeper.apache.org/doc/current/zookeeperJMX.html)监控， 但没有Metrics)[Metrics](https://coreos.com/etcd/docs/latest/metrics.html)[Metrics](https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/util/EurekaMonitors.java)**用户权限**[ACLs](https://www.consul.io/docs/guides/acl.html)[ACLs](https://zookeeper.apache.org/doc/current/zookeeperProgrammers.html#sc_ZooKeeperAccessControl)[基于Role](https://coreos.com/etcd/docs/latest/op-guide/authentication.html)——**安全**[TLS](https://www.consul.io/docs/agent/encryption.html) / [HTTPS](https://www.consul.io/docs/agent/encryption.html)[SSL](https://cwiki.apache.org/confluence/display/ZOOKEEPER/ZooKeeper+SSL+User+Guide)[TLS](https://coreos.com/etcd/docs/latest/op-guide/security.html) / [HTTPS](https://coreos.com/etcd/docs/latest/etcd-live-http-to-https-migration.html)[HTTPS](http://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.0.0.RC2/single/spring-cloud-netflix.html#_registering_a_secure_application)**Web管理界面**[支持](https://www.consul.io/intro/getting-started/ui.html)支持—— （有第三方支持， 例如soyking/e3w）[支持](https://github.com/Netflix/eureka-ui)**Spring Cloud集成**[Spring Cloud Consul](https://cloud.spring.io/spring-cloud-consul/)[Spring Cloud Zookeeper](https://cloud.spring.io/spring-cloud-zookeeper/)[Spring Cloud Etcd](https://github.com/spring-cloud-incubator/spring-cloud-etcd) （孵化状态）[Spring Cloud Netflix](https://cloud.spring.io/spring-cloud-netflix/)[Spring Cloud Kubernetes](https://github.com/spring-cloud-incubator/spring-cloud-kubernetes) （孵化状态）**实现语言**[Go](https://github.com/hashicorp/consul)[Java](https://github.com/apache/zookeeper)[Go](https://github.com/coreos/etcd)[Java](https://github.com/Netflix/eureka)[Go](https://github.com/kubernetes/kubernetes)**用户**未提及[用户列表](https://cwiki.apache.org/confluence/display/ZOOKEEPER/PoweredBy)[用户列表](https://github.com/coreos/etcd/blob/master/Documentation/production-users.md)除了Netflix自用 未提及其他用户[合作方列表](https://kubernetes.io/partners/) 此外，Airbnb开源了由Ruby语言实现的自动服务发现和注册框架SmartStack，它由nerve、 synapse、Zookeeper和HAProxy组成。ZooKeeper负责维护集群状态；nerve负责针对服务进行健康检查及向Zookeeper注册；synapse负责为服务提供者查询Zookeeper并动态配置HAProxy。客户端与HAProxy交互，HAProxy负责健康检查及在针对服务提供者进行负载均衡。 注：对Kubernetes的对比在后继学习之后再补上。
参考 Consul vs. ZooKeeper, doozerd, etcd
Consul vs. SmartStack
Consul vs. Eureka
etcd versus other key-value stores</description></item><item><title>[AWS] 学习AWS上SAS联合账户的使用</title><link>https://mryqu.github.io/post/aws_%E5%AD%A6%E4%B9%A0aws%E4%B8%8Asas%E8%81%94%E5%90%88%E8%B4%A6%E6%88%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 18 Apr 2018 06:11:04 +0000</pubDate><guid>https://mryqu.github.io/post/aws_%E5%AD%A6%E4%B9%A0aws%E4%B8%8Asas%E8%81%94%E5%90%88%E8%B4%A6%E6%88%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>今天顺利学完《SAS Federated Accounts on Amazon Web Services》课程，测验全都答/蒙对了。
创建了EC2实例。
第一次用MobaXterm。相对Putty，省了将.pem SSH密钥通过PuTTYgen工具转换成.ppk格式这一步操作。 在/etc/resolv.conf文件中增加了几个nameserver以指定单位的DNS，在search项增加了多个域名以解析单位的机器名。 安装libXext.x86_64、libXp.x86_64、libXtst.x86_64、xorg-x11-xauth.x86_64、xorg-x11-apps等包以支持图形显示。</description></item><item><title>使用Fetch_API</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8fetch_api/</link><pubDate>Fri, 09 Mar 2018 05:50:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8fetch_api/</guid><description>今天又学了一招在Chrome developer tool中通过Fetch_API发起HTTP请求。 代码示例：
fetch(&amp;#39;https://jsonplaceholder.typicode.com/posts/1&amp;#39;) .then(response =&amp;gt; response.json()) .then(json =&amp;gt; console.log(json))</description></item><item><title>安装Twurl并调试extended tweet mode</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8twurl%E8%B0%83%E8%AF%95extended_tweet_mode/</link><pubDate>Thu, 08 Feb 2018 13:55:35 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8twurl%E8%B0%83%E8%AF%95extended_tweet_mode/</guid><description>在研究tweet字节限制由140字节变为280字节时，想要玩一玩Twitter API控制台工具(https://dev.twitter.com/rest/tools/console)，结果dev.twitter.com跳到了developer.twitter.com，这才发现Twitter REST API按照Standard、Premium和Enterprise划分开始走上收费的道路。 Twitter API控制台工具已经找不到了，官方示例使用twurl命令工具完成的。
安装Twurl 在https://rubyinstaller.org/下载并安装RubyInstaller 执行gem install twurl 调试extended tweet mode 准备环境 认证 twurl authorize --consumer-key key --consumer-secret secret 搜索tweet twurl &amp;#34;/1.1/search/tweets.json?q=scnydq&amp;#34; { &amp;#34;statuses&amp;#34;: [ { &amp;#34;created_at&amp;#34;: &amp;#34;Thu Feb 08 02:22:11 +0000 2018&amp;#34;, &amp;#34;id&amp;#34;: 9.6142489253621e+17, &amp;#34;id_str&amp;#34;: &amp;#34;961424892536205313&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;scnydq.testbody280:001002003004005006007008009010011012013014015016017018019020021022023024025026027028029030031032\u2026 https:\/\/t.co\/q9CyeceQku&amp;#34;, &amp;#34;truncated&amp;#34;: true, &amp;#34;entities&amp;#34;: { &amp;#34;hashtags&amp;#34;: [ ], &amp;#34;symbols&amp;#34;: [ ], &amp;#34;user_mentions&amp;#34;: [ ], &amp;#34;urls&amp;#34;: [ { &amp;#34;url&amp;#34;: &amp;#34;https:\/\/t.co\/q9CyeceQku&amp;#34;, &amp;#34;expanded_url&amp;#34;: &amp;#34;https:\/\/twitter.com\/i\/web\/status\/961424892536205313&amp;#34;, &amp;#34;display_url&amp;#34;: &amp;#34;twitter.com\/i\/web\/status\/9\u2026&amp;#34;, &amp;#34;indices&amp;#34;: [ 117, 140 ] } ] }, &amp;#34;metadata&amp;#34;: { &amp;#34;iso_language_code&amp;#34;: &amp;#34;en&amp;#34;, &amp;#34;result_type&amp;#34;: &amp;#34;recent&amp;#34; }, &amp;#34;source&amp;#34;: &amp;#34;&amp;lt;a href=\&amp;#34;http:\/\/twitter.</description></item><item><title>[JS] 通过升级npm解决了error TS2322和TS2307</title><link>https://mryqu.github.io/post/js_%E9%80%9A%E8%BF%87%E5%8D%87%E7%BA%A7npm%E8%A7%A3%E5%86%B3%E4%BA%86error_ts2322%E5%92%8Cts2307/</link><pubDate>Sun, 28 Jan 2018 05:48:25 +0000</pubDate><guid>https://mryqu.github.io/post/js_%E9%80%9A%E8%BF%87%E5%8D%87%E7%BA%A7npm%E8%A7%A3%E5%86%B3%E4%BA%86error_ts2322%E5%92%8Cts2307/</guid><description>上一个项目有个defect需要解决，很久没有动它了，所以一上来先git pull更新代码库，然后通过gradlew clean build &amp;ndash;refresh-dependencies进行构建，不料竟然碰到很多TS2322和TS2307错误，最后:grunt_build任务以失败告终。通过如下命令更新npm，问题不复重现。
npm cache clean npm install 不过具体是怎么解决的问题，还是不太清楚。有可能是因为npm升级了TypeScript，从而使问题得以解决。
C:\&amp;gt;npm list -g C:\Users\xxxxxx\AppData\Roaming\npm `-- typescript@2.1.6 C:\xxxgitws\xxxxxx-app&amp;gt;npm list typescript xxxxxx-app@3.0.0-0 C:\xxxgitws\xxxxxx-app `-- guides-buildtools-openuibundled@8.0.0 `-- guides-buildtools-openui@8.0.0 `-- typescript@2.4.1</description></item><item><title>[JS] 鼠标点的screenX/Y、clientX/Y、pageX/Y和offsetX/Y</title><link>https://mryqu.github.io/post/js_%E9%BC%A0%E6%A0%87%E7%82%B9%E7%9A%84screenxyclientxypagexy%E5%92%8Coffsetxy/</link><pubDate>Tue, 09 Jan 2018 05:55:33 +0000</pubDate><guid>https://mryqu.github.io/post/js_%E9%BC%A0%E6%A0%87%E7%82%B9%E7%9A%84screenxyclientxypagexy%E5%92%8Coffsetxy/</guid><description>理解 clientX/Y：鼠标点相对浏览器窗口内容区域（viewport）左上角的偏移量。
桌面浏览器基本支持，移动浏览器有可能不支持。 pageX/Y：鼠标点相对浏览器所有渲染内容区域（viewport）左上角的偏移量。(滚动后，文档左上角有可能不在浏览器窗口中，仍旧从文档左上角算起)
桌面浏览器基本支持，移动浏览器有可能不支持。 screenX/Y：鼠标点相对物理显示器左上角的偏移量。
当浏览器换了位置或屏幕分辨率改了，即使clientX/Y不变，screenX/Y值都有可能变动。
桌面和移动浏览器都基本支持。 offsetX/offsetY：鼠标点相对事件目标左上角的偏移量。
实验性质技术，桌面浏览器基本支持，移动浏览器有可能不支持。 代码示例 测试 做了两次测试：第一次测试没有滚动浏览器，第二次测试滚动了浏览器。
两次点击的clientY都是22；
两次点击的screenY都是225；
两次点击的pageY分别是22和428（整个文档渲染区域左上角滚动后没有出现在浏览器内）；
两次点击的offsetY分别是6和413（段落渲染区域左上角滚动后没有出现在浏览器内）。
参考 What is the difference between screenX/Y, clientX/Y and pageX/Y?
getMousePosition.js
MDN: MouseEvent.screenX
MDN: MouseEvent.clientX
MDN: MouseEvent.pageX
MDN: MouseEvent.offsetX</description></item><item><title>[OpenUI5] Theme加载</title><link>https://mryqu.github.io/post/openui5_theme%E5%8A%A0%E8%BD%BD/</link><pubDate>Thu, 28 Dec 2017 05:37:36 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_theme%E5%8A%A0%E8%BD%BD/</guid><description>瞄了一下OpenUI5中UI主题加载，关键点在sap.ui.core.Core.includeLibraryTheme方法。其调用者主要为：
sap.ui.core.Core._boot：启动OpenUI5核心时加载必要的主题 sap.ui.core.Core.initLibrary：加载某个库时会尝试加载其主题 假定config.js内容如下： window[&amp;#39;sap-ui-config&amp;#39;] = { bindingSyntax: &amp;#39;complex&amp;#39;, modules: [ &amp;#34;sap.m.library&amp;#34;, &amp;#34;sap.ui.commons.library&amp;#34;, &amp;#34;sap.ui.table.library&amp;#34;, &amp;#34;sap.ui.layout.library&amp;#34;, &amp;#34;yqu.ui.kexiao.library&amp;#34; ] } }; OpenUI5在加载yqu.ui.kexiao.library库时会尝试加载其主题。
Core.includeLibraryTheme (Core.js?eval:xxxx) Core.initLibrary (Core.js?eval:xxxx) (anonymous) (Interface.js?eval:xx) (anonymous) (library.js?eval:xx) evalModuleStr (sap-ui-core-dbg.js:xxxxx) execModule (sap-ui-core-dbg.js:xxxxx) requireModule (sap-ui-core-dbg.js:xxxxx) jQuery.sap.require (sap-ui-core-dbg.js:xxxxx) Core.loadLibrary (Core.js?eval:xxxx) .............</description></item><item><title>Typescript类型定义文件(.d.ts)生成工具</title><link>https://mryqu.github.io/post/typescript%E7%B1%BB%E5%9E%8B%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/</link><pubDate>Thu, 07 Dec 2017 06:10:34 +0000</pubDate><guid>https://mryqu.github.io/post/typescript%E7%B1%BB%E5%9E%8B%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/</guid><description> Microsoft/dts-gen - dts-gen creates starter TypeScript definition files for any module or library. dtsmake - d.ts file generator tool from JavaScript files. dtsgenerator - d.ts file generator tool, for only JSON Schema files. js2tsd - d.ts file generator tool, no type inferrence. JS2TSD d.ts file generator GUI tool app. Not CLI.</description></item><item><title>[Gradle] 遭遇 Unable to process incoming event 'ProgressComplete' (ProgressCompleteEvent)</title><link>https://mryqu.github.io/post/gradle_%E9%81%AD%E9%81%87_unable_to_process_incoming_event_progresscomplete_progresscompleteevent/</link><pubDate>Thu, 30 Nov 2017 06:08:53 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E9%81%AD%E9%81%87_unable_to_process_incoming_event_progresscomplete_progresscompleteevent/</guid><description>最近开始玩一个项目，结果gradle build总是报错：
FAILURE: Build failed with an exception. * What went wrong: Unable to process incoming event &amp;#39;ProgressComplete &amp;#39; (ProgressCompleteEvent) 参考了帖子Build fails with “Unable to process incoming event ‘ProgressComplete ’ (ProgressCompleteEvent)”：
The Workaround: use the --console plain gradle command line switch The Fix: If you use git + git-bash, upgrade to git 2.x.x (2.9.3 is current and works for me) If you use DOS, try increasing your screen buffer size.(mine is 1024 x 1024) 将Git Window从2.</description></item><item><title>[Golang] 折腾一下Golang项目调试</title><link>https://mryqu.github.io/post/golang_%E6%8A%98%E8%85%BE%E4%B8%80%E4%B8%8Bgolang%E9%A1%B9%E7%9B%AE%E8%B0%83%E8%AF%95/</link><pubDate>Tue, 24 Oct 2017 05:59:46 +0000</pubDate><guid>https://mryqu.github.io/post/golang_%E6%8A%98%E8%85%BE%E4%B8%80%E4%B8%8Bgolang%E9%A1%B9%E7%9B%AE%E8%B0%83%E8%AF%95/</guid><description>想装个MinGW-W64玩玩64位GDB，才发现继上一博文MinGW安装和使用已三年了，不经意间到看到了下列帖子：
MinGW MinGW-w64 TDM-GCC等工具链之间的区别与联系 发现个新环境msys2 MinGW、MinGW-w64 与TDM-GCC 应该如何选择？ 对于mingw-w64、tdm-gcc、Win-builds这三个小纠结一会，觉得自己本身也就是用一下GDB，还是去https://sourceforge.net/projects/mingw-w64/直接下载MinGW-W64好了。
MinGW-W64安装 所用MinGW-W64安装配置：
配置项 配置值 Architecture x86_64 Threads posix Exception seh Golang项目编译 编译Golang项目采用 go build -gcflags “-N -l” 关闭内联优化。
GDB调试 载入runtime-gdb.py脚本以对Go运行时结构进行完美打印和转换(例如显示slice和map值、查看goroutine等)：
参数载入：gdb -d $GCROOT 手工载入：source C:\Go\src\runtime\runtime-gdb.py 折腾一会，最后还是折在GDB on windows with golang: buildsym_init Assertion &amp;ldquo;free_pendings == NULL&amp;rdquo; failed.这个问题上，一调试就DDB崩了，貌似目前无解。 Delve调试 不过Debugging Go Code with GDB里还介绍了另外一个对Golang支持更好的工具Delve。 上手容易，有些命令跟GDB差不多。 好了，就折腾到这里了。目前不太需要的东东就不花费力气了。</description></item><item><title>学习一下TOML</title><link>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%8Btoml/</link><pubDate>Mon, 23 Oct 2017 05:47:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%8Btoml/</guid><description>TOML（Tom&amp;rsquo;s Obvious, Minimal Language）是（GitHub的联合创始人及前CEO）Tom Preston-Werner于2013年创建的语言，其目标是成为一个小规模的易于使用的语义化配置文件格式。TOML被设计为可以无二义性的转换为一个哈希表(Hash table)。它是YAML和JSON的替代品，跟JSON相对对人类更友好，比YAML更简单。 GitHub：toml-lang/toml
Learn toml in Y minutes
TOML简介 （转）</description></item><item><title>[Golang] 使用dep</title><link>https://mryqu.github.io/post/golang_dep/</link><pubDate>Sun, 22 Oct 2017 06:00:25 +0000</pubDate><guid>https://mryqu.github.io/post/golang_dep/</guid><description>之前的博文[Golang]Glide的安装和使用记录了对Glide的学习，本博将记录对Golang包管理工具dep的学习使用。
dep介绍 在2012年，go get成为获取依赖包的方式。dep的FAQ中有一段描述dep是否要取代go get的解答，一句话概括就是：依赖管理工具是为应用管理代码的，go get是为GOPATH管理代码的。go get仅仅支持获取master branch上的latest代码，没有指定version、branch或revision的能力。这不符合gopher对自己项目所依赖的第三方包受控的期望。 在2015年，Russ Cox在Go 1.5发布前期以一个experiment feature身份紧急加入vendor机制，vendor标准化了项目依赖的第三方库的存放位置，隔离不同项目依赖的同一个包的不同版本。 Golang的包管理一直没有官方统一的解决方案，因此也产生了很多非官方的包管理工具。这些工具很多都很不错，但是相互兼容性差。随着Go语言在全球范围内应用的愈加广泛，缺少官方包管理工具这一问题变得日益突出。2016年GopherCon大会后，由微服务框架go-kit作者Peter Bourgon牵头， 在Go官方的组织下，Go包管理委员会经过各种头脑风暴和讨论后发布了“包管理建议书”，并启动了最有可能被接纳为官方包管理工具的项目dep的设计和开发。当前主导dep开发的是Sam Boyer，Sam也是dep底层包依赖分析引擎-gps的作者。2017年年初，dep项目正式对外开放。
安装 我的实验平台是Win10，所以无法通过brew或者shell脚本安装，只能通过go get安装：
go get -u github.com/golang/dep/cmd/dep 安装完，执行dep命令，出现帮助代表安装成功。
$ dep Dep is a tool for managing dependencies for Go projects Usage: &amp;#34;dep [command]&amp;#34; Commands: init Set up a new Go project, or migrate an existing one status Report the status of the project&amp;#39;s dependencies ensure Ensure a dependency is safely vendored in the project prune Pruning is now performed automatically by dep ensure.</description></item><item><title>[Golang] Go项目的国际化</title><link>https://mryqu.github.io/post/golang_go%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%9B%BD%E9%99%85%E5%8C%96/</link><pubDate>Sat, 21 Oct 2017 06:34:41 +0000</pubDate><guid>https://mryqu.github.io/post/golang_go%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%9B%BD%E9%99%85%E5%8C%96/</guid><description>因为我看的那些书里都没有提及Go项目的国际化实现，但在放狗搜索前，还是觉得跟Java/JS项目中的实践应该都差不多。搜了一下才发现自己Too young too simple！ 在Internationalization plan for Go中提到了Golang曾经的I18N路线图：
对国际化文本提供全面支持 对国际化日期、时间等提供支持 对多语言消息提供支持 这个2011年的讨论有人提及Golang已经支持UTF8/unicode，日期时间自己可以格式化，其他人纷纷表示不同意他的观点，然后就没有然后了。 Golang的标准库还有提供完整的I18N支持，所以还需要对众多的Golang I18N库进行技术选型。通过https://golanglibs.com/search?q=i18n可知go-i18n排名第一，而且使用者也比较多。i18n4go为大厂IBM的cloud CTO出品，从Cloud Foundary CLI中提取出来的，估计能遇到的坎都解决掉了，但是排名并不靠前。 最终决定开始我的go-18n学习之旅。
通过go-bindata嵌入i18n properties文件 具体细节见之前的博文Go程序内嵌I18N properties文件。
资源文件 i18n/resources/locale.properties mryqu.hello=Welcome to Golang world! mryqu.intro=This is a go-bindata-i18n example. mryqu.verinfo={{.Cli}} Version {{.Version}} (Build: {{.Build}}) i18n/resources/locale_en.properties mryqu.hello=Welcome to Golang world! mryqu.intro=This is a go-bindata-i18n example. mryqu.verinfo={{.Cli}} Version {{.Version}} (Build: {{.Build}}) i18n/resources/locale_zh-CN.properties mryqu.hello=欢迎来到Golang世界！ mryqu.intro=这是一个go-bindata-i18n示例。 mryqu.verinfo={{.Cli}} 版本 {{.Version}} (构建：{{.Build}}) 其他源码 i18n/i18n.go 与之前的博文Go程序内嵌I18N properties文件相比，这里添加了下面内容：
使用github.com/magiconair/properties包获取properties文件内的键值对； 通过github.com/nicksnyder/go-i18n/i18n包判断properties文件语言、为文件内所有键值对创建新的翻译。（如果不用properties文件，而是json或TOML格式文件，i18n.LoadTranslationFile就可以直接完成这些事情了，见https://github.com/nicksnyder/go-i18n/blob/master/i18n/bundle/bundle.go。） go-i18n的优点：
实现了CLDR plural rules。 使用text/template处理带有变量的字符串。 翻译文件可以是简单的JSON、TOML和YAML。 package i18n //go:generate go-bindata -pkg i18n -o resources.</description></item><item><title>[Golang] GOPATH和包导入</title><link>https://mryqu.github.io/post/golang_gopath%E5%92%8C%E5%8C%85%E5%AF%BC%E5%85%A5/</link><pubDate>Fri, 20 Oct 2017 05:43:09 +0000</pubDate><guid>https://mryqu.github.io/post/golang_gopath%E5%92%8C%E5%8C%85%E5%AF%BC%E5%85%A5/</guid><description>才开始玩GoLang，碰到一些与包导入相关的问题：
go build没有找到vendor目录下的包 local import &amp;ldquo;./XXX&amp;rdquo; in non-local package GoLang自定义包的特点 Go的package不局限于一个文件，可以由多个文件组成。组成一个package的多个文件，编译后实际上和一个文件类似，组成包的不同文件相互之间可以直接引用变量和函数，不论是否导出；因此，组成包的多个文件中不能有相同的全局变量和函数（这里有一个例外就是包的初始化函数：init函数） Go不要求package的名称和所在目录名相同，但是你最好保持相同，否则容易引起歧义。因为引入包的时候，go会使用子目录名作为包的路径，而你在代码中真正使用时，却要使用你package的名称。 每个子目录中只能存在一个package，否则编译时会报错。 Go的package是以绝对路径GOPATH来寻址的，不要用相对路径来导入 包的初始化函数init 包中可以有多个初始化函数init，每个初始化函数都会被调用，且顺序固定。
对同一个Go文件的init()调用顺序是从上到下的 对同一个package中不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的init()函数。 对于对不同的package，如果不相互依赖的话，按照main包中&amp;quot;先import的后调用&amp;quot;的顺序调用其包中的init() 如果package存在依赖，则先调用最早被依赖的包中的init() GOPATH go命令依赖一个重要的环境变量：$GOPATH。从go 1.8开始，GOPATH环境变量现在有一个默认值，如果它没有被设置。 它在Unix上默认为$HOME/go,在Windows上默认为%USERPROFILE%/go。GOPATH支持多个目录。
$GOPATH src |--github.com |-mryqu |-prj1 |-vendor |--prj2 |-vendor pkg |--相应平台 |-github.com |--mryqu |-prj1 |-XXX.a |-YYY.a |-ZZZ.a |-prj2 |-AAA.a |-BBB.a |-CCC.a Go加载包时会从vendor tree、 $GOROOT下的src目录以及$GOPATH中的多目录下的src目录查找。
相对路径导入 通过go build无法完成非本地导入（non-local imports），必须使用go build main.go。go install根本不支持非本地导入。 相对路径导入文档位于https://golang.org/cmd/go/#hdr-Relative_import_paths 更多细节见：
https://groups.google.com/forum/#!topic/golang-nuts/1XqcS8DuaNc/discussion https://github.com/golang/go/issues/12502 https://github.com/golang/go/issues/3515#issuecomment-66066361 参考 Build Web Application with Golang
关于golang中包（package）的二三事儿
Go: local import in non-local package</description></item><item><title>[Golang] Go程序内嵌I18N properties文件</title><link>https://mryqu.github.io/post/golang_go%E7%A8%8B%E5%BA%8F%E5%86%85%E5%B5%8Ci18n_properties%E6%96%87%E4%BB%B6/</link><pubDate>Thu, 19 Oct 2017 06:11:03 +0000</pubDate><guid>https://mryqu.github.io/post/golang_go%E7%A8%8B%E5%BA%8F%E5%86%85%E5%B5%8Ci18n_properties%E6%96%87%E4%BB%B6/</guid><description>本博文将介绍一下如何将I18N properties文件内嵌到Go程序中。一般来说，go-i18n等Go包官方示例使用JSON文件保存I18N消息，而我的示例还是采用properties文件。
go-bindata go-bindata包可以将任何文件转换为可管理的Go源代码，在将二进制数据嵌入Go程序时是非常有帮助的。文件数据在转换成原始字节切片之前可做选择性的gzip压缩。 在我的示例中，我选择用go-bindata将i18n/resources下的i18n properties文件嵌入Go程序。
安装 go get -u github.com/jteeuwen/go-bindata/... 地址最后的三个点 &amp;hellip;会分析所有子目录并下载依赖编译子目录内容，而go-bindata的命令行工具在子目录中。go-bindata命令行工具将被安装到$GOPATH/bin目录中。 资源文件 i18n/resources/locale.properties mryqu.hello=Welcome to Golang world! mryqu.intro=This is a go-bindata example. i18n/resources/locale_en.properties mryqu.hello=Welcome to Golang world! mryqu.intro=This is a go-bindata example. i18n/resources/locale_zh-Hans.properties mryqu.hello=欢迎来到Golang世界！ mryqu.intro=这是一个go-bindata示例。 操练 看了go-bindata的帮助后，感觉go-bindata简单易用。这里就探索一下nocompress选项吧。
cd {MyPrj}/i18n go-bindata -pkg i18n -o resources.go resources/ go-bindata -pkg i18n -o resources-nocompress.go -nocompress resources/ 通过对比resources.go和resources-nocompress.go可以看出，resources.go里面多引入了bytes、compress/gzip和io包，多生成了一个bindataRead函数用于读取gzip压缩后的数据。 在resources.go中的内嵌数据：
var _resourcesLocaleProperties = []byte(&amp;#34;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\xff\xca\x2d\xaa\x2c\x2c\xd5\xcb\x48\xcd\xc9\xc9\xb7\x0d\x4f\xcd\x49\xce\xcf\x4d\x55\x28\xc9\x57\x70\xcf\xcf\x49\xcc\x4b\x57\x28\xcf\x2f\xca\x49\x51\xe4\xe5\x82\xa8\xca\xcc\x2b\x29\xca\xb7\x0d\xc9\xc8\x2c\x56\xc8\x2c\x56\x48\x54\x48\xcf\xd7\x4d\xca\xcc\x4b\x49\x2c\x49\x54\x48\xad\x48\xcc\x2d\xc8\x49\xd5\x03\x04\x00\x00\xff\xff\x45\xdc\x42\x7f\x4f\x00\x00\x00&amp;#34;) var _resourcesLocale_enProperties = []byte(&amp;#34;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\xff\xca\x2d\xaa\x2c\x2c\xd5\xcb\x48\xcd\xc9\xc9\xb7\x0d\x4f\xcd\x49\xce\xcf\x4d\x55\x28\xc9\x57\x70\xcf\xcf\x49\xcc\x4b\x57\x28\xcf\x2f\xca\x49\x51\xe4\xe5\x82\xa8\xca\xcc\x2b\x29\xca\xb7\x0d\xc9\xc8\x2c\x56\xc8\x2c\x56\x48\x54\x48\xcf\xd7\x4d\xca\xcc\x4b\x49\x2c\x49\x54\x48\xad\x48\xcc\x2d\xc8\x49\xd5\x03\x04\x00\x00\xff\xff\x45\xdc\x42\x7f\x4f\x00\x00\x00&amp;#34;) var _resourcesLocale_zhHansProperties = []byte(&amp;#34;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\xff\xca\x2d\xaa\x2c\x2c\xd5\xcb\x48\xcd\xc9\xc9\xb7\x7d\xb6\x66\xd1\x8b\xfd\x7d\xcf\xe6\x2e\x7d\xda\xb1\xc1\x3d\x3f\x27\x31\x2f\xfd\xc9\x8e\x69\xcf\xa7\xf6\xbc\xdf\xd3\xc8\xcb\x05\x51\x98\x99\x57\x52\x94\x6f\xfb\x62\xff\xcc\x67\x33\xd6\x3f\xd9\xd1\xf0\x64\xc7\xaa\xf4\x7c\xdd\xa4\xcc\xbc\x94\xc4\x92\xc4\xe7\x4b\x76\x3d\xd9\xd7\xfd\xb8\xa1\x09\x10\x00\x00\xff\xff\xf7\xd1\x50\xc9\x54\x00\x00\x00&amp;#34;) 在resources-nocompress.go中的内嵌数据：
var _resourcesLocaleProperties = []byte(`mryqu.</description></item><item><title>[Golang] 使用Makefile实现Go项目的跨平台构建</title><link>https://mryqu.github.io/post/golang_%E4%BD%BF%E7%94%A8makefile%E5%AE%9E%E7%8E%B0go%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA/</link><pubDate>Wed, 18 Oct 2017 05:49:28 +0000</pubDate><guid>https://mryqu.github.io/post/golang_%E4%BD%BF%E7%94%A8makefile%E5%AE%9E%E7%8E%B0go%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA/</guid><description>通常编译go程序，都是用go build，对于小的示例代码还可以应付，对于稍大一点的项目就有点繁琐了。 上网调差了一下，发现很多人是通过Makefile的形式对Go项目进行可重现构建的。下面我将以hellomake项目这个小示例展示如何使用Makefile实现Go项目的跨平台构建。
hellomake/Makefile BUILD_ENV := CGO_ENABLED=0 BUILD=`date +%FT%T%z` LDFLAGS=-ldflags &amp;#34;-w -s -X main.Version=${VERSION} -X main.Build=${BUILD}&amp;#34; TARGET_EXEC := hellomake .PHONY: all clean setup build-linux build-osx build-windows all: clean setup build-linux build-osx build-windows clean: rm -rf build setup: mkdir -p build/linux mkdir -p build/osx mkdir -p build/windows build-linux: setup ${BUILD_ENV} GOARCH=amd64 GOOS=linux go build ${LDFLAGS} -o build/linux/${TARGET_EXEC} build-osx: setup ${BUILD_ENV} GOARCH=amd64 GOOS=darwin go build ${LDFLAGS} -o build/osx/${TARGET_EXEC} build-windows: setup ${BUILD_ENV} GOARCH=amd64 GOOS=windows go build ${LDFLAGS} -o build/windows/${TARGET_EXEC}.</description></item><item><title>[Golang] UUID包</title><link>https://mryqu.github.io/post/golang_uuid-package/</link><pubDate>Tue, 17 Oct 2017 15:12:12 +0000</pubDate><guid>https://mryqu.github.io/post/golang_uuid-package/</guid><description>最早Google的Go UUID包位于https://code.google.com/archive/p/go-uuid/ ，后来移到了https://github.com/pborman/uuid 。而https://github.com/google/uuid 是基于pborman版的，区别于之前的实现在于用16字节数组取代了字节切片，缺点是无法表示无效UUID。上述UUID包采用BSD 3-Clause许可协议。 此外还有采用MIT协议的https://github.com/satori/go.uuid ，它支持UUID版本1-5，与RFC 4122和DCE 1.1兼容。通过https://golanglibs.com/top?q=uuid 可以看出，它是GitHub点星(star)最多的UUID包，远远超过了Google的。</description></item><item><title>[Golang] Glide的安装和使用</title><link>https://mryqu.github.io/post/golang_glide/</link><pubDate>Mon, 16 Oct 2017 15:47:55 +0000</pubDate><guid>https://mryqu.github.io/post/golang_glide/</guid><description>不论是开发Java还是你正在学习的Golang，都会遇到依赖管理问题。Java有牛逼轰轰的Maven和Gradle。 Golang亦有Godep、Govendor、Glide、dep等等。本文主要给大家介绍Glide。 Glide 是Golang的包管理工具，是为了解决Golang依赖问题的。 为什么需要Glide ？ 原因很简单，Go语言原生包管理的缺陷。罗列一下Golang的get子命令管理依赖有很多大缺陷：
能拉取源码的平台很有限，绝大多数依赖的是 github.com 不能区分版本，以至于令开发者以最后一项包名作为版本划分 依赖 列表/关系 无法持久化到本地，需要找出所有依赖包然后一个个 go get 只能依赖本地全局仓库（GOPATH/GOROOT），无法将库放置于项目局部仓库（$PROJECT_HOME/vendor） Glide 是有下列几大主要功能：
持久化依赖列表至配置文件中，包括依赖版本（支持范围限定）以及私人仓库等 持久化关系树至 lock 文件中（类似于 yarn 和 cargo），以重复拉取相同版本依赖 兼容 go get 所支持的版本控制系统：Git, Bzr, HG, and SVN 支持 GO15VENDOREXPERIMENT 特性，使得不同项目可以依赖相同项目的不同版本 可以导入其他工具配置，例如： Godep, GPM, Gom, and GB Glide 在Mac或Linux上是很容易安装的，但是在Win10 x64上据说最新版有问题。详见https://github.com/Masterminds/glide/issues/873 。 想多了没用，还是实干吧。从https://github.com/Masterminds/glide/releases 上下载了glide-v0.13.0-windows-amd64.zip，里面就一个glide.exe。 将glide.exe放入%GOPATH%/bin下，然后将%GOPATH%/bin加入环境变量Path中，由于我的Go版本是1.9所以GO15VENDOREXPERIMENT环境变量就不用管了。执行 glide --version ，开头没问题呀！ 进入我的项目目录%GOPATH%/src/helloglide，执行下列命令：
glide create #创建新的工作空间，生成glide.yaml glide get github.com/pborman/uuid #获取uui包 glide install #建立glide.lock版本 go build #构建项目 glide list #列举项目导入的所有包 INSTALLED packages: github.</description></item><item><title>[Golang] 解决GoClipse安装问题</title><link>https://mryqu.github.io/post/golang_%E8%A7%A3%E5%86%B3goclipse%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 14 Oct 2017 17:22:43 +0000</pubDate><guid>https://mryqu.github.io/post/golang_%E8%A7%A3%E5%86%B3goclipse%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/</guid><description>按照GoClipse安装文档安装Eclipse的GoClipse插件时，提示org.eclipse.platform.feature.group无法找到。 我的Eclipse还是Eclipse 4.4 (Luna)，而GoClipse要求Eclipse 4.6 (Neon)及更高版本，看来不听话是没有好下场的。接着这个机会升级到Eclipse 4.7 (Oxygen)吧。
安装gocode、guru、godef gocode在安装LiteIDE时已经安装。GoClipse下载guru会执行go get -u golang.org/x/tools/cmd/guru ，其结果是网站不响应该请求。
go get -u github.com/nsf/gocode go get -u github.com/rogpeppe/godef mkdir %GOPATH%\src\golang.org\x\ cd %GOPATH%\src\golang.org\x\ git clone https://github.com/golang/tools.git go install golang.org/x/tools/cmd/guru 配置GoClipse 测试 齐活！</description></item><item><title>[Golang] 安装Go开发环境</title><link>https://mryqu.github.io/post/golang_devsetup/</link><pubDate>Fri, 13 Oct 2017 15:36:59 +0000</pubDate><guid>https://mryqu.github.io/post/golang_devsetup/</guid><description>项目上有几个Story涉及GoLang。Go语言是谷歌2009发布的第二款开源编程语言。Go语言专门针对多处理器系统应用程序的编程进行了优化，使用Go编译的程序可以媲美C或C++代码的速度，而且更加安全、支持并行进程。 学习新语言从安装环境开始。到https://golang.org/ 下载一个Windows版的安装程序，就可以轻松搞定。 初次上手，习惯性地选了一个IDE。没下jetbrains家的GoLand ，而是拿LiteIDE 试试手。感觉有点卡顿，其他还好。 链接 https://golang.org/
LiteIDE
GoClipse installation</description></item><item><title>[C++] 优化twitcurl项目中的HMAC_SHA1</title><link>https://mryqu.github.io/post/c++_%E4%BC%98%E5%8C%96twitcurl%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84hmac_sha1/</link><pubDate>Mon, 31 Jul 2017 05:46:44 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%BC%98%E5%8C%96twitcurl%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84hmac_sha1/</guid><description>twitcurl开源项目中包含SHA1.cpp和HMAC_SHA1.cpp用于计算Twitter认证所需的HMAC-SHA1签名。 HMAC是密钥相关的哈希运算消息认证码（Hash-based Message Authentication Code），HMAC运算利用哈希算法，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。HMAC_SHA1需要一个密钥，而SHA1不需要。HMAC_SHA1的公式为：SHA1(Key XOR opad, SHA1(Key XOR ipad, text)) 通过分析oauthlib.cpp和HMAC_SHA1.cpp可知：
对于HMAC_SHA1算法，请求URL及参数信息作为文本输入，ConsumerSecret和AccessTokenSecret组合作为密钥输入； 第一步：如果密钥输入大小超过64字节，则先做一次SHA1获取其摘要用于后继操作；否则直接使用密钥进行后继操作； 第二步：密钥输入（/密钥输入摘要）XOR ipad（即0x36）； 第三步：将上一步的[Key XOR ipad]和文本输入并入缓存AppendBuf1； 第四步：使用上一步生成的缓存AppendBuf1一起进行SHA1以产生内部摘要； 第五步：密钥输入（/密钥输入摘要）XOR opad（即0x5C）； 第六步：将上一步的[Key XOR opad]和第四步产生的内部摘要并入缓存AppendBuf2； 第七步：使用上一步生成的缓存AppendBuf2一起进行SHA1以产生外部摘要。 HMAC_SHA1.h中定义的AppendBuf1和AppendBuf2都有4K大小，合计8K。能不能省点空间呢？
下面我们可以看一个小示例：
char srcTest[] = &amp;#34;abcdef&amp;#34;; int srcTestL = strlen(srcTest); char srcTest1[] = &amp;#34;abc&amp;#34;; int srcTestL1 = strlen(srcTest1); char srcTest2[] = &amp;#34;def&amp;#34;; int srcTestL2 = strlen(srcTest2); unsigned char dst1[20] = &amp;#34;&amp;#34;; unsigned char dst2[20] = &amp;#34;&amp;#34;; CSHA1 sha1A = CSHA1(); sha1A.Reset(); sha1A.Update((UINT_8 *)srcTest, srcTestL); sha1A.</description></item><item><title>试试swagger-codegen的invokerPackage和basePackage</title><link>https://mryqu.github.io/post/%E8%AF%95%E8%AF%95swagger-codegen%E7%9A%84invokerpackage%E5%92%8Cbasepackage/</link><pubDate>Mon, 24 Jul 2017 05:42:35 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%AF%95%E8%AF%95swagger-codegen%E7%9A%84invokerpackage%E5%92%8Cbasepackage/</guid><description>环境 mryqu@mryqu MINGW64 /c/playground/helloSwaggerCodegen $ ls config.json swagger.json swagger.yaml swagger-codegen-cli-2.2.3.jar mryqu@mryqu MINGW64 /c/playground/helloSwaggerCodegen $ cat swagger.yaml swagger: &amp;#39;2.0&amp;#39; info: description: Just a SpringFox demo version: &amp;#39;2.0&amp;#39; title: mryqu&amp;#39;s REST API Demo contact: name: mryqu license: name: Apache License Version 2.0 url: https://github.com/mryqu/ host: localhost:8080 basePath: &amp;#34;/hellospringfox&amp;#34; tags: - name: greeting-controller description: Greeting Controller paths: &amp;#34;/greeting{?name}&amp;#34;: get: tags: - greeting-controller summary: Get greeting information operationId: greeting consumes: - application/json produces: - application/json - &amp;#34;*/*&amp;#34; parameters: - name: name in: query description: User Name required: true type: string default: World responses: &amp;#39;200&amp;#39;: description: OK schema: &amp;#34;$ref&amp;#34;: &amp;#34;#/definitions/Greeting&amp;#34; &amp;#39;204&amp;#39;: description: No Content &amp;#39;401&amp;#39;: description: Unauthorized &amp;#39;403&amp;#39;: description: Forbidden definitions: Greeting: type: object properties: content: type: string links: type: array items: &amp;#34;$ref&amp;#34;: &amp;#34;#/definitions/Link&amp;#34; Link: type: object properties: href: type: string rel: type: string templated: type: boolean mryqu@mryqu MINGW64 /c/playground/helloSwaggerCodegen $ cat config.</description></item><item><title>swagger-codegen 2.2.3与2.1.5区别</title><link>https://mryqu.github.io/post/swagger-codegen_2.2.3%E4%B8%8E2.1.5%E5%8C%BA%E5%88%AB/</link><pubDate>Sun, 23 Jul 2017 06:13:46 +0000</pubDate><guid>https://mryqu.github.io/post/swagger-codegen_2.2.3%E4%B8%8E2.1.5%E5%8C%BA%E5%88%AB/</guid><description>支持的语法 $ java -jar swagger-codegen-cli-2.1.6.jar langs Available languages: [android, aspnet5, async-scala, csharp, dart, flash, python-flask, go, java, jaxrs, jaxrs-cxf, jaxrs-resteasy, inflector, javascript, javascript-closure-angular, jmeter, nodejs-server, objc, perl, php, python, qt5cpp, ruby, scala, scalatra, silex-PHP, sinatra, slim, spring-mvc, dynamic-html, html, swagger, swagger-yaml, swift, tizen, typescript-angular, typescript-node, akka-scala, CsharpDotNet2, clojure, haskell-servant] $ java -jar swagger-codegen-cli-2.2.3.jar langs Available languages: [akka-scala, android, apache2, apex, aspnet5, aspnetcore, async-scala, bash, csharp, clojure, cwiki, cpprest, CsharpDotNet2, dart, elixir, eiffel, erlang-server, finch, flash, python-flask, go, go-server, groovy, haskell, jmeter, jaxrs-cxf-client, jaxrs-cxf, java, inflector, jaxrs-cxf-cdi, jaxrs-spec, jaxrs, msf4j, java-play-framework, jaxrs-resteasy-eap, jaxrs-resteasy, javascript, javascript-closure-angular, java-vertx, kotlin, lumen, nancyfx, nodejs-server, objc, perl, php, php-symfony, powershell, pistache-server, python, qt5cpp, rails5, restbed, ruby, scala, scalatra, silex-PHP, sinatra, slim, spring, dynamic-html, html2, html, swagger, swagger-yaml, swift4, swift3, swift, tizen, typescript-angular2, typescript-angular, typescript-fetch, typescript-jquery, typescript-node, undertow, ze-ph] swagger-codegen 2.</description></item><item><title>Ribbon和Spring Cloud Consul</title><link>https://mryqu.github.io/post/ribbon%E5%92%8Cspring_cloud_consul/</link><pubDate>Thu, 29 Jun 2017 05:45:01 +0000</pubDate><guid>https://mryqu.github.io/post/ribbon%E5%92%8Cspring_cloud_consul/</guid><description>学习一下Client Side Load Balancing with Ribbon and Spring Cloud快速入门指南，这里的客户端负载平衡是借助Netflix Ribbon实现的。很魔性，除了application.yml里有Ribbon的配置以及代码包含@RibbonClient、@LoadBalanced注解，应用程序几乎没什么工作要做了。
@RibbonClient和@LoadBalanced的区别 Difference between @RibbonClient and @LoadBalanced讲解了@RibbonClient和@LoadBalanced的区别。 @LoadBalanced是个标记注解，指示被注解的RestTemplate应该使用RibbonLoadBalancerClient与服务进行交互。反过来，这允许在URL除了使用物理主机名+端口号组合外，还可以使用服务名的逻辑标识符。
restTemplate.getForObject(&amp;#34;http://some-service-name/user/{id}&amp;#34;, String.class, 1); @RibbonClient是用于配置Ribbon客户端的。它不是必须的，当使用服务发现且默认Ribbon设置就可以满足需求时，无需使用@RibbonClient注解。 在下列两种情况下需要使用@RibbonClient注解：
需要对特定Robbon客户端使用定制Ribbon设置 没有使用任何服务发现 定制Robbon设置：
@Configuration @RibbonClient(name = &amp;#34;foo&amp;#34;, configuration = FooConfiguration.class) public class TestConfiguration { } 注意FooConfiguration必须由@Configuration注解，但是它不能在主应用上下文@ComponentScan范围内，否则它将被所有@RibbonClient共享。如果使用@ComponentScan（或@SpringBootApplication），需要避免其被包含在内（例如放入独立不重叠的包内或显示指定@ComponentScan扫描的包）。
Spring Cloud Consul和Ribbon 在没用使用任何服务发现时，Ribbon从listOfServers配置里的服务器列表进行选择的。偶在项目中是用Consul的，它主业就是干服务发现的工作，而且还支持Netflix Ribbon。 网上有现成的Spring Cloud Consul和Ribbon示例spring-boot-consul-demo-tax和spring-boot-consul-demo-invoice。使用默认Ribbon设置，所以bootstrap.yml/application.yml里没有Ribbon设置，代码也没有使用@RibbonClient。 启动两个spring-boot-consul-demo-tax微服务实例和一个spring-boot-consul-demo-invoice微服务实例，在浏览器访问spring-boot-consul-demo-invoice微服务，就会发现spring-boot-consul-demo-invoice微服务实例以RoundRobin轮询方式调用两个spring-boot-consul-demo-tax微服务实例了。
Ribbon组件 通过BaseLoadBalancer可以看出Ribbon中的负载均衡器所包含的几个重要组件/属性，正是这几个组件为Ribbon的功能提供支持:
组件 描述 Rule 负载均衡策略，可以插件化地为Ribbon提供各种适用的负载均衡算法。 Ping 判断目标服务是否存活。对应不同的协议不同的方式去探测，得到后端服务是否存活。如有http的，还有对于微服务框架内的服务存活的NIWSDiscoveryPing是通过eureka client来获取的instanceinfo中的信息来获取。 ServerList 服务器列表，可以是静态的也可以是动态的。如果是（通过DynamicServerListLoadBalancer实现）动态的，会有后台线程以一定的间隔时间更新和过滤列表。 LoadBalancerStats 负载均衡器运行信息。记录负载均衡器的实时运行信息，这些运行信息可以被用来作为负载均衡器策略的输入。 负载均衡策略 IRule | 策略名 | 策略描述 | 实现说明 | | - | - | | BestAvailableRule | 选择一个最小并发请求的服务器 | 逐个考察服务器的LoadBalancerStats信息，如果服务器被断路器断了则忽略，在其中选择ActiveRequestsCount最小的服务器。 | | AvailabilityFilteringRule | 过滤掉那些因为一直连接失败的被断路器断了的服务器，并过滤掉那些高并发的服务器（活跃连接数超过配置的阈值） | 使用一个AvailabilityPredicate来包含过滤服务器的逻辑，其实就是检查LoadBalancerStats里记录各个服务器的断路器状态和ActiveRequestsCount状态。当尝试十次后还无法选出合适的服务器，则通关过轮训策略选出一个。 | | ZoneAvoidanceRule | 通过组合判断服务器所在zone的性能和服务器可用性来选择server | 使用ZoneAvoidancePredicate和AvailabilityPredicate来判断是否选择某个服务器，前一个判断判定一个zone的运行性能是否可用，剔除不可用的zone（的所有服务器），AvailabilityPredicate用于过滤掉连接数过多的服务器。 | | RoundRobinRule | roundRobin方式轮询选择服务器 | 维护一个AtomicInteger类型的轮询下标，尝试十次从allServers选择下标对应位置的可用服务器（服务器不可用，则下标原子加一取模）。</description></item><item><title>Spring Cloud Consul Config</title><link>https://mryqu.github.io/post/spring_cloud_consul_config/</link><pubDate>Fri, 23 Jun 2017 05:40:36 +0000</pubDate><guid>https://mryqu.github.io/post/spring_cloud_consul_config/</guid><description>Spring Cloud是在Spring Boot的基础上构建的，用于简化分布式系统构建的工具集，为开发人员提供快速建立分布式系统中的一些常见的模式。例如：分布式版本可控配置(Distributed/versioned configuration)，服务注册与发现(Service registration and discovery)、智能路由(intelligent routing)、服务间调用、负载均衡、断路器(circuit breakers)、微代理(micro-proxy)、控制总线(control bus)、一次性令牌(one-time tokens)、全局锁(global locks)、领导选举和集群状态(leadership election and cluster state)、分布式消息、分布式会话等。 Spring Cloud Config项目快速入门示例展示了用于分布式系统中由Git仓库支持的中央外部配置。但是偶在项目中是用Consul的，而Spring Cloud Consul项目的快速入门示例并没有展示如何使用Consul进行配置管理，所以还是自己攒一下吧。
Spring Cloud Consul简介 HashiCorp公司的Consul是用于基础架构中服务发现和配置的工具，支持服务发现、健康检查、用于不同用途的键值对存储、多数据中心支持。 Spring Cloud Consul通过自动配置及Spring环境和其他Spring编程模型进行绑定实现Cosul与Spring Boot应用的集成。通过一些简单的注释，即可激活应用内的通用模式，使用Hashicorp的Consul构建大型分布式系统。其功能如下：
服务发现: 实例可以向Consul agent注册，客户端可以使用Spring管理的bean发现这些实例 支持Ribbon: 通过Spring Cloud Netflix提供的客户端负载均衡 支持Zuul: 通过Spring Cloud Netflix提供的动态路由和过滤 分布式配置: 使用Consul键值对存储 控制总线: 使用Consul事件的分布式控制事件 安装并启动Consul 每个集群需要最少三台Consul server，以建立仲裁(quorum)，每个机器上必须运行一个consul agent。 Consul Agent:
健康检查 转发查询 Consul Server:
存储数据 响应查询 领导选举 根据参考二Consul安装指南，可以很轻松地在本机安装Consul。用于开发环境启动本地单Consul实例的脚本可以使用参考一Spring Cloud Consul指南中所提到的src/main/bash/local_run_consul.sh。本文中采用如下命令：
consul agent -dev -ui consul-config-demo build.gradle buildscript { repositories { mavenCentral() maven { url &amp;#34;http://repo.</description></item><item><title>OpenGrok使用感受</title><link>https://mryqu.github.io/post/opengrok%E4%BD%BF%E7%94%A8%E6%84%9F%E5%8F%97/</link><pubDate>Mon, 12 Jun 2017 06:22:27 +0000</pubDate><guid>https://mryqu.github.io/post/opengrok%E4%BD%BF%E7%94%A8%E6%84%9F%E5%8F%97/</guid><description>之前为了学习项目涉及的C/C++代码，试用过SourceInsight，后来改成Vim+Exuberant Ctags+Cscope。最近一个美国同事给了个链接，原来那边的兄弟是用OpenGrok搜项目代码的！ OpenGrok是一个快速、便于使用的源码搜索引擎与对照引擎，它能够帮助我们快速地搜索、定位、对照代码树。它可以理解各种程序语言和文件格式，及Mercurial、Git、SCCS、RCS、CVS、Subversion、Teamware、ClearCase、Perforce、Monotone和Bazaar等版本控制历史记录。OpenGrok是OpenSolaris操作系统源文件浏览和搜索的工具。 OpenGrok由Java语言实现，需要Java 1.8、一个Servlet容器以及Exuberant Ctags。 用完就一个字：爽！
参考 OpenGrok主页
GitHub：OpenGrok/OpenGrok
OpenGrok：Comparison with Similar Tools
OpenGrok：Supported Languages and Formats
OpenGrok：Supported Revision Control Systems
Ubuntu环境下OpenGrok的安装及使用</description></item><item><title>ArcGIS REST API资费</title><link>https://mryqu.github.io/post/arcgis_rest_api%E8%B5%84%E8%B4%B9/</link><pubDate>Sat, 20 May 2017 06:25:31 +0000</pubDate><guid>https://mryqu.github.io/post/arcgis_rest_api%E8%B5%84%E8%B4%B9/</guid><description>一个ArcGIS开发者订阅每月有免费的50点积分。
GeoEnrichment API资费 在Esri GeoEnrichment Service提到了资费列表：
GeoEnrichment服务资费 Esri积分 美元 1 Stored GeoEnrichment Variable 0.01 积分 (Per Feature) $0.001 (Per Feature) 1,000 Stored GeoEnrichment Variables 10 积分 (Per Feature) $1.00 (Per Feature) 1 Non-Stored GeoEnrichment Request 0.01 积分 $0.001 1000 Non-Stored GeoEnrichment Requests 10 积分 $1.00 Generated Infographic View 0.01 积分 $0.001 1000 Generated Infographic Views 10 积分 $1.00 Generated Report 10 积分 $1.00 Geocoding API资费 在Esri World Geocoding Service提到了资费列表：
Geocoding服务资费 Esri积分 美元 Geosearch, Individual Address - Not Stored n/a n/a Geocode, Batch or Stored 0.</description></item><item><title>玩玩ArcGIS REST API</title><link>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9arcgis_rest_api/</link><pubDate>Fri, 19 May 2017 05:49:55 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9arcgis_rest_api/</guid><description>了解Esri和ArcGIS 美国环境系统研究所公司（Environmental Systems Research Institute, Inc. 简称Esri公司）成立于1969年，总部设在美国加利福利亚州雷德兰兹市，是世界最大的地理信息系统技术提供商。 ArcGIS是Esri公司集40余年地理信息系统（GIS）咨询和研发经验，奉献给用户的一套完整的GIS平台产品，具有强大的地图制作、空间数据管理、空间分析、空间信息整合、发布与共享的能力。
ArcGIS REST API ArcGIS REST API可用于包括ArcGIS Online在内的ArcGIS平台，包括：
Maps—随时可用的底图、参考层等。可用于快速为您的本地或全球数据添加上下文或背景。一些ArcGIS Online地图有页面主题，可以提供出你的应用所需的全部信息。 World Geocoding Service—通过文本地址、商业名等查找位置，该服务也提供反向服务：通过地理坐标查找最近的地址。 Directions and Routing Service (Network Analysis Service)—解决各种路线规划问题，例如简单的点到点路由、复杂的船舶航线规划、及行驶时间分析。 GeoEnrichment Service—GeoEnrichment 服务借助本地化的人口、场所以及商业信息丰富了用户的地理数据。提交某个点、面、地址或地名后，可通过该服务了解该地区居民的生活习惯和生活方式、附近的商业类型以及区域邮政编码等信息。 Spatial Analysis Service—各种可用于执行通用GIS分析的任务。传统上，包括查找热点和对周边汇总在内的许多任务都需要深度学习和专业知识才能运行。而这些空间分析任务仅包含少量需要研究的参数，也能获得相当不错的结果。 Elevation Analysis service—高程分析服务允许您执行高程分析（轮廓，视角，总结高程）和水文分析（流域和跟踪下游）的各种操作。这些服务参考的数据由Esri托管和策划。 ArcGIS REST API有些是免费的，有些是付费。付费操作需要订阅ArcGIS Online，并减扣账户积分。 使用需付费API时，需要在请求中通过token参数指定访问令牌。获取ArcGIS REST API所需访问令牌的方法，请参见前一博文ArcGIS认证和登录。
响应数据格式 对于ArcGIS REST API，有些响应支持JSON、PJSON（个人理解就是完美打印版的JSON）、XML和BIN格式中的一种或多种。可在请求时通过f参数指定。
使用GeoEnrichment API GeoEnrichment服务能力、属性和限制可以通过下列请求获得：
http://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/GeoEnrichment/?f=pjson 由响应可知，GeoEnrichment端点支持Enrich、CreateReport、Reports、Countries、DataCollections、StandardGeographyLevels这几种操作。
Countries操作 首先试一下国家列表：
http://geoenrich.arcgis.com/arcgis/rest/services/World/GeoenrichmentServer/Geoenrichment/Countries?f=pjson 当然Countries操作也可用于获取单个国家信息： StandardGeographyLevels操作 StandardGeographyLevels服务返回有效地理数据层列表。服务结果是BAIDNamePairs数组，包含数据层ID及相应名称。这些ID可被用于在其他分析中指定数据层。 下面的请求示例列举CN的有效地理数据层列表：
http://geoenrich.arcgis.com/arcgis/rest/services/World/GeoenrichmentServer/Geoenrichment/StandardGeographyLevels/CN?f=pjson DataCollections操作 GeoEnrichment服务使用数据集合的概念定义服务返回的属性。更具体地说，数据集合是用于丰富输入特性的预先组合的属性列表。作为输入特性，集合属性可以描述所提交位置或区域的各种类型信息，例如人口特征和地理上下文。
http://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/Geoenrichment/dataCollections?f=pjson Reports和CreateReport操作 创建报告操作可为描述输入区域的各种用例创建各种高质量报告。如果使用一个点作为研究区域，该服务将围绕该点创建1英里的环形缓冲区以收集和附加丰富数据。或者，您可以围绕该点创建环形缓冲区或特定驾驶时间可达区域，生成包含有关人口特征、消费者支出、业务或市场潜力等相关信息的PDF或Excel报告。 报告选项可用于描述和更好地了解市场，顾客/客户以及特定领域商业竞争。 下面的请求示例列举US数据集中有效报告列表：
http://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/Geoenrichment/Reports/US?f=pjson 下面的请求示例生成以坐标-117.1956、34.0572为中心一英里区域的人口和收入概况报告(report指定为dandi，从上一示例结果中可知为人口和收入概况报告)：
http://geoenrich.arcgis.com/arcgis/rest/services/World/geoenrichmentserver/GeoEnrichment/CreateReport?studyAreas=[{&amp;#34;geometry&amp;#34;:{&amp;#34;x&amp;#34;:-117.1956,&amp;#34;y&amp;#34;:34.0572}}]&amp;amp;report=dandi&amp;amp;f=bin&amp;amp;format=PDF&amp;amp;token={YOUR_TOKEN} Enrich操作 提供地点或区域的事实数据。输入可为：</description></item><item><title>ArcGIS认证和登录</title><link>https://mryqu.github.io/post/arcgis%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</link><pubDate>Thu, 18 May 2017 05:43:22 +0000</pubDate><guid>https://mryqu.github.io/post/arcgis%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</guid><description>申请ArcGIS Online账户 创建应用 点击创建第一个应用： 输入应用所需信息： 查看应用信息： 设置redirect URI： 获取应用访问令牌 默认情况下，访问令牌2小时过期。可在获取访问令牌的请求中加入expiration参数，指定以分钟为单位的过期间隔（响应中单位为秒），最大为14天。 应用登录具有几个内建限制：
通过应用获取的访问令牌仅能读取公开内容和服务。 通过应用获取的访问令牌有可能读取Esri托管的高级内容和服务，并消费代表应用所有者的点数。 应用无法创建、更新、共享、修改和删除在ArcGIS Online或ArcGIS门户网站上的内容（层、文件、服务、地图）。 使用应用登录方式的应用无法列于ArcGIS软件商店。 获取用户访问令牌 用于用户登录的HTTP GET请求如下：
https://www.arcgis.com/sharing/rest/oauth2/authorize?client_id={YOUR_APP_CLIENT_ID}&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;response_type=code 请求用户授权： 返回地址包含code参数，内容中也有一含有code值的文本框： 获取访问令牌的HTTP GET请求包含上面获得的code参数：：
https://www.arcgis.com/sharing/rest/oauth2/token?client_id={YOUR_APP_CLIENT_ID}&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;grant_type=authorization_code&amp;amp;code={GOTTEN_CODE} 访问令牌使用 不同的ArcGIS REST API使用的访问令牌类型可能不同。例如在Accessing the GeoEnrichment service中提到使用GeoEnrichment服务需要用户访问令牌；而在 Authenticate a request to the World Geocoding Service中提到使用Geocoding服务需要应用访问令牌。 下面的示例使用用户访问令牌执行Geocoding服务的操作，结果返回403错误，提示Token is valid but access is denied，具体信息为User does not have permissions to access geocodeAddresses。 参考 ArcGIS: Implementing App Login
ArcGIS: Implementing Named User Login
ArcGIS: Mobile and Native Named User Login</description></item><item><title>玩一下Quandl API</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bquandl_api/</link><pubDate>Thu, 11 May 2017 06:00:43 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bquandl_api/</guid><description>Quandl是为投资专业人士提供财务、经济和替代数据的平台。 Quandl来源于500多家出版商的数据。所有Quandl的数据都可通过API访问，也可以通过包含R、Python、Ruby等多种编程语言及Excel、SAS等软件进行原生访问。Quandl的来源包括联合国，世行和中央银行等提供商的公开数据、来自CLS集团，Zacks和ICE等供应商的核心财务数据、Dun＆Bradstreet的其他数据、以及许多机密来源。 **什么是替代数据？**替代数据的范围非常广泛，起初主要包含了未加工的、原始的公司文件、历史市场价格、投资者表现等数据，而现在替代数据已经涵盖任何从移动手机数据到职位信息再到天气预报、交通、卫星图像等能够被采集到的数据。替代数据世界由一系列模糊的数据集组成，而这些数据集可以被转换为交易信息。Quandl提供的替代数据包括企业财务压力数据、外汇数据、电子邮件收据数据、全球石油储量数据、定量股票选择数据等。 Quandl上的数据分为免费数据和高级（Premium）数据，其中高级数据只能通过订阅访问。
申请Quandl账号 除了在Quandl上注册帐号外，Quandl还支持使用GitHub、Google和LinkedIn账号进行OAuth2认证登录。登录后查看账户设置信息中的API KEY，即可用于后继API访问。 Quandl API 全部的Quandl数据产品，可通过https://www.quandl.com/search查找。Quandl的数据产品来源不同，包含时间序列和表在内的各种对象。 Guandl的大多数数据集只能以时间序列或表中的一种格式打开，其中一些则既可用时间序列格式也可用表格式访问。
时间序列是一段时间内观测或指标集合，以时间为索引且只包含数字数据类型字段。 表包含各种未排序数据类型（字符串、数字、日期等）并可用不同字段进行过滤。 Guandl可指定如下返回类型：
JSON CSV XML 速率限制 认证用户限制10秒300个调用、10分钟2000调用及每天50000调用。使用免费数据集的认证用户并发限制为1，即进行一个调用的同时可以在队列中有一个额外的调用。 高级数据订阅限制10分钟5000调用及每天720000调用。
访问时间序列 获取时间序列数据集数据 GET https://www.quandl.com/api/v3/datasets/{database_code}/{dataset_code}/data.{return_format}?api_key=YOURAPIKEY 获取时间序列数据集元数据 GET https://www.quandl.com/api/v3/datasets/{database_code}/{dataset_code}/metadata.{return_format}?api_key=YOURAPIKEY 获取时间序列数据集数据及元数据 GET https://www.quandl.com/api/v3/datasets/{database_code}/{dataset_code}.{return_format}?api_key=YOURAPIKEY 获取时间序列数据库元数据 GET https://www.quandl.com/api/v3/databases/{database_code}.{return_format}?api_key=YOURAPIKEY 获取整个时间序列数据库(仅能用于订阅的高级数据) GET https://www.quandl.com/api/v3/databases/{database_code}/data?download_type=full&amp;amp;api_key=YOURAPIKEY 查询参数 参数 必需 类型 值 描述 database_code 是 string 数据库代码 dataset_code 是 string 数据集代码 limit 否 int 使用limit=n获得数据集的头n行。使用limit=1获取最新的一行。 column_index 否 int 指定特定列。第0列是日期列且永久返回，因此该处从第1列起。
（mryqu：不指定则显示全部列，指定就显示两列，为什么没有逗号分隔了？） start_date 否 string yyyy-mm-dd 用于过滤的起始日期 end_date 否 string yyyy-mm-dd 用于过滤的结束日期 order 否 string asc</description></item><item><title>Icon/logo and brand guides for social media</title><link>https://mryqu.github.io/post/iconlogo_and_brand_guides_for_social_media/</link><pubDate>Wed, 10 May 2017 06:18:52 +0000</pubDate><guid>https://mryqu.github.io/post/iconlogo_and_brand_guides_for_social_media/</guid><description>Twitter https://abs.twimg.com/favicons/favicon.ico https://brand.twitter.com/en.html Facebook https://www.facebook.com/favicon.ico https://en.facebookbrand.com/ Google https://www.google.com/favicon.ico
YouTube https://www.youtube.com/favicon.ico https://www.youtube.com/yt/brand/using-logo.html Google Analytics https://analytics.google.com/analytics/web/s/analytics_suite_icon.png https://developers.google.com/analytics/terms/branding-policy Google Drive https://ssl.gstatic.com/docs/doclist/images/infinite_arrow_favicon_4.ico https://developers.google.com/drive/v3/web/branding</description></item><item><title>YouTube Analytics Dimensions And Mitrics Research</title><link>https://mryqu.github.io/post/youtube_analytics_dimensions_and_mitrics_research/</link><pubDate>Fri, 28 Apr 2017 06:11:11 +0000</pubDate><guid>https://mryqu.github.io/post/youtube_analytics_dimensions_and_mitrics_research/</guid><description>Dimensions GroupCore
Dim?DimensionData
TypeExampleTest
URLResourcesXvideoSTRINGNO_FORMAT
KHqrLhJPdtETestplaylistSTRINGNO_FORMAT
TestXchannelSTRINGNO_FORMAT
???group
(filter only)Time periodsXdaySTRINGYYYY-MM-DD
2016-05-03TestX7DayTotalsSTRINGYYYY-MM-DD
2014-01-01TestX30DayTotalsSTRINGYYYY-MM-DD
2014-01-01TestXmonthSTRINGYYYY-MM
2016-05TestGeographic areasXcountrySTRING2-letter ISO-3166-1 code
USTestprovince
[use country==US in filter]STRINGISO 3166-2 code
US-ZZTestcontinent
(filter only)subContinent
(filter only)Playback locationsinsightPlaybackLocationTypeSTRINGPossible Value:BROWSECHANNELEMBEDDEDEXTERNAL_APPMOBILESEARCHWATCHYT_OTHER
WATCHTestinsightPlaybackLocationDetail
[use insightPlaybackLocationType
==EMBEDDED in filter]STRINGTestPlayback detailsliveOrOnDemandSTRINGPossible Value:LIVEON_DEMAND
ON_DEMANDTestsubscribedStatusSTRINGPossible Value:SUBSCRIBEDUNSUBSCRIBEDTest?youtubeProductSTRINGPossible Values:COREGAMINGKIDSUNKNOWN
CORETestTraffic sourcesinsightTrafficSourceTypeSTRINGPossible Values:ADVERTISINGANNOTATIONCAMPAIGN_CARDEND_SCREENEXT_URLNO_LINK_EMBEDDEDNO_LINK_OTHERNOTIFICATIONPLAYLISTPROMOTEDRELATED_VIDEOSUBSCRIBERYT_CHANNELYT_OTHER_PAGEYT_PLAYLIST_PAGEYT_SEARCH
YT_CHANNELTestinsightTrafficSourceDetail
[use insightTrafficSourceType in filter]STRINGNO_FORMAT
UC-OpYDuNCwCt-AIHC6xNYdwTestDevicesdeviceTypeSTRINGPossible Values:DESKTOPGAME_CONSOLEMOBILETABLETTVUNKNOWN_PLATFORM
DESKTOPTestoperatingSystemSTRINGPossible Values:ANDROIDBADABLACKBERRYCHROMECASTDOCOMOFIREFOXHIPTOPIOSLINUXMACINTOSHMEEGONINTENDO_3DSOTHERPLAYSTATIONPLAYSTATION_VITAREALMEDIASMART_TVSYMBIANTIZENWEBOSWIIWINDOWSWINDOWS_MOBILEXBOX
WINDOWSTestDemographicsXageGroup
[use specific metric]STRINGPossible Values:age13-17age18-24age25-34age35-44age45-54age55-64age65-TestXgender
[use specific metric]STRINGPossible Values:femalemaleTestEngagement and content sharingXsharingServiceSTRINGPossible Values:AMEBAANDROID_EMAILANDROID_MESSENGERANDROID_MMSBBMBLOGGERCOPY_PASTECYWORLDDIGGDROPBOXEMBEDMAILFACEBOOKFACEBOOK_MESSENGERFACEBOOK_PAGESFOTKAGMAILGOOGOOGLEPLUSGO_SMSGROUPMEHANGOUTSHI5HTC_MMSINBOXIOS_SYSTEM_ACTIVITY_DIALOGKAKAO_STORYKIKLGE_EMAILLINELINKEDINLIVEJOURNALMENEAMEMIXIMOTOROLA_MESSAGINGMYSPACENAVERNEARBY_SHARENUJIJOTHERPINTERESTREDDITSKYPESKYBLOGSONY_CONVERSATIONSSTUMBLEUPONTELEGRAMTEXT_MESSAGETUENTITUMBLRTWITTERUNKNOWNVERIZON_MMSVIBERWECHATWEIBOWHATS_APPWYKOPYAHOOVKONTAKTEODNOKLASSNIKIRAKUTENKAKAOTestAudience retentionelapsedVideoTimeRatio
[use video in filter]FLOATrange from 0.</description></item><item><title>Facebook根据请求API版本返回不同内容？</title><link>https://mryqu.github.io/post/facebook%E6%A0%B9%E6%8D%AE%E8%AF%B7%E6%B1%82api%E7%89%88%E6%9C%AC%E8%BF%94%E5%9B%9E%E4%B8%8D%E5%90%8C%E5%86%85%E5%AE%B9/</link><pubDate>Thu, 27 Apr 2017 06:10:12 +0000</pubDate><guid>https://mryqu.github.io/post/facebook%E6%A0%B9%E6%8D%AE%E8%AF%B7%E6%B1%82api%E7%89%88%E6%9C%AC%E8%BF%94%E5%9B%9E%E4%B8%8D%E5%90%8C%E5%86%85%E5%AE%B9/</guid><description>今天跟测试组同事研究Facebook返回内容时，发现一个奇怪现象：抓取湖南卫视的Page，当API版本为2.3至2.8时，返回结果内容为空；而API版本为2.9时，返回有内容的响应。</description></item><item><title>处理Google Analytics数据类型</title><link>https://mryqu.github.io/post/%E5%A4%84%E7%90%86google_analytics%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 17 Apr 2017 05:50:50 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A4%84%E7%90%86google_analytics%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>发送一个Google Analytics请求 分析响应中的columnHeaders 响应中每一列头都包含数据类型信息，大致包含STRING、INTEGER、FLOAT、DATE、TIME、PERCENT、CURRENCY等。
{ &amp;#34;kind&amp;#34;: &amp;#34;analytics#gaData&amp;#34;, &amp;#34;id&amp;#34;: &amp;#34;https://www.googleapis.com/analytics/v3/data/ga?ids=ga:1XXXXX0&amp;amp;dimensions=ga:campaign,ga:source,ga:medium,ga:date&amp;amp;metrics=ga:users,ga:newUsers,ga:percentNewSessions,ga:sessions,ga:bounceRate,ga:avgSessionDuration,ga:pageviewsPerSession&amp;amp;start-date=30daysAgo&amp;amp;end-date=yesterday&amp;amp;max-results=0&amp;#34;, &amp;#34;query&amp;#34;: { &amp;#34;start-date&amp;#34;: &amp;#34;30daysAgo&amp;#34;, &amp;#34;end-date&amp;#34;: &amp;#34;yesterday&amp;#34;, &amp;#34;ids&amp;#34;: &amp;#34;ga:1XXXXX0&amp;#34;, &amp;#34;dimensions&amp;#34;: &amp;#34;ga:campaign,ga:source,ga:medium,ga:date&amp;#34;, &amp;#34;metrics&amp;#34;: [ &amp;#34;ga:users&amp;#34;, &amp;#34;ga:newUsers&amp;#34;, &amp;#34;ga:percentNewSessions&amp;#34;, &amp;#34;ga:sessions&amp;#34;, &amp;#34;ga:bounceRate&amp;#34;, &amp;#34;ga:avgSessionDuration&amp;#34;, &amp;#34;ga:pageviewsPerSession&amp;#34; ], &amp;#34;start-index&amp;#34;: 1, &amp;#34;max-results&amp;#34;: 0 }, &amp;#34;itemsPerPage&amp;#34;: 0, &amp;#34;totalResults&amp;#34;: 27400, &amp;#34;selfLink&amp;#34;: &amp;#34;https://www.googleapis.com/analytics/v3/data/ga?ids=ga:1XXXXX0&amp;amp;dimensions=ga:campaign,ga:source,ga:medium,ga:date&amp;amp;metrics=ga:users,ga:newUsers,ga:percentNewSessions,ga:sessions,ga:bounceRate,ga:avgSessionDuration,ga:pageviewsPerSession&amp;amp;start-date=30daysAgo&amp;amp;end-date=yesterday&amp;amp;max-results=0&amp;#34;, &amp;#34;nextLink&amp;#34;: &amp;#34;https://www.googleapis.com/analytics/v3/data/ga?ids=ga:1XXXXX0&amp;amp;dimensions=ga:campaign,ga:source,ga:medium,ga:date&amp;amp;metrics=ga:users,ga:newUsers,ga:percentNewSessions,ga:sessions,ga:bounceRate,ga:avgSessionDuration,ga:pageviewsPerSession&amp;amp;start-date=30daysAgo&amp;amp;end-date=yesterday&amp;amp;start-index=1&amp;amp;max-results=0&amp;#34;, &amp;#34;profileInfo&amp;#34;: { &amp;#34;profileId&amp;#34;: &amp;#34;1XXXXX0&amp;#34;, &amp;#34;accountId&amp;#34;: &amp;#34;1XXXXX8&amp;#34;, &amp;#34;webPropertyId&amp;#34;: &amp;#34;UA-XXXXXXX-1&amp;#34;, &amp;#34;internalWebPropertyId&amp;#34;: &amp;#34;1XXXX1&amp;#34;, &amp;#34;profileName&amp;#34;: &amp;#34;Corporate Site (Master Profile)&amp;#34;, &amp;#34;tableId&amp;#34;: &amp;#34;ga:1XXXXX0&amp;#34; }, &amp;#34;containsSampledData&amp;#34;: true, &amp;#34;sampleSize&amp;#34;: &amp;#34;999951&amp;#34;, &amp;#34;sampleSpace&amp;#34;: &amp;#34;3174334&amp;#34;, &amp;#34;columnHeaders&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;ga:campaign&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;DIMENSION&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;STRING&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:source&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;DIMENSION&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;STRING&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:medium&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;DIMENSION&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;STRING&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:date&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;DIMENSION&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;STRING&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:users&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;INTEGER&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:newUsers&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;INTEGER&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:percentNewSessions&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;PERCENT&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:sessions&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;INTEGER&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:bounceRate&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;PERCENT&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:avgSessionDuration&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;TIME&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;ga:pageviewsPerSession&amp;#34;, &amp;#34;columnType&amp;#34;: &amp;#34;METRIC&amp;#34;, &amp;#34;dataType&amp;#34;: &amp;#34;FLOAT&amp;#34; } ], &amp;#34;totalsForAllResults&amp;#34;: { &amp;#34;ga:users&amp;#34;: &amp;#34;2648520&amp;#34;, &amp;#34;ga:newUsers&amp;#34;: &amp;#34;1488536&amp;#34;, &amp;#34;ga:percentNewSessions&amp;#34;: &amp;#34;46.</description></item><item><title>Making Nested Requests using Facebook Graph API</title><link>https://mryqu.github.io/post/making_nested_requests_using_facebook_graph_api/</link><pubDate>Thu, 13 Apr 2017 05:53:26 +0000</pubDate><guid>https://mryqu.github.io/post/making_nested_requests_using_facebook_graph_api/</guid><description>今天又玩了一把Facebook Graph API。当我们抓取Page上的帖子后，之后会发起API请求获取帖子的评论及回复。
获取Page SASsoftware（ID为193453547355388）下的帖子 https://graph.facebook.com/193453547355388/feed?fields=id,XXXX,likes.limit(0).summary(1),comments,XXXX,with_tags&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;since=XXXX&amp;amp;until=XXXX&amp;amp;access_token={YOUR_TOKEN} 获取帖子193453547355388_951786161522119的评论 https://graph.facebook.com/193453547355388_951786161522119/comments?fields=id,from,message,created_time,like_count&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;access_token={YOUR_TOKEN} 获取评论951786161522119_951787458188656的回复 https://graph.facebook.com/951786161522119_951787458188656/comments?fields=id,from,message,created_time,like_count&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;access_token={YOUR_TOKEN} 试用嵌套请求 https://graph.facebook.com/193453547355388/feed?fields=id,XXXX,likes.limit(0).summary(1),comments{id,from,message,type,created_time,like_count,comments{id,from,message,type,created_time,like_count}},XXXX,with_tags&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;since=XXXX&amp;amp;until=XXXX&amp;amp;access_token={YOUR_TOKEN} 这里的请求使用了两级嵌套请求，第一级获取帖子的评论，第二季获取评论的回复，那结果如何？ 一个API请求就能够获得了帖子、评论及回复的信息。但是，考虑到一个帖子的评论或一个评论的回复都可能很多，返回结果是第一个分页结果，还是需要通过/{object-id}/comments API 请求获取，考虑到设计复杂性和性价比，决定放弃这种方案。</description></item><item><title>[MySQL] 将空返回值转换成NULL</title><link>https://mryqu.github.io/post/mysql_%E5%B0%86%E7%A9%BA%E8%BF%94%E5%9B%9E%E5%80%BC%E8%BD%AC%E6%8D%A2%E6%88%90null/</link><pubDate>Sat, 01 Apr 2017 06:17:43 +0000</pubDate><guid>https://mryqu.github.io/post/mysql_%E5%B0%86%E7%A9%BA%E8%BF%94%E5%9B%9E%E5%80%BC%E8%BD%AC%E6%8D%A2%E6%88%90null/</guid><description>当MySQL没有搜索到任何匹配行时，会返回空返回值，如何转换成NULL呢？
方法一 select (original_select_statement) as Alias 这种方法仅对一个单值有效，即：
原语句返回单值，该值将被返回 原语句返回单列零行，将返回NULL 原语句返回多列或多行，查询失败 方法二 使用IFNULL或COALESCE函数。</description></item><item><title>[C++] Compile JsonCpp library using CMake</title><link>https://mryqu.github.io/post/c++_compile_jsoncpp_library_using_cmake/</link><pubDate>Thu, 23 Mar 2017 06:14:57 +0000</pubDate><guid>https://mryqu.github.io/post/c++_compile_jsoncpp_library_using_cmake/</guid><description>本文为升级JsonCpp库操作过程的备份笔记。
Linux/Unix平台 下载JsonCpp 从JsonCpp releases页面可知，当前最高版本为1.8.0。
wget https://github.com/open-source-parsers/jsoncpp/archive/1.8.0.tar.gz tar xzvf 1.8.0.tar.gz cd jsoncpp-1.8.0 mkdir build/release 升级gcc 这里我选择使用gcc 5:
sudo add-apt-repository ppa:ubuntu-toolchain-r/test sudo apt-get update sudo apt-get install gcc-5 g++-5 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 1 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 1 升级cmake JsonCpp 1.8.0要求cmake&amp;gt;=3.1
sudo apt-get install software-properties-common sudo add-apt-repository ppa:george-edison55/cmake-3.x sudo apt-get update sudo apt-get upgrade cmake 编译JsonCpp cmake -DCMAKE_BUILD_TYPE=release -DBUILD_STATIC_LIBS=ON -DBUILD_SHARED_LIBS=OFF -DARCHIVE_INSTALL_DIR=. -G &amp;#34;Unix Makefiles&amp;#34; ../.. make Windows平台 准备环境 首先下载JsonCpp 1.</description></item><item><title>[C++] Build JsonCpp library in Linux platform</title><link>https://mryqu.github.io/post/c++_build_jsoncpp_library_in_linux_platform/</link><pubDate>Wed, 22 Mar 2017 05:47:27 +0000</pubDate><guid>https://mryqu.github.io/post/c++_build_jsoncpp_library_in_linux_platform/</guid><description>wget https://github.com/open-source-parsers/jsoncpp/archive/1.8.0.tar.gz tar xzvf 1.8.0.tar.gz cd jsoncpp-1.8.0/src/lib_json g++ -g -std=c++11 -Wall -fPIC -c -I../../include json_reader.cpp json_value.cpp json_writer.cpp ar rvs libjsoncpp.a *.o g++ -g json_reader.o json_writer.o json_value.o -shared -o libjsoncpp.so</description></item><item><title>升级tsc.js解决TypeScript编译失败问题</title><link>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7tsc.js%E8%A7%A3%E5%86%B3typescript%E7%BC%96%E8%AF%91%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/</link><pubDate>Tue, 07 Mar 2017 06:10:36 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7tsc.js%E8%A7%A3%E5%86%B3typescript%E7%BC%96%E8%AF%91%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/</guid><description>今天项目忽然构建失败，遭遇下列错误：
error TS5052: Option &amp;#39;sourceRoot&amp;#39; cannot be specified without specifying option &amp;#39;sourceMap&amp;#39;. error TS5053: Option &amp;#39;sourceRoot&amp;#39; cannot be specified with option &amp;#39;inlineSourceMap&amp;#39;. 查了下tsconfig.json，发现前两天&amp;quot;sourceMap&amp;quot;属性由true改为了false，又增加了值为true的&amp;quot;inlineSourceMap&amp;quot;属性。 最后只好把项目里的tsc.js从1.6.4升级成2.1.6才解决问题。</description></item><item><title>玩一下uptodate-gradle-plugin插件</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Buptodate-gradle-plugin%E6%8F%92%E4%BB%B6/</link><pubDate>Fri, 03 Mar 2017 05:57:34 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Buptodate-gradle-plugin%E6%8F%92%E4%BB%B6/</guid><description>玩了一下uptodate-gradle-plugin插件，使用这个插件后执行 gradle uptodate 可以看到那些库在Maven Central仓库有新版本，用于辅助判断是否需要更新Java库。 我一般不追新库，所以这个插件对我的用处小，看一看玩一玩，仅此而已。</description></item><item><title>[OpenUI5] 在XMLView中使用带有参数的I18N消息</title><link>https://mryqu.github.io/post/openui5_%E5%9C%A8xmlview%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%B8%A6%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84i18n%E6%B6%88%E6%81%AF/</link><pubDate>Wed, 01 Mar 2017 06:14:39 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%9C%A8xmlview%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%B8%A6%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84i18n%E6%B6%88%E6%81%AF/</guid><description>在做的一个新项目中，美国团队那边齐刷刷地一色用XMLView而不是JSView，碰到一个小问题：那就是怎么在XMLView中设置带有参数的I18N消息。
参考Passing parameters to i18n model within XML view帖子中的方案，基本搞定：
&amp;lt;Input id=&amp;#34;myInput&amp;#34; type=&amp;#34;Text&amp;#34; required=&amp;#34;true&amp;#34; value=&amp;#34;{myyquInput}&amp;#34; placeholder=&amp;#34;{parts:[&amp;#39;i18n&amp;gt;myKey.txt&amp;#39;, &amp;#39;myModel&amp;gt;myProp&amp;#39;], formatter: &amp;#39;jQuery.sap.formatMessage&amp;#39;}&amp;#34; change=&amp;#34;.handleChangeForMyInput&amp;#34;&amp;gt; &amp;lt;layoutData&amp;gt; &amp;lt;l:GridData span=&amp;#34;L6 M8 S9&amp;#34; /&amp;gt; &amp;lt;/layoutData&amp;gt; &amp;lt;/Input&amp;gt; messagebundle.properties：
myKey.txt=&amp;#34;(Example: {0})&amp;#34; 使用sap.ui.model.CompositeBinding可以通过XMLView中的parts加载多个参数，达到我的目的。缺点就是每个参数只能是model/path组合，或者省略model的path。我没有找到直接输入参数值的便捷方法。 阅读sap.ui.base.ManagedObject的bindProperty方法可知，它对part中每一元素查找是否有“&amp;gt;”，有则认为是model/path组合，否则即为path。
ManagedObject.prototype.bindProperty = function(sName, oBindingInfo, _vFormat, _sMode) { var iSeparatorPos, bAvailable = true, oProperty = this.getMetadata().getPropertyLikeSetting(sName); // check whether property or alternative type on aggregation exists if (!oProperty) { throw new Error(&amp;#34;Property \&amp;#34;&amp;#34; + sName + &amp;#34;\&amp;#34; does not exist in &amp;#34; + this); } // old API compatibility (sName, sPath, _vFormat, _sMode) if (typeof oBindingInfo == &amp;#34;string&amp;#34;) { oBindingInfo = { parts: [ { path: oBindingInfo, type: _vFormat instanceof Type ?</description></item><item><title>[OpenUI5] 折腾了一下JSView转换XMLView</title><link>https://mryqu.github.io/post/openui5_%E6%8A%98%E8%85%BE%E4%BA%86%E4%B8%80%E4%B8%8Bjsview%E8%BD%AC%E6%8D%A2xmlview/</link><pubDate>Tue, 21 Feb 2017 05:49:10 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E6%8A%98%E8%85%BE%E4%BA%86%E4%B8%80%E4%B8%8Bjsview%E8%BD%AC%E6%8D%A2xmlview/</guid><description>根据OpenUI5 Developer Guide - Diagnostics Window中的介绍，尝试一下XML View Conversion。
Many code samples are written in JavaScript. To facilitate the conversion of these code samples into XML, OpenUI5 provides a generic conversion tool. To run the tool, proceed as follows:
Run the OpenUI5 app in your browser, for example, open a page in the test suite. Open the support tool by choosing CTRL+ALT+SHIFT+S. Open the Control Tree panel. Select the root UI area in the tree on the left hand side.</description></item><item><title>TypeScript初体验</title><link>https://mryqu.github.io/post/typescript%E5%88%9D%E4%BD%93%E9%AA%8C/</link><pubDate>Wed, 08 Feb 2017 05:59:50 +0000</pubDate><guid>https://mryqu.github.io/post/typescript%E5%88%9D%E4%BD%93%E9%AA%8C/</guid><description>TypeScript介绍 鉴于JavaScript这种脚本语言很难应用于大规模Web应用的开发，微软公司在2012年推出了新的开源编程语言——TypeScript。作为Object Pascal和C#之父Anders Hejisberg的又一作品，TypeScript是JavaScript的超集，但完全兼容JavaScript。相比于JavaScript，TypeScript增加了可选类型、类和模块，扩展了原有的语法，使得代码组织和复用变得更加有序，方便进行大型Web应用的开发。
安装 TypeScript可通过npm进行安装：
npm install -g typescript 查看TypeScript版本：
C:\quTemp&amp;gt;tsc -v Version 2.1.6 我开发主要使用IntelliJ IDEA，它可以很好的编辑TypeScript文件。不过对于一些小练习，还是安装Sublime的TypeScript插件好了：
初体验 menu.ts源文件（来自参看一）： 编译：
tsc menu.ts 执行： 编译结果menu.js： 测试：
下一步计划 学习一下《TypeScript Essentials》和《Mastering TypeScript》这两本书。
参考 Learn TypeScript in 30 Minutes
Learn TypeScript in Y minutes</description></item><item><title>Upload file to Google Drive using LibCurl</title><link>https://mryqu.github.io/post/upload_file_to_google_drive_using_libcurl/</link><pubDate>Fri, 06 Jan 2017 05:26:57 +0000</pubDate><guid>https://mryqu.github.io/post/upload_file_to_google_drive_using_libcurl/</guid><description>This is a sequel to my last blog &amp;ldquo;Upload file to Google Drive using Postman and cURL&amp;rdquo;.
I wrote C++ code using LibCurl to redo the three types of upload, and all of them work which shown in the below log snippet.
Simple upload =&amp;gt; Send header, 0000000309 bytes (0x00000135) 0000: 50 4f 53 54 20 2f 75 70 6c 6f 61 64 2f 64 72 69 POST /upload/dri 0010: 76 65 2f 76 33 2f 66 69 6c 65 73 3f 75 70 6c 6f ve/v3/files?</description></item><item><title>Get Facebook Reaction data using Graph API</title><link>https://mryqu.github.io/post/get_facebook_reaction_data_using_graph_api/</link><pubDate>Wed, 04 Jan 2017 05:54:05 +0000</pubDate><guid>https://mryqu.github.io/post/get_facebook_reaction_data_using_graph_api/</guid><description>Facebook Enhances Everyone&amp;rsquo;s Like With Love, Haha, Wow, Sad, Angry Buttons. For example, there are two reactions in the post 778979332230227: Your can use Facebook Graph API - Reading Reactions to get the reactions data. Note: The API version must be 2.6 or higher. You also can get all reactions count of one post in single Graph API request:</description></item><item><title>Upload file to Google Drive using Postman and cURL</title><link>https://mryqu.github.io/post/upload_file_to_google_drive_using_postman_and_curl/</link><pubDate>Tue, 03 Jan 2017 05:07:44 +0000</pubDate><guid>https://mryqu.github.io/post/upload_file_to_google_drive_using_postman_and_curl/</guid><description>Simple upload For quick transfer of smaller files, for example, 5 MB or less.
Postman cURL curl -T mytest.csv -X POST -H &amp;#34;Content-Type: text/csv&amp;#34; -H &amp;#34;Cache-Control: no-cache&amp;#34; &amp;#34;https://www.googleapis.com/upload/drive/v3/files?uploadType=media&amp;amp;access_token={YOUR_ACCESS_TOKEN}&amp;#34; Multipart upload For quick transfer of smaller files and metadata; transfers the file along with metadata that describes it, all in a single request.
Postman At the beginning, I try to use form-data for body, then the second value can use file directly.</description></item><item><title>在Google Drive上创建存在多个目录下的文件</title><link>https://mryqu.github.io/post/%E5%9C%A8google_drive%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%AD%98%E5%9C%A8%E5%A4%9A%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</link><pubDate>Thu, 29 Dec 2016 06:10:45 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8google_drive%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%AD%98%E5%9C%A8%E5%A4%9A%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</guid><description>准备环境 在Google Drive上创建两个目录: parent1和parent2 代码 package com.yqu.gd; import java.io.IOException; import java.util.ArrayList; import java.util.List; import com.google.api.client.auth.oauth2.Credential; import com.google.api.client.googleapis.auth.oauth2.GoogleCredential; import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport; import com.google.api.client.http.FileContent; import com.google.api.client.http.HttpTransport; import com.google.api.client.json.JsonFactory; import com.google.api.client.json.jackson2.JacksonFactory; import com.google.api.services.drive.Drive; import com.google.api.services.drive.model.File; import com.google.api.services.drive.model.FileList; public class FileWithMultiParents { private static final String APPLICATION_NAME = &amp;#34;Hello Google Drive API&amp;#34;; private static final JsonFactory JSON_FACTORY = JacksonFactory.getDefaultInstance(); private static HttpTransport HTTP_TRANSPORT; static { try { HTTP_TRANSPORT = GoogleNetHttpTransport.newTrustedTransport(); } catch (Throwable t) { t.</description></item><item><title>学习Java Annotation</title><link>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0java_annotation/</link><pubDate>Tue, 27 Dec 2016 05:46:09 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0java_annotation/</guid><description>以前看过Java Annotation，走马观花，现在印象已经不深刻了。这次好好看一下Java Annotation和Spring Annotation。
阅读列表： The Java Tutorials - Annotations
Java Annotation认知(包括框架图、详细介绍、示例说明)
Annotations Gotchas and Best Practices
Annotations: Don&amp;rsquo;t Mess with Java
Java Annotations Are a Big Mistake
Spring Annotation-based container configuration
Spring Framework Annotations cheat sheet
Spring Without XML: The Basics of Spring Annotations vs. Spring XML Files
Spring Annotation Tutorial
Spring Annotations [ Quick Reference ]</description></item><item><title>[C++] 将JSON转成字符串</title><link>https://mryqu.github.io/post/c++_%E5%B0%86json%E8%BD%AC%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/</link><pubDate>Mon, 26 Dec 2016 05:24:36 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E5%B0%86json%E8%BD%AC%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/</guid><description>需要将如下JSON字符串作为GoogleSheets API POST请求的消息体。打算使用JsonCpp实现。
{&amp;#34;majorDimension&amp;#34;:&amp;#34;ROWS&amp;#34;,&amp;#34;values&amp;#34;:[[&amp;#34;Name&amp;#34;,&amp;#34;Sex&amp;#34;,&amp;#34;Age&amp;#34;,&amp;#34;Height&amp;#34;,&amp;#34;Weight&amp;#34;],[&amp;#34;阿尔弗雷德&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;14&amp;#34;,&amp;#34;69&amp;#34;,&amp;#34;112.5&amp;#34;],[&amp;#34;爱丽丝&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;13&amp;#34;,&amp;#34;56.5&amp;#34;,&amp;#34;84&amp;#34;],[&amp;#34;芭芭拉&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;13&amp;#34;,&amp;#34;65.3&amp;#34;,&amp;#34;98&amp;#34;],[&amp;#34;凯露&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;14&amp;#34;,&amp;#34;62.8&amp;#34;,&amp;#34;102.5&amp;#34;],[&amp;#34;亨利&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;14&amp;#34;,&amp;#34;63.5&amp;#34;,&amp;#34;102.5&amp;#34;],[&amp;#34;詹姆斯&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;12&amp;#34;,&amp;#34;57.3&amp;#34;,&amp;#34;83&amp;#34;],[&amp;#34;简&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;12&amp;#34;,&amp;#34;59.8&amp;#34;,&amp;#34;84.5&amp;#34;],[&amp;#34;雅妮特&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;15&amp;#34;,&amp;#34;62.5&amp;#34;,&amp;#34;112.5&amp;#34;],[&amp;#34;杰弗瑞&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;13&amp;#34;,&amp;#34;62.5&amp;#34;,&amp;#34;84&amp;#34;],[&amp;#34;约翰&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;12&amp;#34;,&amp;#34;59&amp;#34;,&amp;#34;99.5&amp;#34;],[&amp;#34;乔伊斯&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;11&amp;#34;,&amp;#34;51.3&amp;#34;,&amp;#34;50.5&amp;#34;],[&amp;#34;茱迪&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;14&amp;#34;,&amp;#34;64.3&amp;#34;,&amp;#34;90&amp;#34;],[&amp;#34;罗伊斯&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;12&amp;#34;,&amp;#34;56.3&amp;#34;,&amp;#34;77&amp;#34;],[&amp;#34;玛丽&amp;#34;,&amp;#34;女&amp;#34;,&amp;#34;15&amp;#34;,&amp;#34;66.5&amp;#34;,&amp;#34;112&amp;#34;],[&amp;#34;菲利普&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;16&amp;#34;,&amp;#34;72&amp;#34;,&amp;#34;150&amp;#34;],[&amp;#34;罗伯特&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;12&amp;#34;,&amp;#34;64.8&amp;#34;,&amp;#34;128&amp;#34;],[&amp;#34;罗纳德&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;15&amp;#34;,&amp;#34;67&amp;#34;,&amp;#34;133&amp;#34;],[&amp;#34;托马斯&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;11&amp;#34;,&amp;#34;57.5&amp;#34;,&amp;#34;85&amp;#34;],[&amp;#34;威廉&amp;#34;,&amp;#34;男&amp;#34;,&amp;#34;15&amp;#34;,&amp;#34;66.5&amp;#34;,&amp;#34;112&amp;#34;]]} 最终代码：</description></item><item><title>[C++] 调试libcurl程序</title><link>https://mryqu.github.io/post/c++_%E8%B0%83%E8%AF%95libcurl%E7%A8%8B%E5%BA%8F/</link><pubDate>Sun, 25 Dec 2016 21:22:31 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E8%B0%83%E8%AF%95libcurl%E7%A8%8B%E5%BA%8F/</guid><description>最近在调试通过libcurl发送GoogleSheets API POST请求时，增加了一点经验，特此总结。
GoogleSheets API 请求 POST /v4/spreadsheets?access_token={YOUR_ACCESSTOKEN}&amp;amp;fields=spreadsheetId HTTP/1.1 Host: sheets.googleapis.com Content-Type: application/json;charset=UTF-8 Accept: application/json Cache-Control: no-cache {&amp;#34;properties&amp;#34;:{&amp;#34;title&amp;#34;:&amp;#34;newhaha&amp;#34;},&amp;#34;sheets&amp;#34;:[{&amp;#34;properties&amp;#34;:{&amp;#34;title&amp;#34;:&amp;#34;Sheet1&amp;#34;}}]} libcurl调试 当GoogleSheets API 请求失败时，仅能获得返回的状态码和消息。感觉没有更多信息可以研究！后来通过CURLOPT_VERBOSE和CURLOPT_DEBUGFUNCTION获得了更多调试信息。
使用CURLOPT_VERBOSE curl_easy_setopt(m_curl, CURLOPT_VERBOSE, 1L); 这样就可以看到请求报头、响应报头和消息体了。
使用CURLOPT_DEBUGFUNCTION 使用libcurl API指南中CURLOPT_DEBUGFUNCTION示例代码即可。这样就可以看到完整的请求和响应内容了。</description></item><item><title>[OpenUI5] jQuery.sap.formatMessage的一点注意事项</title><link>https://mryqu.github.io/post/openui5_jquery.sap.formatmessage%E7%9A%84%E4%B8%80%E7%82%B9%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</link><pubDate>Mon, 19 Dec 2016 05:34:50 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_jquery.sap.formatmessage%E7%9A%84%E4%B8%80%E7%82%B9%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</guid><description>今天偶然发现I18N properties文件中有字符串包含替换符，可是没起作用，还是明晃晃输出了{0}。 仔细研究一下，才发现原因在于字符串中包含单个&amp;rsquo;，OpenUI5使用jQuery.sap.formatMessage替换I18N字符串，如果仅含有一个&amp;rsquo;字符的话，其/('')|'([^']+(?:''[^']*)*)(?:'|$)|\{([0-9]+(?:\s*,[^{}]*)?)\}|[{}]/g 就只触发第二组替换了。如果想显示单个字符&amp;rsquo;，需要用两个字符&amp;rsquo;转义。 不过问题来了，负责翻译I18N的同事是否清楚jQuery.sap.formatMessage关于字符&amp;rsquo;的限制呢？</description></item><item><title>恢复误删文件内容</title><link>https://mryqu.github.io/post/%E6%81%A2%E5%A4%8D%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9/</link><pubDate>Fri, 02 Dec 2016 05:49:46 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%81%A2%E5%A4%8D%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9/</guid><description>昨天鼠标有毛病，本意是选择Ultraedit中的文件，结果莫名其妙关闭了。重新打开后，内容都丢了，而且还认为是正藏保存的。傻眼了，记了一年多的内容呀！ 今天终于找到恢复方法了，右键点击文件-查看属性-选择以前版本-选择版本并恢复。我的天呀，终于不必愁眉苦脸了！</description></item><item><title>尝试Travis CI</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95travis_ci/</link><pubDate>Sat, 05 Nov 2016 06:00:40 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95travis_ci/</guid><description>从GitHub上下载的很多项目都包含一个.travis.yml文件，一开始不知道是什么鬼，后来才知道是Travis CI配置文件。 Travis CI是基于云的持续集成项目，供GitHub上的开源项目使用。对于GitHub上的项目来说，Travis CI无需自己部署服务器，仅需添加一个.travis.yml文件就可进行持续集成，入侵性很小，所以很多项目都纷纷采用了。
Travis CI与Jenkins的比较 对于企业开发来收，目前主流还是Jenkins/Hudson，下面可以看一下二者的功能比较。
名称平台许可构建器：Windows构建器：Java构建器：其他通知集成 IDE集成 其他Jenkins-HudsonWeb容器Creative Commons和 MITMSBuild
NAntAnt
Maven&amp;nbsp;2
KundoCmake
Gant
Gradle
Grails, Phing
Rake
Ruby
SCons
Python
shell script
command-lineAndroid
Email
Google Calendar
IRC
XMPP
RSS
Twitter
Slack
Catlight
CCMenu
CCTrayEclipse
IntelliJ IDEA
NetBeansBugzilla
Google Code
Jira
Bitbucket
Redmine
FindBugs
Checkstyle
PMD&amp;nbsp;and&amp;nbsp;Mantis
Trac
HP ALMTravis CI已在云上部署MIT无Ant
Maven
GradleC
C++
Clojure
Elixir
Erlang
Go
Groovy
Haskell
Java
Node.js
Perl
PHP
Python
Ruby
Rust
Scala</description></item><item><title>update-alternatives与JAVA_HOME</title><link>https://mryqu.github.io/post/update-alternatives%E4%B8%8Ejava_home/</link><pubDate>Wed, 02 Nov 2016 06:15:02 +0000</pubDate><guid>https://mryqu.github.io/post/update-alternatives%E4%B8%8Ejava_home/</guid><description>测试 /etc/profile配置 export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 使用update-alternatives切换JAVA hadoop@note50064:~$ which java /usr/bin/java hadoop@note50064:~$ sudo update-alternatives --config java There are 2 choices for the alternative . Selection Path Priority Status ------------------------------------------------------------ 0 /usr/lib/jvm/java-7-oracle/jre/bin/java 1072 auto mode * 1 /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java 1071 manual mode 2 /usr/lib/jvm/java-7-oracle/jre/bin/java 1072 manual mode Press enter to keep the current choice[*], or type selection number: hadoop@note50064:~$ ls -l /usr/bin/java lrwxrwxrwx 1 root root 22 Nov 21 03:26 /usr/bin/java -&amp;gt; /etc/alternatives/java hadoop@note50064:~$ ls -l /etc/alternatives/java lrwxrwxrwx 1 root root 46 Nov 1 01:44 /etc/alternatives/java -&amp;gt; /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java hadoop@note50064:~$ java -version java version &amp;#34;1.</description></item><item><title>Hello Google Drive APIs</title><link>https://mryqu.github.io/post/hello_google_drive_apis/</link><pubDate>Thu, 20 Oct 2016 06:32:31 +0000</pubDate><guid>https://mryqu.github.io/post/hello_google_drive_apis/</guid><description>准备环境 当前我的Google Drive内容如下： 继续使用博文《Google Sheets API认证和鉴权》中用过的应用yquGSTest，不过需要激活Google Drive API： Google Drive API测试 方法drive.about.get测试 方法drive.about.get用于获取用户、驱动和系统容量等信息。
方法drive.files.list测试 方法drive.files.list用于列举或搜索文件。
与Microsoft OneDriveAPI仅列举请求目录下文件不同，方法drive.files.list列举文件时返回了所有目录和文件，例如子目录FolderTest1下的文件Class_cn_Tab.csv也在响应内容里面。
方法drive.files.get测试 方法drive.files.get用于通过ID获取文件元数据。下面获得Class_cn_Tab.csv文件的元数据。
方法drive.files.create测试 方法drive.files.create用于创建一个新文件。
在API Explorer中仅能指定新文件的元数据，没法上传文件内容，所以虽然测试成功且GoogleDrive里也会显示新的文件，但是打不开。这种仅指定元数据不提供内容的方式特别适合创建目录。
https://developers.google.com/drive/v3/web/manage-uploads里面说明了如何在创建或更新文件时上传文件内容。
通过Java JDK创建文件 与博文《Google Sheets API认证和鉴权》中获取访问令牌的差异如下：
GET https://accounts.google.com/o/oauth2/v2/auth? scope=**&amp;lt;font color=&amp;#34;#FF0000&amp;#34;&amp;gt;https://www.googleapis.com/auth/drive&amp;lt;/font&amp;gt;** https://www.googleapis.com/auth/drive.readonly profile&amp;amp;amp; redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;amp; response_type=code&amp;amp;amp; client_id=826380598768-5935tlo90sccvr691ofmp4nrvpthrnn6.apps.googleusercontent.com``` 代码如下： package com.yqu.gd;
import java.io.IOException; import java.util.Collections; import java.util.List;
import com.google.api.client.auth.oauth2.Credential; import com.google.api.client.googleapis.auth.oauth2.GoogleCredential; import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport; import com.google.api.client.http.FileContent; import com.google.api.client.http.HttpTransport; import com.google.api.client.json.JsonFactory; import com.google.api.client.json.jackson2.JacksonFactory; import com.google.api.services.drive.Drive; import com.google.api.services.drive.model.File; import com.google.api.services.drive.model.FileList;
public class HelloGoogleDrive {</description></item><item><title>使用OneDrive的根API资源</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8onedrive%E7%9A%84%E6%A0%B9api%E8%B5%84%E6%BA%90/</link><pubDate>Sun, 16 Oct 2016 06:40:59 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8onedrive%E7%9A%84%E6%A0%B9api%E8%B5%84%E6%BA%90/</guid><description>OneDrive的根API资源 可以使用OneDrive的这些根API资源来访问一个项目或驱动。
|路径|资源 |&amp;mdash;&amp;ndash; |/drive|用户的默认驱动。 |/drives|列举对认证用户可用的驱动。 |/drives/{drive-id}|通过ID访问一个特定驱动。 |/drives/{drive-id}/root/children|列举特定驱动根路径下项目。 |/drive/items/{item-id}|通过ID访问一个元素。 |/drive/special/{special-id}|通过已知名访问一个特殊（命名）目录。ID目前可取值为：documents、photos、cameraroll、approot、music。 |/shares/{share-id}|通过共享ID或共享URL访问一个元素。
元素可由路径定位，通过在任何元素或驱动URL后加冒号。
|路径|资源 |&amp;mdash;&amp;ndash; |/drive/root:/path/to/file|通过根绝对路径访问一个元素。 |/drive/items/{item-id}:/path/to/file|通过相对路径访问一个元素。 |/drive/root:/path/to/file:/children|通过根绝对路径列举一个元素的子项。 |/drive/items/{item-id}:/path/to/file:/children|通过相对路径列举一个元素的子项。
测试 获取默认驱动 列举可用驱动 通过ID获取指定驱动 列举特定驱动根路径下项目 通过ID访问一个目录&amp;quot;文档&amp;quot; 访问特殊目录documents 通过共享ID访问文件CN_EN_JP_KO.xlsx 将文件CN_EN_JP_KO.xlsx共享，获取其共享URL： 通过共享ID使用OneDrive API访问文件CN_EN_JP_KO.xlsx： 通过根绝对路径访问文件CN_EN_JP_KO.xlsx 注意root后有冒号： 通过相对路径访问文件CN_EN_JP_KO.xlsx 712B21FCE8E08C92!442是目录&amp;quot;文档&amp;quot;的ID，注意其后有冒号： 通过根绝对路径列举目录&amp;quot;文档&amp;quot;的子元素 注意root和路径（/文档）后都有冒号： 通过相对路径列举目录&amp;quot;FolderTest&amp;quot;的子元素 为了测试，首先我在目录&amp;quot;文档&amp;quot;创建子目录&amp;quot;FolderTest&amp;quot;，然后在目录&amp;quot;FolderTest&amp;quot;中创建mryqu.txt文件。
712B21FCE8E08C92!442是目录&amp;quot;文档&amp;quot;的ID，注意其后有冒号；路径（/FolderTest）后也有冒号。</description></item><item><title>Microsoft OneDrive API访问速率限制</title><link>https://mryqu.github.io/post/microsoft_onedrive_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6/</link><pubDate>Sat, 15 Oct 2016 06:11:28 +0000</pubDate><guid>https://mryqu.github.io/post/microsoft_onedrive_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6/</guid><description>一开始查看OneDrive文档Quota facet,，发现里面介绍的是OneDrive存储容量配额，跟API访问速率限制没有关系。除此之外，没有发现任何相关信息。 OneDrive文档Error response里面，看到如下跟访问速率限制相关的错误：
Status code: 429 (Too Many Requests)和509 (Bandwidth LimitExceeded) The code property: activityLimitReached (The app or user hasbeen throttled) Detailed error code: throttledRequest (Too many requests)</description></item><item><title>OneDrive认证时的"Public clients can't send a client secret."错误</title><link>https://mryqu.github.io/post/onedrive%E8%AE%A4%E8%AF%81%E6%97%B6%E7%9A%84public_clients_cant_send_a_client_secret%E9%94%99%E8%AF%AF/</link><pubDate>Fri, 14 Oct 2016 05:40:38 +0000</pubDate><guid>https://mryqu.github.io/post/onedrive%E8%AE%A4%E8%AF%81%E6%97%B6%E7%9A%84public_clients_cant_send_a_client_secret%E9%94%99%E8%AF%AF/</guid><description>在进行Microsoft OneDrive认证和登录实验的过程中，曾经用下列命令过去访问令牌：
POST https://login.live.com/oauth20_token.srf Content-Type: application/x-www-form-urlencoded client_id={client_id}&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf&amp;amp;client_secret={client_secret} &amp;amp;code={code}&amp;amp;grant_type=authorization_code 结果返回：
{&amp;#34;error&amp;#34;:&amp;#34;invalid_request&amp;#34;,&amp;#34;error_description&amp;#34;:&amp;#34;Public clients can&amp;#39;t send a client secret.&amp;#34;} 一个&amp;quot;public client&amp;quot;指的是移动或桌面应用(web服务则是&amp;quot;confidentialclient&amp;quot;)。由于跳转URI是https://login.live.com/oauth20_desktop.srf，因而MSA返回该错误响应。这种情况下，不应该提供client_secret，使用下列请求即可。
POST https://login.live.com/oauth20_token.srf Content-Type: application/x-www-form-urlencoded client_id={client_id}&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf&amp;amp;code={code}&amp;amp;grant_type=authorization_code</description></item><item><title>Microsoft OneDrive认证和登录</title><link>https://mryqu.github.io/post/microsoft_onedrive%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</link><pubDate>Thu, 13 Oct 2016 05:59:43 +0000</pubDate><guid>https://mryqu.github.io/post/microsoft_onedrive%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</guid><description>为OneDrive注册自己的应用 Registering your app for OneDrive API里面有提到，平台支持web和移动应用两种，而默认情况下是web应用，需要一或多个跳转URI。对于原生应用，可以选择移动应用。选择移动应用后跳转URI则变成urn:ietf:wg:oauth:2.0:oob（带外认证）了，正是我想要的结果！
OneDrive认证 OneDrive authentication and sign-in有个按钮可以获得测试Token，无需注册新的应用就可以请求到与登录账户绑定的、一个有效期1小时的开发者Token。从https://dev.onedrive.com/auth/get-token.js中我们可以看到其所用的http请求为TokenFlow，其跳转URI设为https://dev.onedrive.com/auth/callback.htm。而 OneDrive authentication and sign-in 中提到对于移动应用和桌面应用，跳转URI应设为https://login.live.com/oauth20_desktop.srf （注：使用urn:ietf:wg:oauth:2.0:oob的话，MSA连响应都没有）。
Token Flow测试 HTTP GET请求如下：
https://login.live.com/oauth20_authorize.srf?client_id=b9aaf3be-6892-42a5-8a04-4a87bc28ce7b&amp;amp;scope=onedrive.readonly+wl.signin&amp;amp;response_type=code&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf 响应如下，认证失败：
https://login.live.com/oauth20_desktop.srf?lc=1033#error=unsupported_response_type&amp;amp;error_description=The+provided+value+for+the+input+parameter+&amp;#39;response_type&amp;#39;+is+not+allowed+for+this+client.+Expected+value+is+&amp;#39;code&amp;#39;. 找了很久微软的帖子，也没说为什么Token Flow不要使，一直纠结是微软不支持还是我配置有问题。后来，看了RFC6749 The OAuth 2.0 Authorization Framework，才明白Token Flow就是规范里的Implicit GrantFlow。如果我的应用配置为web应用，是可以看到Allow ImplicitFlow选择框的。好吧，当选择移动应用时微软不支持Token Flow，我的配置没问题！！！
Code Flow测试 用于用户登录的HTTP GET请求如下： https://login.live.com/oauth20_authorize.srf?client_id=b9aaf3be-6892-42a5-8a04-4a87bc28ce7b&amp;amp;scope=onedrive.readonly+wl.signin&amp;amp;response_type=token&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf 请求用户授权：此时浏览器上地址变为： https://account.live.com/Consent/Update?ru=https://login.live.com/oauth20_authorize.srf?lc=1033&amp;amp;client_id=b9aaf3be-6892-42a5-8a04-4a87bc28ce7b&amp;amp;scope=onedrive.readonly+wl.signin&amp;amp;response_type=code&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf&amp;amp;uaid=78...e6&amp;amp;pid=...16&amp;amp;mkt=EN-US&amp;amp;scft=DSA...hfC&amp;amp;contextid=7F...D6&amp;amp;mkt=EN-US&amp;amp;uiflavor=host&amp;amp;id=27...69&amp;amp;uaid=78...e6&amp;amp;client_id=00...42&amp;amp;rd=none&amp;amp;scope=&amp;amp;cscope=onedrive.readonly+wl.signin 最终跳转的地址包含了code参数： 获取访问令牌的HTTP POST请求包含上面获得的code参数： POST https://login.live.com/oauth20_token.srf Content-Type: application/x-www-form-urlencoded client_id=b9aaf3be-6892-42a5-8a04-4a87bc28ce7b&amp;amp;redirect_uri=https://login.live.com/oauth20_desktop.srf&amp;amp;code=M9...5e-b...a-e...5-6685-d...06&amp;amp;grant_type=authorization_code 在OneDrive API中使用获得的访问令牌： 参考 Getting started with OneDrive API SDKs for OneDrive integration Registering your app for OneDrive API OneDrive authentication and sign-in Sign-in Microsoft Account &amp;amp; Azure AD users in a single app Develop with the OneDrive API getting #error=unsupported_response_type&amp;amp;error_description=AADSTS70005: with token request</description></item><item><title>Hello Microsoft OneDrive API</title><link>https://mryqu.github.io/post/hello_microsoft_onedrive_api/</link><pubDate>Wed, 12 Oct 2016 06:14:09 +0000</pubDate><guid>https://mryqu.github.io/post/hello_microsoft_onedrive_api/</guid><description>OneDriveAPI提供了一套HTTP服务用以将应用连接到OneDrive个人版、OneDrive商业版及SharePoint在线文档库上的文件和目录。OneDriveAPI使应用连接Office 365上文档及访问OneDrive和SharePoint上文件高级功能变得容易。
测试源 为了省事，就用我自己私人的OneDrive做测试吧。 获取Token 最省事的方法是在OneDrive authentication and sign-in里面获得测试Token，无需注册新的应用就可以请求到与登录账户绑定的、一个有效期1小时的开发者Token。
测试API 获取默认Drive 查看Drive 根目录内容 从上图可知，根目录包含一个包含&amp;quot;050709大同&amp;quot;子目录，该子目录的id为&amp;quot;712B21FCE8E08C92!112&amp;quot;。从整个响应内容可知，根目录包含&amp;quot;文档&amp;quot;子目录，其id为&amp;quot;712B21FCE8E08C92!442&amp;quot;。
查看Drive &amp;ldquo;文档&amp;quot;目录 该目录下有一个CN_EN_JP_KO.xlsx文件，其@content.downloadUrl属性值为下载链接。
获取CN_EN_JP_KO.xlsx文件 如果将链接直接放入浏览器，下载后将文件名变更成xlsx后缀，即可用Excel打开。
参考 Develop with the OneDrive API</description></item><item><title>比较OneDrive、OneDriveforBusiness和Office365</title><link>https://mryqu.github.io/post/%E6%AF%94%E8%BE%83onedriveonedriveforbusiness%E5%92%8Coffice365/</link><pubDate>Tue, 11 Oct 2016 05:43:57 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%AF%94%E8%BE%83onedriveonedriveforbusiness%E5%92%8Coffice365/</guid><description>OneDrive与OneDrive for Business的区别 OneDrive与OneDrive for Business名字接近，如果认为是个人版和商业版的区别，OneDrive forBusiness在OneDrive基础上增加一些商业高级功能，那就没有正确理解二者的区别。
OneDrive（以前称之为SkyDrive）是微软提供的云端私人存储，通过Microsoft账户或Outlook.com获得。使用OneDrive在云上存储文档、图片和其他文件，可以共享给好友，甚至内容协作。可以随意决定你自己的使用方式。 OneDrive forBusiness是用于商业目的的在线存储，它既可以在微软云上也可以在组织/企业的SharePoint服务器上。OneDrive forBusiness是Office365或SharePoint服务器的主要组成部分，提供存储、共享和同步团队或项目工作文档的地方。你的OneDrive forBusiness由你的工作组织/企业管理，以便进行工作文档协作。你的工作组织/企业的网站集管理员控制你对文档库的权限。 功能桌面同步- Windows PC- Mac OS(Soon)移动应用- Windows Tablet- Android- iOS- Windows Phone- XBox在浏览器内创建/编辑Office文档与桌面版Office 集成实时协同编辑Office文档文档版本和历史信息- 简单自动创建版本和版本恢复- 版本管理(主次版本或仅主版本，手动创建版本需要checkout选项和其他高级版本选项)多重身份认证支持审计与报告
用于细颗粒度控制的高级管理功能
审批工作流使用SharePoint Designer创建定制工作流对文档创建列添加自己的元数据高级安全管理对内容创建视图(可保存视图、过滤器等等)创建列表进行数据管理(通告、任务、联系人等等)保留策略(取决于SharePoint计划)文档模板eDiscoverySharePoint提供的功能SSO/ADFS/Directory同步支持内建标准一致性存储容量5GB/15GB1TB/5TB Office 365 Office 365是一套用于个人、教育或商业活动的云服务。商业和企业计划可提供一套提高生产效率的产品。使用Office365，可以获得的Office应用(Word、Excel、PowerPoint、OneNote、Outlook和Publisher)，以及50GB邮箱容量、用于企业即时消息、音视频电话和web会议的Skypefor Business、作为企业社交网络的Yammer、用于文件管理的SharePoint及1TB的OneDrive存储。
参考 OneDrive for Business vs OneDrive – Know the difference OneDrive, OneDrive for Business, and Office 365: What’s Best? What is OneDrive for Business?
Ultimate Guide in choosing between OneDrive, OneDrive for Business and Office 365</description></item><item><title>在线文档/存储 API/SDK</title><link>https://mryqu.github.io/post/%E5%9C%A8%E7%BA%BF%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8_apisdk/</link><pubDate>Mon, 10 Oct 2016 06:08:44 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8%E7%BA%BF%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8_apisdk/</guid><description>本博文是社交媒体API/SDK的姊妹篇。
社交媒体API编程平台/语言OneDrive Filepicker SDK:
快速下载或链接在OneDrive中的文件，或将文件保存到OneDrive官方:
AndroidiOS （使用UIDocumentPicker约定）Web /JavaScriptWindows（使用FileOpenPicker或 FileSavePicker）
OneDrive APISDK:
操作OneDrive上的文件，无需处理认证、JSON解析、HTTP连接等细节官方:
Windows .NET / C#/ XamariniOSPython（目前不支持OneDrive for Business）AndroidGoogle SheetsAPI SDK:
访问和更新Google电子表格官方:
AndroidGoiOSJavaJavaScript.NETNode.jsPHPPythonRubyGoogle Drive APISDK:
在移动/web应用中读、写和同步在Google Drive上的文件官方:
AndroidGoiOS (Object-C&amp;amp; Swift)JavaJavaScript.NETNode.jsPHPPythonRubyDropbox API SDK:
操作Dropbox上的文件官方:
.NETJavaJavaScriptPythonSwiftObjective-C社区:
AndroidGoJavaJavaScriptObjective-CNode.jsPHPSwiftBox API SDK:
操作Box上的文件官方:
Java.NETNode.jsPythonRubyChromeSalesforceIOSAndroidWindows(Mobile)iCloud APISDK:
操作iCloud上的资源官方:
CloudKit JS库CloudKitSwift库CloudKitObjective-C库社区:
PythonJavaAmazonDrive API :
操作Amazon Drive上的文件</description></item><item><title>使用Tableau导入Google Analytics</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8tableau%E5%AF%BC%E5%85%A5google_analytics/</link><pubDate>Thu, 06 Oct 2016 06:03:22 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8tableau%E5%AF%BC%E5%85%A5google_analytics/</guid><description>配置界面 Date Range配置选项 Segment配置选项 Dimension配置选项 Measure Group配置选项 Measure配置选项</description></item><item><title>Dropbox API访问速率限制</title><link>https://mryqu.github.io/post/dropbox_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6/</link><pubDate>Wed, 05 Oct 2016 06:06:00 +0000</pubDate><guid>https://mryqu.github.io/post/dropbox_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6/</guid><description>Dropbox的Data ingress guide介绍了关于Dropbox API访问速率限制。 错误Status code: 429 (Too ManyRequests)用于表示API访问速率超限，如果响应包内容为JSON，则包含too_many_requests或too_many_write_operations值进行更进一步说明。 关联用户的应用，访问速率限制仅适用于每用户。一个用户关联多个应用，各应用互不影响。 关联团队的应用当调用商业端点（BusinessEndpoint），访问速率限制仅适用于每个团队。如果应用有团队成员文件访问权限但是正在调用用户端点（UserEndpoint），访问速率限制仅适用于每个团队成员。这意味着，对于关联团队的应用，一个团队关联多个应用，各应用互不影响；单个应用代表多个团队成员的请求，也不会影响团队成员彼此的访问速率限制。 超过速率限制后的响应包含一个Retry-After头，提供按秒计的等待间隔值，应用在这段时间内不应重试请求以免再获得速率限制响应。 Dropbox不会公布其API速率限制值，开发时要假设Dropbox会在今后调整其API速率限制。</description></item><item><title>Hello Dropbox API</title><link>https://mryqu.github.io/post/hello_dropbox_api/</link><pubDate>Tue, 04 Oct 2016 05:53:29 +0000</pubDate><guid>https://mryqu.github.io/post/hello_dropbox_api/</guid><description>本博文用来记录一下粗略体验Dropbox关于用户、文件、共享三方面API的过程。
准备环境 还是用我私人的Dropbox做测试，所以只显示Public目录下的东东了。 用户类API测试 方法get_current_account测试 方法get_account测试 方法get_space_usage测试 文件类API测试 方法list_folder测试 方法list_folder其实是列举文件和目录，而且是分层的。如果path没设，则显示根目录下的元素。
方法get_metadata测试 方法get_metadata用于获取一个元素（文件/目录）的元数据。
方法create_folder测试 方法get_preview测试 方法get_preview仅支持 .doc、 .docx、 .docm、 .ppt、 .pps、 .ppsx、 .ppsm、.pptx、.pptm、 .xls、 .xlsx、 .xlsm、.rtf文件类型。就我的测试而言，没看出跟下面的download方法有多大区别。
这里尝试了一下path的其他使用方式。除了最常规的文件路径外，path参数还可以使用id或rev。
方法download测试 方法search测试 方法upload测试 方法delete测试 方法delete用于删除一个元素（文件/目录）。
方法permanently_delete测试 方法permanently_delete是支持Dropbox商业应用，而我的是开发应用，因而测试失败。
共享类API测试 方法share_folder测试 方法list_folders测试 方法unshare_folder测试 方法unshare_folder使用的是异步任务的方式，需要通过下列的方法check_job_status查询任务进度及结果。
方法check_job_status测试 方法create_share_link测试 share_folder可以通过邮件或Dropbox账户的方式分享给其他Dropbox用户，而share_link甚至可以共享给没有安装Dropbox的使用者。
方法get_share_links测试 方法get_shared_link_file测试 方法revoke_shared_link测试 revoke_shared_link竟然不返回结果，查证文档后确实如此。
学习总结 Dropbox关于文件共享方面的API占比相对OneDrive、Google Drive要多一些。 Dropbox API相对OneDrive、GoogleDrive而言，成熟度更低。按照REST的Richardson成熟度模型来说仅在2-级别，它的REST资源还是动词，例如get_metadata、check_job_status。
参考 Dropbox Dropbox API v2 for HTTP Developers Dropbox API Explorer</description></item><item><title>Dropbox认证和登录</title><link>https://mryqu.github.io/post/dropbox%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</link><pubDate>Mon, 03 Oct 2016 05:44:29 +0000</pubDate><guid>https://mryqu.github.io/post/dropbox%E8%AE%A4%E8%AF%81%E5%92%8C%E7%99%BB%E5%BD%95/</guid><description>为Dropbox申请自己的应用 Dropbox OAuth Guide提到：对于命令行或桌面应用，没办法让浏览器重定向回你的应用。这种情况下，你的应用无需包含redirect_uri参数。Dropbox将向用户显示认证码，以用于复制到你的应用来获得可重用的访问令牌。基于此，对于桌面应用，redirect_uri不用设置；对于web应用，我选择了http://localhost以便测试。Dropbox网站没有提及urn:ietf:wg:oauth:2.0:oob。 Dropbox认证 Token Flow测试 HTTP GET请求如下：
https://www.dropbox.com/oauth2/authorize?client_id=**3t...hi**&amp;amp;redirect_uri=http://localhost&amp;amp;response_type=token&amp;amp;state=dsxoekdmpyt 成功跳转到如下URI：
http://localhost/#access_token= 连App secret都不用，仅凭App Key就可以获得访问令牌！看来还是认证码方式更安全一些。最后把应用的Allowimplicit grant选项改成Disallow以确保安全。
Code Flow测试 HTTP GET请求如下：
https://www.dropbox.com/oauth2/authorize?client_id=3t...hi&amp;amp;response_type=code&amp;amp;state=wecidskklsxpxl123 请求用户授权： 显示认证码： 获取访问令牌的HTTP POST请求包含上面获得的code参数：
POST https://api.dropboxapi.com/1/oauth2/token Content-Type: application/x-www-form-urlencoded Cache-Control: no-cache code=oV...9I&amp;amp;amp;client_id=3t...hi&amp;amp;amp;client_secret=j...7&amp;amp;amp;grant_type=authorization_code 参考 Dropbox API
Dropbox OAuth Guide Dropbox authorize API Dropbox token API</description></item><item><title>Tableau不支持导入OneDrive文件？</title><link>https://mryqu.github.io/post/tableau%E4%B8%8D%E6%94%AF%E6%8C%81%E5%AF%BC%E5%85%A5onedrive%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 02 Oct 2016 05:39:38 +0000</pubDate><guid>https://mryqu.github.io/post/tableau%E4%B8%8D%E6%94%AF%E6%8C%81%E5%AF%BC%E5%85%A5onedrive%E6%96%87%E4%BB%B6/</guid><description>没有发现Tableau的Microsoft OneDrive连接器，OData连接器和WebData连接器都不成。查了一下Tableau社区，就寥寥无几的几个帖子提到OneDrive。其中一个帖子提到了Using OneDrive as a Tableau Data Source。这个博文在2015年5月提到Tableau还不支持直连OneDrive上的文件，建议用OneDrive SyncApp同步到Tableau服务器上再导入。 貌似现在还是如此！！</description></item><item><title>使用Tableau导入Google Sheets</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8tableau%E5%AF%BC%E5%85%A5google_sheets/</link><pubDate>Sat, 01 Oct 2016 06:02:55 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8tableau%E5%AF%BC%E5%85%A5google_sheets/</guid><description>尝试一下用Tableau导入Google Sheets，操作过程中没看到配置项，比较简洁。
用Google账户授权Tableau 显示所有电子表格 选择一个电子表格 导入一个电子表格 参考 Connect Directly to Google Sheets in Tableau 10 Tableau connector examples</description></item><item><title>在Google API中使用访问令牌的三种方式</title><link>https://mryqu.github.io/post/%E5%9C%A8google_api%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8C%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</link><pubDate>Thu, 29 Sep 2016 05:33:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8google_api%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8C%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid><description>在Google Developers OAuth 2.0 playground 中设置OAuth2.0配置时，可以发现有一个访问令牌位置的选择框，其值为：
Authorization header w/ OAuth prefix Authorization header w/ Bearer prefix Access_token URL parameter 按照前面博文《Google Sheets API认证和鉴权 》中的方法生成一个访问令牌。下面我就用这个访问令牌对这三种使用方式进行一下尝试。
认证头使用OAuth前缀 认证头使用Bearer前缀 使用access_token URL参数 结论：这三种访问令牌位置的使用都工作正常，API结果相同！</description></item><item><title>Hello Google Sheets API</title><link>https://mryqu.github.io/post/hello_google_sheets_api/</link><pubDate>Wed, 28 Sep 2016 06:00:05 +0000</pubDate><guid>https://mryqu.github.io/post/hello_google_sheets_api/</guid><description>准备环境 首先在Google Sheets创建了SpreadSheetTest1和To-do list两个电子表格，以备使用。 API测试 方法spreadsheets.get测试 方法spreadsheets.get可以获得一个电子表格中所有表单的内容和元数据。 下面是用Postman进行同样操作： 方法spreadsheets.values.get测试 方法spreadsheets.values.get可以获得一个电子表格中所有表单的内容。 方法spreadsheets.create测试 方法spreadsheets.create可以创建一个新的电子表格。 查看GoogleSheets，也可以看到新创建的电子表格SpreadSheetCreate1。由于我的请求里没有数据，因此下图中数据区也是空空。 方法spreadsheets.values.append测试 方法spreadsheets.values.append可以向电子表格中添加内容。 查看Google Sheets，也可以看到刚才创建的电子表格SpreadSheetCreate1有了九个单元格新数据。 学习结论 Google Sheets API可以创建、读取和修改电子表格，但是没有找到删除电子表格的方法。 Google SheetsAPI可以创建、读取、修改和删除一个电子表格内容，例如方法spreadsheets.batchUpdate中deleteSheet就可以删除一个表单，而deleteDimension就可以删除一个表单中的行/列。
参考 Google Sheets Google Sheets API Google API Explorer: Sheets</description></item><item><title>Google Sheets API认证和鉴权</title><link>https://mryqu.github.io/post/google_sheets_api%E8%AE%A4%E8%AF%81%E5%92%8C%E9%89%B4%E6%9D%83/</link><pubDate>Tue, 27 Sep 2016 05:44:22 +0000</pubDate><guid>https://mryqu.github.io/post/google_sheets_api%E8%AE%A4%E8%AF%81%E5%92%8C%E9%89%B4%E6%9D%83/</guid><description>玩一把用于Google Sheets API的OAuth2认证，以获得用于Sheets API的访问令牌。
注册Google Sheets应用 首先在Google API Console注册一个应用： Google Sheets API鉴权 用于用户登录的HTTPGET请求如下（scope选择了profile、对文件元数据和内容只读访问、对表单和属性只读访问）： GET https://accounts.google.com/o/oauth2/v2/auth? scope=https://www.googleapis.com/auth/spreadsheets.readonly https://www.googleapis.com/auth/drive.readonly profile&amp;amp; redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp; response_type=code&amp;amp; client_id=826380598768-5935tlo90sccvr691ofmp4nrvpthrnn6.apps.googleusercontent.com 首先要求用户登录：要求登录后用户的授权：返回页面包含授权码： 获取访问令牌的HTTPPOST请求包含上面获得的授权码（在创建Google应用时获得的client_id和client_secret）： POST https://www.googleapis.com/oauth2/v4/token Content-Type: application/x-www-form-urlencoded code=4/-qpp...qA&amp;amp; client_id=826380598768-5935tlo90sccvr691ofmp4nrvpthrnn6.apps.googleusercontent.com&amp;amp; client_secret=5...r&amp;amp; redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp; grant_type=authorization_code 参考 Google Sheets Google Sheets API Authorize Google Sheets API Requests Using OAuth 2.0 for Mobile and Desktop Applications Using OAuth 2.0 for Web Server Applications</description></item><item><title>[Maven] 构建多模块项目</title><link>https://mryqu.github.io/post/maven_%E6%9E%84%E5%BB%BA%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE/</link><pubDate>Sat, 03 Sep 2016 07:07:55 +0000</pubDate><guid>https://mryqu.github.io/post/maven_%E6%9E%84%E5%BB%BA%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE/</guid><description>在前一篇博文[Gradle] 将多项目转换成Maven项目中利用Gradle转换成Maven构建脚本，将朋友糊弄过去了。后来想想，还是给他做一个重头搭建多模块Maven项目的演示吧。
创建根（父）项目 下列脚本可以创建一个包含pom.xml的yqu-ts-parent目录：
mvn archetype:generate -DgroupId=com.yqu.ts -DartifactId=yqu-ts-parent -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 测试结果： 进入yqu-ts-parent目录，删除src子目录，然后将pom.xml文件中packaging节点内容由jar改为pom。pom表示它是一个被继承的模块
创建子项目 在yqu-ts-parent目录中运行下列脚本可以创建两个包含pom.xml文件的子目录yqu-ts-service和yqu-ts-webapp：
mvn archetype:generate -DgroupId=com.yqu.ts -DartifactId=yqu-ts-service -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false mvn archetype:generate -DgroupId=com.yqu.ts -DartifactId=yqu-ts-webapp -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 测试结果： 这两个命令会修改yqu-ts-parent项目的pom.xml，增加了两个子模块yqu-ts-service和yqu-ts-webapp。对于两个字模块的pom.xml，增加packaging节点，由于这两个子模块将用SpringBoot实现因而内容都为jar。
确认项目/模块的pom.xml yqu-ts-parent项目的pom.xml yqu-ts-service模块的pom.xml yqu-ts-webapp模块的pom.xml</description></item><item><title>[Gradle] 将多项目转换成Maven项目</title><link>https://mryqu.github.io/post/gradle_%E5%B0%86%E5%A4%9A%E9%A1%B9%E7%9B%AE%E8%BD%AC%E6%8D%A2%E6%88%90maven%E9%A1%B9%E7%9B%AE/</link><pubDate>Fri, 02 Sep 2016 05:46:07 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%B0%86%E5%A4%9A%E9%A1%B9%E7%9B%AE%E8%BD%AC%E6%8D%A2%E6%88%90maven%E9%A1%B9%E7%9B%AE/</guid><description>手头有一个构建多项目的Gradle构建脚本，但是一个哥们问我能不能换成Maven的，搜到一篇gradle项目与maven项目相互转化，照着实践，证明多项目构建也是可行的。
文件结构介绍 ts-demo目录 setting.gradle build.gradle ts-service目录 build.gradle src目录 ts-webapp目录 build.gradle src目录 ts-demo/setting.gradle rootProject.name = &amp;#39;ts-demo&amp;#39; include &amp;#34;ts-service&amp;#34; include &amp;#34;ts-webapp&amp;#34; project(&amp;#34;:ts-service&amp;#34;).name = &amp;#34;ts-service&amp;#34; project(&amp;#34;:ts-webapp&amp;#34;).name = &amp;#34;ts-webapp&amp;#34; ts-demo/build.gradle buildscript { repositories { mavenCentral() } } allprojects { apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#39;maven&amp;#39; repositories { mavenCentral() } group = &amp;#39;com.yqu&amp;#39; version = &amp;#39;0.1.0&amp;#39; task writeNewPom { pom { project { inceptionYear &amp;#39;2016&amp;#39; licenses { license { name &amp;#39;The Apache Software License, Version 2.</description></item><item><title>安装Tableau Public</title><link>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85tableau_public/</link><pubDate>Tue, 30 Aug 2016 06:18:43 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85tableau_public/</guid><description>Tableau Public的安装文件可在http://public.tableau.com/s/下载。 安装后创建Tableau Public账户，并进入注册所用信箱激活账户即可。
Tableau Public可导入的服务器很有限，Tableau Desktop就丰富多了。</description></item><item><title>在Coursera上选了几门Tableau课程</title><link>https://mryqu.github.io/post/%E5%9C%A8coursera%E4%B8%8A%E9%80%89%E4%BA%86%E5%87%A0%E9%97%A8tableau%E8%AF%BE%E7%A8%8B/</link><pubDate>Mon, 29 Aug 2016 06:09:47 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8coursera%E4%B8%8A%E9%80%89%E4%BA%86%E5%87%A0%E9%97%A8tableau%E8%AF%BE%E7%A8%8B/</guid><description>今天在赤兔数据挖掘群里看到有人说Coursera上有Tableau课程，有机会学习一下我司竞争对手的课程，也是不错的。
有五门课程属于加州大学的使用Tableau可视化商业数据专业课系列：
Fundamentals of Visualization with Tableau Essential Design Principles for Tableau Explaining Your Data Using Tableau Creating Dashboards and Storytelling with Tableau Data Visualization with Tableau Project 有一门课程属于杜克大学的Excel到MySQL: 用于商业的分析技术专业课系列：
Data Visualization and Communication with Tableau 当然现在这些课只能听一听，不掏钱是没有分数的</description></item><item><title>[Hue] 清空MySQL数据库的hue.django_content_type表时遇到由于外键约束无法删除错误!</title><link>https://mryqu.github.io/post/hue_%E6%B8%85%E7%A9%BAmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84hue.django_content_type%E8%A1%A8%E6%97%B6%E9%81%87%E5%88%B0%E7%94%B1%E4%BA%8E%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF/</link><pubDate>Fri, 26 Aug 2016 05:24:54 +0000</pubDate><guid>https://mryqu.github.io/post/hue_%E6%B8%85%E7%A9%BAmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84hue.django_content_type%E8%A1%A8%E6%97%B6%E9%81%87%E5%88%B0%E7%94%B1%E4%BA%8E%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF/</guid><description>Hue （Hadoop User Experience）是一个使用ApacheHadoop分析数据的Web界面。它可以：
将数据加载到Hadoop 查看数据、处理数据或准备数据 分析数据、搜索数据、对数据进行可视化分析 默认Hue服务器使用嵌入式数据库SQLite存储元数据和查询信息。当我将其迁移到MySQL时，按照Cloudera - Hue Installation Guide的步骤同步数据库时后清空MySQL中的django_content_type表时遭遇下列问题：
hadoop@node50064:~$ $HUE_HOME/build/env/bin/hue syncdb --noinput Syncing... Creating tables ... Creating table auth_permission Creating table auth_group_permissions Creating table auth_group Creating table auth_user_groups Creating table auth_user_user_permissions Creating table auth_user Creating table django_openid_auth_nonce Creating table django_openid_auth_association Creating table django_openid_auth_useropenid Creating table django_content_type Creating table django_session Creating table django_site Creating table django_admin_log Creating table south_migrationhistory Creating table axes_accessattempt Creating table axes_accesslog Installing custom SQL .</description></item><item><title>[Hue] 解决Filesystem root '/' should be owned by 'hdfs'</title><link>https://mryqu.github.io/post/hue_%E8%A7%A3%E5%86%B3filesystem_root_should_be_owned_by_hdfs/</link><pubDate>Wed, 24 Aug 2016 05:36:55 +0000</pubDate><guid>https://mryqu.github.io/post/hue_%E8%A7%A3%E5%86%B3filesystem_root_should_be_owned_by_hdfs/</guid><description>安装Hue后，通过about页面检查配置，有一个提示：Filesystemroot &amp;lsquo;/&amp;rsquo; should be owned by &amp;lsquo;hdfs&amp;rsquo; 我在hadoop集群都使用用户hadoop，并没有创建用户hdfs。解决方案是将hue.ini中的default_hdfs_superuser设置：
# This should be the hadoop cluster admin default_hdfs_superuser=hadoop 重启Hue后警告解除，呵呵。</description></item><item><title>了解GSA(Google Search Appliance)</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3gsagoogle_search_appliance/</link><pubDate>Tue, 23 Aug 2016 05:31:01 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3gsagoogle_search_appliance/</guid><description>今天的公司邮件有提及GSA，才了解了一下这个被谷歌停止研发的产品。 GSA(Google Search Appliance)是由Google公司出品的提供文件索引功能的一种机架设备，用于企业内部局域网、web服务、门户、文件共享服务、Sharepoint、数据库、内容管理系统、企业应用的实时数据（例如ERP）、基于云的系统（例如谷歌文档）的搜索。操作系统能够为CentOS，软件由谷歌出品，硬件由戴尔制造。当前GSA版本7.6，分两种型号：G100支持2千万文档，G500支持一亿文档。 2016年初谷歌向商业伙伴和客户发了一封密信：GSA在2018年后将被中止。自2016年不再进行三年牌照续期，2017年仅对已有硬件客户进行一年牌照续期。在此期间，谷歌将继续修复问题、提供安全更新和技术支持。 一点感言：以前是一直很酸爽，用不到后是心里狂奔“呵呵呵”，这真是一个好产品。
参考 Google Search Appliance WIKI: Google Search Appliance&amp;quot; Forbes: So Long Google Search Appliance</description></item><item><title>搞清楚CONSUL_PORT_8500_TCP_ADDR</title><link>https://mryqu.github.io/post/%E6%90%9E%E6%B8%85%E6%A5%9Aconsul_port_8500_tcp_addr/</link><pubDate>Mon, 22 Aug 2016 05:41:54 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%90%9E%E6%B8%85%E6%A5%9Aconsul_port_8500_tcp_addr/</guid><description>Consul集群里既有Server也有Client。那除了Consul serverleader，其他节点怎么加入这个Consul集群里呢？我目前看到的Docker方案是其他节点使用consul agent -join$CONSUL_PORT_8500_TCP_ADDR加入Consul集群的。那么CONSUL_PORT_8500_TCP_ADDR是怎么设置到其他容器节点的？
root@httpd:/# env CONSUL_PORT_8300_TCP_PORT=8300 CONSUL_PORT_53_TCP_PORT=53 VAGRANT_CONSUL_1_PORT_8301_UDP_ADDR=172.17.0.2 HOSTNAME=httpd CONSUL_PORT_8301_TCP_PROTO=tcp VAGRANT_CONSUL_1_PORT_8302_TCP_PORT=8302 VAGRANT_CONSUL_1_PORT_53_UDP_PROTO=udp CONSUL_1_PORT_8300_TCP_ADDR=172.17.0.2 VAGRANT_CONSUL_1_PORT_8301_TCP_ADDR=172.17.0.2 CONSUL_1_PORT_8400_TCP=tcp://172.17.0.2:8400 CONSUL_1_PORT_53_UDP=udp://172.17.0.2:53 CONSUL_1_PORT_8300_TCP_PROTO=tcp APACHE_RUN_USER=www-data VAGRANT_CONSUL_1_PORT_8301_TCP_PROTO=tcp CONSUL_PORT_8301_UDP=udp://172.17.0.2:8301 VAGRANT_CONSUL_1_PORT_8400_TCP_ADDR=172.17.0.2 CONSUL_PORT_53_TCP_ADDR=172.17.0.2 VAGRANT_CONSUL_1_PORT_8301_UDP_PORT=8301 CONSUL_1_PORT_53_TCP=tcp://172.17.0.2:53 CONSUL_1_PORT_8300_TCP_PORT_START=8300 CONSUL_PORT_53_TCP_PROTO=tcp VAGRANT_CONSUL_1_PORT_8302_TCP=tcp://172.17.0.2:8302 VAGRANT_CONSUL_1_PORT_8300_UDP_END=udp://172.17.0.2:8302 CONSUL_1_NAME=/vagrant_httpd_1/consul_1 CONSUL_1_PORT_8300_UDP_PORT_END=8302 VAGRANT_CONSUL_1_PORT_53_TCP_PROTO=tcp CONSUL_1_PORT_8500_TCP=tcp://172.17.0.2:8500 CONSUL_PORT_53_UDP_ADDR=172.17.0.2 CONSUL_PORT_8300_TCP_PORT_START=8300 CONSUL_1_PORT_53_TCP_PORT=53 CONSUL_1_PORT_8302_UDP_PORT=8302 VAGRANT_CONSUL_1_PORT_8400_TCP=tcp://172.17.0.2:8400 CONSUL_1_PORT_8300_UDP_END=udp://172.17.0.2:8302 CONSUL_PORT_8302_UDP_PORT=8302 CONSUL_PORT_8302_TCP_ADDR=172.17.0.2 VAGRANT_CONSUL_1_PORT_8301_UDP_PROTO=udp CONSUL_1_PORT_8302_TCP_PORT=8302 CONSUL_1_PORT_8301_TCP=tcp://172.17.0.2:8301 CONSUL_ENV_CONSUL_OPTIONS=-bootstrap -client 0.0.0.0 VAGRANT_CONSUL_1_PORT_8302_UDP_PORT=8302 CONSUL_1_PORT_8302_UDP=udp://172.17.0.2:8302 CONSUL_PORT_53_UDP_PORT=53 VAGRANT_CONSUL_1_PORT_8302_UDP_PROTO=udp VAGRANT_CONSUL_1_PORT_8300_TCP_START=tcp://172.17.0.2:8300 CONSUL_PORT_8302_UDP_ADDR=172.17.0.2 CONSUL_PORT_8300_TCP=tcp://172.17.0.2:8300 CONSUL_1_PORT_8302_TCP_ADDR=172.17.0.2 CONSUL_1_PORT_53_TCP_PROTO=tcp VAGRANT_CONSUL_1_PORT_53_TCP=tcp://172.17.0.2:53 CONSUL_1_PORT_8302_UDP_PROTO=udp VAGRANT_CONSUL_1_PORT_8300_TCP=tcp://172.17.0.2:8300 CONSUL_1_PORT_8301_TCP_PROTO=tcp CONSUL_PORT_8400_TCP=tcp://172.17.0.2:8400 VAGRANT_CONSUL_1_PORT_8500_TCP_PROTO=tcp CONSUL_PORT_8301_TCP_PORT=8301 VAGRANT_CONSUL_1_PORT_53_UDP_PORT=53 VAGRANT_CONSUL_1_PORT_8300_TCP_PROTO=tcp CONSUL_1_PORT_8301_UDP_ADDR=172.17.0.2 CONSUL_1_PORT_8300_TCP_START=tcp://172.17.0.2:8300 APACHE_LOG_DIR=/var/log/apache2 CONSUL_PORT_53_TCP=tcp://172.17.0.2:53 VAGRANT_CONSUL_1_PORT_8301_TCP_PORT=8301 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin CONSUL_PORT_8500_TCP_ADDR=172.</description></item><item><title>Hello UnRAVL</title><link>https://mryqu.github.io/post/hello_unravl/</link><pubDate>Thu, 18 Aug 2016 05:47:19 +0000</pubDate><guid>https://mryqu.github.io/post/hello_unravl/</guid><description>UnRAVL介绍 UnRAVL（Uniform REST API ValidationLanguage）是用于验证REST应用编程接口的JSON领域特定语言。UnRAVL由SAS架构师DavidBiesack实现，并作为SAS开源软件在GitHub上发布。
UnRAVL脚本包含一个REST API调用的JSON描述:
HTTP方法（GET、POST、PUT、DELETE、HEAD、PATCH） URI (可选的)HTTP头 (可选的)请求消息体 (可选的)认证 对于每个API调用，一个UnRAVL脚本可以包含用于验证结果的一或多个断言。某些断言可以表达为前置条件，即在进行API调用之前必须为真。下列内容可以断言：
结果消息体匹配期望的JSON、文本或其他数据 存在带有特定值的特定头 HTTP状态码为特定值或在特定集合内 响应消息体匹配基准（benchmark） 通过Groovy表达式测试响应或环境变量中的元素为真 一个环境变量已赋值 UnRAVL也支持从RESTAPI调用结果中抽取数据、与环境变量进行数据绑定并用于之后的API调用验证。例如，将一个创建资源的POST 调用响应的Location 头进行保存，并将此URL用于后继GET 、PUT 、DELETE 调用。 模板功能提供了可重用的API验证构建能力。
UnRAVL示例 build.gradle buildscript { repositories { mavenCentral() } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; jar { baseName = &amp;#39;HelloUnRAVL&amp;#39; version = &amp;#39;0.1.0&amp;#39; } repositories { mavenCentral() } sourceCompatibility = 1.7 targetCompatibility = 1.7 ext { jacksonVersion = &amp;#34;2.5.+&amp;#34; groovyVersion = &amp;#34;2.</description></item><item><title>[RabbitMQ] AutorecoveringConnection在连接恢复后才调用ShutdownListener</title><link>https://mryqu.github.io/post/rabbitmq_autorecoveringconnection%E5%9C%A8%E8%BF%9E%E6%8E%A5%E6%81%A2%E5%A4%8D%E5%90%8E%E6%89%8D%E8%B0%83%E7%94%A8shutdownlistener/</link><pubDate>Sat, 13 Aug 2016 06:00:17 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_autorecoveringconnection%E5%9C%A8%E8%BF%9E%E6%8E%A5%E6%81%A2%E5%A4%8D%E5%90%8E%E6%89%8D%E8%B0%83%E7%94%A8shutdownlistener/</guid><description>想玩一玩RabbitMQ中的ShutdownListener和RecoveryListener，又不想写自己的重连接逻辑，所以使用了ConnectionFactory类的setAutomaticRecoveryEnabled方法让其自动恢复连接。代码如下：
package com.yqu.rabbitmq; import com.rabbitmq.client.*; import java.io.IOException; public class AutoRecoveryRecv { private final static String QUEUE_NAME = &amp;#34;hello&amp;#34;; public static void main(String[] argv) throws Exception { try { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(ConnectionFactoryConfiguration.HOST); factory.setUsername(ConnectionFactoryConfiguration.USERNAME); factory.setPassword(ConnectionFactoryConfiguration.PASSWORD); factory.setAutomaticRecoveryEnabled(true); factory.setNetworkRecoveryInterval(10000); Connection connection = factory.newConnection(); connection.addShutdownListener(new ShutdownListener() { @Override public void shutdownCompleted(ShutdownSignalException cause) { String hardError = &amp;#34;&amp;#34;; String applInit = &amp;#34;&amp;#34;; if (cause.isHardError()) { hardError = &amp;#34;connection&amp;#34;; } else { hardError = &amp;#34;channel&amp;#34;; } if (cause.</description></item><item><title>[RabbitMQ] 了解多个同名rabbitmq-server文件</title><link>https://mryqu.github.io/post/rabbitmq_%E4%BA%86%E8%A7%A3%E5%A4%9A%E4%B8%AA%E5%90%8C%E5%90%8Drabbitmq-server%E6%96%87%E4%BB%B6/</link><pubDate>Fri, 12 Aug 2016 06:13:28 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_%E4%BA%86%E8%A7%A3%E5%A4%9A%E4%B8%AA%E5%90%8C%E5%90%8Drabbitmq-server%E6%96%87%E4%BB%B6/</guid><description>安装完RabbitMQ后，查了查机器中多了六个rabbitmq-server文件，除了两个位于/usr/lib/rabbitmq目录下的可以不理，其他都有什么区别呢？ 下面针对这四个文件进行一下介绍：
/etc/init.d/rabbitmq-server： RabbitMQ服务器的开机自启动脚本 /usr/sbin/rabbitmq-server： init脚本所启动的主服务器程序脚本 /etc/logrotate.d/rabbitmq-server：logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。该文件是针对rabbitmq-server的logrotate配置，默认情况下logrotate每周对/var/log/rabbitmq/下的log文件进行处理。 /usr/lib/ocf/resource.d/rabbitmq/rabbitmq-server：OCF指开放集群框架（Open Clustering Framework）。当使用pacemaker配置RabbitMQHA时，作为OCF 资源代理脚本，用于操作和监控RabbitMQ节点。OCF 规范（尤其是与资源代理相关的部分）详见在Open Clustering Framework Resource Agent API。</description></item><item><title>[RabbitMQ] 强制杀死RabbitMQ进程</title><link>https://mryqu.github.io/post/rabbitmq_%E5%BC%BA%E5%88%B6%E6%9D%80%E6%AD%BBrabbitmq%E8%BF%9B%E7%A8%8B/</link><pubDate>Thu, 11 Aug 2016 05:10:09 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_%E5%BC%BA%E5%88%B6%E6%9D%80%E6%AD%BBrabbitmq%E8%BF%9B%E7%A8%8B/</guid><description> 首先，尝试使用init.d脚本优雅关闭RabbitMQ sudo /etc/init.d/rabbitmq-server stop 如果不成功的话，使用 ps -eaf | grep erl 查看进程及父进程ID。输出第三列为父进程ID。找到仍是erlang进程（而不是启动进程的shell脚本）的第一个祖先进程，杀死它，这会同样终止其他子进程。上述示例中进程1301为&amp;quot;/bin/sh -e/usr/lib/rabbitmq/bin/rabbitmq-server&amp;quot;，已经不是erlang进程了，所以杀死进程1587就可以了。对于目前的RabbitMQ版本，可直接使用： sudo pkill beam.smp</description></item><item><title>获取Facebook User Token</title><link>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96facebook_user_token/</link><pubDate>Tue, 09 Aug 2016 05:25:47 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96facebook_user_token/</guid><description>使用Facebook Graph API搜索主页数据，可以用App Token也可以用User Token。 获取Facebook App Token一贴中已经介绍了如何获取Facebook App Token，这里就介绍一下如何获取UserToken。
参考3 Facebook Login - Advance - Manually Build a Login Flow给出了如何构建一个signURL，RestFB的getLoginDialogUrl方法就实现了这样的功能。redirectUri一开始直接想用带外认证urn:ietf:wg:oauth:2.0:oob，可是Facebook不认呀。 Facebook Login - Advance - Manually Build a Login Flow已经提到了：对于桌面应用，redirectUri必须是https://www.facebook.com/connect/login_success.html 。
获取Facebook User Token步骤 生成signURL 生成signURL并进行Get请求：
curl &amp;#34;https://www.facebook.com/dialog/oauth?client_id={appId}&amp;amp;redirect_uri=https://www.facebook.com/connect/login_success.html&amp;amp;response_type=token&amp;amp;scope=public_profile&amp;#34; 可以从返回的页面中获取登录表单：
认证 使用自己的Facebook账户和密码填充上一表单，使用Post请求进行认证：
curl -X POST &amp;#34;{form-action}&amp;#34; -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; --data &amp;#34;lsd={lsd_value}&amp;amp;api_key={api_key_value}&amp;amp;cancel_url={cancel_rul_value}&amp;amp;isprivate={isprivate=_value}&amp;amp;legacy_return={legacy_return_value}&amp;amp;profile_selector_ids={profile_selector_ids_value}&amp;amp;return_session={return_session_value}&amp;amp;skip_api_login={skip_api_login_value}&amp;amp;signed_next={skip_api_login_value}&amp;amp;trynum={trynum_value}&amp;amp;timezone={timezone_value}&amp;amp;lgndim={lgndim_value}&amp;amp;lgnrnd={lgnrnd_value}&amp;amp;lgnjs={lgnjs_value}&amp;amp;email={your_facebook_account}&amp;amp;pass={your_facebook_password}&amp;amp;login={login_value}&amp;amp;persistent={persistent_value}&amp;amp;default_persistent={default_persistent_value}&amp;#34; 获取User Token Facebook通过认证后返回302响应，其Location头是下面这个样子的，很好获取（也可以参考一下RestFB的fromQueryString函数实现）。
https://www.facebook.com/connect/login_success.html#access_token={userToken}&amp;amp;expires_in={expire} 参考 Facebook Login - Access Tokens Facebook Login - Access Tokens - App Access Tokens Facebook Login - Advance - Manually Build a Login Flow RestFB： GET LOGIN DIALOG URL RestFB： EXTENDING AN ACCESS TOKEN Facebook Dialog OAuth Tutorial</description></item><item><title>[RabbitMQ] Hello RabbitMQ Clustering</title><link>https://mryqu.github.io/post/rabbitmq_hello_rabbitmq_clustering/</link><pubDate>Mon, 08 Aug 2016 05:58:43 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_hello_rabbitmq_clustering/</guid><description>RabbitMQ集群文档的介绍是： 一个RabbitMQ代理（broker）是一或多个Erlang节点的逻辑组合，每个节点运行RabbitMQ应用并共享用户、虚拟主机、队列、交换器、绑定和运行时参数。有时我们将节点集合称之为集群。 对RabbitMQ代理操作所需的所有数据/状态都会在所有节点上复制。唯一的例外是消息队列，默认存在于创建队列的节点上，但是对所有其他节点可见并可访问。集群内节点通过主机名互相通信，所以这些主机名必须能被集群内所有节点解析。
在Ubuntu上安装RabbitMQ 我在三台Ubuntu服务器上安装了RabbitMQ，分别是node50064，node50069和node51054。
执行下列命令将APT仓库添加到/etc/apt/sources.list.d: echo &amp;#39;deb http://www.rabbitmq.com/debian/ testing main&amp;#39; | sudo tee /etc/apt/sources.list.d/rabbitmq.list (可选地)为了避免未签名包告警，使用 apt-key将RabbitMQ网站的公钥添加到信赖密钥列表： wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add - 执行下列命令更新包列表： sudo apt-get update 安装rabbitmq-server包： sudo apt-get install rabbitmq-server 配置RabbitMQ
修改/etc/rabbitmq/enabled_plugins使能管理插件： [rabbitmq_management]. 修改/etc/default/rabbitmq-server，增大每用户可打开文件数（我的系统不使用systemd，无需修改/etc/systemd/system/rabbitmq-server.service.d/limits.conf）： ulimit -S -n 4096 修改/etc/rabbitmq/rabbitmq-env.conf，激活长主机名并使用每个主机的完整域名作为本地节点名： USE_LONGNAME=true NODENAME=rabbit@`env hostname -f` 关闭RabbitMQ：
sudo /etc/init.d/rabbitmq-server stop 配置RabbitMQ集群 首先启动node50064上的RabbitMQ（注：会有告警，可忽略。-detached选项就会导致PID不写入PID文件。）：
sudo rabbitmq-server -detached RabbitMQ节点和CLI工具(例如rabbitmqctl)使用cookie来判断节点间是否可以通信。两个能够通信的节点必须拥有相同的共享密文，称之为Erlangcookie。集群中所有节点必须拥有相同cookie。必须在node50069和node51054关闭RabbitMQ的情况下，从node50064将其cookie复制到node50069（对node51054也做相同操作）： 更省事的方式，是在node50069和node51054没有安装RabbitMQ之前就将node50064上的cookie复制过来，这样node50069和node51054上的erlang节点就不会自己生成cookie了。
手工配置集群：
ubuntu@node50069:~$sudo rabbitmq-server -detached ubuntu@node50069:~$sudo rabbitmqctl stop_app ubuntu@node50069:~$sudo rabbitmqctl join_cluster rabbit@node50064.mryqu.com ubuntu@node50069:~$sudo rabbitmqctl start_app ubuntu@node51054:~$sudo rabbitmq-server -detached ubuntu@node51054:~$sudo rabbitmqctl stop_app ubuntu@node51054:~$sudo rabbitmqctl join_cluster rabbit@node50064.</description></item><item><title>[RabbitMQ] Hello RabbitMQ</title><link>https://mryqu.github.io/post/rabbitmq_hello_rabbitmq/</link><pubDate>Sun, 07 Aug 2016 05:54:08 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_hello_rabbitmq/</guid><description>为了快速入门RabbitMQ，我主要学习了下列参考中的两个链接：RabbitMQ教程和SpringAMQP范例。这里对所学教程做一个小笔记。
准备工作 由于我不打算跑本机上的RabbitMQ服务器，所有对代码稍有修改。
TutorialConfiguration.java public class TutorialConfiguration { public static final String HOST = &amp;#34;mryqu-rabbitmq-server&amp;#34;; public static final String USERNAME = &amp;#34;mryqu&amp;#34;; public static final String PASSWORD = &amp;#34;mryqu-pwd&amp;#34;; } 对原有代码进行修改 // factory.setHost(&amp;#34;localhost&amp;#34;); factory.setHost(TutorialConfiguration.HOST); factory.setUsername(TutorialConfiguration.USERNAME); factory.setPassword(TutorialConfiguration.PASSWORD); } RabbitMQ函数 发布方和消费方首先要创建连接，通过连接创建通道。通过通道也可以声明交换器，也可以直接声明队列。
函数Exchange.DeclareOk exchangeDeclare(String exchange, Stringtype, boolean durable, boolean autoDelete, boolean internal, Maparguments)用于声明交换器。其中exchange为队列名；type为交换器类型，例如fanout、direct、header和topic，注意无法改变已存在交换器的类型；durable为true时为持久交换器，在服务器重启后仍将存在，默认为false；autoDelete为true时，当所有的消费者使用完交换器后，服务器会自动删除交换器。服务器必须为判断交换器未使用提供一个合理时延，起码允许客户端能够创建一个代理并将其与队列绑定。默认为false；internal为true时为内部交换器，客户端不能直接向其发布消息，默认为false。 函数Queue.DeclareOk queueDeclare(String queue, boolean durable,boolean exclusive, boolean autoDelete, Map arguments)用于声明队列，其中queue为队列名；durable为true时为持久队列，在服务器重启后仍将存在。默认为false；exclusive为true时为私有队列，仅在当前连接中可以访问队列，当连接关闭时删除该队列。默认为true；autoDelete为true时，当所有的消费者使用完队列后，服务器会自动删除队列。最后一个消费者可被显式取消或由于通道关闭而取消。如果队列从没有消费者，队列将不会被删除。应用可以像对普通队列一样使用Delete方法显式删除自动删除队列。默认为true。 函数Queue.BindOk queueBind(String queue, String exchange, StringroutingKey, Map arguments)用于通过路由关键字将队列与交换器进行绑定。 函数void basicPublish(String exchange, String routingKey, booleanmandatory, boolean immediate, BasicProperties props, byte[]body)用于发布者发布消息。其中exchange为交换器名；routingKey为路由关键字，使用默认交换器及命名队列时可直接设为队列名；mandatory标志告知服务器当消息无法路由到队列时如何处理。如果标志被设上，服务器通过一个Return方法返回无法路由的消息。如果标志为空，服务器就仅丢弃消息。默认为false；immediate标志告知服务器当消息无法立即路由到队列消费者时如何处理。如果标志被设上，服务器通过一个Return方法返回无法路由的消息。如果标志为空，服务器就将消息放入队列，但不保证消息最终被消费。默认为false；props可设置下列子属性（可参考com.</description></item><item><title>[RabbitMQ] 在Widnows平台安装配置RabbitMQ</title><link>https://mryqu.github.io/post/rabbitmq_%E5%9C%A8widnows%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AErabbitmq/</link><pubDate>Sat, 06 Aug 2016 05:29:19 +0000</pubDate><guid>https://mryqu.github.io/post/rabbitmq_%E5%9C%A8widnows%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AErabbitmq/</guid><description>RabbitMQ介绍 RabbitMQ是基于高级消息队列协议的消息代理软件。RabiitMQ服务器由Erlang语言开发，客户端支持多种主流编程语言。 RabbitMQ由LShift和CohesiveFT合营公司Rabbit技术有限公司开发，在2010年4月被SpringSource收购，2013年5月归入Pivotal软件。 RabbitMQ项目包括：
RabbitMQ交换服务器自身 用于HTTP、流文本定向消息协议(STOMP)和消息队列遥测传输协议(MQTT)的网关 Java、.NET Framework和Erlang语言的AMQP客户端库 支持定制插件的插件平台，内建插件集合为: Shovel插件，负责从一个消息代理（broker）向另一个移动/复制消息。 Federation插件，在消息代理之间有效共享消息(基于exchange这一级) Management插件，监控和管理消息代理 STOMP插件，提供STOMP协议支持 MQTT插件，提供MQTT协议支持 LDAP插件，RabbitMQ通过外部LDAP服务器进行认证和授权 在Widnows平台安装RabbitMQ 根据http://www.rabbitmq.com/install-windows.html安装Erlang和RabbitMQ服务器，运行RabbitMQ安装程序时需要选择“Runas Administrator”，否则事后需要执行下列命令修正.erlang.cookie位置错误。
copy /Y %SystemRoot%\.erlang.cookie %HOMEDRIVE%%HOMEPATH% 设置环境变量（及安装并启动RabbitMQ服务）
SET　ERLANG_HOME=C:\tools\erl8.0 SET RABBITMQ_SERVER＝C:\tools\RabbitMQ_Server\rabbitmq_server-3.6.5 SET　RABBITMQ_BASE=C:\rabbitmq-data ECHO []. &amp;gt; C:\rabbitmq-data\rabbitmq.config %RABBITMQ_SERVER%\sbin\rabbitmq-service.bat install %RABBITMQ_SERVER%\sbin\rabbitmq-service.bat start 安装管理插件 rabbitmq-management插件提供用于管理和监控RabbitMQ服务器的基于HTTP的API，以及基于浏览器的界面和一个控制台工具rabbitmqadmin。功能包括：
声明、列举和删除exchange、queue、binding、用户、虚拟主机和权限。 监控队列长度、消息总速率和每通道速率、连接数据速率等。 发送和接受消息。 监控Erlang进程、文件描述符和内存使用。 导出/导入对象定义到JSON格式 强制关闭连接、清除队列。 重启RabbitMQ后登录http://guest:guest@localhost:15672/，即可见到管理页面。 rabbitmqctl 通过rabbitmqctl创建一个管理员用户admin和一个对虚拟主机有读写权限的普通用户mryqu： 自建管理员用户admin的默认用户guest的区别在于：guest仅能本机访问RabbitMQ，除非在rabbitmq.config增加loopback_users设置。
使用HTTP管理API 将配置导出成JSON格式：
curl -i -u guest:guest http://localhost:15672/api/definitions 激活其他插件 例如激活shovel插件：
%RABBITMQ_SERVER%\sbin\rabbitmq-plugins.bat enable rabbitmq_shovel %RABBITMQ_SERVER%\sbin\rabbitmq-plugins.bat enable rabbitmq_shovel_management 测试RabbitMQ 使用GETTING STARTED: Messaging with RabbitMQ中的代码即可，由于我想试验非本机访问RabbitMQ，因此添加了application.properties：</description></item><item><title>[Spark]Spark和Hive集成</title><link>https://mryqu.github.io/post/spark_spark%E5%92%8Chive%E9%9B%86%E6%88%90/</link><pubDate>Wed, 03 Aug 2016 06:10:01 +0000</pubDate><guid>https://mryqu.github.io/post/spark_spark%E5%92%8Chive%E9%9B%86%E6%88%90/</guid><description>在前一博文[Spark] Spark2集群安装实践中安装了Spark后，发现和Hive还没有集成在一起，此外Hive自己也不好使了。
hadoop@node50064:~$hive ls: cannot access /usr/local/spark/lib/spark-assembly-*.jar: No such file or directory ................. 原来Spark assemblyjar在Spark2中已经不存在了，而Hive脚本判断系统存在Spark后仍要使用，需要将$HIVE_HOME/bin/hive中的这部分代码注释掉：
# add Spark assembly jar to the classpath #if [[ -n &amp;#34;$SPARK_HOME&amp;#34; ]] #then # sparkAssemblyPath=`ls ${SPARK_HOME}/lib/spark-assembly-*.jar` # CLASSPATH=&amp;#34;${CLASSPATH}:${sparkAssemblyPath}&amp;#34; #fi 至此，Hive本身工作正常。下面开始Spark和Hive集成配置工作。
Spark SQL CLI需要使用到Hive Metastore，因此需要在[Hive] 安装Hive 1.2.x的基础上继续修改$HIVE_HOME/conf/hive-site.xml： 将$HIVE_HOME/conf/hive-site.xml软连接到$SPARK_HOME/conf目录中: cd $SPARK_HOME/conf ln -s $HIVE_HOME/conf/hive-site.xml 启动Hive Metastore和HiveServer2： hive --service metastore &amp;amp; hive --service hiveserver2 &amp;amp; 下面进行验证工作：
hadoop@node50064:~$ hive hive&amp;gt; use default; OK Time taken: 0.942 seconds hive&amp;gt; show tables; OK apachelog b complex_datatypes_example dummy empinfo irisdata primitive_dataytpes_example testhivedrivertable Time taken: 0.</description></item><item><title>Hive与Spark的版本搭配</title><link>https://mryqu.github.io/post/hive%E4%B8%8Espark%E7%9A%84%E7%89%88%E6%9C%AC%E6%90%AD%E9%85%8D/</link><pubDate>Tue, 02 Aug 2016 05:46:59 +0000</pubDate><guid>https://mryqu.github.io/post/hive%E4%B8%8Espark%E7%9A%84%E7%89%88%E6%9C%AC%E6%90%AD%E9%85%8D/</guid><description> Hive on Spark: Getting Started里面介绍了如果Hive的查询引擎选择Spark的话，Hive所需相关配置。如果用一个不兼容的Hive和Spark版本，有潜在风险，例如Spark2就没有spark-assembly-*.jar可供低版本Hive使用。 问题来了，么查找已测试的Hive和Spark版本对呢？ 网上有人说看Hive代码根路径下的pom.xml。例如Hive branch-1.2中pom.xml包含spark.version为1.3.1，这说明官方在进行Hive1.2.0测试时用的Spark 1.3.1。 此外，也可借鉴C家、H家和MapR技术栈的版本搭配：
CDH 5 Packaging and Tarball Information中列出了CHD5中技术栈的版本情况。 在Hortonworks Data Platform列出了HDP所用的技术栈的版本情况。 MapR Ecosystem Support Matrix中列出了MapR中技术栈的版本情况。</description></item><item><title>[Spark] Set spark.yarn.archive</title><link>https://mryqu.github.io/post/spark_set_spark.yarn.archive/</link><pubDate>Mon, 01 Aug 2016 05:30:15 +0000</pubDate><guid>https://mryqu.github.io/post/spark_set_spark.yarn.archive/</guid><description>提交Spark作业时，遇到没有设置spark.yarn.jars和spark.yarn.archive的告警：
16/08/01 05:01:19 INFO yarn.Client: Preparing resources for our AM container 16/08/01 05:01:20 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME. 16/08/01 05:01:23 INFO yarn.Client: Uploading resource file:/tmp/spark-AA-BB-CC-DD-EE/__spark_libs__XXX.zip -&amp;gt; hdfs://node50064.mryqu.com:9000/user/hadoop/.sparkStaging/application_1469998883123_0001/__spark_libs__XXX.zip 解决方案：
cd $SPARK_HOME zip spark-archive.zip jars/* hadoop fs -copyFromLocal spark-archive.zip echo &amp;#34;spark.yarn.archive=hdfs:///node50064.mryqu.com:9000/user/hadoop/spark-archive.zip&amp;#34; &amp;gt;&amp;gt; conf/spark-defaults.conf 如系统没有安装zip，可执行sudoapt-get install zip进行安装。 这样就不用每次上传Spark的jar文件到HDFS，YARN会找到Spark的库以用于运行作业。</description></item><item><title>短网址服务学习和测试</title><link>https://mryqu.github.io/post/%E7%9F%AD%E7%BD%91%E5%9D%80%E6%9C%8D%E5%8A%A1%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 30 Jul 2016 05:56:48 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%9F%AD%E7%BD%91%E5%9D%80%E6%9C%8D%E5%8A%A1%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B5%8B%E8%AF%95/</guid><description>短网址服务 短网址（Short URL） ，顾名思义就是在形式上比较短的网址。通常用的是asp或者php转向，在Web2.0的今天，不得不说，这是一个潮流。目前已经有许多类似服务，借助短网址您可以用简短的网址替代原来冗长的网址，让使用者可以更容易的分享链接。 网上的短网址服务一堆堆的，例如谷歌家的goo.gl，bit.ly为推特家提供了bit.ly及为亚马逊家提供了amzn.to，推特家自己的t.co，新浪家的t.cn，百度家的dwz.cn，简直数不过来。 SearchEngineLand曾对国外市面上的URL缩短服务进行了分析总结，列出了推荐使用的和应尽力避免使用的服务。该评测从是否为301转向（永久转向，相对302为暂时转向）、是否支持Tracking（追踪链接的来源）、是否支持主流的Twitter客户端、缩短后的URL字数、是否支持自定义URL、是否支持分享等多个方面进行评价。具体结果见此表。 短网址算法 算法一 将长网址md5生成32位签名串,分为4段, 每段4个字节（即32位）; 对这四段循环处理, 取4个字节（32位）, 将他看成16进制串与0x3fffffff(30位1)与操作,即超过30位的忽略处理; 这30位分成6段, 每5位的数字作为字母表的索引取得特定字符, 依次进行获得6位字符串; 总的md5串可以获得4个6位串; 取里面的任意一个就可作为这个长url的短url地址; 算法二 把数字和字符组合做一定的映射,就可以产生唯一的字符串,如第62个组合就是aaaaa9,第63个组合就是aaaaba,再利用洗牌算法，把原字符串打乱后保存，那么对应位置的组合字符串就会是无序的组合。 把长网址存入数据库,取返回的id,找出对应的字符串,例如返回ID为1，那么对应上面的字符串组合就是bbb,同理ID为2时，字符串组合为bba,依次类推,直至到达62种组合后才会出现重复的可能，所以如果用上面的62个字符，任意取6个字符组合成字符串的话，你的数据存量达到500多亿后才会出现重复的可能。
短网址服务测试(基于新浪短地址服务) 短地址服务是否验证长URL？ 对于不存在的长地址http://www.mryqu.com/test/test.html，新浪短地址服务没有验证，直接转成了短地址http://t.cn/RtXngGQ 。
如果长url其实是该短地址服务产生的短地址，如何处理？ 对于长地址http://t.cn/RtXngGQ ，新浪短地址服务做了检查识别出短地址,并直接按照http://www.mryqu.com/test/test.html返回短地址http://t.cn/RtXngGQ 。
如果长url其实是其他短地址服务产生的短地址，如何处理？ 我用长地址http://blog.sina.com.cn/yandongqu 在百度短地址服务获得了短地址http://dwz.cn/3TE3bq ，将其作为新浪短地址服务的输入，新浪短地址服务识别出短地址，获得原始长地址http://blog.sina.com.cn/yandongqu ，并返回相应短地址短地址http://t.cn/RLoGZKa 。
参考 短网址 短网址服务，我们该怎么选？ URL Shorteners: Which Shortening Service Should You Use? 短链接URL系统是怎么设计的？ tinyURL的设计方案与实现【一】</description></item><item><title>[Spark]Spark2集群安装实践</title><link>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 28 Jul 2016 05:47:45 +0000</pubDate><guid>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</guid><description>从Spark2.0.0开始，Spark使用Scala2.11构建，不再对Java7和Python2.6进行支持。当然不编译Spark源码的话，无需安装Scala。
Spark集群模型 Spark应用作为集群上一组独立进程运行，由你的主程序（即驱动程序）的SparkContext对象管理。为了在集群上运行，SparkContext可以与若干类型集群管理器（Spark自带的独立集群管理器、Mesos、YARN）连接，集群管理器为应用分配资源。Spark需要集群节点上的执行者（executor）为应用执行计算或存储数据。接下来，它将应用代码发送给执行者，最后SparkContext将人物发往执行者进行运行。
准备工作 安装Scala # Scala Installation wget www.scala-lang.org/files/archive/scala-2.11.8.deb sudo dpkg -i scala-2.11.8.deb # sbt Installation echo &amp;#34;deb https://dl.bintray.com/sbt/debian /&amp;#34; | sudo tee -a /etc/apt/sources.list.d/sbt.list sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823 sudo apt-get update sudo apt-get install sbt 安装Java8 sudo apt-add-repository ppa:webupd8team/java -y sudo apt-get update -y sudo apt-get install oracle-java8-installer -y sudo apt-get install oracle-java8-set-default 环境变量设置 在~/.bashrc中添加：
# Set SPARK_HOME export SPARK_HOME=/usr/local/spark export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin 最后通过source~/.bashrc刷新配置文件。
安装Spark （在node50064上）下载并配置Spark wget http://d3kbcqa49mib13.</description></item><item><title>twitcurl获取访问令牌（AccessToken和AccessTokenSecret）的实现流程</title><link>https://mryqu.github.io/post/twitcurl%E8%8E%B7%E5%8F%96%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8Caccesstoken%E5%92%8Caccesstokensecret%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B/</link><pubDate>Fri, 01 Jul 2016 05:34:09 +0000</pubDate><guid>https://mryqu.github.io/post/twitcurl%E8%8E%B7%E5%8F%96%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8Caccesstoken%E5%92%8Caccesstokensecret%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B/</guid><description>twitterClient.cpp中有一段代码是没有AccessToken和AccessTokenSecret的情况下，通过ConsumerKey、ConsumerKeySecret、UserName和UaserPassword获取AccessToken和AccessTokenSecret。 一般实现是通过重定向到Twitter页面去授权应用，通过callbackURL获得Twitter传过来的AccessToken和AccessTokenSecret信息。twitcurl既可以通过访问twitter.com获取PIN，也可以交由twitcurl自动获得。 如果通过twitter.com处理PIN，twitcurl会提供授权链接。进入链接后输入用户名和密码，会重定向到Twitter应用的callbackURL（例如http://www.mryqu.com/test.html?oauth_token={OAuthToken}&amp;amp;oauth_verifier={OAuthVerifier} ），其中oauth_verifier值即为所谓的PIN。 下面我们看一下twitcurl是如何实现不访问twitter.com获取AccessToken和AccessTokenSecret的。
GET https://api.twitter.com/oauth/request_tokentwitCurl::oAuthRequestToken 方法实现该HTTP请求，允许消费者应用获得一个OAuth请求令牌以请求用户授权。除了HTTP OAuth头外，twitcurl实现没有其他HTTP头，也没有消息体内容。HTTP OAuth头包含如下项： oauth_consumer_key oauth_nonce oauth_signature oauth_signature_method oauth_timestamp oauth_version 通过如下HTTP响应可以获得oauth_token和oauth_token_secret，保存在oAuth对象的m_oAuthTokenKey和m_oAuthTokenSecret变量中：
oauth_token=XXXXXX&amp;amp;oauth_token_secret=XXXXXX&amp;amp;oauth_callback_confirmed=true GET https://api.twitter.com/oauth/authorize?oauth_token=XXXXXXtwitterObj.oAuthHandlePIN 方法实现该HTTP请求，获取响应页面中表单的authenticity_token和oauth_token元素的值。除了HTTP OAuth头外，twitcurl实现没有其他HTTP头，也没有消息体内容。HTTP OAuth头包含如下项： oauth_consumer_key oauth_nonce oauth_signature oauth_signature_method oauth_timestamp oauth_token （取自上一HTTP响应） oauth_version HTTP响应片段：
POST https://api.twitter.com/oauth/authorize?oauth_token=XXXXXXtwitterObj.oAuthHandlePIN 方法实现该HTTP请求，允许消费者应用使用OAuth请求令牌请求用户授权。HTTP OAuth头包含如下项： oauth_consumer_key oauth_nonce oauth_signature oauth_signature_method oauth_timestamp oauth_token （取自上一HTTP响应） oauth_version HTTP请求消息体内容为：
oauth_token=XXXXXX&amp;amp;authenticity_token=XXXXXX&amp;amp;session[username_or_email]=**XXXXX**X&amp;amp;session[password]=XXXXXX HTTP响应片段：通过如下HTTP响应可以获得oauth_verifier，保存在oAuth对象的m_oAuthPin变量中。
GET https://api.twitter.com/oauth/access_tokentwitterObj.oAuthAccessToken 方法实现该HTTP请求，允许消费者应用使用OAuth请求令牌交换OAuth访问令牌。HTTP OAuth头包含如下项： oauth_consumer_key oauth_nonce oauth_signature oauth_signature_method oauth_timestamp oauth_token oauth_verifier （取自上一HTTP响应） oauth_version HTTP响应：
oauth_token=XXXXXX&amp;amp;oauth_token_secret=XXXXXX&amp;amp;user_id=XXXXXX&amp;amp;screen_name=XXXXXX&amp;amp;x_auth_expires=0 通过HTTP响应可以获得oauth_token、oauth_token_secret和user_id，保存在oAuth对象的m_oAuthTokenKey、m_oAuthTokenSecret和m_oAuthScreenName变量中，可以将此OAuth访问令牌保存下来以备之后的使用，下次就无需再次申请访问令牌了。
参考 Twitter OAuth Overview Twitter PIN-based authorization Github: mryqu/twitcurl OAuth Core 1.</description></item><item><title>微信语音导出和转换</title><link>https://mryqu.github.io/post/%E5%BE%AE%E4%BF%A1%E8%AF%AD%E9%9F%B3%E5%AF%BC%E5%87%BA%E5%92%8C%E8%BD%AC%E6%8D%A2/</link><pubDate>Sat, 18 Jun 2016 05:23:05 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%BE%AE%E4%BF%A1%E8%AF%AD%E9%9F%B3%E5%AF%BC%E5%87%BA%E5%92%8C%E8%BD%AC%E6%8D%A2/</guid><description>用微信语音发送了一段儿子朗诵诗，想导出来做个念想，结果发现还挺麻烦。
在tencent/MicsoMsg目录下有名字很长的文件夹就是微信聊天记录存放的文件夹，每登陆一个微信就会产生一个名字很长的文件夹。在这个目下下有个Voice2目录，将下面的子目录按照日期排序缩小范围，查找疑似子目录下的amr文件，想办法拷贝到计算机中。 一开始我按照网上的攻略用格式工厂转换成mp3，报错。用Ultraedit打开文件，头部显示有silk_v3。SILKv3编码是Skype向第三方开发人员和硬件制造商提供免版税认证(RF)的Silk宽带音频编码器，Skype后来将其开源。在Github上找到了https://github.com/kn007/silk-v3-decoder，搞定！</description></item><item><title>使用Jacoco</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8jacoco/</link><pubDate>Thu, 16 Jun 2016 05:41:19 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8jacoco/</guid><description>在以前的项目都是用Cobertura做代码覆盖率测试的，这次有机会接触了一下另一个代码覆盖率Java库JaCoco。 JaCoCo拥有友好的授权形式。JaCoCo使用了Eclipse PublicLicense，方便个人用户和商业用户使用。JaCoCo/EclEmma项目除了提供JaCoCo库之外，还提供了Ant任务、Maven插件及EclEmmaEclipse插件，也可以使用JavaAgent技术监控Java程序。很多第三方的工具提供了对Jacoco的集成，如SonarQube、Jenkins、Netbeans、IntelliJIDEA、Gradle等。 JaCoCo包含多种级别的覆盖率计数器，包含指令级覆盖(Instructions，C0coverage)，分支（Branches，C1coverage）、圈复杂度(CyclomaticComplexity)、行覆盖(Lines)、方法覆盖(non-abstractmethods)、类覆盖(classes)。
指令覆盖：计数单元是单个java字节码指令，指令覆盖率提供了代码是否被执行的信息，该指标完全独立与源码格式。 分支覆盖率：度量if和switch语句的分支覆盖情况，计算一个方法里面的总分支数，确定执行和不执行的分支数量。 圈复杂度：在（线性）组合中，计算在一个方法里面所有可能路径的最小数目，缺失的复杂度同样表示测试案例没有完全覆盖到这个模块。 行覆盖率：度量被测程序的每行代码是否被执行，判断标准行中是否至少有一个指令被执行。 方法覆盖率：度量被测程序的方法执行情况，是否执行取决于方法中是否有至少一个指令被执行。 类覆盖率：度量计算class类文件是否被执行。 JaCoCo的一个主要优点是使用Java代理，可以动态（on-the-fly）对类进行插桩。这样代码覆盖率分析简化了预插桩过程，也无需考虑classpath的设置。但是还存在如下不适合动态插桩的情况，需要线下对字节码进行预插桩：
运行环境不支持java agent。 部署环境不允许设置JVM参数。 字节码需要被转换成其他的虚拟机如Android Dalvik VM。 动态修改字节码过程中和其他agent冲突。 示例 我这个懒人还是在Building a Hypermedia-Driven RESTful Web Service示例的基础上稍作修改，熟悉一下JaCoCo的使用。
build.gradle buildscript { repositories { mavenCentral() } dependencies { classpath(&amp;#34;org.springframework.boot:spring-boot-gradle-plugin:1.X.Y.RELEASE&amp;#34;) } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#39;spring-boot&amp;#39; apply plugin: &amp;#39;jacoco&amp;#39; jar { baseName = &amp;#39;hello-jacoco&amp;#39; version = &amp;#39;0.1.0&amp;#39; } repositories { mavenCentral() } sourceCompatibility = 1.8 targetCompatibility = 1.</description></item><item><title>在Outlook 2013中查看邮件的消息头</title><link>https://mryqu.github.io/post/%E5%9C%A8outlook_2013%E4%B8%AD%E6%9F%A5%E7%9C%8B%E9%82%AE%E4%BB%B6%E7%9A%84%E6%B6%88%E6%81%AF%E5%A4%B4/</link><pubDate>Thu, 09 Jun 2016 05:24:46 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8outlook_2013%E4%B8%AD%E6%9F%A5%E7%9C%8B%E9%82%AE%E4%BB%B6%E7%9A%84%E6%B6%88%E6%81%AF%E5%A4%B4/</guid><description>双击邮件后选择File菜单，点击Porperties按钮： 查看Internet headers：</description></item><item><title>[OpenUI5] 复习Controller lifecycle</title><link>https://mryqu.github.io/post/openui5_%E5%A4%8D%E4%B9%A0controller_lifecycle/</link><pubDate>Fri, 27 May 2016 05:36:54 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%A4%8D%E4%B9%A0controller_lifecycle/</guid><description>昨天看到有同事添加了几个Controller的回调，对其中的onBeforeExit、beforeExit没一点印象。
sap.ui.controller(&amp;#34;kx123.foo&amp;#34;, { onInit: function () { console.info(&amp;#34;foo onInit called&amp;#34;); }, onBeforeExit: function(){ console.info(&amp;#34;foo onBeforeExit called&amp;#34;) ; } , beforeExit: function() { console.info(&amp;#34;foo beforeExit called&amp;#34;) ; }, onBeforeRendering: function() { console.info(&amp;#34;foo onBeforeRendering called&amp;#34;); }, onExit: function() { console.info(&amp;#34;foo onExit called&amp;#34;); } }); 查了一下如下OpenUI5开发指南 MVC中关于Controllers的介绍。
SAPUI5 provides predefined lifecycle hooks forimplementation. You can add event handlers or other functions tothe controller and the controller can fire events, for which othercontrollers or entities can register.</description></item><item><title>Facebook Graph API之分享数</title><link>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E5%88%86%E4%BA%AB%E6%95%B0/</link><pubDate>Fri, 13 May 2016 05:56:49 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E5%88%86%E4%BA%AB%E6%95%B0/</guid><description>现在Facebook帖子上有一个分享计数，下面这个湖南卫视的帖子可以看到总共有3个。 点进去可以查看这3个分享的具体情况： 使用Facebook Graph Explorer却可以得到分享数为7： 差4个分享，有点醉！ 其实我刚才刚刚用消息给朋友共享了这个帖子，由于是不是公开的，所以Facebook网页显示上是不计入的，但是API却是统计的。</description></item><item><title>Facebook Graph API之点赞数</title><link>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E7%82%B9%E8%B5%9E%E6%95%B0/</link><pubDate>Thu, 12 May 2016 06:24:44 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E7%82%B9%E8%B5%9E%E6%95%B0/</guid><description>现在Facebook帖子上有一个心情计数，下面这个湖南卫视的帖子可以看到总共有293个。 通过Facebook Graph API获得的点赞数为275个。 示例里的帖子心情计数293包括点赞数275、大爱数13、笑趴数4、【未知表情计数】1。 这里可以看到点赞可以细分为点赞、大爱、笑趴、哇、心碎和怒这六种表情。</description></item><item><title>Facebook Graph API之主页名</title><link>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E4%B8%BB%E9%A1%B5%E5%90%8D/</link><pubDate>Mon, 09 May 2016 06:32:07 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E4%B8%BB%E9%A1%B5%E5%90%8D/</guid><description>今天Alisa同学说搜中国湖南卫视的主页报错，我一直都只是用SASsoftware和我的YquTest做的开发测试。赶紧赶过去看了一眼，实验证明搜hntvchina好使，搜中国湖南卫视就会出错。 感觉中国湖南卫视就像是hntvchina的显示名，而SASsoftware的显示名其实是SAS software。 又和小伙伴一起创建了一个主页玩玩，让我们输入的名字最后成了显示名，而真正生成的名字将空格用&amp;quot;-&amp;ldquo;代替然后又加了一串数字，感觉像防止主键冲突。</description></item><item><title>Get comments count using Facebook Graph API</title><link>https://mryqu.github.io/post/get_comments_count_using_facebook_graph_api/</link><pubDate>Fri, 06 May 2016 05:50:38 +0000</pubDate><guid>https://mryqu.github.io/post/get_comments_count_using_facebook_graph_api/</guid><description>通过fields参数获取评论/回复个数 通过预判评论/回复个数，以决定是否发起/{object-id}/commentsAPI请求，可以显著减少API请求个数。
获取帖子的评论数 https://graph.facebook.com/{YOUR_PAGE_ID}/feed?fields=id,XXXX,likes.limit(0).summary(1),comments.limit(0).summary(1),XXXX,with_tags&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;since=XXXX&amp;amp;until=XXXX&amp;amp;include_hidden=true&amp;amp;access_token={YOUR_ACCESS_TOKEN} 获取评论的回复数 https://graph.facebook.com/{YOUR_POST_ID}/comments?fields=id,from,message,created_time,like_count,comments.limit(0).summary(1)&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;limit=100&amp;amp;since=XXXX&amp;amp;until=XXXX&amp;amp;include_hidden=true&amp;amp;access_token={YOUR_ACCESS_TOKEN} comments.summary.total_count解读 在Facebook Graph指南中/{object-id}/comments提到了total_count数值是随filter变动的。
filter为stream，total_count为该节点下所有评论及其回复的总数； filter为toplevel，total_count为该节点下顶层评论/回复的总数。 由于在我的使用场景中为设置filter，而其默认值为toplevel，则total_count为该节点下顶层评论/回复的总数。</description></item><item><title>Get likes count using fields parameters in Facebook Graph API</title><link>https://mryqu.github.io/post/get_likes_count_using_fields_parameters_in_facebook_graph_api/</link><pubDate>Thu, 05 May 2016 06:02:17 +0000</pubDate><guid>https://mryqu.github.io/post/get_likes_count_using_fields_parameters_in_facebook_graph_api/</guid><description>原来获得Facebook帖子/评论的点赞数，需要额外单独发送一次API请求： 通过对Facebook GraphAPI中fields参数添加likes.limit(0).summary(1)，仅需一次API请求就可获得帖子/评论的所有信息：</description></item><item><title>使用SpringFox自动生成Swagger文档</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8springfox%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90swagger%E6%96%87%E6%A1%A3/</link><pubDate>Thu, 28 Apr 2016 06:03:36 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8springfox%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90swagger%E6%96%87%E6%A1%A3/</guid><description>前面的博文Swagger实践和总结总体上探索了一下Swagger，这里着重研究Springfox。 Springfox Java库源自MartyPitt创建的swagger-springmvc项目。Swagger是一系列对RESTful接口进行规范描述和页面展示的工具，而通过Springfox将Swagger与Spring-MVC整合,可以将代码中的注解转换为符合Swagger开放API声明(OpenAPI Specification，OAS)的swagger.json文件,springfox-swagger-ui提供了将swagger.json转换为html页面的服务。
HelloSpringfox示例 尽管springfox-demos中的boot-swagger很全面了。但是对于一个写程序的人来说，不亲自写一遍，总觉得可能会有陷阱和漏洞，缺乏那么一点点自信。 我的示例是以Building a Hypermedia-Driven RESTful Web Service为基础修改的，懒人总是要找个肩膀。
build.gradle jar { baseName = &amp;#39;hello-springfox&amp;#39; version = &amp;#39;0.1.0&amp;#39; } dependencies { compile(&amp;#34;org.springframework.boot:spring-boot-starter-actuator&amp;#34;) compile(&amp;#34;org.springframework.boot:spring-boot-starter-web&amp;#34;) compile(&amp;#34;org.springframework.boot:spring-boot-starter-hateoas&amp;#34;) compile(&amp;#34;io.springfox:springfox-swagger2:${springfoxVersion}&amp;#34;) compile(&amp;#34;io.springfox:springfox-swagger1:${springfoxVersion}&amp;#34;) compile(&amp;#34;io.springfox:springfox-swagger-ui:${springfoxVersion}&amp;#34;) testCompile(&amp;#34;com.jayway.jsonpath:json-path&amp;#34;) testCompile(&amp;#34;org.springframework.boot:spring-boot-starter-test&amp;#34;) } Application.java package com.yqu.hellospringfox; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } Greeting.java package com.yqu.hellospringfox; import org.springframework.hateoas.ResourceSupport; import com.fasterxml.jackson.annotation.JsonCreator; import com.fasterxml.jackson.annotation.JsonProperty; public class Greeting extends ResourceSupport { private final String content; @JsonCreator public Greeting(@JsonProperty(&amp;#34;content&amp;#34;) String content) { this.</description></item><item><title>了解PhantomJS</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3phantomjs/</link><pubDate>Wed, 13 Apr 2016 06:02:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3phantomjs/</guid><description>今天看到我们的项目依赖PhantomJS，就稍作了解。
PhantomJS 是什么? 官方介绍如下：
PhantomJS is a headless WebKit scriptable with a JavaScript API. It has fast and native support for various web standards: DOM handling, CSS selector, JSON, Canvas, and SVG.
PhantomJS是无需浏览器基于WebKit的全Web栈，支持JS解析引擎、渲染引擎、请求处理等，但是不包括显示和用户交互页面。
PhantomJS的使用场景 无浏览器网站测试：支持使用Jasmine、QUnit、Mocha、Capybara、WebDriver等框架进行功能测试。 页面截屏：抓取页面内容，包括SVG和Canvas。 页面自动化：使用标准DOMAPI或jQuery等通用库访问和操作网页。 网页监控：监控网页加载和导出成标准HAR文件。让使用YSlow和Jenkins的性能分析自动化。 大概可以估计出PhantomJS的作用了，应该是用于单元测试吧。</description></item><item><title>[OpenUI5] sap.ui.model.SimpleType及其子类中的约束</title><link>https://mryqu.github.io/post/openui5_sap.ui.model.simpletype%E5%8F%8A%E5%85%B6%E5%AD%90%E7%B1%BB%E4%B8%AD%E7%9A%84%E7%BA%A6%E6%9D%9F/</link><pubDate>Tue, 12 Apr 2016 05:57:21 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_sap.ui.model.simpletype%E5%8F%8A%E5%85%B6%E5%AD%90%E7%B1%BB%E4%B8%AD%E7%9A%84%E7%BA%A6%E6%9D%9F/</guid><description>对OpenUI5模型中的数据项如何设置类型，如何设置最大最小值等约束呢？这一切可以通过研究sap.ui.model.SimpleType及其子类获得答案。
sap.ui.model.SimpleType类图 SimpleType子类Integer约束测试 下面的示例中有两个sap.m.Input控件，第一个为文本类型输入没有约束，第二个整数类型输入有约束：
that.oNameInput = new Input({ id: sFormId+&amp;#34;-name&amp;#34;, type: sap.m.InputType.Text, value: &amp;#34;{/name}&amp;#34;, layoutData: new GridData({span: &amp;#34;L3 M5 S6&amp;#34;}) }); that.oCountInput = new Input({ id: sFormId+&amp;#34;-count&amp;#34;, type: sap.m.InputType.Number, value: { path:&amp;#39;/count&amp;#39;, type: &amp;#39;sap.ui.model.type.Integer&amp;#39;, constraints: { minimum : 1, maximum : 50 } }, placeholder: &amp;#34;(1-50)&amp;#34;, layoutData: new GridData({span: &amp;#34;L3 M5 S6&amp;#34;}) }); 完整示例代码： 二者调试信息的差异： 一个仅指定了映射路径；另一个除了指定映射路径外，明确指定了模型数据项类型及约束。
测试结果 that.oCountInput施加了范围1到50的约束。如果输入值在范围内，则界面和模型中的count值都会改变；如果输入值不再范围内，则模型中的count值保留上一有效值，而界面发生改变且无告警。 调试堆栈如下：
PropertyBinding.setExternalValue (sap-ui-core-dbg.js:57174) ManagedObject.updateModelProperty (sap-ui-core-dbg.js:34286) ManagedObject.setProperty (sap-ui-core-dbg.js:32531) InputBase.setProperty (InputBase-dbg.js:690) InputBase.setValue (InputBase-dbg.js:1007) Input.setValue (Input-dbg.</description></item><item><title>[OpenUI5] 使用DateRangeSelection</title><link>https://mryqu.github.io/post/openui5_%E4%BD%BF%E7%94%A8daterangeselection/</link><pubDate>Mon, 11 Apr 2016 05:58:48 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E4%BD%BF%E7%94%A8daterangeselection/</guid><description>今天使用了DateRangeSelection来选择日期范围。 DateRangeSelection范例
sap.m.DateRangeSelection jsDoc
DateRangeSelection源代码
sap.ui.core.format.DateFormat jsDoc
Working with Dates in Sapui5
sap.ui.core.format.DateFormat
通过阅读上述资料，DateRangeSelection内存储的起始、结束时间为Date类。可以通过设置displayFormat和delimiter来改变界面上日期的表现形式；不支持valueFormat，因此只能通过getDateValue()、getSecondDateValue()获取Date对象，然后通过DateFormat获得相应格式化的日期字符串。 DateRangeSelection最新版代码提供了setMinDate()和setMaxDate()函数，但是jsDoc还没有体现，我司目前所用的OpenUI5版本还不支持。</description></item><item><title>Use proxy on RestFB</title><link>https://mryqu.github.io/post/use_proxy_on_restfb/</link><pubDate>Mon, 04 Apr 2016 06:18:35 +0000</pubDate><guid>https://mryqu.github.io/post/use_proxy_on_restfb/</guid><description>曾经有人向RestFB开过issue（https://github.com/restfb/restfb/issues/116）询问如何给其设置代理，issue里回复扩展DefaultWebRequestor。下面的代码基于该方案并测试通过。
package com.yqu.restfb; import com.restfb.DefaultFacebookClient; import com.restfb.DefaultJsonMapper; import com.restfb.FacebookClient; import com.restfb.Version; import java.io.IOException; import java.net.HttpURLConnection; import java.net.InetSocketAddress; import java.net.Proxy; import java.net.URL; public class HelloRestFBWithProxy { private static class DefaultWebRequestor extends com.restfb.DefaultWebRequestor { protected HttpURLConnection openConnection(URL url) throws IOException { HttpURLConnection httpURLConnection = null; if (useProxyFlag.booleanValue()) { InetSocketAddress proxyLocation = new InetSocketAddress( hostName, port); Proxy proxy = new Proxy(Proxy.Type.HTTP, proxyLocation); try { httpURLConnection = (HttpURLConnection) url .openConnection(proxy); return httpURLConnection; } catch (Exception e) { return (HttpURLConnection) url.</description></item><item><title>在Linux终端下启动SAS管理控制台</title><link>https://mryqu.github.io/post/%E5%9C%A8linux%E7%BB%88%E7%AB%AF%E4%B8%8B%E5%90%AF%E5%8A%A8sas%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%8F%B0/</link><pubDate>Tue, 29 Mar 2016 21:50:15 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8linux%E7%BB%88%E7%AB%AF%E4%B8%8B%E5%90%AF%E5%8A%A8sas%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%8F%B0/</guid><description>在Linux终端下没有X11显示系统的情况下，可以通过如下命令将X11转移到其他X视窗服务器以显示SMC界面：
$ export DISPLAY=[machine]:[port] $ pwd /local/install/SASServer/SASHome/SASManagementConsole/9.4 $ ./sasmc</description></item><item><title>[C++] 给twitcurl添加访问频次限制信息获取功能</title><link>https://mryqu.github.io/post/c++_%E7%BB%99twitcurl%E6%B7%BB%E5%8A%A0%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E5%8A%9F/</link><pubDate>Thu, 24 Mar 2016 06:05:53 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E7%BB%99twitcurl%E6%B7%BB%E5%8A%A0%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E5%8A%9F/</guid><description>在我之前的博文Twitter API访问频次限制处理中，描述了Twitter API访问频次限制及Twitter4J对其处理。twitcurl项目并没有这样的功能，今天我将getLastRateLimitStatus功能添加到了twitcurl。 通过添加如下代码，我可以获取响应头信息：
curl_easy_setopt( m_curlHandle, CURLOPT_HEADERFUNCTION, curlHeaderCallback ); curl_easy_setopt( m_curlHandle, CURLOPT_HEADERDATA, this ); 输出的调试信息如下：
Enter string to search: va Limit search results to: 2 twitCurl::curlHeaderCallback headers: HTTP/1.1 200 OK twitCurl::curlHeaderCallback headers: cache-control: no-cache, no-store, must-revalidate, pre-check=0, post-check=0 twitCurl::curlHeaderCallback headers: content-disposition: attachment; filename=json.json twitCurl::curlHeaderCallback headers: content-encoding: gzip twitCurl::curlHeaderCallback headers: content-length: 1301 twitCurl::curlHeaderCallback headers: content-type: application/json;charset=utf-8 twitCurl::curlHeaderCallback headers: date: Thu, 24 Mar 2016 04:59:41 GMT twitCurl::curlHeaderCallback headers: expires: Tue, 31 Mar 1981 05:00:00 GMT twitCurl::curlHeaderCallback headers: last-modified: Thu, 24 Mar 2016 04:59:41 GMT twitCurl::curlHeaderCallback headers: pragma: no-cache twitCurl::curlHeaderCallback headers: server: tsa_b twitCurl::curlHeaderCallback headers: set-cookie: guest_id=v1:145879558114535127; Domain=.</description></item><item><title>遇到"vagrant up"无法读取box元数据问题</title><link>https://mryqu.github.io/post/%E9%81%87%E5%88%B0vagrant_up%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96box%E5%85%83%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</link><pubDate>Fri, 18 Mar 2016 06:46:16 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%81%87%E5%88%B0vagrant_up%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96box%E5%85%83%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</guid><description>昨天在某个Windows Server2008上升级了Vagrant (1.8.1)和VitualBox(5.0.16)，然后vagrant up就开始出问题了。
C:\foo&amp;gt;vagrant up Bringing machine &amp;#39;xfoo&amp;#39; up with &amp;#39;virtualbox&amp;#39; provider... ==&amp;gt; xfoo: Box ‘foo-ubuntu‘ could not be found. Attempting to find and install... xfoo: Box Provider: virtualbox xfoo: Box Version: &amp;gt;= 0.12.0, &amp;lt; 1.0.0 ==&amp;gt; xfoo: Box file was not detected as metadata. Adding it directly... You specified a box version constraint with a direct box file path. Box version constraints only work with boxes from Vagrant Cloud or a custom box host.</description></item><item><title>升级Windows版Git客户端</title><link>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7windows%E7%89%88git%E5%AE%A2%E6%88%B7%E7%AB%AF/</link><pubDate>Thu, 17 Mar 2016 06:10:33 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8D%87%E7%BA%A7windows%E7%89%88git%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid><description>今天在公司收到通知，说Git又有安全漏洞了，需要升级到最新的2.7.3。扫了一眼Get ready to patch Git servers, clients – nasty-looking bugs surface，漏洞涉及到2.x、1.9和1.7版本。 我本机装的是git version 1.9.5.msysgit.0，这才发现MsysGit去年八月份就被Git for Windows 2.x取代了。这次顺手把Git Extensions也给升级到2.48.05了。</description></item><item><title>[HBase] 使用HBase Shell时遇到ZooKeeper exists failed after 4 attempts错误</title><link>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8hbase_shell%E6%97%B6%E9%81%87%E5%88%B0zookeeper_exists_failed_after_4_attempts%E9%94%99%E8%AF%AF/</link><pubDate>Sat, 05 Mar 2016 06:21:09 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8hbase_shell%E6%97%B6%E9%81%87%E5%88%B0zookeeper_exists_failed_after_4_attempts%E9%94%99%E8%AF%AF/</guid><description>今天打开HBase Shell就闪退，可是前两天还好好的。错误如下：
2016-03-05 00:32:23,597 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper exists failed after 4 attempts 2016-03-05 00:32:23,598 WARN [main] zookeeper.ZKUtil: hconnection-0x2dba911d0x0, quorum=node50064.mryqu.com:2181,node50069.mryqu.com:2181,node51054.mryqu.com:2181, baseZNode=/hbase Unable to set watcher on znode (/hbase/hbaseid) org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid at org.apache.zookeeper.KeeperException.create(KeeperException:99) at org.apache.zookeeper.KeeperException.create(KeeperException:51) at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper:1045) at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper:220) at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil:419) at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId:65) at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry:105) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager:905) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.&amp;lt;init&amp;gt;(ConnectionManager:648) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl:45) at at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:238) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:218) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:119) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.</description></item><item><title>[HBase] 才发现HBase REST服务占用的是8080端口</title><link>https://mryqu.github.io/post/hbase_%E6%89%8D%E5%8F%91%E7%8E%B0hbase_rest%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8%E7%9A%84%E6%98%AF8080%E7%AB%AF%E5%8F%A3/</link><pubDate>Thu, 03 Mar 2016 05:43:11 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E6%89%8D%E5%8F%91%E7%8E%B0hbase_rest%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8%E7%9A%84%E6%98%AF8080%E7%AB%AF%E5%8F%A3/</guid><description>今天用一下Tomcat，结果发现8080端口还被占了，谁呀？ 竟然是HBase REST服务占用的！！看了一下Ports Used by Components of CDH 5，发现ClouderaCDH里是这么用的：
8080：Non- Cloudera Manager - managed HBase REST Service 20550：Cloudera Manager - managed HBase REST Service 8085：HBase REST UI 8080端口还是留着吧，对hbase-site.xml做如下修改： 重启HBase REST服务：
hbase-daemon.sh stop rest hbase-daemon.sh start rest 通过HBase REST UI检查，REST服务端口改成了20550： 另一种修改REST服务端口的方式是在启动HBase REST服务命令时通过-p选项直接指定端口。例如：
hbase-daemon.sh start rest -p 20550 参考 Linux – Which application is using port 8080 Configuring and Using the HBase REST API Ports Used by Components of CDH 5</description></item><item><title>[Zookeeper] 运行Zookeeper REST服务实践</title><link>https://mryqu.github.io/post/zookeeper_%E8%BF%90%E8%A1%8Czookeeper_rest%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 02 Mar 2016 05:57:16 +0000</pubDate><guid>https://mryqu.github.io/post/zookeeper_%E8%BF%90%E8%A1%8Czookeeper_rest%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5/</guid><description>Zookeeper REST服务介绍 通常我们应该使用Java/C客户端绑定访问ZooKeeper服务器。不过由于大多数语言内建支持基于HTTP的协议，RESTZooKeeper网关还是很有用的。ZooKeeper REST实现使用Jersey JAX-RS，其REST绑定参考SPEC.txt。其中org.apache.zookeeper.server.jersey.resources.ZNodeResource是项目的核心类，提供Http请求方式对ZooKeeper节点的添加、修改、查询和删除功能，以xml方式返回数据；org.apache.zookeeper.server.jersey.RestMain提供主函数入口。
以Ant脚本方式启动 这是GitHub：apache/zookeeper - REST implementation中介绍的方式。
cd $ZOOPEEPER_HOME ant cd src/contrib/rest nohup ant run&amp;amp; 如果仅是临时运行一下REST服务，ant run即可。 通过nohug提交作业可以确保在退出控制台后ZookeeperREST服务仍在后台运行。当需要关闭时，通过jobs命令查找当前所有运行的作业，通过fg [job_spec]命令关闭作业。 以rest.sh方式启动 cd $ZOOKEEPER_HOME mkdir src/contrib/rest/lib cp build/contrib/rest/zookeeper-dev-rest.jar src/contrib/rest/lib/ cp build/contrib/rest/lib/*.jar src/contrib/rest/lib/ cp zookeeper-3.4.X.jar src/contrib/rest/lib/ cp src/java/lib/*.jar src/contrib/rest/lib/ 启动
cd $ZOOKEEPER_HOME/src/contrib/rest ./rest.sh start 停止
cd $ZOOKEEPER_HOME/src/contrib/rest ./rest.sh stop 查看日志
cd $ZOOKEEPER_HOME/src/contrib/rest tail -f zkrest.log 测试 将我的Zookeeper从node50064复制到node50069和node51054上，分别在三台机器上启动Zookeeper和ZookeeperREST服务。
访问application.wadl 获取根节点数据 获取根节点的子节点 导出节点及znode层次数据 参考 GitHub：apache/zookeeper - REST implementation Zookeeper开启Rest服务(3.4.6) Hue（五）集成Zookeeper New ZooKeeper Browser app!</description></item><item><title>[HBase] 安装HBase 1.2.x + ZooKeeper 3.4.x 集群</title><link>https://mryqu.github.io/post/hbase_%E5%AE%89%E8%A3%85hbase_1.2.x_+_zookeeper_3.4.x_%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 29 Feb 2016 06:23:10 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E5%AE%89%E8%A3%85hbase_1.2.x_+_zookeeper_3.4.x_%E9%9B%86%E7%BE%A4/</guid><description>安装HBase，首先需要参考一下The versions of Hadoop supported with each version of HBase，以便确定Hadoop和HBase各自的版本。
集群规划 |节点|角色 |&amp;mdash;&amp;ndash; |node50064|NameNode RessourceManager QuorumPeerMain HMaster |node50069|Datanode SecondNameNode QuorumPeerMain HMasterHRegionServer |node51054|Datanade QuorumPeerMain HRegionServer
ZooKeeper在HBase集群中的作用 HBase regionserver向ZooKeeper注册，提供HBase regionserver状态信息（是否在线） HMaster启动时候会将HBase 系统表-ROOT-加载到ZooKeeper集群，通过zookeeper集群可以获取当前系统表.META.的存储所对应的regionserver信息。 HMaster主要作用在于，通过HMaster维护系统表-ROOT-,.META.，记录regionserver所对应region变化信息。此外还负责监控处理当前HBase集群中regionserver状态变化信息。
Zookeeper安装 （在node50064上）下载并配置ZooKeeper wget http://apache.mirrors.tds.net/zookeeper/zookeeper-3.4.x/zookeeper-3.4.x.tar.gz tar -xzf zookeeper-3.4.x.tar.gz sudo mv zookeeper-3.4.x /usr/local/zookeeper sudo chown -R &amp;#34;hadoop:hadoop&amp;#34; /usr/local/zookeeper sudo mkdir /var/log/zookeeper sudo chown -R &amp;#34;hadoop:hadoop&amp;#34; /var/log/zookeeper sudo mkdir /var/lib/zookeeper sudo chown -R &amp;#34;hadoop:hadoop&amp;#34; /var/lib/zookeeper cd /var/lib/zookeeper touch myid echo 1 &amp;gt; myid cd /usr/local/zookeeper/conf 通过cpzoo_sample.</description></item><item><title>[Hadoop] Hadoop3信息</title><link>https://mryqu.github.io/post/hadoop_hadoop3%E4%BF%A1%E6%81%AF/</link><pubDate>Sun, 21 Feb 2016 07:12:33 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_hadoop3%E4%BF%A1%E6%81%AF/</guid><description>查看了一下Hadoop 3.0.0-alpha1，结果没查到什么太多信息。 Hadoop Roadmap
HADOOP Move to JDK8+ Classpath isolation on bydefault HADOOP-11656 Shell scriptrewrite HADOOP-9902 Move default ports out of ephemeralrange HDFS-9427 HDFS Removal of hftp in favor ofwebhdfs HDFS-5570 Support for more than twostandby NameNodes HDFS-6440 Support for Erasure Codes inHDFS HDFS-7285 YARN MAPREDUCE Derive heap size ormapreduce.*.memory.mb automatically MAPREDUCE-5785 Apache Hadoop 3.0.0-alpha1-SNAPSHOT JIRA: Hadoop Common 3.0.0-alpha1 http://search-hadoop.com/?q=Hadoop+3: 在Hadoop及其子项目中搜索Hadoop3 Hadoop 3支持最低的JDK版本是JDK8，可在hadoop-commontrunck分支（当前默认分支trunck分支为3.0.0-alpha1，master分支为2.8.0）获得其源码。</description></item><item><title>[C++]获取Facebook帖子生成的SAS时间</title><link>https://mryqu.github.io/post/c++_%E8%8E%B7%E5%8F%96facebook%E5%B8%96%E5%AD%90%E7%94%9F%E6%88%90%E7%9A%84sas%E6%97%B6%E9%97%B4/</link><pubDate>Sat, 20 Feb 2016 06:13:22 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E8%8E%B7%E5%8F%96facebook%E5%B8%96%E5%AD%90%E7%94%9F%E6%88%90%E7%9A%84sas%E6%97%B6%E9%97%B4/</guid><description>写了一个小代码分析Facebook帖子生成时间字符串，将其解析成SAS时间。 简而言之，time_t存储的是距00:00:00, Jan 1, 1970 UTC的秒数（epoch），其中tm_year存储的是当前年数减去1900；而SAS时间起始点为00:00:00, Jan 1, 1960UTC；转换主要使用difftime获取两者的时间差。
代码如下：
参考 C++: time_t C++: time C++: gmtime</description></item><item><title>[C++]获取推文生成的SAS时间</title><link>https://mryqu.github.io/post/c++_%E8%8E%B7%E5%8F%96%E6%8E%A8%E6%96%87%E7%94%9F%E6%88%90%E7%9A%84sas%E6%97%B6%E9%97%B4/</link><pubDate>Fri, 19 Feb 2016 06:07:14 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E8%8E%B7%E5%8F%96%E6%8E%A8%E6%96%87%E7%94%9F%E6%88%90%E7%9A%84sas%E6%97%B6%E9%97%B4/</guid><description>写了一个小代码分析推文生成时间字符串，将其解析成SAS时间。 简而言之，time_t存储的是距00:00:00, Jan 1, 1970 UTC的秒数（epoch），其中tm_year存储的是当前年数减去1900；而SAS时间起始点为00:00:00, Jan 1, 1960UTC；转换主要使用difftime获取两者的时间差。 代码如下：
参考 C++: time_t C++: time C++: gmtime</description></item><item><title>[Hadoop] YARN DistributedShell实践</title><link>https://mryqu.github.io/post/hadoop_yarn_distributedshell%E5%AE%9E%E8%B7%B5/</link><pubDate>Sun, 31 Jan 2016 06:20:46 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_yarn_distributedshell%E5%AE%9E%E8%B7%B5/</guid><description>YARN DistributedShell介绍 Hadoop2的源代码中实现了两个基于YARN的应用，一个是MapReduce，另一个是非常简单的应用程序编程实例——DistributedShell。DistributedShell是一个构建在YARN之上的non-MapReduce应用示例。它的主要功能是在Hadoop集群中的多个节点，并行执行用户提供的shell命令或shell脚本（将用户提交的一串shell命令或者一个shell脚本，由ApplicationMaster控制，分配到不同的container中执行)。
YARN DistributedShell测试 执行下列命令进行测试：
hadoop jar /usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.X.jar -shell_command /bin/ls -shell_args /home/hadoop -jar /usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.X.jar 客户端日志显示执行成功：
参考 如何运行YARN中的DistributedShell程序 YARN DistributedShell源码分析与修改 YARN Distributedshell解析</description></item><item><title>了解HTML5 Data Adapter for SAS®（h54s）</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3html5_data_adapter_for_sash54s/</link><pubDate>Sat, 30 Jan 2016 06:20:15 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3html5_data_adapter_for_sash54s/</guid><description>今天在LinkedIn上看到一个消息，SAS的银牌合作伙伴Boemska开源了他们的HTML5 Data Adapter forSAS®（h54s）。 H54S是一个库，帮助和管理基于HTML5(JavaScript)的Web应用与部署在SAS企业BI平台上以SAS语言开发的后端数据服务之间的无缝双向通信。可以让Web程序员和SAS开发者协作以前所未有的速度和敏捷创建通用Web应用。 服务器端要求：
SAS® BI平台 (9.2及更高版本) SAS® 存储过程Web应用 (集成技术) 粗略扫了一下h54s.sas、h54s.js和method.js：编写一个引入h54s.sas的SAS存储过程，接收前端的JSON数据，经过该SAS存储过程处理后返回给前端JSON结果。
参考 HTML5 Data Adapter for SAS®（h54s） GitHub：boemska/h54s</description></item><item><title>[算法] 汉明重量（Hamming Weight）</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E6%B1%89%E6%98%8E%E9%87%8D%E9%87%8Fhamming_weight/</link><pubDate>Sat, 16 Jan 2016 07:02:17 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E6%B1%89%E6%98%8E%E9%87%8D%E9%87%8Fhamming_weight/</guid><description>LeetCode题191是算整数中比特1的个数，即汉明重量或汉明权重。
汉明重量 汉明重量是一串符号中非零符号的个数。因此它等同于同样长度的全零符号串的汉明距离。在最为常见的数据位符号串中，它是1的个数。 汉明重量是以理查德·卫斯里·汉明的名字命名的，它在包括信息论、编码理论、密码学等多个领域都有应用。
算法 位移实现 我自己的实现就是这种。通过判别n是否为0作为循环退出条件，如果n为0x1的话就位移一次，可是n为0x80000000还是需要位移32次。
public int hammingWeight(int n) { int res = 0; while(n!=0) { res+= (n &amp;amp; 0x1); n &amp;gt;&amp;gt;&amp;gt;=1; } return res; } n &amp;amp; (n-1)实现 public int hammingWeight(int n) { int res = 0; for(;n!=0;n = n &amp;amp; (n-1)) { res++; } return res; } 减1操作将最右边的符号从0变到1，从1变到0，与操作将会移除最右端的1。如果最初n有X个1，那么经过X次这样的迭代运算，n将减到0。n&amp;amp; (n-1)实现在大多数比特为0的情况下是效率最高的。 此外n &amp;amp; (n-1)常用于判断数是否为2的幂数（LeetCode题231）：
----- binary ---- n n n-1 n&amp;amp;(n-1) -- ---- ---- ------- 0 0000 0111 0000 * 1 0001 0000 0000 * 2 0010 0001 0000 * 3 0011 0010 0010 4 0100 0011 0000 * 5 0101 0100 0100 6 0110 0101 0100 7 0111 0110 0110 8 1000 0111 0000 * 9 1001 1000 1000 10 1010 1001 1000 11 1011 1010 1010 12 1100 1011 1000 13 1101 1100 1100 14 1110 1101 1100 15 1111 1110 1110 JDK实现 java.</description></item><item><title>使用Facebook Graph API中的fields参数</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8facebook_graph_api%E4%B8%AD%E7%9A%84fields%E5%8F%82%E6%95%B0/</link><pubDate>Fri, 15 Jan 2016 05:50:04 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8facebook_graph_api%E4%B8%AD%E7%9A%84fields%E5%8F%82%E6%95%B0/</guid><description>使用Facebook Graph API进行查询，v2.3和v2.4版返回结果截然不同。使用v2.3之前的FacebookGraph API获得的响应信息很详细，而使用v2.4及之后的Facebook Graph API获得的响应基本没什么信息！ 这可是相同的AccessToken呀。卖萌的话，可以说句“吓死宝宝了”。
Using the Graph API提到可以使用fields参数选择所需字段，照着v2.3的加上了id、name、about、awards&amp;hellip;&amp;hellip; 失而复得，虚惊一场！！！
Using the Graph API里不仅提到了选择参数，还提到可以使用字段表达式进行嵌套查询。 likes字段使用limit(1)限定其仅返回一个点赞数据，反正我还要使用GraphAPI对帖子点赞数据进行请求，返回一个点赞知道需不需要请求就好了。
comments字段还制定了二级字段attachment、id和from。这样comments字段既不会漏了我需要的子字段，也不会多出来我不需要的字段。在上图GraphAPI Explorer中，左侧comments字段下面的”Search for afield“链接可以提示那些子字段可选，很方便。</description></item><item><title>[CSS] 判断一条CSS样式规则的覆盖者</title><link>https://mryqu.github.io/post/css_%E5%88%A4%E6%96%AD%E4%B8%80%E6%9D%A1css%E6%A0%B7%E5%BC%8F%E8%A7%84%E5%88%99%E7%9A%84%E8%A6%86%E7%9B%96%E8%80%85/</link><pubDate>Thu, 14 Jan 2016 05:48:14 +0000</pubDate><guid>https://mryqu.github.io/post/css_%E5%88%A4%E6%96%AD%E4%B8%80%E6%9D%A1css%E6%A0%B7%E5%BC%8F%E8%A7%84%E5%88%99%E7%9A%84%E8%A6%86%E7%9B%96%E8%80%85/</guid><description>最近项目中有个OpenUI5控件显示缺少左填充，可它在公司的演示项目中却是正常的。接着发现.sasUiWndSectionCont是决定进行填充CSS规则。可是怎么在我的项目中就不成了呢？ 调试过程如下：
打开Chrome开发者工具，选择元素检测器（ElementInspector），选择计算后样式（Computed）标签页，鼠标移动到感兴趣的左填充上（padding-left），点击圆圈图标查看详细内容 跳到样式标签页后发现VDB项目下的.sasUiWndSectionCont定义覆盖了htmlcommons的。 定位成功!</description></item><item><title>处理Twitter API访问速率超限错误</title><link>https://mryqu.github.io/post/%E5%A4%84%E7%90%86twitter_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E8%B6%85%E9%99%90%E9%94%99%E8%AF%AF/</link><pubDate>Wed, 13 Jan 2016 05:54:56 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A4%84%E7%90%86twitter_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E8%B6%85%E9%99%90%E9%94%99%E8%AF%AF/</guid><description>与处理Facebook API访问速率超限错误需要对比好几个Facebook错误代码相比，Twitter的API访问速率超限错误只需要处理HTTP响应代码429即可，很轻松。</description></item><item><title>处理Facebook API访问速率超限错误</title><link>https://mryqu.github.io/post/%E5%A4%84%E7%90%86facebook_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E8%B6%85%E9%99%90%E9%94%99%E8%AF%AF/</link><pubDate>Tue, 12 Jan 2016 06:20:52 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A4%84%E7%90%86facebook_api%E8%AE%BF%E9%97%AE%E9%80%9F%E7%8E%87%E8%B6%85%E9%99%90%E9%94%99%E8%AF%AF/</guid><description>对于下列Facebook通用错误，我个人觉的#2、#4、#9、#17、#18和#32错误都可以向客户端报告FacebookAPI访问速率超限，至于#5不确定。
|Error number|PHP Constant name|Error description|Generated by methods |&amp;mdash;&amp;ndash; |2|API_EC_SERVICE|Service temporarily unavailable|(all) |4|API_EC_TOO_MANY_CALLS|Application request limit reached|(all) |5|API_EC_BAD_IP|Unauthorized source IP address|(all) |9|API_EC_RATE|User is performing too many actions| |17|API_EC_USER_TOO_MANY_CALLS|User request limit reached| |18|API_EC_REQUEST_RESOURCES_EXCEEDED|This API call could not be completed due to resourcelimits| |32||Page request limit reached|
参考 Rate Limiting on the Facebook Graph API Facebook API Error Codes for Developers</description></item><item><title>SocialMedia Error Handling</title><link>https://mryqu.github.io/post/socialmedia_error_handling/</link><pubDate>Sun, 10 Jan 2016 05:57:41 +0000</pubDate><guid>https://mryqu.github.io/post/socialmedia_error_handling/</guid><description>Facebook - Handling Errors https://developers.facebook.com/docs/graph-api/using-graph-api#errors
Marketing API Error Codes https://developers.facebook.com/docs/marketing-api/error-reference
Games Payments Error Codes https://developers.facebook.com/docs/games_payments/fulfillment/errorcodes
List of Error Codes for Facebook&amp;rsquo;s API Facebook曾经有过错误代码列表，后来不提供了。这里提供完整错误代码列表。 http://www.fb-developers.info/tech/fb_dev/faq/general/gen_10.html
Twitter Error Codes &amp;amp; Responses https://dev.twitter.com/overview/api/response-codes
Google Analytics Core Reporting API - Standard Error Responses https://developers.google.com/analytics/devguides/reporting/core/v3/coreErrors#standard_errors
YouTube YouTube API v2.0 – Understanding API Error Responses https://developers.google.com/youtube/2.0/developers_guide_protocol_error_responses
Youtube Data API - Errors https://developers.google.com/youtube/v3/docs/errors</description></item><item><title>Facebook API Endpoint URL</title><link>https://mryqu.github.io/post/facebook_api_endpoint_url/</link><pubDate>Sat, 09 Jan 2016 05:44:05 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_api_endpoint_url/</guid><description>阅读com.restfb.DefaultFacebookClient中的createEndpointForApiCall方法，发现有四种端点URL。
端点URL地址说明FACEBOOK_READ_ONLY_ENDPOINT_URL
https://api-read.facebook.com/method从官方PHP客户端抓取的只读函数列表，当API请求为如下列表项，使用该只读端点URL。
admin.getallocationadmin.getapppropertiesadmin.getbannedusersadmin.getlivestreamvialinkadmin.getmetricsadmin.getrestrictioninfoapplication.getpublicinfoauth.getapppublickeyauth.getsessionauth.getsignedpublicsessiondatacomments.getconnect.getunconnectedfriendscountdashboard.getactivitydashboard.getcountdashboard.getglobalnewsdashboard.getnewsdashboard.multigetcountdashboard.multigetnewsdata.getcookiesevents.getevents.getmembersfbml.getcustomtagsfeed.getappfriendstoriesfeed.getregisteredtemplatebundlebyidfeed.getregisteredtemplatebundlesfql.multiqueryfql.queryfriends.arefriendsfriends.getfriends.getappusersfriends.getlistsfriends.getmutualfriendsgifts.getgroups.getgroups.getmembersintl.gettranslationslinks.getnotes.getnotifications.getpages.getinfopages.isadminpages.isappaddedpages.isfanpermissions.checkavailableapiaccesspermissions.checkgrantedapiaccessphotos.getphotos.getalbumsphotos.gettagsprofile.getinfoprofile.getinfooptionsstream.getstream.getcommentsstream.getfiltersusers.getinfousers.getloggedinuserusers.getstandardinfousers.hasapppermissionusers.isappuserusers.isverifiedvideo.getuploadlimitsFACEBOOK_GRAPH_VIDEO_ENDPOINT_URL
https://graph-video.facebook.comAPI请求以/video或/advideos结尾FACEBOOK_ENDPOINT_URL
https://www.facebook.comAPI请求以logout.php结尾FACEBOOK_GRAPH_ENDPOINT_URL</description></item><item><title>Facebook Graph API之我的常用URL笔记</title><link>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E6%88%91%E7%9A%84%E5%B8%B8%E7%94%A8url%E7%AC%94%E8%AE%B0/</link><pubDate>Fri, 08 Jan 2016 06:20:20 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8B%E6%88%91%E7%9A%84%E5%B8%B8%E7%94%A8url%E7%AC%94%E8%AE%B0/</guid><description>获取Facebook主页Id https://graph.facebook.com/v2.5/SasSoftware?access_token={accessToken}&amp;amp;format=json 上面示例是通过主页名SasSoftware获取其主页Id。
获取Facebook主页帖子 https://graph.facebook.com/v2.5/{pageId}/feed?limit=100&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;access_token={accessToken}&amp;amp;since=2015-01-01&amp;amp;util=2015-12-31 https://graph.facebook.com/{pageId}/feed?limit=100&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;access_token={accessToken}&amp;amp;since=1420041660&amp;amp;util=1422634320 https://graph.facebook.com/v2.0/{pageId}/feed?limit=100&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;access_token={accessToken}&amp;amp;since=1420041660&amp;amp;util=1422634320 通过Facebook Graph API 2.5或不带版本的API仅能获取帖子的Id、创建时间和帖子内容，而FacebookGraph API 2.0则可以获得更多内容。
获取Facebook帖子的评论信息 https://graph.facebook.com/{postId}/comments?limit=100&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;access_token={accessToken}
获取Facebook帖子的点赞信息 https://graph.facebook.com/{postId}/likes?limit=100&amp;amp;format=json&amp;amp;include_hidden=true&amp;amp;summary=true&amp;amp;access_token={accessToken}</description></item><item><title>cURL错误处理</title><link>https://mryqu.github.io/post/curl%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</link><pubDate>Thu, 07 Jan 2016 06:08:54 +0000</pubDate><guid>https://mryqu.github.io/post/curl%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/</guid><description>cURL执行错误分为两种：
通过curl_easy_perform函数执行请求结果，返回值不是CURLE_OK。错误信息除了可以对照CURLcode定义查看，也可以通过设置CURLOPT_ERRORBUFFER设置错误缓存区获得人类易读的错误文字信息。范例见https://curl.haxx.se/libcurl/c/CURLOPT_ERRORBUFFER.html curl = curl_easy_init(); if(curl) { CURLcode res; char errbuf[CURL_ERROR_SIZE]; curl_easy_setopt(curl, CURLOPT_URL, &amp;#34;http://example.com&amp;#34;); curl_easy_setopt(curl, CURLOPT_ERRORBUFFER, errbuf); errbuf[0] = 0; res = curl_easy_perform(curl); if(res != CURLE_OK) { size_t len = strlen(errbuf); fprintf(stderr, &amp;#34;\nlibcurl: (%d) &amp;#34;, res); if(len) fprintf(stderr, &amp;#34;%s%s&amp;#34;, errbuf, ((errbuf[len - 1] != &amp;#39;\n&amp;#39;) ? &amp;#34;\n&amp;#34; : &amp;#34;&amp;#34;)); else fprintf(stderr, &amp;#34;%s\n&amp;#34;, curl_easy_strerror(res)); } } 另一种是curl_easy_perform返回CURLE_OK，但是HTTP响应代码为400及以上的整数。HTTP响应代码可以通过curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE,&amp;amp;httpCode)获得错误消息需要通过curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION,curlCallback)获得消息体后解析而得。</description></item><item><title>为cURL库设置HTTP代理的代码片段</title><link>https://mryqu.github.io/post/%E4%B8%BAcurl%E5%BA%93%E8%AE%BE%E7%BD%AEhttp%E4%BB%A3%E7%90%86%E7%9A%84%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/</link><pubDate>Wed, 06 Jan 2016 06:01:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%BAcurl%E5%BA%93%E8%AE%BE%E7%BD%AEhttp%E4%BB%A3%E7%90%86%E7%9A%84%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/</guid><description>在twitcurl看到cURL库设置http代理的方法，记录一下。
void twitCurl::prepareCurlProxy() { if( m_curlProxyParamsSet ) { return; } curl_easy_setopt( m_curlHandle, CURLOPT_PROXY, NULL ); curl_easy_setopt( m_curlHandle, CURLOPT_PROXYUSERPWD, NULL ); curl_easy_setopt( m_curlHandle, CURLOPT_PROXYAUTH, (long)CURLAUTH_ANY ); std::string proxyIpPort(&amp;#34;&amp;#34;); if( getProxyServerIp().size() ) { utilMakeCurlParams( proxyIpPort, getProxyServerIp(), getProxyServerPort() ); } curl_easy_setopt( m_curlHandle, CURLOPT_PROXY, proxyIpPort.c_str() ); if( m_proxyUserName.length() &amp;amp;amp;&amp;amp;amp; m_proxyPassword.length() ) { std::string proxyUserPass; utilMakeCurlParams( proxyUserPass,getProxyUserName(),getProxyPassword() ); curl_easy_setopt( m_curlHandle,CURLOPT_PROXYUSERPWD,proxyUserPass.c_str() ); } m_curlProxyParamsSet = true; }</description></item><item><title>Facebook Graph API之message_tags</title><link>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8Bmessage_tags/</link><pubDate>Tue, 05 Jan 2016 06:38:10 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E4%B9%8Bmessage_tags/</guid><description>message_tag是Facebook帖子和评论中消息标记的设置档，包括标记ID、文本、类型、偏移和长度。 今天才注意到Facebook帖子（Post）中message_tag是一个JSON对象，而评论（Comment）中message_tag是一个JSON数组。
帖子中的message_tag是这个样子的：
&amp;#34;message_tags&amp;#34;: { &amp;#34;88&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;168597536563870&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;IBM&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 88, &amp;#34;length&amp;#34;: 3 } ], &amp;#34;93&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;241760048297&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Fidelity Investments&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 93, &amp;#34;length&amp;#34;: 20 } ], &amp;#34;115&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;145619362306025&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;ABB&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 115, &amp;#34;length&amp;#34;: 3 } ], &amp;#34;120&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;252467906271&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Quintiles&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 120, &amp;#34;length&amp;#34;: 9 } ], &amp;#34;131&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;193453547355388&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;SAS Software&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 131, &amp;#34;length&amp;#34;: 12 } ], &amp;#34;161&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;702317053131576&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Duke Energy&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 161, &amp;#34;length&amp;#34;: 11 } ], &amp;#34;174&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;313176732094295&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Toshiba Global Commerce Solutions&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 174, &amp;#34;length&amp;#34;: 33 } ], &amp;#34;209&amp;#34;: [ { &amp;#34;id&amp;#34;: &amp;#34;20531316728&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Facebook&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;page&amp;#34;, &amp;#34;offset&amp;#34;: 209, &amp;#34;length&amp;#34;: 8 } ] } 评论中的message_tag是这个样子的：</description></item><item><title>Facebook Graph API获取帖子订阅信息之limit参数</title><link>https://mryqu.github.io/post/facebook_graph_api%E8%8E%B7%E5%8F%96%E5%B8%96%E5%AD%90%E8%AE%A2%E9%98%85%E4%BF%A1%E6%81%AF%E4%B9%8Blimit%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 04 Jan 2016 05:30:32 +0000</pubDate><guid>https://mryqu.github.io/post/facebook_graph_api%E8%8E%B7%E5%8F%96%E5%B8%96%E5%AD%90%E8%AE%A2%E9%98%85%E4%BF%A1%E6%81%AF%E4%B9%8Blimit%E5%8F%82%E6%95%B0/</guid><description>不同版本Facebook Graph API对 获取帖子订阅信息中limit参数要求不同：
v2.0及以下版本没有说明 v2.1、v2.2和v2.3版本上限为250 v2.4和v2.5版本上限为100</description></item><item><title>[C++]用正则表达式检查日期格式yyyy-MM-dd</title><link>https://mryqu.github.io/post/c++_%E7%94%A8%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A3%80%E6%9F%A5%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8Fyyyy-mm-dd/</link><pubDate>Thu, 31 Dec 2015 06:21:51 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E7%94%A8%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A3%80%E6%9F%A5%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8Fyyyy-mm-dd/</guid><description>写了一个小程序使用C++的正则表达式检查日期是否符合yyyy-MM-dd格式： 结果总是抛出exception，错误代码不是error_brack就是error_escape。检查了一下代码，没觉得不符合ECMAScript语法法则。 查了一下我的环境，用的gcc 4.7.0。试了一下regex_match的例子，没问题，但是稍微改动一下用\d{4}检查4位数字就又抛exception了。
C:\&amp;gt;g++ -v Using built-in specs. COLLECT_GCC=C:\quTools\Anaconda\Scripts\g++.bat\..\..\MinGW\bin\g++.exe COLLECT_LTO_WRAPPER=c:/qutools/anaconda/mingw/bin/../libexec/gcc/x86_64-w64-mingw32/4.7.0/lto-wrapper.exe Target: x86_64-w64-mingw32 Configured with: ../../../build/gcc/src/configure --target=x86_64-w64-mingw32 --prefix=/c/bb/vista64-mingw32/mingw-x86-x86_64/build/build/root --with-sysroot=/c/bb/vista64-mingw32/mingw-x86-x86_64/build/build/root --enable-languages=all,obj-c++ --enable-fully-dynamic-string --disable-multilib Thread model: win32 gcc version 4.7.0 20111220 (experimental) (GCC) 搜了一下，发现C++2011标准中的regex功能直到gcc 4.9.0才正式发布。啥也不说了，在Mingw-w64 Toolchains上直接下载个gcc 5.3.0试试，一切正常了
C:\ctest&amp;gt;g++ -v Using built-in specs. COLLECT_GCC=g++ COLLECT_LTO_WRAPPER=C:/tools/mingw32/bin/../libexec/gcc/i686-w64-mingw32/5.3.0/lto-wrapper.exe Target: i686-w64-mingw32 Configured with: ../../../src/gcc-5.3.0/configure --host=i686-w64-mingw32 --build=i686-w64-mingw32 --target=i686-w64-mingw32 --prefix=/mingw32 --with-sysroot=/c/mingw530/i686-530-posix-dwarf-rt_v4-rev0/mingw32 --with-gxx-include-dir=/mingw32/i686-w64-mingw32/include/c++ --enable-shared --enable-static --disable-multilib --enable-languages=c,c++,fortran,lto --enable-libstdcxx-time=yes --enable-threads=posix --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --disable-sjlj-exceptions -- with-dwarf2 --disable-isl-version-check --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch=i686 --with-tune=generic --with-libiconv --with-system-zlib --with-gmp=/c/mingw530/prerequisites/i686-w64-mingw32-static --with-mpfr=/c/mingw530/prerequisites/i686-w64-mingw32-static --with-mpc=/c/mingw530/prerequisites/i686-w64-mingw32-static --with-isl=/c/mingw530/prerequisites/i686-w64-mingw32-static --with-pkgversion=&amp;#39;i686-posix-dwarf-rev0, Built by MinGW -W64 project&amp;#39; --with-bugurl=http://sourceforge.</description></item><item><title>解决使用twitcurl.lib遇到的LNK1112和LNK2038链接错误</title><link>https://mryqu.github.io/post/%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8twitcurl.lib%E9%81%87%E5%88%B0%E7%9A%84lnk1112%E5%92%8Clnk2038%E9%93%BE%E6%8E%A5%E9%94%99%E8%AF%AF/</link><pubDate>Wed, 30 Dec 2015 14:52:38 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8twitcurl.lib%E9%81%87%E5%88%B0%E7%9A%84lnk1112%E5%92%8Clnk2038%E9%93%BE%E6%8E%A5%E9%94%99%E8%AF%AF/</guid><description>在使用twitcurl.lib时，遭遇下列链接错误：
fatal error LNK1112: module machine type &amp;#39;X86&amp;#39; conflicts with target machine type &amp;#39;x64&amp;#39; libtwitcurl.lib(twitcurl.obj) : error LNK2038: mismatch detected for &amp;#39;RuntimeLibrary&amp;#39;: value &amp;#39;MD_DynamicRelease&amp;#39; doesn&amp;#39;t match value &amp;#39;MT_StaticRelease&amp;#39; in xxxxx.obj 解决方法：</description></item><item><title>[C++]玩玩Designated Initializer</title><link>https://mryqu.github.io/post/c++_%E7%8E%A9%E7%8E%A9designated_initializer/</link><pubDate>Mon, 28 Dec 2015 06:18:40 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E7%8E%A9%E7%8E%A9designated_initializer/</guid><description>玩一把gcc的Designated Initializers： 测试结果：结构体内的变量必须按照声明的顺序初始化，并且不能遗漏，否则会报“sorry, unimplemented:non-trivial designated initializers not supported”错误。
参考 C99标准 Bug 55606 - sorry, unimplemented: non-trivial designated initializers not supported C++ - g++: sorry, unimplemented: non-trivial designated initializers not supported - SysTutorials QA http://stackoverflow.com/questions/31215971/non-trivial-designated-initializers-not-supported Non-trivial designated initializers not supported · Issue #8 · couchbaselabs/cbforest · GitHub</description></item><item><title>twitcurl生成HTTP OAuth头的实现流程</title><link>https://mryqu.github.io/post/twitcurl%E7%94%9F%E6%88%90http_oauth%E5%A4%B4%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 27 Dec 2015 06:12:09 +0000</pubDate><guid>https://mryqu.github.io/post/twitcurl%E7%94%9F%E6%88%90http_oauth%E5%A4%B4%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B/</guid><description>对twitcurl代码做了一些修改，结果遇到了认证失败的错误：
{“errors”:[{“message”:”Could not authenticate you”,”code”:32}]} 通过继续修改twitcurl代码改正问题，学习了twitcurl的认证授权部分代码。其授权部分主要在oauthlib.h和oauthlib.cpp中的oAuth类实现中。下面主要分析一下oAuth::getOAuthHeader方法。
外部数据 Http URL: https://api.twitter.com/1.1/search/tweets.json Http头参数:
|参数键|参数值 |&amp;mdash;&amp;ndash; |q|va |count|23 |result_type|recent
Http授权参数:
|参数键|参数值 |&amp;mdash;&amp;ndash; |oauth_consumer_key|xvz1evFS4wEEPTGEFPHBog |oauth_signature_method|HMAC-SHA1 |oauth_token|370773112-GmHxMAgYyLbNEtIKZeRNFsMKPR9EyMZeS9weJAEb |oauth_version|1.0
oAuth::getOAuthHeader方法 通过buildOAuthHttpParameterKeyValPairs(params, true,rawKeyValuePairs);对Http头参数中参数值进行百分号编码（URL编码），编码后结果放在哈希表rawKeyValuePairs中 rawKeyValuePairs: 键值qvacount23result_typerecent 假定HTTP内容是经过百分号编码的，通过buildOAuthRawDataKeyValPairs( rawData,false, rawKeyValuePairs );找到内容中的键值对，放入哈希表rawKeyValuePairs中 rawKeyValuePairs: 键值qvacount23result_typerecent 通过buildOAuthTokenKeyValuePairs( includeOAuthVerifierPin,std::string( &amp;quot;&amp;quot; ), rawKeyValuePairs, true );创建认授权证： rawKeyValuePairs: 键值说明qvacount23result_typerecentoauth_consumer_keyxvz1evFS4wEEPTGEFPHBogoauth_nonce131862295819ctwitcurl实现就是时戳项加一个随机数oauth_signature_methodHMAC-SHA1固定值oauth_timestamp1318622958oauth_token370773112-GmHxMAgYyLbNEtIKZeRNFsMKPR9EyMZeS9weJAEboauth_version1.0固定值 通过getSignature( eType, pureUrl, rawKeyValuePairs,oauthSignature );获得签名 生成 sigBase： 使用consumer_secret和token_secret组成signing_key，使用HMAC_SHA1算法通过sigBase和signing_key生成摘要strDigest：B6 79 C0 AF 18 F4 E9 C5 87 AB 8E 20 0A CD 4E 48 A9 3F 8C B6(非真实计算而得数据) 通过base64_encode进行编码：tnnArxj06cWHq44gCs1OSKk/jLY= (非真实计算而得数据) 通过百分比编码获得最终签名： (非真实计算而得数据) 通过rawKeyValuePairs.</description></item><item><title>表情符号之Unicode和UTF-8编码</title><link>https://mryqu.github.io/post/%E8%A1%A8%E6%83%85%E7%AC%A6%E5%8F%B7%E4%B9%8Bunicode%E5%92%8Cutf-8%E7%BC%96%E7%A0%81/</link><pubDate>Sat, 26 Dec 2015 06:06:24 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%A1%A8%E6%83%85%E7%AC%A6%E5%8F%B7%E4%B9%8Bunicode%E5%92%8Cutf-8%E7%BC%96%E7%A0%81/</guid><description>最近在玩表情符号，这个表情符号Unicode表格，还挺全： http://apps.timwhitlock.info/emoji/tables/unicode 此外也常用这个在线编码转换工具进行验证：http://tool.oschina.net/encode 表情符号的Unicode范围在Android - How to filter emoji (emoticons) from a string?有提到过：
U+2190 to U+21FF U+2600 to U+26FF U+2700 to U+27BF U+3000 to U+303F U+1F300 to U+1F64F U+1F680 to U+1F6FF</description></item><item><title>[C++] 我服务器上的GCC版本不支持C++11特性</title><link>https://mryqu.github.io/post/c++_%E6%88%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84gcc%E7%89%88%E6%9C%AC%E4%B8%8D%E6%94%AF%E6%8C%81c++11%E7%89%B9%E6%80%A7/</link><pubDate>Fri, 25 Dec 2015 06:10:29 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E6%88%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84gcc%E7%89%88%E6%9C%AC%E4%B8%8D%E6%94%AF%E6%8C%81c++11%E7%89%B9%E6%80%A7/</guid><description>用了点C++11特性，结果编译失败，编译参数加&amp;quot;-std=c++0x&amp;quot;，结果识别不出来。
$ g++ -v Using built-in specs. Target: amd64-undermydesk-freebsd Configured with: FreeBSD/amd64 system compiler Thread model: posix gcc version 4.2.1 20070719 [FreeBSD] C++0x/C++11 Support in GCC提到GCC 4.3版本之后才支持C++11特性，白折腾一把！ 好吧，我用gcc docker!</description></item><item><title>[C++]遭遇error C2039: 'min' : is not a member of 'std'</title><link>https://mryqu.github.io/post/c++_%E9%81%AD%E9%81%87error_c2039_min__is_not_a_member_of_std/</link><pubDate>Tue, 22 Dec 2015 05:31:50 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E9%81%AD%E9%81%87error_c2039_min__is_not_a_member_of_std/</guid><description>使用Visual Studio2013编译twitcurl遭遇下列错误：
error C2039: &amp;#39;min&amp;#39; : is not a member of &amp;#39;std&amp;#39; 解决方法：
#include &amp;lt;algorithm&amp;gt;</description></item><item><title>Visual Studio: 使用简体中文（GB2312）编码加载文件, 有些字节已用Unicode替换字符更换</title><link>https://mryqu.github.io/post/visual_studio_%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87gb2312%E7%BC%96%E7%A0%81%E5%8A%A0%E8%BD%BD%E6%96%87%E4%BB%B6_%E6%9C%89%E4%BA%9B%E5%AD%97%E8%8A%82%E5%B7%B2%E7%94%A8unicode%E6%9B%BF%E6%8D%A2%E5%AD%97%E7%AC%A6%E6%9B%B4%E6%8D%A2/</link><pubDate>Mon, 21 Dec 2015 05:55:02 +0000</pubDate><guid>https://mryqu.github.io/post/visual_studio_%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87gb2312%E7%BC%96%E7%A0%81%E5%8A%A0%E8%BD%BD%E6%96%87%E4%BB%B6_%E6%9C%89%E4%BA%9B%E5%AD%97%E8%8A%82%E5%B7%B2%E7%94%A8unicode%E6%9B%BF%E6%8D%A2%E5%AD%97%E7%AC%A6%E6%9B%B4%E6%8D%A2/</guid><description>遭遇下列VS2010错误: Some bytes have been replaced with the Unicodesubstitution character while loading file base64.cpp with ChineseSimplified (GB2312) encoding. Saving the file will not preserve theoriginal file contents. 我的Visual Studio已经勾选了Auto-detect UTF-8 encoding withoutsignature: Ultraedit不能正常显示base64.cpp，但Sublime Text能正常显示。 原因是base64.cpp并不是UTF-8编码，但是包含一个十六进制为&amp;quot;E9&amp;quot;的字符，即带重音符的e。由于我的系统locale是RPC，所以显示不正常，估计系统locale改成CP1252 - Windows 拉丁语1代码页就可以了。用Sublime Text将其转存为UTF-8编码当然也可以。</description></item><item><title>[C++] Building twitcurl Library in Unix platform</title><link>https://mryqu.github.io/post/c++_building_twitcurl_library_in_unix_platform/</link><pubDate>Sat, 19 Dec 2015 05:47:33 +0000</pubDate><guid>https://mryqu.github.io/post/c++_building_twitcurl_library_in_unix_platform/</guid><description> Download twitcurl source from https://github.com/swatkat/twitcurl using Git client. git clone https://github.com/swatkat/twitcurl.git In Unix shell, cd into libtwitcurl directory. Compile all of the twitcurlsource files into object files. g++ -Wall -fPIC -c -I. twitcurl.cpp oauthlib.cpp urlencode.cpp base64.cpp HMAC_SHA1.cpp SHA1.cpp Building twitcurl asstatic library: Use the archive commandto build twitcurl library from object files. ar rvs libtwitcurl.a *.o</description></item><item><title>[C++] 使用NM查看目标文件的符号列表</title><link>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8nm%E6%9F%A5%E7%9C%8B%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%A6%E5%8F%B7%E5%88%97%E8%A1%A8/</link><pubDate>Fri, 18 Dec 2015 06:10:13 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8nm%E6%9F%A5%E7%9C%8B%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%A6%E5%8F%B7%E5%88%97%E8%A1%A8/</guid><description>练习使用nm查看目标文件的符号列表。此外发现G++竟然创建了两套构造函数和析构函数。
nm命令 -a或&amp;ndash;debug-syms：显示调试符号。 -B：等同于&amp;ndash;format=bsd，用来兼容MIPS的nm。 -C或&amp;ndash;demangle：将低级符号名解码(demangle)成用户级名字。这样可以使得C++函数名具有可读性。 -D或&amp;ndash;dynamic：显示动态符号。该任选项仅对于动态目标(例如特定类型的共享库)有意义。 -fformat：使用format格式输出。format可以选取bsd、sysv或posix，该选项在GNU的nm中有用。默认为bsd。 -g或&amp;ndash;extern-only：仅显示外部符号。 -n、-v或&amp;ndash;numeric-sort：按符号对应地址的顺序排序，而非按符号名的字符顺序。 -p或&amp;ndash;no-sort：按目标文件中遇到的符号顺序显示，不排序。 -P或&amp;ndash;portability：使用POSIX.2标准输出格式代替默认的输出格式。等同于使用任选项-fposix。 -s或&amp;ndash;print-armap：当列出库中成员的符号时，包含索引。索引的内容包含：哪些模块包含哪些名字的映射。 -r或&amp;ndash;reverse-sort：反转排序的顺序(例如，升序变为降序)。 &amp;ndash;size-sort：按大小排列符号顺序。该大小是按照一个符号的值与它下一个符号的值进行计算的。 -tradix或&amp;ndash;radix=radix：使用radix进制显示符号值。radix只能为&amp;quot;d&amp;quot;表示十进制、&amp;ldquo;o&amp;quot;表示八进制或&amp;quot;x&amp;quot;表示十六进制。 &amp;ndash;target=bfdname：指定一个目标代码的格式，而非使用系统的默认格式。 -u或&amp;ndash;undefined-only：仅显示没有定义的符号(那些外部符号)。 -l或&amp;ndash;line-numbers：对每个符号，使用调试信息来试图找到文件名和行号。对于已定义的符号，查找符号地址的行号。对于未定义符号，查找指向符号重定位入口的行号。如果可以找到行号信息，显示在符号信息之后。 -V或&amp;ndash;version：显示nm的版本号。 &amp;ndash;help：显示nm的任选项。 练习 symtest.hpp #include &amp;lt;iostream&amp;gt; class SymTest { SymTest(); SymTest(int x); ~SymTest(); void foo(); }; symtest.cpp #include &amp;#34;symtest.hpp&amp;#34; SymTest::SymTest() { printf(&amp;#34;SymTest::SymTest\n&amp;#34;); } SymTest::SymTest(int x) { printf(&amp;#34;SymTest::SymTest(int)\n&amp;#34;); } SymTest::~SymTest() { printf(&amp;#34;SymTest::~SymTest\n&amp;#34;); } void SymTest::foo() { printf(&amp;#34;SymTest::foo\n&amp;#34;); } 编译 NM: -g 仅显示外部符号 -C 显示用户级名字 学习了StackOverflow上的帖子Dual emission of constructor symbols，才了解这是G++的一个已知问题，两套构造函数分别是complete objectconstructor和base object constructor。
NM: -A 在每个符号前显示文件名 NM: -l 在每个符号前显示行号 mymachine&amp;gt; g++ -c symtest.</description></item><item><title>FileUpload Streaming</title><link>https://mryqu.github.io/post/fileupload_streaming/</link><pubDate>Sun, 13 Dec 2015 06:02:47 +0000</pubDate><guid>https://mryqu.github.io/post/fileupload_streaming/</guid><description>最近看一下org.apache.tomcat.util.http.fileupload，这个包是从commons-fileupload和commons-io复制而来，为了避免冲突而改名。 Apache Commons FileUpload是用于servlet和web应用的健壮、高性能文件上传库，它支持 RFC 1867和RFC2047。 传统的文件上传API假设文件在被用户访问前必须存储在某处，这种途径便捷、易于访问，但是消耗内存和耗时。流处理API允许在高性能和低内存配置之间做一点折中。 首先，需要确保请求是一个文件上传请求。这通过与传统API相同的静态方法实现：
// Check that we have a file upload request boolean isMultipart = ServletFileUpload.isMultipartContent(request); 现在需要解析请求获取成分项：
// Create a new file upload handler ServletFileUpload upload = new ServletFileUpload(); // Parse the request FileItemIterator iter = upload.getItemIterator(request); while (iter.hasNext()) { FileItemStream item = iter.next(); if (!item.isFormField()) { String name = item.getFieldName(); if(name==null) continue; InputStream stream = item.openStream(); System.out.println(&amp;#34;File field &amp;#34; + name + &amp;#34; with file name &amp;#34; + item.</description></item><item><title>Sublime Text2+Ctags+Cscope使用实践</title><link>https://mryqu.github.io/post/sublime_text2+ctags+cscope%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 09 Dec 2015 07:07:45 +0000</pubDate><guid>https://mryqu.github.io/post/sublime_text2+ctags+cscope%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/</guid><description>安装 安装Package Control 步骤见https://packagecontrol.io/installation#st2
安装CTags插件 通过 Preference -&amp;gt; Package Control -&amp;gt; InstallPackage安装Ctags插件（快捷键Ctrl+Shift+P，输入install） 打开Preference -&amp;gt; Package Settings -&amp;gt; Ctags -&amp;gt;Settings-Default和Setting-User，将Settings-Default中的内容拷贝到Setting-User中，将&amp;quot;command&amp;quot;: &amp;quot;&amp;quot; 中的 &amp;quot;&amp;quot; 填入Ctags.exe的路径位置 打开C工程根目录，在上点击右键，选择Ctags:Rebuild tags 安装Cscope插件 同样通过 Preference -&amp;gt; Package Control -&amp;gt; InstallPackage安装Cscope插件（快捷键Ctrl+Shift+P，输入install） 通过cscope –Rb在C工程根目录创建cscope.out文件 Cscope在ST2上没有包配置菜单，需要打开CscopeSublime.sublime-settings文件(我的机器在C:/Users/yqu/AppData/Roaming/SublimeText 2/Packages/Cscope目录下)，将 &amp;ldquo;executable&amp;rdquo;: &amp;quot;&amp;quot; 中的 &amp;ldquo;&amp;ldquo;填入Cscope.exe的路径位置,将 &amp;ldquo;database_location&amp;rdquo;: &amp;quot;&amp;rdquo; 中的&amp;quot;&amp;ldquo;填入cscope.out的路径位置。 使用 CTags命令 |Command|Key Binding|Alt Binding|Mouse Binding |&amp;mdash;&amp;ndash; |rebuild_ctags|ctrl+t, ctrl+r| | |navigate_to_definition|ctrl+t, ctrl+t|ctrl+&amp;gt;|ctrl+shift+left_click |jump_prev|ctrl+t, ctrl+b|ctrl+&amp;lt;|ctrl+shift+right_click |show_symbols|alt+s| | |show_symbols (all files)|alt+shift+s| | |show_symbols (suffix)|ctrl+alt+shift+s| | Cscope命令 Ctrl + \ - Show Cscope options Ctrl + L , Ctrl + S - Look up symbol undercursor Ctrl + L , Ctrl + D - Look up definition undercursor Ctrl + L , Ctrl + E - Look up functions calledby the function under the cursor Ctrl + L , Ctrl + R - Look up functionscalling the function under the cursor Ctrl + Shift + [ - Jump back Ctrl + Shift + ] - Jump forward 其他快捷键 Ctrl + p - 快速定位项目中的文件 Ctrl + R - 获取当前文件中的函数列表（# 和 @分别为变量和函数），这个功能也使得ST2不需要taglist插件了。 参考 使用Sublime Text3+Ctags+Cscope替代Source Insight Exuberant Ctags笔记 Cscope笔记</description></item><item><title>[C++] 使用readelf</title><link>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8readelf/</link><pubDate>Tue, 08 Dec 2015 06:06:31 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8readelf/</guid><description>在计算机科学中，ELF文件（Executableand LinkableFormat）是一种用于二进制文件、可执行文件、目标代码、共享库和核心转储格式文件，是UNIX系统实验室（USL）作为应用程序二进制接口（ApplicationBinaryInterface，ABI）而开发和发布的，也是Linux的主要可执行文件格式。1999年，被86open项目选为x86架构上的类Unix操作系统的二进制文件标准格式，用来取代COFF。因其可扩展性与灵活性，也可应用在其它处理器、计算机系统架构的操作系统上。 ELF文件由4部分组成，分别是ELF头（ELF header）、程序头表（Program headertable）、节（Section）和节头表（Section headertable）。实际上，一个文件中不一定包含全部内容，而且他们的位置也未必如同所示这样安排，只有ELF头的位置是固定的，其余各部分的位置、大小等信息由ELF头中的各项值来决定。 而readelf用于显示ELF文件的信息。 Usage: readelf &amp;lt;option(s)&amp;gt; elf-file(s) Display information about the contents of ELF format files Options are: -a --all 全部 Equivalent to: -h -l -S -s -r -d -V -A -I -h --file-header ELF头 Display the ELF file header -l --program-headers 程序头表 Display the program headers --segments An alias for --program-headers -S --section-headers 节头 Display the sections&amp;#39; header --sections An alias for --section-headers -g --section-groups 节组 Display the section groups -t --section-details 节细节 Display the section details -e --headers 全部头 Equivalent to: -h -l -S -s --syms 符号表 Display the symbol table --symbols An alias for --syms --dyn-syms 动态符号表 Display the dynamic symbol table -n --notes 核心注释 Display the core notes (if present) -r --relocs 重定位 Display the relocations (if present) -u --unwind Display the unwind info (if present) -d --dynamic 动态节 Display the dynamic section (if present) -V --version-info 版本节 Display the version sections (if present) -A --arch-specific 架构信息 Display architecture specific information (if any) -c --archive-index 该架构下符号/文件索引 Display the symbol/file index in an archive -D --use-dynamic Use the dynamic section info when displaying symbols -x --hex-dump=&amp;lt;number|name&amp;gt; Dump the contents of section &amp;lt;number|name&amp;gt; as bytes -p --string-dump=&amp;lt;number|name&amp;gt; Dump the contents of section &amp;lt;number|name&amp;gt; as strings -R --relocated-dump=&amp;lt;number|name&amp;gt; Dump the contents of section &amp;lt;number|name&amp;gt; as relocated bytes -w[lLiaprmfFsoRt] or --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames, =frames-interp,=str,=loc,=Ranges,=pubtypes, =gdb_index,=trace_info,=trace_abbrev,=trace_aranges, =addr,=cu_index] 显示DWARF2调试节 Display the contents of DWARF2 debug sections --dwarf-depth=N Do not display DIEs at depth N or greater --dwarf-start=N Display DIEs starting with N, at the same depth or deeper -I --histogram 柱状图 Display histogram of bucket list lengths -W --wide 输出宽度 Allow output width to exceed 80 characters @&amp;lt;file&amp;gt; Read options from &amp;lt;file&amp;gt; -H --help 帮助 Display this information -v --version 版本 Display the version number of readelf 练习 - 查看ELF文件头 hadoop@node51054:/usr/bin$ readelf -h curl ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&amp;#39;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: EXEC (Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x4023b1 Start of program headers: 64 (bytes into file) Start of section headers: 152600 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 9 Size of section headers: 64 (bytes) Number of section headers: 27 练习 - 查看符号表 hadoop@node51054:/usr/bin$ readelf -s curl Symbol table &amp;#39;.</description></item><item><title>[C++] 使用ldd</title><link>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8ldd/</link><pubDate>Mon, 07 Dec 2015 06:05:11 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%BD%BF%E7%94%A8ldd/</guid><description>ldd是用来查看共享库依赖的Shell脚本命令。下面来看一下ldd命令的参数。 -v：显示所有信息，例如包括符号版本信息。 -u：显示没有使用的直接依赖。 -d：执行重新定位，报告任何缺失对象（仅针对ELF） -r：对数据对象和函数执行重新定位，报告任何缺失对象或函数（仅针对ELF） Oracle - Linker and Libraries Guide - Relocations介绍了重新定位技术的来龙去脉，也介绍了ldd命令的相关使用。
ldd练习 hadoop@node51054:/usr/bin$ ldd curl linux-vdso.so.1 =&amp;gt; (0x00007ffefe989000) libcurl.so.4 =&amp;gt; /usr/lib/x86_64-linux-gnu/libcurl.so.4 (0x00007fb86cf8f000) libz.so.1 =&amp;gt; /lib/x86_64-linux-gnu/libz.so.1 (0x00007fb86cd76000) libpthread.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fb86cb58000) libc.so.6 =&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fb86c790000) libidn.so.11 =&amp;gt; /usr/lib/x86_64-linux-gnu/libidn.so.11 (0x00007fb86c55d000) librtmp.so.0 =&amp;gt; /usr/lib/x86_64-linux-gnu/librtmp.so.0 (0x00007fb86c343000) libssl.so.1.0.0 =&amp;gt; /lib/x86_64-linux-gnu/libssl.so.1.0.0 (0x00007fb86c0e4000) libcrypto.so.1.0.0 =&amp;gt; /lib/x86_64-linux-gnu/libcrypto.so.1.0.0 (0x00007fb86bd08000) libgssapi_krb5.so.2 =&amp;gt; /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2 (0x00007fb86bac1000) liblber-2.4.so.2 =&amp;gt; /usr/lib/x86_64-linux-gnu/liblber-2.4.so.2 (0x00007fb86b8b2000) libldap_r-2.4.so.2 =&amp;gt; /usr/lib/x86_64-linux-gnu/libldap_r-2.4.so.2 (0x00007fb86b661000) /lib64/ld-linux-x86-64.so.2 (0x00007fb86d1f6000) libgnutls.so.26 =&amp;gt; /usr/lib/x86_64-linux-gnu/libgnutls.so.26 (0x00007fb86b3a2000) libgcrypt.</description></item><item><title>[C++] GNU Binutils之ar和ranlib</title><link>https://mryqu.github.io/post/c++_gnu_binutils%E4%B9%8Bar%E5%92%8Cranlib/</link><pubDate>Sun, 06 Dec 2015 07:36:13 +0000</pubDate><guid>https://mryqu.github.io/post/c++_gnu_binutils%E4%B9%8Bar%E5%92%8Cranlib/</guid><description>GNU binutils是一组二进制工具集。包括：ld、as、addr2line、ar、gprof、nm、objcopy、objdump、ranlib、size、strings、strip等。本文重点学习一下其中的ar和ranlib。
ar命令 ar用于建立、修改、提取档案文件(archive)。archive是一个包含多个被包含文件的单一文件（也称之为库文件），其结构保证了可以从中检索并得到原始的被包含文件（称之为archive中的member）。member的原始文件内容、模式（权限）、时间戳、所有者和组等属性都被保存在archive中。member被提取后，他们的属性被恢复到初始状态。 ar命令第一个参数可混合指令代码（operationcode p）和修饰符标志（modifier flags mod），可按意愿添加一个折线。
ar [--plugin name] [-X32_64] [-]p[mod [relpos] [count]] archive [member...] 指令参数 d：删除档案文件中的成员文件。 m：移动在档案文件中的成员文件，改变次序。可以借助修饰符标志a、b、i移动到指定位置。 p：显示档案文件中的成员文件内容。 q：将文件快速附加在档案文件末端。不检查、不替换已有同名成员文件，也不更新档案文件的符号表索引，修饰符标志a、b、i无效。然而很多不同系统都假设q指令重建档案文件的符号表索引，因此GNU将其按照r指令进行相同实现。 r：将文件插入档案文件中。检查并替换已有同名成员文件，重建档案文件的符号表索引，借助修饰符标志a、b、i将文件插入到指定位置。 t：显示档案文件中所包含的文件。 x：自档案文件中取出成员文件。 修饰符标志 a &amp;lt;成员文件&amp;gt;：将文件插入档案文件中指定的成员文件之后。 b&amp;lt;成员文件&amp;gt;：将文件插入档案文件中指定的成员文件之前。 c：建立档案文件。当更新档案文件时，档案文件不存在则创建档案文件，但会告警。此标志可抑制告警。 D：以确定模式工作。 f：为避免过长的文件名不兼容于其他系统的ar指令指令，可利用此参数，截掉要放入档案文件中过长的成员文件名称。 i &amp;lt;成员文件&amp;gt;：将文件插入档案文件中指定的成员文件之前。（等同标志b） I：可接受但不使用。 N：使用count参数。当档案文件中存在多个同名成员，用于指定提取/删除的个数。 o：保留档案文件中文件的日期。如无此参数，则输出文件的修改时间为提取时间。 s：若档案文件中包含了对象模式，可利用此参数建立档案文件的符号表。 S：不产生符号表。 T：使指定档案文件成为瘦档案文件。例如将多个档案文件加入目标档案文件，目标档案文件可以包含符号索引及对源档案文件中成员文件的引用。 u：只将日期较新文件插入档案文件中。 v：程序执行时显示详细的信息。 V：显示版本信息。 练习 # 将当前目录下所有.o打包成libyqutest.a档案文件：r插入，v显示操作信息，s生成符号表。 ar rvs libyqutest.a *.o # 制作瘦档案文件：r插入，c建立档案文件，T指定为瘦档案文件。 ar -rcT libkx.a libke.a libxiao.a ranlib命令 为档案文件创建符号索引。
ranlib [-vVt] archive 选项：
-v、-V或&amp;ndash;version：显示版本 -t：更新档案文件符号映射的时戳。 最早在Unix系统上ar程序是单纯用来打包多个.o到.a（类似于tar做的事情），而不处理.o里的符号表。Linker程序则需要.a文件提供一个完整的符号表，所以当时就写了单独的ranlib程序用来产生linker所需要的符号信息，也就是说那时，产生一个对linker合格的的.a文件需要做ar和ranlib两步 。如今，ar-s就做了ranlib的工作，但为了保证这些早期Makefile文件的兼容性，ranlib被保留下来了。</description></item><item><title>[MapR培训笔记] Hadoop生态系统</title><link>https://mryqu.github.io/post/mapr%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0_hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F/</link><pubDate>Sat, 05 Dec 2015 00:00:41 +0000</pubDate><guid>https://mryqu.github.io/post/mapr%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0_hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F/</guid><description>SQL: Language designed for querying &amp;amp; transformingdata held in a relational database management system. NoSQL: Database model that&amp;rsquo;s not necessaryly held intabular format. Often, NoSQL refers to data that is flat or nestedin format. Log Data: Information captured about organization&amp;rsquo;sinternal system, external customer interactions &amp;amp; how they&amp;rsquo;reused Streaming Data: Twitter, Facebook, Web click data, Webform data. Flume: Reliable, scalable service used to collectstreaming data in Hadoop cluster. Sqoop: Transfers data between external data store &amp;amp;Hadoop cluster.</description></item><item><title>[Spring Boot] 让非Spring管理的类获得一个Bean</title><link>https://mryqu.github.io/post/spring_boot_%E8%AE%A9%E9%9D%9Espring%E7%AE%A1%E7%90%86%E7%9A%84%E7%B1%BB%E8%8E%B7%E5%BE%97%E4%B8%80%E4%B8%AAbean/</link><pubDate>Fri, 04 Dec 2015 06:08:47 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_%E8%AE%A9%E9%9D%9Espring%E7%AE%A1%E7%90%86%E7%9A%84%E7%B1%BB%E8%8E%B7%E5%BE%97%E4%B8%80%E4%B8%AAbean/</guid><description>我有一个工具类，它既会被SpringBean调用，也会被非Spring管理的类调用。我想在这个工具类里获得Spring注入了拦截器的RestTemplate。一开始考虑了ApplicationContextAware、ContextLoaderListener和ContextLoaderServlet，最后采用了下面这种改动最小的解决方案。
示例代码 Application.java @SpringBootApplication public class Application{ public static void main(String[] args) { final ApplicationContext applicationContext = SpringApplication.run(Application.class, args); MyUtil.setApplicationContext(applicationContext); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } MyUtil.java public class MyUtil { private static ApplicationContext applicationContext; public static void setApplicationContext(ApplicationContext context) { applicationContext = context; } public static void doSomething() { RestTemplate _restTemplate = applicationContext.getBean(RestTemplate.class); ........ } }</description></item><item><title>[Spring Boot] Use alwaysUseFullPath for Spring MVC URL mapping</title><link>https://mryqu.github.io/post/spring_boot_use_alwaysusefullpath_for_spring_mvc_url_mapping/</link><pubDate>Thu, 03 Dec 2015 06:38:56 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_use_alwaysusefullpath_for_spring_mvc_url_mapping/</guid><description>简介 SpringMVC的URL映射有一个控制路径匹配的参数alwaysUseFullPath。当它被设置为true后，总是使用当前servlet上下文中的全路径进行URL查找，否则使用当前servlet映射内的路径。默认为false。下面示例一下当一个请求的全路径通过servlet映射找到所服务的RequestDispatcherservelet后alwaysUseFullPath为false时URL映射表现：
servlet mapping = &amp;ldquo;/*&amp;rdquo;; request URI = &amp;ldquo;/test/a&amp;rdquo; -&amp;gt; &amp;ldquo;/test/a&amp;rdquo; servlet mapping = &amp;ldquo;/&amp;rdquo;; request URI = &amp;ldquo;/test/a&amp;rdquo; -&amp;gt; &amp;ldquo;/test/a&amp;rdquo; servlet mapping = &amp;ldquo;/test/*&amp;rdquo;; request URI = &amp;ldquo;/test/a&amp;rdquo; -&amp;gt; &amp;ldquo;/a&amp;rdquo; servlet mapping = &amp;ldquo;/test&amp;rdquo;; request URI = &amp;ldquo;/test&amp;rdquo; -&amp;gt; &amp;quot;&amp;quot; servlet mapping = &amp;ldquo;/*.test&amp;rdquo;; request URI = &amp;ldquo;/a.test&amp;rdquo; -&amp;gt; &amp;quot;&amp;quot; 从org.springframework.web.util.UrlPathHelper的getLookupPathForRequest方法可知，当alwaysUseFullPath为true时使用getPathWithinApplication获得待查找的全路径，否则使用getPathWithinServletMapping获得待查找的剩余路径。 如果对alwaysUseFullPath的设置进行修改，对RestController的请求映射也要做相应的设置修改。
@RequestMapping(value = {&amp;#34;**/test/dosomething**&amp;#34;}, method = RequestMethod.POST, produces = { MediaType.APPLICATION_JSON_VALUE }) 假设servlet映射为&amp;quot;/test/*&amp;ldquo;且RestControoler仅在方法级别进行请求映射，如果alwaysUseFullPath为true时请求映射为上面的&amp;rdquo;/test/dosomething&amp;quot;。则在alwaysUseFullPath改为false后，请求映射相应改为&amp;quot;/dosomething&amp;quot;即可。
alwaysUseFullPath设置范例 想在SpringBoot应用中设定alwaysUseFullPath为true，可通过BeanPostProcessor完成其设置。
@SpringBootApplication public class Application implements BeanPostProcessor { public static void main(String[] args) { final ApplicationContext applicationContext = SpringApplication.</description></item><item><title>[Hadoop] YARN中Application Manager和Application Master区别</title><link>https://mryqu.github.io/post/hadoop_yarn%E4%B8%ADapplication_manager%E5%92%8Capplication_master%E5%8C%BA%E5%88%AB/</link><pubDate>Sat, 28 Nov 2015 05:56:33 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_yarn%E4%B8%ADapplication_manager%E5%92%8Capplication_master%E5%8C%BA%E5%88%AB/</guid><description>术语Application Master和Application Manager经常被交换使用。其实，ApplicationMaster是一个主要的容器，用于请求、启动和监控应用特定资源；而ApplicationManager是资源管理器中的一个部件。 一个作业在YARN中启动流程如下：
首先客户端向YARN资源管理器提交应用，包括请求容器启动上下文所需的信息。 接着资源管理器中的应用管理器协商好一个容器，为应用引导一个Application Master实例。 之后Application Master向资源管理器注册并请求容器。 当ApplicationMaster同节点管理器进行通信启动所授予的容器之后，为每个容器指定容器启动上下文描述（CLC，包括执行启动的命令、安全令牌、依赖[可执行文件、压缩包]、环境变量等等）。 Application Master管理应用执行。在执行期间，应用向ApplicationMaster提供进度和状态信息。客户端通过查询资源管理器或直接与ApplicationMaster联系，可以监控应用的状态。 Application Master向资源管理器报告应用结束。 应用管理器负责维护一系列已提交的应用。当应用提交后，它首先验证应用规格，为ApplicationMaster拒绝任何请求无法满足资源的应用（例如，集群中没有节点有足够资源运行ApplicationMaster自身）。之后确保没有已经运行的使用相同应用ID的其他应用，错误的客户端或恶意客户端有可能导致此类问题。最后，将提交的应用转给调度器。已结束应用从资源管理器内存完全清除之前，此部件也负责记录和管理这些已结束应用。当应用结束，它将应用汇总信息放在守护进程的日志文件。最后，应用管理器在应用完成用户请求后很久都会在缓存中保留该已结束应用。配置参数yarn.resourcemanager.max-completed-applications控制资源管理器在任意时刻可以记住的已结束应用的最大数量。该缓存是先入先出队列，为了存放最新的已结束应用，最老的应用将被移出。 参考 Difference between Application Manager and Application Master in YARN? Application Master 启动流程与服务简介</description></item><item><title>[MapR培训笔记]Hadoop基础</title><link>https://mryqu.github.io/post/mapr%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0_hadoop%E5%9F%BA%E7%A1%80/</link><pubDate>Wed, 25 Nov 2015 06:23:37 +0000</pubDate><guid>https://mryqu.github.io/post/mapr%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0_hadoop%E5%9F%BA%E7%A1%80/</guid><description>学习目标 大数据介绍: 理解大数据定义，判断是否存在大数据问题，描述如何用Hadoop解决大数据问题； Hadoop核心元素:描述分布式文件系统如何工作，map/reduce如何在分布式文件系统上处理数据； Hadoop工具生态系统: 了解Hadoop相关工具及其作用； 解决大数据用例: 描述Hadoop生态系统如何协同解决各种大数据用例，如何在不同场景下选择工具。 第一课 数据如何变大 学习目标 定义大数据及大数据问题 描述Hadoop主要部件 大数据 差不多是4V中的前三个,以及使数据难于描述、存储或处理的一些其他特性
Volume（大量）:太大以至于系统无法处理 Variety（多样）: 太多不同种类的数据，无法简单描述 Velocity（高速）: 数据产生太快以至于系统无法处理 Value（价值）: Hadoop主要部件 Google收到大数据挑战后，认识到无法用传统关系型数据库解决，创建了GFS+BigTabel+Map/Reduce。
GFS将文件分割成块，分布在集群的节点上。文件块在不同节点进行复制，以防止节点故障导致的数据丢失。 BigTable是使用GFS存储和获取数据的（分布式、多级）数据库系统。BigTable使用行键、列键和时戳映射到所存储的数据，可以不重写已有数据在不同时间对相同信息进行采集。行被分片为称之为Tablet的子表，分布到集群内。BigTable被设计成可以处理大量数据，可以无需重新配置已有文件的情况下向集群添加新的节点。 并行处理范式map/reduce被用于处理存储在GPS上的数据。map/reduce代表处理的两个步骤。在mapping阶段，所有数据在逻辑上分割，map函数应用于所有割片以生成键值对。框架对所有来自mapper的键值对进行排序然后在reducer之间分片。在reduce阶段，reduce函数应用于所有分片。map/reduce是一种分而治之的方式，将单个庞大的作业分解成一系列小的可管理的任务。 Google实验多年后发表了论文阐述了他们的大数据解决方案。DougCutting以此在Yahoo开发一个项目，后来开源成Apache基金会项目下的Hadoop（Cutting儿子玩具象的名字）。 Mapr利用Hadoop理念，开发了更快、更稳定的企业版Hadoop。
第二课 Hadoop核心 学习目标 本地&amp;amp;分布式文件系统 MapR-FS中的数据管理 （使用命令行）执行数据管理 Map Reduce范式 本地文件系统 HFS/NTFS（读写）和CDFS（只读）都是本地文件系统。文件系统中每个文件都由一个iNode和一系列数据块构成。iNode存储文件元数据，例如文件类型、权限、所有者、文件名和最后一次修改时间等信息，它还存储文件所存储的数据块的指针。数据块用于存储文件的实际内容。 本地文件系统的常见问题
硬盘故障：本地硬盘镜像（RAID-1） 丢失：云镜像 人为失误 误删：定期增量备份 空间不足：增加硬盘、硬盘阵列（RAID-0） 分布式文件系统 分布式文件系统行为与RAID-0类似，但硬盘分布在多个服务器上。由Sun微系统公司开发的网络文件系统NFS仍广泛用于在网络内存储和获取数据。 分布式文件系统当处理数据时致力于透明性，即对于客户端程序来说，文件系统与本地文件系统类似，分布式文件系统不可见。由于数据在网络内多个机器内分布，分布式文件系统使用数据定位器存储数据位置信息。与本地文件系统中的iNode类似，数据定位器只想数据在分布式文件系统中存储的位置。
MapR-FS存储 MapRFS是分布式文件系统，是Hadoop的MapR分发版的底层文件系统。它支持所有前面提到的本地文件系统特性，包括读写访问、本地或远程镜像，及在联机时对文件系统扩容的能力。此外，MapR文件系统可以加载并直接处理已有HDFS或NFS文件系统中的数据。
物理存储 集群是一组使用分布文件系统（例如MapR-FS）的计算机。集群中每个计算机称为一个节点，每个节点有一或多个物理硬盘。 在MapR-FS中，硬盘组合成组，称为存储池（storagepool）。默认一个存储池有三块硬盘组成。当数据写往存储池，数据在三个磁盘拆分写入，增加写速度。每个节点包含一或多个存储池，所有节点上的所有存储池构成了MapR-FS上的全部可用存储。
逻辑存储 MapR-FS将数据写入称之为容器（container）的逻辑单元。一个容器默认大小32GB，一个存储池通常有多个容器。容器内的数据在集群内节点间复制以防止单点故障或硬盘故障。 容器组合成卷（volume）。卷是跨集群内一组节点的数据资源逻辑抽象概念。所有容器及其副本在卷拓扑内的节点上分布。MapR-FS使用称之为容器定位数据库（CDLB）的特定服务存储容器及其副本的位置。CLDB为MapR-FS执行数据定位功能。它为数据存储在那个容器及找到集群内容器及其副本提供查找信息。 许多集群存储策略定义在卷这一级。
定义 拓扑（Topology）、快照（Snapshots）、配额（Quotas）、复制（Replication）、镜像（Mirrors）、权限（Permissions）、压缩（Compression）。
拓扑:可以配置不同的拓扑以实施某些数据存放在某些物理位置，例如机架和节点。通过这种方式，你可以设计数据来开发引用局部性以获得性能、可用性和其他适用于你的任意标准。之后可以将这些拓扑与卷进行关联。 压缩: 卷内数据当被写入硬盘时会被自动压缩。 镜像:可以配置策略集群内本地镜像或远程另一集群镜像。镜像对磁盘故障济公一定程度的保护，远程镜像当整个集群故障时可用于灾难恢复。 卷快照:在维护活动卷的持续一致性的同时，员徐创建数据的时间点版本。快照对用户错误提供一定程度的保护，也可以让你在任意时间返回某个数据集版本。快照可以手工创建，也可以基于计划自动定期执行。 配额:磁盘空间使用的上限。每个卷、用户或组都可以有一个配额。用户和组配额适用于对该用户和组所负责的所有卷的大小之和。硬配额在达到配额后会阻止写入，软配额则是发送告警邮件。 权限: 卷级别的权限可被设置为dump、restore、modify、delete或fullcontrol。卷内的文件和目录可以有标准的UNIX权限。 复制:包含卷内容的容器可被冗余复制。默认的复制因子为3，原始数据加上两个备份，但是每个卷都可以设置自己的复制因子。卷内所有容器具有相同的复制设置。 汇总 MapR文件系统支持POSIX语义及NFS导出。 MapR文件系统被写入到一个卷，卷是复制、镜像、快照、拓扑和使用权限等数据管理功能的一个管理抽象。 卷数据保存在容器内，卷用于定义数据位置及数据复制。 容器被写入到存储池，存储池是一个或多个物理硬盘。</description></item><item><title>[OpenUI5] 控件的Property、Aggregation和Association如何自动具有的Getter和Setter？</title><link>https://mryqu.github.io/post/openui5_%E6%8E%A7%E4%BB%B6%E7%9A%84propertyaggregation%E5%92%8Cassociation%E5%A6%82%E4%BD%95%E8%87%AA%E5%8A%A8%E5%85%B7%E6%9C%89%E7%9A%84getter%E5%92%8Csetter/</link><pubDate>Fri, 13 Nov 2015 06:04:43 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E6%8E%A7%E4%BB%B6%E7%9A%84propertyaggregation%E5%92%8Cassociation%E5%A6%82%E4%BD%95%E8%87%AA%E5%8A%A8%E5%85%B7%E6%9C%89%E7%9A%84getter%E5%92%8Csetter/</guid><description>定义了OpenUI5控件的Property、Aggregation、Association和Event后，该控件就会出现这些Property、Aggregation和Association的Getter和Setter，是什么机制自动生成的这些Getter和Setter的？
OpenUI5控件都继承自sap.ui.core.Control，其父类为sap.ui.core.Element，在祖父类为sap.ui.base.ManagedObject。sap.ui.base.ManagedObject类定义了Properties、Aggregations、Associations和Events这些管理特性。
Getter和Setter的生成机制都在sap.ui.core.ManagedObjectMetadata中实现的。首先我们看一下sap.ui.core.ManagedObjectMetadata这个类的源代码片段：
ManagedObjectMetadata.prototype.generateAccessors = function() { var proto = this.getClass().prototype, prefix = this.getName() + &amp;#34;.&amp;#34;, methods = this._aPublicMethods, n; function add(name, fn, info) { if ( !proto[name] ) { proto[name] = (info &amp;amp;&amp;amp; info.deprecated) ? deprecation(fn, prefix + info.name) : fn; } methods.push(name); } for (n in this._mProperties) { this._mProperties[n].generate(add); } for (n in this._mAggregations) { this._mAggregations[n].generate(add); } for (n in this._mAssociations) { this._mAssociations[n].generate(add); } for (n in this._mEvents) { this.</description></item><item><title>[Git] 操作Git仓库已删除文件</title><link>https://mryqu.github.io/post/git_%E6%93%8D%E4%BD%9Cgit%E4%BB%93%E5%BA%93%E5%B7%B2%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6/</link><pubDate>Wed, 11 Nov 2015 05:49:56 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E6%93%8D%E4%BD%9Cgit%E4%BB%93%E5%BA%93%E5%B7%B2%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6/</guid><description>忙着工作，忽然出了一下神，觉得自己对Git仓库已删除文件的操作还没有练习过，决定找资料学习一下。
列举所有Git仓库已删除文件 下列命令可以列举出所有提交信息及被删除的文件：
git log --diff-filter=D --summary 下列命令可以列举出所有被删除的文件，不显示提交信息：
git log --diff-filter=D --summary | grep delete 列举一个Git仓库已删除文件的提交历史信息 仅使用git log无法查看Git仓库已删除文件的提交历史信息。
git log $deletedFile fatal: ambiguous argument &amp;#39;deletedFile&amp;#39;: unknown revision or path not in the working tree. 下列命令则可以：
git log -- $deletedFile 恢复一个Git仓库已删除文件 找到删除该文件的提交哈希值
git rev-list -n 1 HEAD -- $deletedFile 通过删除该文件提交（$deletingCommit）的前一个提交($deletingCommit~1)恢复已删除文件:
git checkout $deletingCommit~1 -- $deletedFile 参考 Is there a way in Git to list all deleted files in the repository
Git: Getting the history of a deleted file</description></item><item><title>Twitter API访问频次限制处理</title><link>https://mryqu.github.io/post/twitter_api%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6%E5%A4%84%E7%90%86/</link><pubDate>Tue, 10 Nov 2015 06:11:32 +0000</pubDate><guid>https://mryqu.github.io/post/twitter_api%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6%E5%A4%84%E7%90%86/</guid><description>在我前面的博文社交媒体API访问频次限制中，列举了Twitter API访问频次限制。
Twitter API访问频次限制 TwitterAPI访问频次按15分钟为间隔。有两类桶：15分钟内允许15次调用，及15分钟内允许180次调用。Twitter搜索属于后者，在15分钟内允许180次调用。 当向Twitter发送请求后，可以通过解析响应头来获取限制信息。该信息是基于应用/用户上下文的：
X-Rate-Limit-Limit: 对给定请求的访问速率上限 X-Rate-Limit-Remaining: 15分钟时间窗中剩余请求数 X-Rate-Limit-Reset: 速率限制复位前（基于UTC）的剩余时间窗秒数 一旦对Twitter的请求超过了频次限制，Twitter将返回HTTP 429 “Too ManyRequests”响应码及如下消息体：
{ &amp;#34;errors&amp;#34;: [ { &amp;#34;code&amp;#34;: 88, &amp;#34;message&amp;#34;: &amp;#34;Rate limit exceeded&amp;#34; } ] } 除了通过解析响应头，还可以通过向Twitter发送rate_limit_status请求获取API访问限制信息。
Twitter4J对Twitter API访问频次限制的处理 Twitter4J的RateLimitStatusJSONImpl类用于处理响应头中的访问限制信息： Twitter4J的TwitterResponseImpl抽象类用于存放解析过的访问限制信息以供应用程序使用： 此外，还可以注册RateLimitStatusListener监听器实例。由Twitter4J的TwitterBaseImpl类可知，当解析到响应头中的API访问频次限制信息，RateLimitStatusListener监听器实例的onRateLimitStatus方法会被调用；当收到的响应码为420&amp;quot;Enhance Your Claim&amp;quot;、503 &amp;ldquo;Service Unavailable&amp;quot;或429 &amp;ldquo;Too ManyRequests&amp;rdquo;，RateLimitStatusListener监听器实例的onRateLimitReached方法将会被调用。</description></item><item><title>[Git] 分支笔记</title><link>https://mryqu.github.io/post/git_%E5%88%86%E6%94%AF%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 08 Nov 2015 05:44:25 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E5%88%86%E6%94%AF%E7%AC%94%E8%AE%B0/</guid><description>最近接触了一些Git远程分支的操作和管理，做个笔记。
创建本地分支 git branch [branch] 切换本地分支 git checkout [branch] 删除本地分支 git branch -D [branch] 重命名本地分支 git branch -m [oldbranch] [newbranch] 查看分支 # 查看本地分支 （-v选项可以显示sha1和提交消息标题） git branch git branch -v # 查看远程分支 git branch -r git branch -rv # 查看本地和远程分支 git branch -a git branch -av 向远程分支推送（远程分支不存在则会创建远程分支） # 期望本地分支与远程分支同名，可以先切换到本地分支进行提交 git push [remote] [branch] # 通过-u选项同时使新创建的远程分支成为本地分支的上游分支 git push -u [remote] [branch] # 期望本地分支与远程分支使用不同名称 git push [remote] [localbranch]:[remotebranch] # 例子： git push origin v9:v9 使用存在的远程分支创建本地分支，远程分支也成为新创建的本地分支的上游分支 # 期望本地分支与远程分支同名 git checkout --track [remote]/[remotebranch] # 例子： git checkout --track origin/v9 # 当git checkout [branch]执行时，本地分支不存在且仅与一个远程分支名匹配事， # 其效果等同上面--track选项。 # 期望本地分支与远程分支使用不同名称 git checkout -b [localbranch] [remote]/[remotebranch] # 例子： git checkout -b v9test origin/v9 本地分支和远程分支都存在的情况下，使远程分支也成为本地分支的上游分支 # 使远程分支成为当前本地分支的上游分支 git branch -u [remote]/[remotebranch] # 使远程分支成为某一特定本地分支的上游分支 git branch --set-upstream-to=[remote]/[remotebranch] [localbranch] 去除本地分支的上游分支 git branch --unset-upstream [branch] 删除远程分支 git push [remote] :[remotebranch] # 或 git push --delete [remote] [remotebranch] 在本地库删除已废弃的远程分支 # 远程分支被别人删除后，自己本地库中该远程分支为废弃状态，可使用下列命令移除该远程分支 git remote prune [remote] 参考 Git Branching - Branches in a Nutshell</description></item><item><title>社交媒体API访问频次限制</title><link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93api%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6/</link><pubDate>Sat, 07 Nov 2015 05:38:39 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93api%E8%AE%BF%E9%97%AE%E9%A2%91%E6%AC%A1%E9%99%90%E5%88%B6/</guid><description>Facebook API访问频次限制 Facebook Graph API访问频次限制 Facebook Marketing API访问频次限制 FAcebook Graph API允许每用户每60分钟200次API调用。Facebook MarketingAPI随广告用户级别变化。
Twitter API访问频次限制 TwitterAPI访问频次按15分钟为间隔。有两类桶：15分钟内允许15次调用，及15分钟内允许180次调用。Twitter搜索属于后者，在15分钟内允许180次调用。
Google Analytics API Limits and Quotas Google Analytics Core Reporting API - API Limits and Quotas
Google Analytics Real Time Reporting API - API Limits and Quotas
Google Analytics Multi-Channel Funnels Reporting API - API Limits and Quotas
每个项目每天50000个请求，可增加。
每个IP 10 QPS（query per second）。
在Developers Console上，该配额是指per-userlimit。默认设置为1秒1个查询，可被调整为最大值10。 如果你的应用从单个IP地址发出所有API请求，你需要考虑在每个请求中使用userIP或quotaUser参数以获取对每个用户QPS的满配额。 Understand YouTube Analytics API Quota Usage 暂时没有查到Youtube Analytics API固定配额，不过看起来查询维度对配额使用的影响更大。</description></item><item><title>Spring Accessing Facebook Data Guide调试笔记</title><link>https://mryqu.github.io/post/spring_accessing_facebook_data_guide%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/</link><pubDate>Fri, 06 Nov 2015 05:45:40 +0000</pubDate><guid>https://mryqu.github.io/post/spring_accessing_facebook_data_guide%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/</guid><description>尝试Spring Accessing Facebook Data Guide时，除了要像Spring Accessing Twitter Data Guide调试笔记中那样设置代理，还碰到几个其他问题，这里记录一下。
Null Pointer Exception 描述
java.lang.NullPointerException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51] at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51] at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:133) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:121) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208) ~[spring-aop-4.2.3.RELEASE.jar:4.2.3.RELEASE] at com.sun.proxy.$Proxy49.isAuthorized(Unknown Source) ~[na:na] at hello.HelloController.helloFacebook(HelloController.java:26) ~[bin/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51] at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51] at org.</description></item><item><title>[Spring Boot] Hello MethodInvokingFactoryBean and MethodInvokingBean</title><link>https://mryqu.github.io/post/spring_boot_hello_methodinvokingfactorybean_and_methodinvokingbean/</link><pubDate>Thu, 05 Nov 2015 05:58:07 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_hello_methodinvokingfactorybean_and_methodinvokingbean/</guid><description>简介 在用spring管理我们的类的时候有时候希望有些属性值是来源于一些配置文件，系统属性，或者一些方法调用的结果，对于前两种使用方式可以使用spring的PropertyPlaceholderConfigurer类来注入，对于后一种则可以使用org.springframework.beans.factory.config.MethodInvokingFactoryBean类来生成需要注入的bean的属性。
通过MethodInvokingFactory Bean类，可注入方法返回值。MethodInvokingFactoryBean用来获得某个方法的返回值，该方法既可以是静态方法，也可以是实例方法。该方法的返回值可以注入bean实例属性，也可以直接定义成bean实例。
MethodInvokingBean是MethodInvokingFactoryBean的父类，更为简单。跟MethodInvokingFactoryBean相比，不会对容器返回任何值。
类层次关系 示例代码： package com.yqu.methodinvoker; import java.util.Arrays; import java.util.Properties; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.config.MethodInvokingBean; import org.springframework.beans.factory.config.MethodInvokingFactoryBean; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; @SpringBootApplication public class Application { private static final Logger log = LoggerFactory.getLogger(Application.class); public static void main(String[] args) { SpringApplication app = new SpringApplication(Application.class); app.setWebEnvironment(false); app.setShowBanner(false); app.run(args); log.info(&amp;#34;sysProp http.proxyHost:&amp;#34;+System.getProperty(&amp;#34;http.proxyHost&amp;#34;)); log.info(&amp;#34;sysProp http.proxyPort:&amp;#34;+System.getProperty(&amp;#34;http.proxyPort&amp;#34;)); } @Bean public MethodInvokingFactoryBean methodInvokingFactoryBean() { MethodInvokingFactoryBean mfBean = new MethodInvokingFactoryBean(); mfBean.setStaticMethod(&amp;#34;java.lang.System.setProperties&amp;#34;); Properties props = System.</description></item><item><title>Spring Accessing Twitter Data Guide调试笔记</title><link>https://mryqu.github.io/post/spring_accessing_twitter_data_guide%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/</link><pubDate>Wed, 04 Nov 2015 05:57:55 +0000</pubDate><guid>https://mryqu.github.io/post/spring_accessing_twitter_data_guide%E8%B0%83%E8%AF%95%E7%AC%94%E8%AE%B0/</guid><description>尝试Spring Accessing Twitter Data Guide时碰到几个问题，这里记录一下。
连接超时问题 遇到I/O error on POST request for&amp;quot;https://api.twitter.com/oauth/request_token&amp;quot;错误:
org.springframework.web.client.ResourceAccessException: I/O error on POST request for &amp;#34;https://api.twitter.com/oauth/request_token&amp;#34;:Connection timed out: connect; nested exception is java.net.ConnectException: Connection timed out: connect at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:582) at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:547) at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:468) at org.springframework.social.oauth1.OAuth1Template.exchangeForToken(OAuth1Template.java:187) at org.springframework.social.oauth1.OAuth1Template.fetchRequestToken(OAuth1Template.java:115) at org.springframework.social.connect.web.ConnectSupport.fetchRequestToken(ConnectSupport.java:212) at org.springframework.social.connect.web.ConnectSupport.buildOAuth1Url(ConnectSupport.java:199) at org.springframework.social.connect.web.ConnectSupport.buildOAuthUrl(ConnectSupport.java:126) at org.springframework.social.connect.web.ConnectController.connect(ConnectController.java:226) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:775) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.</description></item><item><title>Hello Spring Social LinkedIn</title><link>https://mryqu.github.io/post/hello_spring_social_linkedin/</link><pubDate>Tue, 03 Nov 2015 05:50:46 +0000</pubDate><guid>https://mryqu.github.io/post/hello_spring_social_linkedin/</guid><description>本想玩玩Spring SocialLinkedIn，看看能从LinkedIn哪里获得什么有价值的数据。可是LinkedIn现在放开的只有r_basicprofile、r_emailaddress、rw_company_admin、w_share权限，如LinkedIn developer program transition所说的不要在认证中请求r_fullprofile、r_network、r_contactinfo、rw_nus、rw_groups和w_messages权限了。 在LinkedIn API Console中可试最多的是CompaniesAPI，可是我在LinkedIn上没有公司主页可以创建。所以浅尝则止，没什么太多可分享的。
参考 Spring Social LinkedIn Project
Spring Social Project
GitHub: spring-projects/spring-social-samples
LinkedIn Developer
LinkedIn API Console
LinkedIn developer program transition</description></item><item><title>Hello Spring Social Twitter</title><link>https://mryqu.github.io/post/hello_spring_social_twitter/</link><pubDate>Sun, 01 Nov 2015 06:03:04 +0000</pubDate><guid>https://mryqu.github.io/post/hello_spring_social_twitter/</guid><description>学习了Spring Accessing Twitter Data Guide，稍作修改，练习一下用Spring Social Twitter搜索推文。
HelloSpringTwitter代码 src/main/java/com/yqu/springtwitter/Application.java package com.yqu.springtwitter; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } src/main/java/com/yqu/springtwitter/HelloController.java package com.yqu.springtwitter; import javax.inject.Inject; import org.springframework.social.connect.ConnectionRepository; import org.springframework.social.twitter.api.SearchResults; import org.springframework.social.twitter.api.Twitter; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; @Controller @RequestMapping(&amp;#34;/&amp;#34;) public class HelloController { private Twitter twitter; private ConnectionRepository connectionRepository; @Inject public HelloController(Twitter twitter, ConnectionRepository connectionRepository) { this.</description></item><item><title>Cisco AnyConnect Secure Mobility Client的VPN profile位置</title><link>https://mryqu.github.io/post/cisco_anyconnect_secure_mobility_client%E7%9A%84vpn_profile%E4%BD%8D%E7%BD%AE/</link><pubDate>Sat, 31 Oct 2015 06:19:11 +0000</pubDate><guid>https://mryqu.github.io/post/cisco_anyconnect_secure_mobility_client%E7%9A%84vpn_profile%E4%BD%8D%E7%BD%AE/</guid><description>在其安装路径C:\Program Files\Cisco\Cisco AnyConnect Secure MobilityClient搜寻未果。
全盘搜索后，发现在这个位置：C:\ProgramData\Cisco\Cisco AnyConnect Secure MobilityClient\Profile</description></item><item><title>[Eclipse] 遭遇Unable to install breakpoint due to missing line number attribute</title><link>https://mryqu.github.io/post/eclipse_%E9%81%AD%E9%81%87unable_to_install_breakpoint_due_to_missing_line_number_attribute/</link><pubDate>Fri, 30 Oct 2015 05:49:54 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse_%E9%81%AD%E9%81%87unable_to_install_breakpoint_due_to_missing_line_number_attribute/</guid><description>今天遇到了“Unable to install breakpoint due to missing line numberattribute. Modify compiler options to generate line numberattributes”问题。 检查Preferences -&amp;gt; Java -&amp;gt; Perference，&amp;ldquo;Add linenumber attributes to generated class files (used by thedebugger)&amp;ldquo;已经勾选了。 应该是SpringAOP产生的代码没有行数信息，但是我自己写的代码还是带行数信息的，因此虽然会弹出这些烦人的警告，所设断点还是其作用的。让它不再提示即可。</description></item><item><title>[Spring Boot] 使用多个Servlet</title><link>https://mryqu.github.io/post/spring_boot_%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AAservlet/</link><pubDate>Wed, 28 Oct 2015 06:07:53 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AAservlet/</guid><description>当使用Spring boot的嵌入式servlet容器时，可以通过Springbean或扫描Servlet组件的方式注册Servlet、Filter和Servlet规范的所有监听器(例如HttpSessionListener)。
当urlMapping不是很复杂时，可以通过ServletRegistrationBean、FilterRegistrationBean和ServletListenerRegistrationBean获得完整控制。如果bean实现了ServletContextInitializer接口的话则可以直接注册。 当使用@ServletComponentScan扫描Servlet组件时，Servlet、过滤器和监听器可以是通过@WebServlet、@WebFilter和@WebListener自动注册 示例代码 Application.java package com.yqu.multiservlet; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.context.embedded.ServletRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.web.servlet.DispatcherServlet; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } @Bean public ServletRegistrationBean dispatcherRegistration( DispatcherServlet dispatcherServlet) { ServletRegistrationBean registration = new ServletRegistrationBean(dispatcherServlet); registration.addUrlMappings(&amp;#34;/hirest/*&amp;#34;); printStacks(); return registration; } @Bean public ServletRegistrationBean servletRegistrationBean() { printStacks(); return new ServletRegistrationBean( new SigninServlet(), &amp;#34;/signin&amp;#34;); } private void printStacks() { StackTraceElement[] elements = Thread.currentThread().getStackTrace(); System.</description></item><item><title>Spring 框架: @RestController vs @Controller</title><link>https://mryqu.github.io/post/spring%E6%A1%86%E6%9E%B6_restcontroller_vs_controller/</link><pubDate>Fri, 23 Oct 2015 05:57:46 +0000</pubDate><guid>https://mryqu.github.io/post/spring%E6%A1%86%E6%9E%B6_restcontroller_vs_controller/</guid><description>今天扫了一眼RestController注解的实现，它是@Controller和@ResponseBody的合体。
@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Controller @ResponseBody public @interface RestController { String value() default &amp;#34;&amp;#34;; } 至于@RestController与@Controller的所有区别，还不是完全明了。看了Srivatsan Sundararajan和Swapna Sagi的大作Spring Framework: @RestController vs @Controller，感觉豁然开朗。
Spring MVC框架和REST Spring基于MVC框架的注解简化了创建RESTful web服务流程。传统MVS控制器和RESTfulweb服务控制器关键区别在于HTTP响应体创建方式。传统MVC控制器依赖试图技术，而RESTfulweb服务控制器仅仅返回对象并将对象数据作为JSON/XML直接写到HTTP响应中。关于使用Spring框架创建RESTfulWEB服务的技术细节，点击这里。 图1: Spring MVC传统工作流
Spring MVC REST工作流 传统Spring MVC REST工作流步骤如下:
客户端以URI形式向web服务发送一个请求。The client sends a request to a webservice in URI form. 请求被DispatcherServlet拦截用于查找处理器映射（Handler Mappings）及类型。 在应用上下文文件中定义的处理器映射会告知DispatcherServlet用于基于请求查找控制器的策略。 Spring MVC支持三种类型的请求URI与控制器间的映射：注解、名称转换和显式映射。 请求由控制器处理后，响应返回给DispatcherServlet后分发给视图。 在图1中，注意在传统工作流中ModelAndView对象由控制器转发给客户端。在方法上使用@ResponseBody注解，Spring可让应用直接从控制器返回数据，不再查找视图。从第4版起，引入@RestController注解进一步简化处理流程。两种使用方式解释如下。
使用@ResponseBody注解 当对一个方法使用@ResponseBody注解后，Spring将返回值进行转换并自动写入Http响应中。控制器类的每个方法必须使用@ResponseBody进行注解。 图2: Spring 3.x MVC RESTful web服务工作流
幕后工作 Spring在幕后注册了一系列HttpMessageConverters。HTTPMessageConverter负责根据预先定义的MIME类型将请求体转换成特定类及将特定类转换成响应体。每次一个请求匹配上@ResponseBody，Spring遍历所有已注册的HTTPMessageConverter，查找到第一个匹配上给定MIME类型和类的HTTPMessageConverter用之进行实际转换。
代码示例 下面过一个使用@ResponseBody的简单示例。
创建名为Employee的Java POJO类。
package com.example.spring.model; import javax.</description></item><item><title>Gradle multi-project Builds on HelloSocialMedia</title><link>https://mryqu.github.io/post/gradle_multi-project_builds_on_hellosocialmedia/</link><pubDate>Thu, 22 Oct 2015 05:38:15 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_multi-project_builds_on_hellosocialmedia/</guid><description>尝试对我的HelloSocialMedia演示代码集合使用Gradle的多项目构建，项目结构如下：
HelloSocialMedia/ build.gradle settings.gradle HelloYoutubeAnalytics/ build.gradle HelloGoogleAnalytics/ build.gradle HelloTwitter4J/ build.gradle HelloRestFB/ build.gradle settings.gradle
rootProject.name = &amp;#39;HelloSocialMedia&amp;#39; include &amp;#34;HelloYoutubeAnalytics&amp;#34; include &amp;#34;HelloGoogleAnalytics&amp;#34; include &amp;#34;HelloTwitter4J&amp;#34; include &amp;#34;HelloRestFB&amp;#34; project(&amp;#34;:HelloYoutubeAnalytics&amp;#34;).name = &amp;#34;HelloSocialMedia-YoutubeAnalytics&amp;#34; project(&amp;#34;:HelloGoogleAnalytics&amp;#34;).name = &amp;#34;HelloSocialMedia-GoogleAnalytics&amp;#34; project(&amp;#34;:HelloTwitter4J&amp;#34;).name = &amp;#34;HelloSocialMedia-Twitter4J&amp;#34; project(&amp;#34;:HelloRestFB&amp;#34;).name = &amp;#34;HelloSocialMedia-RestFB&amp;#34; build.gradle
buildscript { repositories { mavenCentral() } } subprojects { apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; repositories { mavenCentral() } sourceCompatibility = 1.8 targetCompatibility = 1.8 } HelloYoutubeAnalytics/build.gradle
jar { baseName = &amp;#39;hello-youbube-analytics&amp;#39; version = &amp;#39;0.</description></item><item><title>Hello RestFB</title><link>https://mryqu.github.io/post/hello_restfb/</link><pubDate>Wed, 21 Oct 2015 05:55:32 +0000</pubDate><guid>https://mryqu.github.io/post/hello_restfb/</guid><description>RestFB是一个简单灵活的Facebook图谱API和REST客户端Java库。本演示用它来获取一个Facebook主页下的帖子、评论及回复。
获取Facebook AccessToken 示例代码 package com.yqu.restfb; import java.util.List; import com.restfb.Connection; import com.restfb.DefaultFacebookClient; import com.restfb.FacebookClient; import com.restfb.Parameter; import com.restfb.Version; import com.restfb.types.Comment; import com.restfb.types.Page; import com.restfb.types.Post; public class HelloRestFB { public static void main(String[] args) { FacebookClient facebookClient = new DefaultFacebookClient( MY_ACCESS_TOKEN, Version.VERSION_2_5); Page pageInfo = (Page) facebookClient.fetchObject(&amp;#34;YquTest&amp;#34;, Page.class, new Parameter[0]); Connection postConnection = facebookClient.fetchConnection( pageInfo.getId() + &amp;#34;/feed&amp;#34;, Post.class, new Parameter[] { Parameter.with(&amp;#34;limit&amp;#34;, 10), Parameter.with(&amp;#34;include_hidden&amp;#34;, &amp;#34;true&amp;#34;) }); if (postConnection.getData().size() &amp;lt;= 0) { System.</description></item><item><title>Twitter的高级搜索和过滤功能</title><link>https://mryqu.github.io/post/twitter%E7%9A%84%E9%AB%98%E7%BA%A7%E6%90%9C%E7%B4%A2%E5%92%8C%E8%BF%87%E6%BB%A4%E5%8A%9F%E8%83%BD/</link><pubDate>Tue, 20 Oct 2015 06:08:31 +0000</pubDate><guid>https://mryqu.github.io/post/twitter%E7%9A%84%E9%AB%98%E7%BA%A7%E6%90%9C%E7%B4%A2%E5%92%8C%E8%BF%87%E6%BB%A4%E5%8A%9F%E8%83%BD/</guid><description>刚接触Twitter的搜索功能，以为仅能用关键字搜索推文。后来才知道，Twitter搜索不仅支持关键字的与或非逻辑处理，还能根据日期、地理位置、推文是否有链接、图像、视频、转推、回复等条件进行过滤。例如：
即包含&amp;quot;andrew&amp;quot;又包含&amp;quot;2015&amp;quot;的推文``` https://twitter.com/search?q=andrew 2015&amp;amp;src=typd - 完全匹配&amp;#34;andrew 2015&amp;#34;的推文``` https://twitter.com/search?q=&amp;#34;andew 2015&amp;#34;&amp;amp;src=typd 包含&amp;quot;andrew&amp;quot;或&amp;quot;2015&amp;quot;的中文推文``` https://twitter.com/search?q=andew OR 2015 lang:zh&amp;amp;src=typd - 包含&amp;#34;andrew&amp;#34;的推文（包括转推）``` https://twitter.com/search?q=andrew include:retweets&amp;amp;src=typd 包含&amp;quot;andrew&amp;quot;的推文（不包括转推）``` ttps://twitter.com/search?q=andrew exclude:retweets&amp;amp;src=typd - 包含&amp;#34;andrew&amp;#34;且有URL链接的推文``` https://twitter.com/search?q=andrew filter:links&amp;amp;src=typd 包含&amp;quot;andrew&amp;quot;且没有URL链接的推文``` https://twitter.com/search?q=andrew -filter:links&amp;amp;src=typd ### 参考 [Twitter Advanced Search](https://twitter.com/search-advanced) [Using Twitter Advanced Search](https://support.twitter.com/articles/71577) [How to Master Twitter Search: Basic Boolean Operators and Filters](http://thesocialchic.com/2013/04/26/how-to-master-twitter-search/)</description></item><item><title>Hello Twitter4J</title><link>https://mryqu.github.io/post/hello_twitter4j/</link><pubDate>Mon, 19 Oct 2015 06:10:11 +0000</pubDate><guid>https://mryqu.github.io/post/hello_twitter4j/</guid><description>Twitter4J是Twitter API的第三方Java库。本演示用它通过关键字搜索推文。
获取Twitter应用证书 示例代码
package com.yqu.twitter4j; import twitter4j.Query; import twitter4j.QueryResult; import twitter4j.Status; import twitter4j.Twitter; import twitter4j.TwitterFactory; public class HelloTwitter4J { // I18NOK:CLS public static void main(String[] args) { try { // The factory instance is re-useable and thread safe. Twitter twitter = TwitterFactory.getSingleton(); Query query = new Query(&amp;#34;夏洛特烦恼&amp;#34;); query.setLang(&amp;#34;zh&amp;#34;); query.setCount(10); QueryResult result = twitter.search(query); for (Status status : result.getTweets()) { System.out.println(status.getCreatedAt()+&amp;#34;:&amp;#34;+status.getText()); } } catch (Exception e) { e.printStackTrace(); } } } twitter.</description></item><item><title>[Gradle] 创建含有依赖库的jar文件</title><link>https://mryqu.github.io/post/gradle_%E5%88%9B%E5%BB%BA%E5%90%AB%E6%9C%89%E4%BE%9D%E8%B5%96%E5%BA%93%E7%9A%84jar%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 18 Oct 2015 05:54:13 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%88%9B%E5%BB%BA%E5%90%AB%E6%9C%89%E4%BE%9D%E8%B5%96%E5%BA%93%E7%9A%84jar%E6%96%87%E4%BB%B6/</guid><description>想把自己的Gradle项目打成jar文件，但是&amp;rsquo;gradle build jar&amp;rsquo;生成的jar文件不含依赖库。
按照Gradle – Create a Jar file with dependencies改写了自己的build.gradle，成功包含了依赖库。但是依赖库不再是原来的jar文件，而是以目录的形式存在。
我的build.gradle
buildscript { repositories { mavenCentral() } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; jar { baseName = &amp;#39;HelloTwitter4J&amp;#39; version = &amp;#39;0.1.0&amp;#39; } task fatJar(type: Jar) { baseName = &amp;#39;HelloTwitter4J-all&amp;#39; version = &amp;#39;0.1.0&amp;#39; manifest { attributes &amp;#34;Main-Class&amp;#34;: &amp;#34;com.yqu.cdfwebtool.twitter.TwitterRateInfo&amp;#34; } from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } } with jar } repositories { mavenCentral() } sourceCompatibility = 1.</description></item><item><title>Hello Youtube Analytics</title><link>https://mryqu.github.io/post/hello_youtube_analytics/</link><pubDate>Sat, 17 Oct 2015 06:10:21 +0000</pubDate><guid>https://mryqu.github.io/post/hello_youtube_analytics/</guid><description>Google Credential设置见我之前的博文解决 &amp;ldquo;Access Not Configured. The API (YouTube Analytics API) is not enabled for your project.&amp;rdquo;。
示例代码：
package com.yqu.yt; import java.io.IOException; import java.io.PrintStream; import java.math.BigDecimal; import java.util.List; import com.google.api.client.auth.oauth2.Credential; import com.google.api.client.googleapis.auth.oauth2.GoogleCredential; import com.google.api.client.http.HttpTransport; import com.google.api.client.http.javanet.NetHttpTransport; import com.google.api.client.json.JsonFactory; import com.google.api.client.json.jackson2.JacksonFactory; import com.google.api.services.youtube.YouTube; import com.google.api.services.youtube.model.Channel; import com.google.api.services.youtube.model.ChannelListResponse; import com.google.api.services.youtubeAnalytics.YouTubeAnalytics; import com.google.api.services.youtubeAnalytics.model.ResultTable; import com.google.api.services.youtubeAnalytics.model.ResultTable.ColumnHeaders; import com.google.common.collect.Lists; public class HelloYoutubeAnalytics { //I18NOK:CLS private static final HttpTransport HTTP_TRANSPORT = new NetHttpTransport(); private static final JsonFactory JSON_FACTORY = new JacksonFactory(); private static YouTube youtube; private static YouTubeAnalytics analytics; public static void main(String[] args) { // These scopes are required to access information about the // authenticated user&amp;#39;s YouTube channel as well as Analytics // data for that channel.</description></item><item><title>解决"Access Not Configured. The API (YouTube Analytics API) is not enabled for your project."</title><link>https://mryqu.github.io/post/%E8%A7%A3%E5%86%B3_access_not_configured._the_youtube_analytics_api_is_not_enabled_for_your_project/</link><pubDate>Fri, 16 Oct 2015 06:32:52 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%A7%A3%E5%86%B3_access_not_configured._the_youtube_analytics_api_is_not_enabled_for_your_project/</guid><description>在用Google Developers OAuth 2.0 Playground试用Google YoutubeAnalytics API时总是返回下列403 Forbidden错误:
{ &amp;#34;code&amp;#34; : 403, &amp;#34;errors&amp;#34; : [ { &amp;#34;domain&amp;#34; : &amp;#34;usageLimits&amp;#34;, &amp;#34;message&amp;#34; : &amp;#34;Access Not Configured. The API (YouTube Analytics API) is not enabled for your project. Please use the Google Developers Console to update your configuration.&amp;#34;, &amp;#34;reason&amp;#34; : &amp;#34;accessNotConfigured&amp;#34;, &amp;#34;extendedHelp&amp;#34; : &amp;#34;https://console.developers.google.com&amp;#34; } ], &amp;#34;message&amp;#34; : &amp;#34;Access Not Configured. The API (YouTube Analytics API) is not enabled for your project. Please use the Google Developers Console to update your configuration.</description></item><item><title>Use proxy on Google Analytics API</title><link>https://mryqu.github.io/post/use_proxy_on_google_analytics_api/</link><pubDate>Fri, 09 Oct 2015 05:34:55 +0000</pubDate><guid>https://mryqu.github.io/post/use_proxy_on_google_analytics_api/</guid><description>使用Google API创建HTTP传输层是这样子的，没有可以传入代理的地方。
HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport(); 仔细研究一下com.google.api.client.googleapis.javanet.GoogleNetHttpTransport，发现其实现是使用com.google.api.client.http.javanet.NetHttpTransport.Builder生成一个com.google.api.client.http.javanet.NetHttpTransport对象。
com.google.api.client.http.javanet.NetHttpTransport.Builder和com.google.api.client.http.javanet.NetHttpTransport是都支持代理的。不用GoogleNetHttpTransport这个封装，直接对com.google.api.client.http.javanet.NetHttpTransport.Builder设置代理即可生成使用代理的HttpTransport对象。
Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(&amp;#34;XXXX&amp;#34;, 80)); HttpTransport httpTransport = new NetHttpTransport.Builder().setProxy(proxy). trustCertificates(GoogleUtils.getCertificateTrustStore()).build();</description></item><item><title>获取Facebook App Token</title><link>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96facebook_app_token/</link><pubDate>Thu, 08 Oct 2015 06:06:04 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96facebook_app_token/</guid><description>今天看了一下如何用Facebook的App Id和App Secret获取App Token。
可以使用RestFB，一行搞定：
FacebookClient.AccessToken ac = new DefaultFacebookClient(Version.LATEST) .obtainAppAccessToken(appId, appSecret); curl命令也超简单：
curl &amp;#34;https://graph.facebook.com/v2.5/oauth/access_token?client_id={appId}&amp;amp;client_secret={appSecret}&amp;amp;grant_type=client_credentials&amp;#34; 我的一个Facebook应用YquTest如下： 通过其App Id和App Secret进行实验，获得结果可以用上一篇博文Facebook开发调试工具提到的访问口令工具验证，完全一致！
参考 Facebook Login - Access Tokens
Facebook Login - Access Tokens - App Access Tokens</description></item><item><title>Facebook开发调试工具</title><link>https://mryqu.github.io/post/facebook%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Wed, 07 Oct 2015 07:13:44 +0000</pubDate><guid>https://mryqu.github.io/post/facebook%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description>Facebook开发调试工具大体位于https://developers.facebook.com/tools-and-support/下。
访问口令工具:这里所提供的用户口令便于测试应用，会过期。应用口令不会过期，应该秘密存储。 图谱API探索工具:测试图谱API或FQL查询。 JS JDK控制台: 可以加载FacebookJS库，执行HTML代码 URL调试器:可以让Facebook的爬虫抓取你的网站，看看你的网站在Facebook被共享时的模样。 这里面我用的最多的是图谱API探索工具，其次就是看图谱API参考文档了。</description></item><item><title>Remote debugging on microservice at docker container inside vagrant box</title><link>https://mryqu.github.io/post/remote_debugging_on_microservice_at_docker_container_inside_vagrant_box/</link><pubDate>Mon, 05 Oct 2015 05:59:07 +0000</pubDate><guid>https://mryqu.github.io/post/remote_debugging_on_microservice_at_docker_container_inside_vagrant_box/</guid><description>Docker compose configuration foo-service: image: foo-service:latest hostname: foo-service dns: 127.0.0.1 restart: always Vagrant configuration config.vm.network &amp;#34;forwarded_port&amp;#34;, guest: 8787, host: 8787, auto_correct: true Consul configuration curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;java_option_server_port:java_option_xms:java_option_xmx:java_option_debug&amp;#39; http://localhost:8500/v1/kv/config/foo-service/jvm/java_options curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;-Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n&amp;#39; http://localhost:8500/v1/kv/config/foo-service/jvm/java_option_debug IntelliJ IDEA configuration</description></item><item><title>继续使用Win10的Windows defender</title><link>https://mryqu.github.io/post/%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8win10%E7%9A%84windows_defender/</link><pubDate>Sun, 04 Oct 2015 05:49:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8win10%E7%9A%84windows_defender/</guid><description>从Win7升级到了Win10，有一天忽然发现Microsoft SecurityEssentials不见了。上网一查，才知道被Win10内置了，改叫Windows defender。可是Windowsdefender也没见运行呀？
提示说“此应用已经关闭，不会监视你的计算机”。
开始追查！！！
通过“Windows键+X”进入控制面板 在安全中心，发现是腾讯的电脑管家导致Windows defender被禁用。 关闭电脑管家的实时系统防护。 收到安全性提示，选择启用Windows defender。 又见到小城墙了</description></item><item><title>Node.js npm代理设置</title><link>https://mryqu.github.io/post/node.js_npm%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/</link><pubDate>Wed, 30 Sep 2015 06:06:46 +0000</pubDate><guid>https://mryqu.github.io/post/node.js_npm%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/</guid><description>用Gradle编译当前一个项目，总是报告Node.js的包管理工具npm安装node包失败。美国那边没有问题，不知道是否跟防火墙有关。
npm的代理设置为：
npm config set proxy http://proxyServer:proxyPort npm config set https-proxy http://proxyServer:proxyPort 操作显示能解决我的部分问题！
参考 NPM小结</description></item><item><title>遭遇"HTTPS endpoint unresponsive and insecure mode isn't enabled."</title><link>https://mryqu.github.io/post/%E9%81%AD%E9%81%87https_endpoint_unresponsive_and_insecure_mode_isnt_enabled./</link><pubDate>Tue, 29 Sep 2015 05:38:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%81%AD%E9%81%87https_endpoint_unresponsive_and_insecure_mode_isnt_enabled./</guid><description>今天使用docker-compose去获取最新的镜像，遭遇&amp;quot;HTTPS endpoint unresponsive andinsecure mode isn&amp;rsquo;t enabled.&amp;ldquo;错误。
mryqu$ docker-compose pull Pulling cadvisor (docker.mryqu.com/google/cadvisor:latest)... Traceback (most recent call last): File &amp;#34;&amp;lt;string&amp;gt;&amp;#34;, line 3, in &amp;lt;module&amp;gt; File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.main&amp;#34;, line 32, in main File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.docopt_command&amp;#34;, line 21, in sys_dispatch File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.command&amp;#34;, line 34, in dispatch File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.docopt_command&amp;#34;, line 24, in dispatch File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.command&amp;#34;, line 66, in perform_command File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.cli.main&amp;#34;, line 235, in pull File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.project&amp;#34;, line 285, in pull File &amp;#34;/code/build/docker-compose/out00-PYZ.pyz/compose.service&amp;#34;, line 713, in pull File &amp;#34;/code/build/docker-compose/out00-PYZ.</description></item><item><title>Hello Google Analytics</title><link>https://mryqu.github.io/post/hello_google_analytics/</link><pubDate>Mon, 28 Sep 2015 05:57:14 +0000</pubDate><guid>https://mryqu.github.io/post/hello_google_analytics/</guid><description>Google Credential设置见我之前的博文Google Analytics API Error 403: &amp;ldquo;User does not have any Google Analytics Account&amp;rdquo;。
示例代码：
package com.yqu.ga; import java.io.File; import java.io.IOException; import java.io.InputStream; import java.util.List; import com.google.api.client.googleapis.auth.oauth2.GoogleCredential; import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport; import com.google.api.client.http.HttpRequest; import com.google.api.client.http.HttpRequestInitializer; import com.google.api.client.http.HttpTransport; import com.google.api.client.json.JsonFactory; import com.google.api.client.json.gson.GsonFactory; import com.google.api.services.analytics.Analytics; import com.google.api.services.analytics.AnalyticsScopes; import com.google.api.services.analytics.model.Accounts; import com.google.api.services.analytics.model.GaData; import com.google.api.services.analytics.model.GaData.ColumnHeaders; import com.google.api.services.analytics.model.GaData.Query; import com.google.api.services.analytics.model.Profiles; import com.google.api.services.analytics.model.Webproperties; public class HelloAnalytics { // I18NOK:CLS private static enum AuthType { SERVICE_ACCOUNT, SERVICE_ACCOUNT_P12, OAUTH }; protected static final String APPLICATION_NAME = &amp;#34;Hello Analytics&amp;#34;; protected static final JsonFactory JSON_FACTORY = GsonFactory .</description></item><item><title>Twitter开发调试工具</title><link>https://mryqu.github.io/post/twitter%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Sun, 27 Sep 2015 05:58:02 +0000</pubDate><guid>https://mryqu.github.io/post/twitter%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description>Twitter开发调试工具主要位于https://dev.twitter.com/下。
API status: 显示Twitter API可用性和性能 API参考文档 API控制台工具：测试TwitterAPI 管理自己的应用：对自己的应用进行配置 我用的最多的是API参考文档，其次是API控制台工具。</description></item><item><title>SocialMedia API Policy and Terms</title><link>https://mryqu.github.io/post/socialmedia_api_policy_and_terms/</link><pubDate>Sat, 26 Sep 2015 07:01:32 +0000</pubDate><guid>https://mryqu.github.io/post/socialmedia_api_policy_and_terms/</guid><description>Facebook Facebook Terms and Policies: https://www.facebook.com/policies Statement of Rights and Responsibilities: https://www.facebook.com/legal/terms Data Policy: https://www.facebook.com/about/privacy
Twitter Twitter Terms of Service: https://twitter.com/tos?lang=en Twitter Privacy Policy: https://twitter.com/privacy?lang=en Twitter Developer Agreement: https://dev.twitter.com/overview/terms/agreement Twitter Developer Policy: https://dev.twitter.com/overview/terms/policy
Google (Google Analytics &amp;amp; YouTube Analytics) Google APIs Terms of Service: https://developers.google.com/terms/ Google Privacy Policy: https://www.google.com/intl/en/policies/privacy/
LinkedIn User Agreement: https://www.linkedin.com/legal/user-agreement Privacy Policy: https://www.linkedin.com/legal/privacy-policy API Terms of Use: https://developer.linkedin.com/legal/api-terms-of-use Cookies on the LinkedIn site: https://www.linkedin.com/legal/cookie_policy
微博 开发者协议: http://open.weibo.com/wiki/开发者协议 应用运营管理规范: http://open.</description></item><item><title>社交媒体API/SDK</title><link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93api_sdk/</link><pubDate>Fri, 25 Sep 2015 06:04:42 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93api_sdk/</guid><description>社交媒体API编程平台/语言Facebook API:应用广告：提升应用安装量和使用率。Analytics for Apps：制定基于数据的客户和广告决策。匿名登录：用户无需分享自己的信息即可注册使用您的应用。应用邀请：方便用户直接与好友分享他们喜欢的应用。应用链接：应用间链接的开放式跨平台标准。应用盈利：Facebook 和 LiveRail 广告助您实现应用盈利。 移动应用受众网络：Facebook 广告助您实现应用盈利。游戏：实现游戏跨平台，覆盖数百万Facebook玩家。Facebook 登录：方便用户跨设备注册您的应用。Messenger：扩大展示，帮助用户发现您的应用。Parse：更快速地构建强大的移动应用。分享：借助 Facebook，提升网站和应用内容的知名度。社交插件：让您的网站和应用更具社交性和吸引力的最简单方式。ThreatExchange：分享威胁信息，保障用户安全。官方:iOSAndroidUnityJavascriptPHP
第三方: Cocos2d-x C Flash HTML5 Java JavaScript Lua Node.js Objective-C Qt Ruby Unity V-Play WinJSTwitter API：TweetsUsersEntitiesPlaces官方:iOSAndroidOSXWebJava第三方:iOSAndroidJavaASPC++ClojureColdFusion.NETGoJavascript/node.jsLua/Corona SDKObjective-CPerlPHPPythonRubyGoogle Analytics Configuration APIs：自动执行帐户和用户配置。Management API：访问和管理帐户、媒体资源、数据视图等Google Analytics（分析）实体。 Provision API：创建新的Google Analytics（分析）帐户。Google Analytics Reporting APIs：借助报告API，您可以自动化复杂的报告任务，进而节省时间。您还可以使用相应API将Google Analytics（分析）数据与您自己的业务数据整合在一起，从而获得更深入的分析数据。 Core Reporting API：通过查询维度和指标来创建自定义报告。Multi-channel Funnels Reporting API：查看您用户的归因和转化路径数据。 Real-time Reporting API：查看您的媒体资源上当前发生的活动。 Embed API：几分钟内即可将信息中心嵌入第三方网站。 Metadata API：查看 API 维度和指标列表以及属性。官方:JavaPythonPHPJavascriptLinkedIn SDK:登录LinkedIn在LinkedIn进行内容分享在用户档案上添加（学位、证书等）信息管理公司页官方:iOSAndroidJavascriptREST APIYouTube API：Youtube Play API：使用内嵌播放器在你的应用直接播放视频，定制回放体验。实际上YouTube提供的是IFRAME、Android API、iOS API、PLAYER PARAMETERS。Youtube Data API：搜索YouTube内容、上传视频、创建和管理播放列表等功能。Youtube Analytics and Reporting API：获取YouTube视频和频道的统计、流行指标等信息。Youtube Analytics API：支持生成定制YouTube分析报告的实时有针对性的查询。API提供过滤和排序参数，因此调用程序无需支持这些功能。每个API请求指定数据范围，也能获取每周和每月的数据集，调用程序无需存储获得的数据集，也无需跨数据范围汇总统计信息。Youtube Reporting API：为频道或内容所有人获取包含YouTube分析数据的一批报告。用于能够导入大数据集并进行过滤、排序、数据挖据的应用。每个报告包含预定义字段集合。开发者使用该API预定报表任务，每个任务标识YouTube所要生成的报告。YouTube生成可以异步下载的日报告。每个报告包含唯一的一天数据。YouTube Live Streaming API：预定YouTube现场直播，管理直播视频流。官方:Java JavaScript .</description></item><item><title>Twitter的访问令牌（AccessToken）不过期</title><link>https://mryqu.github.io/post/twitter%E7%9A%84%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8Caccesstoken%E4%B8%8D%E8%BF%87%E6%9C%9F/</link><pubDate>Wed, 23 Sep 2015 06:19:27 +0000</pubDate><guid>https://mryqu.github.io/post/twitter%E7%9A%84%E8%AE%BF%E9%97%AE%E4%BB%A4%E7%89%8Caccesstoken%E4%B8%8D%E8%BF%87%E6%9C%9F/</guid><description>Twitter OAuth FAQ中提到了目前Twitter访问令牌不会过期，省事了。</description></item><item><title>Google Analytics之segment（分块、分割、细分）</title><link>https://mryqu.github.io/post/google_analytics%E4%B9%8Bsegment%E5%88%86%E5%9D%97%E5%88%86%E5%89%B2%E7%BB%86%E5%88%86/</link><pubDate>Tue, 22 Sep 2015 06:44:04 +0000</pubDate><guid>https://mryqu.github.io/post/google_analytics%E4%B9%8Bsegment%E5%88%86%E5%9D%97%E5%88%86%E5%89%B2%E7%BB%86%E5%88%86/</guid><description>Segment是指你的GoogleAnalytics（分析）数据子集。例如，在你的整个用户群中，你可使用一个segment指定来自特定国家或城市的用户，使用另一个segment指定购买特定产品系列或访问网站上特定部分的用户。 Segment可让你隔离出这些数据子集并进行分析，从而检查并响应业务中的各个子趋势。例如，如果你发现特定地理区域的用户所购买的特定产品系列的数量低于正常水平，就可以查看是不是因为竞争对手在以更低的价格销售同类型的产品。如果是这样，你可以通过向那些用户提供忠诚度折扣来弱化竞争对手在价格方面的优势。 你还可以使用segment作为再营销受众群体的基础。例如，您可针对男装页面的访问者创建一个用户细分，然后利用重点宣传您添加到这些页面上的新产品的再营销广告系列来专门定位这些用户（再营销受众群体）。
Segment类型 Segment代表会话子集或用户子集：
会话子集：例如，源自广告系列 A 的所有会话；发生购买行为的所有会话 用户子集：例如，之前有过购买行为的用户；向其购物车添加了商品，但未完成购买的用户 先了解一下 Google Analytics（分析）用户模型有助于了解segment的工作原理。 GoogleAnalytics（分析）用户模型由三大要素构成：
用户 会话 - 用户到达您的网站资源并与之互动。所有这些用户互动都会被划组到所谓的会话中。 点击（Hit）-在会话中，用户会与您的网站资源互动。每次互动都被称为一次点击。这些点击包括网页浏览、事件、交易等等。 一个用户可以有多个会话，每个会话可以有多次点击。下图直观显示了这一关系： Google Analytics（分析）用户模型
使用Segment Segment是非破坏性的过滤器，不会更改您的基础数据。应用segment之后，它会在您浏览报告的过程中始终保持有效状态，直到您将其移除。您一次最多可以应用四个细分，并可在报告中将各个细分的结果放在一起比较。 除分析数据之外，Segment还可以用于构建再营销受众群体。 GoogleAnalytics（分析）包含预定义segment（系统segment），您可以按原样使用这些segment，也可以通过复制并修改这些segment来创建新的自定义segment。您也可以从头开始构建自己的segment。另外，您可以从 Google Analytics（分析）解决方案库导入segment，这是一个免费的市场，GoogleAnalytics（用户）可在其中分享各种segment以及开发的其他解决方案。
Segment的定义和范围 在 Google Analytics（分析）报告中，您可以通过创建基于维度和指标的过滤器来定义segment：
用户类型完全匹配“回访用户” 国家/地区完全匹配“美国” 电子商务转化率&amp;gt;“0.2%” 除了您在过滤器中使用的维度和指标之外，您还可以为过滤器设置数据范围。您可以使用三种范围：
点击：单次操作中的行为，例如查看网页或播放视频。 会话：单次会话中的行为；例如在会话过程中用户完成的目标或产生的收入。 用户：在所用日期范围（最多 90天）内所有会话中的行为；例如，在日期范围内的所有会话中用户完成的所有目标或产生的所有收入。 你可以使用segment生成工具定义组成segment的过滤器。
Segment限制 Segment需要遵守以下限制：
Segment总数上限 每个帐户 1000个segment 每个数据视图中，每位用户 100个segment 每个数据视图，所有用户共享100个segment 这些限制适用于系统segment以及您创建或导入的所有segment。达到这些数量上限后，你就无法创建或导入更多segment。 应用于报告的segment 你一次最多可以在报告中应用4个segment。
日期范围 使用基于用户的segment时，您在报告中应用的日期范围不能超过90天。如果您已将日期范围设置为90天以上，那么当您创建基于用户的segment时，GoogleAnalytics（分析）会从开始日期算起，将该日期范围重置为90天。 基于“第一次会话的日期”的segment的最大范围是31天。
多渠道路径 请不要在多渠道路径报告中使用segment，你可以使用转化segment。
Segment与filter的区别 在Googleanalytics中，Segment与filter都侧重于对数据的切片。在很多情况下，应用这两者返回的结果是相同的，但其本质是不同的。那么，何时应该使用segment，何时应该使用filter呢？ 如果你想选择整个访问则使用segment，如果想查找所有访问中的特定事件、pageviews等则使用filter。 Segment：对于segment，每个访问都检查是否符合segment条件。对于满足条件的会话，所有行都会被获得。对于不满足条件的会话，不会获得任何行。 Filter：对于filter，所有访问的所有行都会检查是否满足条件，仅满足过滤器条件的行会被获得。 个人感受：Google analytics中的filter就像SQL中的where语句，而segment就像SQL中groupby相应的having语句。
参考 About Segments
The key difference between segments and filters</description></item><item><title>Google Anaytics和Youtube Analytics的维度和指标</title><link>https://mryqu.github.io/post/google_anaytics%E5%92%8Cyoutube_analytics%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%92%8C%E6%8C%87%E6%A0%87/</link><pubDate>Sun, 20 Sep 2015 07:05:33 +0000</pubDate><guid>https://mryqu.github.io/post/google_anaytics%E5%92%8Cyoutube_analytics%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%92%8C%E6%8C%87%E6%A0%87/</guid><description>Google Anaytics的维度和指标 Google Anaytics 维度和指标浏览器
Youtube Analytics的维度和指标 Youtube Anaytics 维度 Youtube Anaytics指标
参考 Google Anaytics Core Reporting API - 常用查询</description></item><item><title>Google Analytics API Error 403: "User does not have any Google Analytics Account"</title><link>https://mryqu.github.io/post/google_analytics_api_error_403_user_does_not_have_any_google_analytics_account/</link><pubDate>Sat, 19 Sep 2015 06:05:53 +0000</pubDate><guid>https://mryqu.github.io/post/google_analytics_api_error_403_user_does_not_have_any_google_analytics_account/</guid><description>试用Google Analytics API，使用service account的认证方式，结果它报错:“User doesnot have any Google Analytics Account”。
解决方法：
在Google开发者控制台中确认Analytics API已经使能 Service account的邮箱域为@developer.gserviceaccount.com 拥有适当的AccountID和ProfileID，并将serviceaccount（至少以读取和分析权限）添加到Google Analytics profile 参考 Google&amp;rsquo;s instructions for adding an email address to an Analytics profile</description></item><item><title>遭遇“GsonFactory cannot be resolved”</title><link>https://mryqu.github.io/post/%E9%81%AD%E9%81%87gsonfactory_cannot_be_resolved/</link><pubDate>Fri, 18 Sep 2015 05:07:00 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%81%AD%E9%81%87gsonfactory_cannot_be_resolved/</guid><description>遭遇GsonFactory无法解析的错误：
...\HelloAnalytics.java:7: error: package com.google.api.client.json.gson does not exist import com.google.api.client.json.gson.GsonFactory; ^ ...\HelloAnalytics.java:28: error: cannot find symbol private static final JsonFactory JSON_FACTORY = GsonFactory.getDefaultInstance(); ^ symbol: variable GsonFactory location: class HelloAnalytics 2 errors :compileJava FAILED 解决方案为在_gradle.build_中添加：
compile &amp;#39;com.google.api-client:google-api-client-gson:1.20.0&amp;#39; exclude module: &amp;#39;httpclient&amp;#39; 参考 GsonFactory cannot be found</description></item><item><title>Google Anaytics资料</title><link>https://mryqu.github.io/post/google_anaytics%E8%B5%84%E6%96%99/</link><pubDate>Thu, 17 Sep 2015 05:29:03 +0000</pubDate><guid>https://mryqu.github.io/post/google_anaytics%E8%B5%84%E6%96%99/</guid><description>Google官方资料 Google Analytics（分析）帮助中心 (英文版) Google Analytics团队的博客 Avinash的Google+ Google Analytics Fundamental：有组织性的一个教程 外部资料 An introduction to Google Analytic (slideshare)：相当于一个全面的、提纲式的Google Analytics学习笔记 Google Analytics CheatSheet：制作的一个更加简练的备忘录 蓝鲸网站分析笔记：关注GoogleAnalytics应用 流量的秘密——Google Analytics网站分析与优化技巧》 Advanced Web Metrics with Google Analytics》 Google analytics-understanding Vistor Behavior》 《网站分析实战》</description></item><item><title>kitematic代理设置</title><link>https://mryqu.github.io/post/kitematic%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/</link><pubDate>Wed, 16 Sep 2015 06:09:37 +0000</pubDate><guid>https://mryqu.github.io/post/kitematic%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/</guid><description>在DockerToolbox目录下创建一个批处理脚本文件kitematic_proxy.cmd，插入下面代码，将&amp;quot;YOUR_PROXY&amp;quot;替换为所用的代理（http://host:port）。
set proxy=YOUR_PROXY SET HTTP_PROXY=%proxy% SET HTTPS_PROXY=%proxy% for /f %%i in (&amp;#39;docker-machine.exe ip default&amp;#39;) do set DOCKER_HOST=%%i SET NO_PROXY=%DOCKER_HOST% set DOCKER_HOST=tcp://%DOCKER_HOST%:2376 cd Kitematic Kitematic.exe 参考 kitematic Proxy/VPN error reports #1031</description></item><item><title>利用curl完成Google API、Facebook、DropBox、OneDrive等社交媒体的OAuth认证</title><link>https://mryqu.github.io/post/%E5%88%A9%E7%94%A8curl%E5%AE%8C%E6%88%90google_apifacebookdropboxonedrive%E7%AD%89%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93%E7%9A%84oauth%E8%AE%A4%E8%AF%81/</link><pubDate>Mon, 14 Sep 2015 06:22:41 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%A9%E7%94%A8curl%E5%AE%8C%E6%88%90google_apifacebookdropboxonedrive%E7%AD%89%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93%E7%9A%84oauth%E8%AE%A4%E8%AF%81/</guid><description>Twitter 没法用curl完成Twitter认证，可以尝试witter/twurl。
Facebook 通过curl命令获取访问密钥：
curl &amp;#34;https://graph.facebook.com/oauth/access_token?client_id={YOUR_APP_ID}&amp;amp;client_secret={YOUR_APP_SECRET}&amp;amp;grant_type=client_credentials&amp;#34; Google API 这里Google应用的客户端ID格式大概为XXX-YYY.apps.googleusercontent.com。
Google Analytics 首先通过浏览器访问下列链接获取code：
https://accounts.google.com/o/oauth2/v2/auth?scope=https://www.googleapis.com/auth/analytics.readonly%20profile&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;response_type=code&amp;amp;client_id={YOUR_APP_ID} 通过curl命令获取访问密钥：
curl -X POST -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; -H &amp;#34;Cache-Control: no-cache&amp;#34; -d &amp;#39;code={GOTTEN_CODE}&amp;amp;client_id={YOUR_APP_ID}&amp;amp;client_secret={YOUR_APP_SECRET}&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;grant_type=authorization_code&amp;#39; &amp;#34;https://www.googleapis.com/oauth2/v4/token&amp;#34; Youtube Analytics 首先通过浏览器访问下列链接获取code：
https://accounts.google.com/o/oauth2/v2/auth?scope=https://www.googleapis.com/auth/yt-analytics.readonly%20profile&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;response_type=code&amp;amp;client_id={YOUR_APP_ID} 通过curl命令获取访问密钥：
curl -X POST -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; -H &amp;#34;Cache-Control: no-cache&amp;#34; -d &amp;#39;code={GOTTEN_CODE}&amp;amp;client_id={YOUR_APP_ID}&amp;amp;client_secret={YOUR_APP_SECRET}&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;grant_type=authorization_code&amp;#39; &amp;#34;https://www.googleapis.com/oauth2/v4/token&amp;#34; Google drive &amp;amp; sheets 首先通过浏览器访问下列链接获取code：
https://accounts.google.com/o/oauth2/v2/auth?scope=https://www.googleapis.com/auth/spreadsheets%20https://www.googleapis.com/auth/drive%20profile&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;response_type=code&amp;amp;client_id={YOUR_APP_ID} 通过curl命令获取访问密钥：
curl -X POST -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; -H &amp;#34;Cache-Control: no-cache&amp;#34; -d &amp;#39;code={GOTTEN_CODE}&amp;amp;client_id={YOUR_APP_ID}&amp;amp;client_secret={YOUR_APP_SECRET}&amp;amp;redirect_uri=urn:ietf:wg:oauth:2.0:oob&amp;amp;grant_type=authorization_code&amp;#39; &amp;#34;https://www.googleapis.com/oauth2/v4/token&amp;#34; DropBox 首先通过浏览器访问下列链接获取code：
https://api.dropbox.com/1/oauth2/authorize?client_id={YOUR_APP_ID}&amp;amp;response_type=code&amp;amp;state=kx123 通过curl命令获取访问密钥：
curl -X POST -H &amp;#34;Content-Type: application/x-www-form-urlencoded&amp;#34; -H &amp;#34;Cache-Control: no-cache&amp;#34; -d &amp;#39;code={GOTTEN_CODE}&amp;amp;client_id={YOUR_APP_ID}&amp;amp;client_secret={YOUR_APP_SECRET}&amp;amp;grant_type=authorization_code&amp;#39; &amp;#34;https://api.</description></item><item><title>第三方开源Facebook Java API</title><link>https://mryqu.github.io/post/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BC%80%E6%BA%90facebook_java_api/</link><pubDate>Sun, 13 Sep 2015 06:14:26 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BC%80%E6%BA%90facebook_java_api/</guid><description>|API|许可类型|活跃度|最后更新|文档|注释 |&amp;mdash;&amp;ndash; |SpringSocial|Apache 2.0|活跃||有|良好 |RestFB|MIT|活跃||有|良好 |BatchFB|MIT|一般||有|良好 |Facebook BlackBerry SDK|MIT|停止更新|2011-8-22|无|老项目，停止更新较早 |FB4J|GPLv2|停止更新|2010-02-14|无|老项目，停止更新较早 |FB Java API|MIT|项目宣布停止|2013-2-5|有|主页建议转到RestFB |JFALibrary|GPLv3|停止更新|2011-5-22|无|很少的提交，且停止更新较早 |Javabook|Apache 2.0|停止更新|2007-9-5|有一点|项目在停止更新前未完成</description></item><item><title>[C++] addr2line使用</title><link>https://mryqu.github.io/post/c++_addr2line%E4%BD%BF%E7%94%A8/</link><pubDate>Fri, 11 Sep 2015 05:33:28 +0000</pubDate><guid>https://mryqu.github.io/post/c++_addr2line%E4%BD%BF%E7%94%A8/</guid><description>GNU Binutils的Addr2line工具是一个可以将指令的地址和可执行程序转换成文件名、函数名和源代码行数的工具。这种功能对于将跟踪地址转换成更有意义的内容来说简直是太棒了。
下面是一个小示例testAddr2line.c：
#include &amp;#34;stdio.h&amp;#34; void test() { printf(&amp;#34;Hello Addr2line\n&amp;#34;); } int main() { test(); return 0; } 编译时使用-g选项包含调试符号条，使用-Wl,-Map=testAddr2line.map选项输出MapFile。
gcc -Wl,-Map=testAddr2line.map -g -o testAddr2line testAddr2line.c testAddr2line.map部分内容如下： testAddr2line中也包含符号表信息，因而可以使用objdump查找：
hadoop@node51054:~/ctest$ objdump -t testAddr2line | grep &amp;#39;main\|test&amp;#39; testAddr2line: file format elf64-x86-64 0000000000000000 l df *ABS* 0000000000000000 testAddr2line.c 0000000000000000 F *UND* 0000000000000000 __libc_start_main@@GLIBC_2.2.5 0000000000400547 g F .text 0000000000000015 main 0000000000400536 g F .text 0000000000000011 test 使用addr2line：
hadoop@node51054:~/ctest$ addr2line -e testAddr2line 400536 /home/hadoop/ctest/testAddr2line.c:3 hadoop@node51054:~/ctest$ addr2line -e testAddr2line -f 400536 test /home/hadoop/ctest/testAddr2line.</description></item><item><title>一张图学习一门语言</title><link>https://mryqu.github.io/post/%E4%B8%80%E5%BC%A0%E5%9B%BE%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%97%A8%E8%AF%AD%E8%A8%80/</link><pubDate>Thu, 10 Sep 2015 05:58:41 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%80%E5%BC%A0%E5%9B%BE%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%97%A8%E8%AF%AD%E8%A8%80/</guid><description>今天看到两个不错的图：
Javascript in one pic Python3 in one pic</description></item><item><title>从Gradle bootRun任务向Spring Boot应用传递环境变量</title><link>https://mryqu.github.io/post/%E4%BB%8Egradle_bootrun%E4%BB%BB%E5%8A%A1%E5%90%91spring_boot%E5%BA%94%E7%94%A8%E4%BC%A0%E9%80%92%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</link><pubDate>Tue, 08 Sep 2015 06:32:44 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BB%8Egradle_bootrun%E4%BB%BB%E5%8A%A1%E5%90%91spring_boot%E5%BA%94%E7%94%A8%E4%BC%A0%E9%80%92%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</guid><description>尝试了从Gradle bootRun任务中传递环境变量给Spring Boot应用，下面是示例代码和演示。
示例代码 Application.java package com.yqu.gradlesysprop; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; @SpringBootApplication public class Application { private static final Logger log = LoggerFactory.getLogger(Application.class); public static void main(String[] args) { SpringApplication app = new SpringApplication(Application.class); app.setWebEnvironment(false); app.setShowBanner(false); app.run(args); } @Bean public CommandLineRunner demo1() { return (args) -&amp;gt; { log.info(&amp;#34;mryqu.prop.test=&amp;#34;+ System.getProperty(&amp;#34;mryqu.prop.test&amp;#34;)); }; } } build.gradle buildscript { repositories { mavenCentral() } dependencies { classpath(&amp;#34;org.springframework.boot:spring-boot-gradle-plugin:1.2.6.RELEASE&amp;#34;) } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#39;spring-boot&amp;#39; jar { baseName = &amp;#39;hello-gradlesysprop&amp;#39; version = &amp;#39;0.</description></item><item><title>Gradle代理配置</title><link>https://mryqu.github.io/post/gradle%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 31 Aug 2015 05:46:52 +0000</pubDate><guid>https://mryqu.github.io/post/gradle%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>HTTP代理配置 gradlew -Dhttp.proxyHost=[myServer] -Dhttp.proxyPort=[myPort] -Dhttp.proxyUser=[myUser] -Dhttp.proxyPassword=[myPassword] HTTPS代理配置 gradlew -Dhttps.proxyHost=[myServer] -Dhttps.proxyPort=[myPort] -Dhttps.proxyUser=[myUser] -Dhttps.proxyPassword=[myPassword]</description></item><item><title>[Hibernate Tools] 通过数据库表生成JPA Entity类</title><link>https://mryqu.github.io/post/hibernate_tools_%E9%80%9A%E8%BF%87%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%94%9F%E6%88%90jpa_entity%E7%B1%BB/</link><pubDate>Sun, 30 Aug 2015 08:56:57 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate_tools_%E9%80%9A%E8%BF%87%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%94%9F%E6%88%90jpa_entity%E7%B1%BB/</guid><description>本文与前一博文[Hibernate Tools] 通过JPA Entity类生成数据库表 正好相反，实践一下如何通过数据库表生成JPA Entity类。
在Eclipse中安装JBoss Tools中的Hibernate Tools插件 创建JPA项目PetStoreDemo 使用向导创建JPA项目 项目基本设置 设置JPA Facet 此处选用了Generatic 2.1平台，用户库HIBERNATE_JPA包含如下jar文件：
hibernate-commons-annotations.jar hibernate-core.jar hibernate-jpa-2.1-api.jar 通过数据库表生成JPA Entity类 执行“Generate Entities from Tables” 选择库表 设置库表关联关系 定制生成Entity的默认行为 设置单个Entity 生成结果 下面以Item为例，展示生成结果。
package com.yqu.jpetstore; import java.io.Serializable; import javax.persistence.*; import java.math.BigDecimal; @Entity @Table(name=&amp;#34;item&amp;#34;) @NamedQuery(name=&amp;#34;Item.findAll&amp;#34;, query=&amp;#34;SELECT i FROM Item i&amp;#34;) public class Item implements Serializable { private static final long serialVersionUID = 1L; private String itemid; private String attr1; private String attr2; private String attr3; private String attr4; private String attr5; private BigDecimal listprice; private String status; private BigDecimal unitcost; private Product product; private Supplier supplierBean; public Item() { } @Id @GeneratedValue(strategy=GenerationType.</description></item><item><title>[Hibernate Tools] 通过JPA Entity类生成数据库表</title><link>https://mryqu.github.io/post/hibernate_tools_%E9%80%9A%E8%BF%87jpa_entity%E7%B1%BB%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8/</link><pubDate>Sat, 29 Aug 2015 07:19:26 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate_tools_%E9%80%9A%E8%BF%87jpa_entity%E7%B1%BB%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8/</guid><description>以前用过hbm2ddlAnt任务通过Hibernate映射文件生成数据库DDL。现在使用JPA后，不知道还有没有标准工具了。找了一圈，还是HibernateTools。
在Eclipse中安装JBoss Tools中的Hibernate Tools插件 创建JPA项目CustomerDemo 使用向导创建JPA项目 项目基本设置 设置JPA Facet 此处选用了EclipseLink 2.5.x平台。如选择Generatic2.1平台，在生成数据库Schema时会报“Generate Tables from Entities is notsupported by the Generic Platform”。 用户库ECLIPSELINK_JPA包含如下jar文件：
eclipselink.jar javax.persistence.jar org.eclipse.persistence.jpa.modelgen.jar org.eclipse.persistence.jpars.jar Entity类代码及设置 Customer类 package hello; import javax.persistence.*; @Entity @Table(name=&amp;#34;CUSTOMER&amp;#34;) public class Customer { @Id @Column(name=&amp;#34;CUSTOMER_ID&amp;#34;, nullable=false, updatable=false, unique=true) @GeneratedValue(strategy=GenerationType.AUTO) private Long id; @Column(name = &amp;#34;CUSTOMER_FNAME&amp;#34;) private String firstName; @Column(name = &amp;#34;CUSTOMER_LNAME&amp;#34;) private String lastName; protected Customer() {} public Customer(String firstName, String lastName) { this.firstName = firstName; this.</description></item><item><title>试用了一下Kitematic</title><link>https://mryqu.github.io/post/%E8%AF%95%E7%94%A8%E4%BA%86%E4%B8%80%E4%B8%8Bkitematic/</link><pubDate>Fri, 28 Aug 2015 06:31:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%AF%95%E7%94%A8%E4%BA%86%E4%B8%80%E4%B8%8Bkitematic/</guid><description>Kitematic是一个一个简单的 Docker容器管理GUI程序，它可以在Windows/Mac上更快速、更简单的运行Docker。Kitematic 完全自动化了 Docker安装和设置过程，并提供了一个直观的图形用户接口（GUI）来在Windows/Mac上运行 Docker。Kitematic集成了Docker Machine来在Windows/Mac上分发一个虚拟机并安装 Docker引擎。 在Kitematic上可以在DockerHub上查询Docker镜像、并用之创建容器。也可以对特定Docker容器进行环境变量、Volume和端口等配置。对记不住Docker命令的懒人是一个福利。
参考 Kitematic官网
Github：Kitematic
DOCKER ONLINE MEETUP: KITEMATIC IN ACTION</description></item><item><title>SAS过程步支持的第三方编程语言</title><link>https://mryqu.github.io/post/sas%E8%BF%87%E7%A8%8B%E6%AD%A5%E6%94%AF%E6%8C%81%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link><pubDate>Tue, 25 Aug 2015 05:58:04 +0000</pubDate><guid>https://mryqu.github.io/post/sas%E8%BF%87%E7%A8%8B%E6%AD%A5%E6%94%AF%E6%8C%81%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid><description>编程语言接口描述C, C++PROC PROTOPROC PROTO可以以批处理模式注册以外部的C或C++程序。当C函数在PROC PROTO注册后，他们能被FCMP过程里声明的任何SAS函数或子程序调用, 也能被COMPILE过程里声明的任何SAS函数、子程序或方法块调用。PROC FCMPSAS函数编译器(FCMP)过程可以创建、测试和存储SAS函数和CALL子程序，这些SAS函数和CALL子程序之后可用于其它SAS过程步或数据步。PROC FCMP能够使用数据步语法创建存储在数据集内的SAS函数和CALL子程序。该过程步接受数据步语句的轻微变化，你可以使用PROC FCMP所创建的SAS函数和CALL子程序中SAS编程语言的大部分功能。GroovyPROC GROOVYPROC GROOVY是在SAS9.3引入，为特定Groovy内联代码提供提交快的SAS程序，也能运行存储在外部文件中的Groovy程序。 JavaJAVAOBJSAS9提供的数据步组件对象。示例： ``` data _null_; length s_out $200; declare JavaObj j1 ('java/lang/String','KE'); declare JavaObj j2 ('java/lang/String','XIAO'); j1.callStringMethod ('concat', j2, s_out); put s_out=; j1.delete(); j2.delete(); run; ``` PROC JLAUNCHJLaunch过程步允许在SAS显示管理器系统（DMS）内启动Java GUI程序。示例： ``` proc jlaunch direct librefs debug app='com/sas/analytics/cmpfunceditor/app/FCmpFunctionEditorApp'; picklist name='base/cmpedit.txt'; run; ``` LuaPROC LUAPROC LUA是在SAS9.4引入，为特定Lua内联代码提供提交快的SAS程序，也能运行存储在外部文件中的Lua程序。RPROC IMLPROC IML提供了灵活的矩阵编程语言，可以与R集成。示例： ``` libname mmsamp "!sasroot\mmcommon\sample"; proc iml; run ExportDatasetToR("mmsamp.hmeq_train" , "mm_inds"); submit /R; attach(mm_inds) # ----------------------------------------------- # FITTING THE LOGISTIC MODEL # ----------------------------------------------- logiten&lt;- glm(BAD ~ VALUE + factor(REASON) + factor(JOB) + DEROG + CLAGE + NINQ + CLNO , family=binomial) # ----------------------------------------------- # SAVING THE OUTPUT PARAMETER ESTIMATE TO LOCAL FILE # ----------------------------------------------- save(logiten, file=&amp;quot;c:/temp/outmodel.</description></item><item><title>漫谈Lua</title><link>https://mryqu.github.io/post/%E6%BC%AB%E8%B0%88lua/</link><pubDate>Mon, 24 Aug 2015 05:49:45 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%BC%AB%E8%B0%88lua/</guid><description>由于工作需要，最近用了有一段时间Lua了。对于脚本语言，研究生时用过Tcl/Tk做过网络仿真，后来在工作中学过Ruby，不同程度地用过UnixShell、Python、Javascript、Groovy、SAS和R。这里面UnixShell脚本是针对特定操作系统的脚本，SAS和R是用于特定业务领域（统计）的脚本，Javascript现在做Web富客户端是绕不过去的。用于通用领域的脚本中，Python容易上手、成熟、工具库多、资源丰富、文档等支持强大、几乎能做任何事：网络、图形界面、桌面程序、服务器、图形处理、算法等。可是我司将Lua而不是Python集成到SAS9.4中了。我使用它之前对其一无所知。很好奇Lua的历史及特长，是什么让我司对其青睐有加的？
何为Lua？ Lua是一门强大、快速、轻量级、可嵌入的脚本语言。Lua结合了简单的程序语法以及基于关联数组和扩展语义的强大数据描述结构。Lua是动态类型语言，通过在基于寄存器的虚拟机上解析字节码进行运行，具有自动内存管理和增量垃圾回收功能，极适于配置、脚本和快速原型开发。
Lua的历史 Lua在葡萄牙语中指的是“月亮”。Lua由PUC-Rio（巴西的里约热内卢天主教大学）的一个团队设计、实现和维护。Lua由Tecgraf（原先的计算机图形技术组）发明，并作为自由软件发行。现在由LabLua维护。Tecgraf和LabLua是PUC-Rio计算机科学系的两个实验室。 Lua发明者：Waldemar, Roberto, Luiz由Ernani d&amp;rsquo;Almeida拍摄(2011)
|Lua版本|发行时间|Lua版本|发行时间 |&amp;mdash;&amp;ndash; |1.0|未公开|3.1|1998/07/11 |1.1|1994/07/08|3.2|1999/07/08 |2.1|1995/02/07|4.0|2000/11/06 |2.2|1995/11/28|5.0|2003/04/11 |2.3|未公开|5.1|2006/02/21 |2.4|1996/03/14|5.2|2011/12/16 |2.5|1996/11/19|5.3|2015/01/12 |3.0|1997/07/01
Lua优点 经过验证的、健壮的语言：Lua已经被用于很多工业程序中(例如Adobe的PhotoshopLightroom)、嵌入式系统中(例如，用于巴西数字电视的Ginga中间件)和游戏中(例如魔兽和愤怒的小鸟)。Lua是游戏开发中主要的脚本语言。 速度快：许多Benchmark显示Lua是解释性脚本语言中最快的。例如Lua vs Python3 on X64 Ubuntu显示Lua比Python3要快很多。此外，LuaJIT项目提供在目标平台上的即时编译，可以让Lua有更优越的性能。 可移植：Lua以很小的包进行分发，在任何具有标准C编译器的系统上即可开箱即用地进行编译。Lua可在所有Unix发行版和Windows、移动设备、嵌入微处理器和IBM大型机等系统上运行。 可嵌入：Lua以很小的体积提供了一个快速语言引擎，所以易于嵌入到应用中。Lua具有简明、很好文档化的API，允许同其他语言紧密集成。非常易于通过其他语言库扩展Lua，同样其他语言程序也易于用Lua扩展。Lua不仅仅被用于扩展C和C++程序，还有Java、C#、Smalltalk、Fortran、Ada、Erlang、甚至注入Perl和Ruby之类的其他脚本语言。 功能强大（但简明）：Lua设计的一个基本概念是对所实现的功能提供元机制，而不是在语言中直接提供一堆功能。例如，Lua不是一个纯的面向对象语言，但它提供了用于实现类和集成的元机制。Lua的元机制带来概念的简明性并保持语言很小，同时允许语义以非传统的方式进行扩展。 体积小：Lua5.3.1的压缩包包含源代码和文档，体积仅276K，解压缩后为1.1M。源代码包含大约23000行C代码。在64位Linux下，使用所有标准Lua库的Lua解释器占242K，Lua库占414K。 免费：开源，使用非常自由的MIT许可证发布软件。 为什么SAS集成Lua？ 通过本文所附文章，基本可以判断SAS集成Lua是内部驱动的； 首先Lua有助SAS研发部门完成特定产品的开发工作（特别是新版本的SAS预报服务器）。Lua的优雅语法、现代设计和对数据结构的支持，可以让你以新的方式书写SAS程序，克服SAS宏语言的种种不足。SAS中的Lua生态系统有助于提升质量、一致性和重用性，从而以更低的代价获得更高的生产力。
参考 Lua官网
The History of Lua
Lua 为什么在游戏编程领域被广泛运用？
Lua简明教程
Driving SAS® with Lua
Using Lua within your SAS programs
The implementation of Lua 5.0
The LuaJIT Project</description></item><item><title>[OpenUI5] sap.ui.define源码分析</title><link>https://mryqu.github.io/post/openui5_sap.ui.define%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Sun, 23 Aug 2015 06:35:00 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_sap.ui.define%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>jQuery.sap.define通过名字、依赖、模块值或工厂定义一个Javascript模块。
jQuery.sap.define函数源码在jquery.sap.global.js，执行时可在sap-ui-core.js中找到。
通过判断jQuery.sap.define的sModuleName参数类型是否为string类型，获得参数实际对应使用用途，通过移换参数获得真实的sResourceName（js文件路径）、vFactory（模块工厂）、aDependencies（依赖模块）及bExport。
通过[OpenUI5] jQuery.sap.declare源码分析里介绍过的declareModule函数宣称当前模块已存在，通过[OpenUI5] jQuery.sap.require源码分析里介绍过的requireModule函数解析当前模块的每一个依赖。
sap.ui.define = function(sModuleName, aDependencies, vFactory, bExport) { var sResourceName, i; // optional id if ( typeof sModuleName === &amp;#39;string&amp;#39; ) { sResourceName = sModuleName + &amp;#39;.js&amp;#39;; } else { // shift parameters bExport = vFactory; vFactory = aDependencies; aDependencies = sModuleName; sResourceName = _execStack[_execStack.length - 1]; } // convert module name to UI5 module name syntax (might fail!) sModuleName = urnToUI5(sResourceName); // optional array of dependencies if ( !</description></item><item><title>[OpenUI5] jQuery.sap.declare源码分析</title><link>https://mryqu.github.io/post/openui5_jquery.sap.declare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Sun, 23 Aug 2015 00:03:20 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_jquery.sap.declare%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>jQuery.sap.declare用于宣称一个模块已存在。
在OpenUI5开发指南&amp;ndash;精粹&amp;ndash;优化应用&amp;ndash;模块化和依赖管理中对declare介绍是:
Modules can declare themselves by calling the static jQuery.sap.declare functionwith their name. This helpsSAPUI5tocheck at runtime whether a loaded module contains the expectedcontent by comparing the required name against the declared name.As a side effect,jQuery.sap.declare ensures that the parent namespace of the module name exists in the currentglobal namespace (window).Formore information, see jQuery.sap.declare.
For modules without declaration, the framework assumes that themodule has the expected content and declares it with the name thatwas used for loading.</description></item><item><title>[OpenUI5] jQuery.sap.require源码分析</title><link>https://mryqu.github.io/post/openui5_jquery.sap.require%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Sat, 22 Aug 2015 07:32:23 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_jquery.sap.require%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>jQuery.sap.require用于解析一个或多个模块依赖。
jQuery.sap.require函数源码在jquery.sap.global.js，执行时可在sap-ui-core.js中找到。
通过下面的源代码可知，jQuery.sap.require首先通过ui5ToRJS将javascript类名转换为js文件名，例如sap.m.Dialog转换为sap/m/Dialog.js，然后执行requireModule函数。
requireModule函数查找该模块在sap.ui.core.Core对象的mModules中是否存在，不存在则添加并设为INITIAL状态，判断模块是否已经被加载、执行过，如果没有则设为LOADING状态并通过ajax以同步方式加载代码（如果当前是debug模式则选择-dbg版本的js文件URL），加载失败设为FAILED状态，加载成功则设为LOADED状态并执行代码，执行失败设为FAILED状态，执行成功设为READY状态。
jQuery.sap.require = function(vModuleName, fnCallback) { if ( arguments.length &amp;gt; 1 ) { // legacy mode with multiple arguments, each representing a dependency for (var i = 0; i &amp;lt; arguments.length; i++) { jQuery.sap.require(arguments[i]); } return this; } // check for an object as parameter for sModuleName // in case of this the object contains the module name and the type // which could be {modName: &amp;#34;sap.ui.core.Dev&amp;#34;, type: &amp;#34;view&amp;#34;} if (typeof (vModuleName) === &amp;#34;object&amp;#34;) { jQuery.</description></item><item><title>[Hive] Hive 表UDTF和汇聚UDAF学习</title><link>https://mryqu.github.io/post/hive_hive_%E8%A1%A8udtf%E5%92%8C%E6%B1%87%E8%81%9Audaf%E5%AD%A6%E4%B9%A0/</link><pubDate>Thu, 20 Aug 2015 05:48:48 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive_%E8%A1%A8udtf%E5%92%8C%E6%B1%87%E8%81%9Audaf%E5%AD%A6%E4%B9%A0/</guid><description>在之前的博文[Hive] Hive Macro和UDF实践中，我对Hive的宏和普通UDF进行学习并实践，这里将针对Hive表UDF（UDTF）和汇聚UDF（UDAF）进行学习。 普通UDF可以对一行表数据进行处理输出一个单元格数据；UDTF可以对一行表数据进行处理输出多列甚至多行数据；UDAF可以对整表数据进行处理输出某种汇聚结果。
UDTF Hive支持的内建UDTF有explode()、json_tuple()和inline()等函数。
查看UDTF介绍 选个好理解的explode函数吧。
hive&amp;gt; describe function explode; OK explode(a) - separates the elements of array a into multiple rows, or the elements of a map into multiple rows and columns Time taken: 0.009 seconds, Fetched: 1 row(s) 测试内建UDTF 像inline函数需要根元素为ARRAY，第二层元素为STRUCT，搭建环境有点麻烦。所以还是接着擼explode函数吧。 上述命令将三行的列a中数组元素拆成7行字符串。那执行&amp;quot;select explode(a), b fromcomplex_datatypes_example;&amp;ldquo;会返回什么呢？结果是7行还是3行？ 谜底就是错误提示&amp;quot;Only a single exp.ression in the SELECT clause issupported with UDTF&amp;rsquo;s.&amp;quot;！
UDTF实现 一个定制UDTF要继承GenericUDTF抽象类并实现initialize、process及close方法。Hive调用initialize方法以将参数类型通知给UDTF。UDTF必须返回UDTF之后产生的行对象相应的对象观察器。一旦initialize()被调用后，Hive将使用process()方法将行传递给UDTF。在process()方法中，UDTF生成行并调用forward()方法将行转给其他运算符。当所有的行都传递给UDTF后，Hive将最终调用close()方法。 通过FunctionRegistry类可知explode函数的实现类为GenericUDTFExplode。下面通过GenericUDTFExplode对照参考四Hive Developer Guide - UDTF学习一下UDTF实现。
GenericUDTFExplode继承了抽象父类GenericUDTF 在initialize方法中，GenericUDTFExplode检查输入列是否为ARRAY或MAP类型，不是的话抛出异常。如果输入列为ARRAY类型，则输出列名为col，类型为输入列数组中元素类型；如果输入列为MAP类型，则输出列名为key和value，类型分别为输入列MAP的键与值相应的类型； 在process方法中，针对输入列ARRAY或MAP的每一个元素调用forward()方法将所生成的行转给其他运算符； 在close()方法中，实现为空。 UDAF Hive支持的内建UDAF有sum()、count()、min()和histogram_numeric()等函数。</description></item><item><title>安装Gerrit的commit-msg钩子</title><link>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85gerrit%E7%9A%84commit-msg%E9%92%A9%E5%AD%90/</link><pubDate>Wed, 19 Aug 2015 05:34:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85gerrit%E7%9A%84commit-msg%E9%92%A9%E5%AD%90/</guid><description>对Gerrit进行首次提交前需要安装commit-msg钩子，每次总忘，每次都总是搜邮件，还是记博客里方便些。
gitdir=$(git rev-parse --git-dir); scp -p -P 29418 [your username]@[your Gerrit review server]:hooks/commit-msg {gitdir}/hooks/ 参考
Gerrit：commit-msg Hook
Gerrit工作流</description></item><item><title>[Hive] Hive Macro和UDF实践</title><link>https://mryqu.github.io/post/hive_hive_macro%E5%92%8Cudf%E5%AE%9E%E8%B7%B5/</link><pubDate>Tue, 18 Aug 2015 05:09:46 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive_macro%E5%92%8Cudf%E5%AE%9E%E8%B7%B5/</guid><description>测试数据库 hive&amp;gt; describe empinfo; OK firstname string lastname string id int age int city string state string Time taken: 0.047 seconds, Fetched: 6 row(s) hive&amp;gt; select * from empinfo; OK John Jones 99980 45 Payson Arizona Mary Jones 99982 25 Payson Arizona Eric Edwards 88232 32 San Diego California Mary Ann Edwards 88233 32 Phoenix Arizona Ginger Howell 98002 42 Cottonwood Arizona Sebastian Smith 92001 23 Gila Bend Arizona Gus Gray 22322 35 Bagdad Arizona Mary Ann May 32326 52 Tucson Arizona Erica Williams 32327 60 Show Low Arizona Leroy Brown 32380 22 Pinetop Arizona Elroy Cleaver 32382 22 Globe Arizona Time taken: 0.</description></item><item><title>[OpenUI5] 加载时替换JavaScript源文件</title><link>https://mryqu.github.io/post/openui5_%E5%8A%A0%E8%BD%BD%E6%97%B6%E6%9B%BF%E6%8D%A2javascript%E6%BA%90%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 16 Aug 2015 07:22:40 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%8A%A0%E8%BD%BD%E6%97%B6%E6%9B%BF%E6%8D%A2javascript%E6%BA%90%E6%96%87%E4%BB%B6/</guid><description>我有一些自己定制的OpenUI5控件，有时会修改某个方法内的逻辑，这个好处理，在ChromedevTool直接修改加载后JS代码并保存就可以直接调试。如果修改了property、aggregation或者init方法内的逻辑的话，由于错过了初始化就不灵了，而重新加载的话又丢失了自己新加的调试代码。
我的解决方法如下：
清除Chrome缓存 在sap-ui-core-dbg.js里requireModule方法内设置断点，设置断点条件为response.indexOf(&amp;ldquo;Dialog.extend(&amp;quot;mryqu.test.control.KexiaoDialog&amp;rdquo;)&amp;gt;0这样当OpenUI5加载KexiaoDialog.js文件时就会触发断点。 重新加载我的OpenUI5项目：http://www.mryqu.com/test123/?sap-ui-debug=true&amp;amp;sap-ui-preload=false 当断点被触发时，在Console执行： response=&amp;#39;(function ()\n\ {\n\ &amp;#34;use strict&amp;#34;;\n\ \n\ jQuery.sap.require(&amp;#34;sap.m.Button&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.Dialog&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.HBox&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.Input&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.RadioButton&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.VBox&amp;#34;);\n\ jQuery.sap.require(&amp;#34;sap.m.Text&amp;#34;);\n\ \n\ var Button = sap.m.Button;\n\ var Dialog = sap.m.Dialog;\n\ var HBox = sap.m.HBox;\n\ var Icon = sap.ui.core.Icon;\n\ var Input = sap.m.Input;\n\ var RadioButton = sap.m.RadioButton;\n\ var Text = sap.m.Text;\n\ var VBox = sap.m.VBox;\n\ \n\ Dialog.extend(&amp;#34;mryqu.test.control.KexiaoDialog&amp;#34;, {\n\ metadata: {\n\ properties: {\n\ &amp;#34;tableName&amp;#34; : {type : &amp;#34;string&amp;#34;, defaultValue : &amp;#34;&amp;#34;},\n\ },\n\ associations: {\n\ invoker: {type: &amp;#34;sap.</description></item><item><title>[Hive] Hive表文件存储格式</title><link>https://mryqu.github.io/post/hive_hive%E8%A1%A8%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/</link><pubDate>Fri, 14 Aug 2015 06:25:23 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive%E8%A1%A8%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/</guid><description>Hive支持的内建表文件存储格式如下：
|存储格式|介绍 |&amp;mdash;&amp;ndash; |TEXTFILE|按照纯文本文件格式存储。如果配置hive.default.fileformat没有设置的话，TEXTFILE是默认文件格式。
此存储格式下，数据不做压缩的话，磁盘开销大，数据解析开销大。使用Gzip、Bzip2、Snappy等进行压缩使用（系统自动检查，执行查询时自动解压）的话，Hive不能对数据进行切分，从而无法对数据进行并行操作。 |SEQUENCEFILE|按照压缩的Sequence File格式存储。
SequenceFile一般是在HDFS FileSystem中生成，供map调用的原始文件。Hive中的SequenceFile继承自Hadoop API 的SequenceFile，不过它的key为空，使用value存放实际的值，这样是为了避免MR在运行map阶段的排序过程。 |RCFILE|按照RCFile (Record Columnar File)格式存储。
在Hive0.6.0引入。RCFile是在计算机集群中判断如何存储关系型表的数据存放结构，是Facebook、俄亥俄州立大学、中科院计算所联合研究成果。FCFile结构是由数据存储格式、数据压缩方式、数据读取优化技术等多种模块的系统组合，可以实现数据存放的四个要求：(1)快速加载，(2) 快速处理查询，(3) 高效利用存储空间 (4) 非常适用于动态数据访问模式。
它遵循“先按行划分，再垂直划分”的设计理念。当查询过程中，针对它并不关心的列时，它会在IO上跳过这些列。需要说明的是，RCFile在map阶段从远端拷贝仍然是拷贝整个数据块，并且拷贝到本地目录后RCFile并不是真正直接跳过不需要的列，并跳到需要读取的列，而是通过扫描每一个row group的头部定义来实现的，但是在整个HDFS Block 级别的头部并没有定义每个列从哪个rowgroup起始到哪个row group结束。所以在读取所有列的情况下，RCFile的性能反而没有SequenceFile高。 |ORC|在Hive 0.11.0引入。ORC(Optimized RowColumnar)存储源自于RCFile。FCFile把每列都当作二进制blob处理，而ORC存储列元数据，针对列类型使用特定的读写器。ORC支持ACID、内建索引和复杂类型。官网上介绍“其性能显著快于RCFile或Parquet”。Facebook和Yahoo等大公司都在使用。 |PARQUET|在Hive 0.13.0引入。Parquet源自于google Dremel系统。Parquet最初的设计动机是存储嵌套式数据，将这类数据存储成列式格式，以方便对其高效压缩和编码，且使用更少的IO操作取出需要的数据，这也是Parquet相比于ORC的优势，它能够透明地将Protobuf和thrift类型的数据进行列式存储，在Protobuf和thrift被广泛使用的今天，与parquet进行集成，是一件非容易和自然的事情。除了上述优势外，相比于ORC,Parquet没有太多其他可圈可点的地方，比如它不支持update操作（数据写成后不可修改），不支持ACID等。 |AVRO|在Hive 0.13.0引入。Avro是数据序列化系统，由Hadoop项目开发的。
测试 $ echo -e &amp;#39;1\x01foo&amp;#39; &amp;gt; tabft.txt $ echo -e &amp;#39;2\x01bar&amp;#39; &amp;gt;&amp;gt; tabft.txt $ hive hive&amp;gt; create table tabft (id int, name string); hive&amp;gt; quit; $ hadoop fs -put tabft.txt /user/hive/warehouse/tabft $ hive hive&amp;gt; create table tabft_txt (id int, name string) STORED AS TEXTFILE; hive&amp;gt; insert into table tabft_txt select * from tabft; hive&amp;gt; create table tabft_seq (id int, name string) STORED AS SEQUENCEFILE; hive&amp;gt; insert into table tabft_seq select * from tabft; hive&amp;gt; create table tabft_rc (id int, name string) STORED AS RCFILE; hive&amp;gt; insert into table tabft_rc select * from tabft; hive&amp;gt; create table tabft_orc (id int, name string) STORED AS ORC; hive&amp;gt; insert into table tabft_orc select * from tabft; hive&amp;gt; create table tabft_parq (id int, name string) STORED AS PARQUET; hive&amp;gt; insert into table tabft_parq select * from tabft; hive&amp;gt; create table tabft_avro (id int, name string) STORED AS AVRO; hive&amp;gt; insert into table tabft_avro select * from tabft; 获取Sequence文件信息 在我的环境下，按照压缩的Sequence File格式存储后的文件是非压缩的。 获取ORC文件信息 参考 Hive 语言手册 - DDL</description></item><item><title>[Hive] Hive数据类型</title><link>https://mryqu.github.io/post/hive_hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Thu, 13 Aug 2015 06:14:56 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>Hive支持的数据类型 原始数据类型 TINYINT SMALLINT INT BIGINT BOOLEAN FLOAT DOUBLE STRING BINARY TIMESTAMP DECIMAL DECIMAL(precision, scale) DATE VARCHAR CHAR 复杂数据类型 array_type map_type struct_type union_type 原始数据类型 在理解原始数据类型时，耗时最多的是TIMESTAMP和BINARY，下文会着重介绍我对这两种类型的理解。 首先创建表primitive_dataytpes_example，字段之间的分隔符没有采用默认的ctrlA，而是使用逗号分隔：
create table primitive_dataytpes_example ( a TINYINT, b SMALLINT, c INT, d BIGINT, e BOOLEAN, f FLOAT, g DOUBLE, h STRING, i BINARY, j TIMESTAMP, k DECIMAL, l DECIMAL (10,2), m DATE, n VARCHAR(20), o CHAR(20) ) ROW FORMAT DELIMITED FIELDS TERMINATED BY &amp;#39;,&amp;#39; LINES TERMINATED BY &amp;#39;\n&amp;#39;; 接下来插入一条记录（dummy表的使用见参考三）：</description></item><item><title>了解Objenesis</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3objenesis/</link><pubDate>Wed, 12 Aug 2015 06:04:09 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3objenesis/</guid><description>Objenesis是一个很小的Java库，作用是绕过构造器创建一个实例。Java已经支持通过Class.newInstance()动态实例化Java类，但是这需要Java类有个适当的构造器。很多时候一个Java类无法通过这种途径创建，例如：
构造器需要参数 构造器有副作用 构造器会抛出异常 Objenesis可以绕过上述限制。它一般用于：
序列化、远程处理和持久化：无需调用代码即可将Java类实例化并存储特定状态。 代理、AOP库和Mock对象：可以创建特定Java类的子类而无需考虑super()构造器。 容器框架：可以用非标准方式动态实例化Java类。例如Spring引入Objenesis后，Bean不再必须提供无参构造器了。 Objenesis内部提供了多个不同JVM上的解决方案：
参考 Objenesis项目官网
GitHub：Objenesis</description></item><item><title>[Hive] Hive UDF not supported in insert/values command</title><link>https://mryqu.github.io/post/hive_hive_udf_not_supported_in_insertvalues_command/</link><pubDate>Mon, 10 Aug 2015 05:58:27 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive_udf_not_supported_in_insertvalues_command/</guid><description>创建一个带有timestamp字段的表，想要在insert/values语句中使用UDF，结果报错。
hive&amp;gt; create table t2 (id int, time timestamp); OK Time taken: 0.045 seconds hive&amp;gt; insert into t2 values(1,current_timestamp()); FAILED: SemanticException [Error 10293]: Unable to create temp file for insert values Expr*ession of type TOK_FUNCTION not supported in insert/values 参考一中提到：”Hive does not support literals for complex types (array,map, struct, union), so it is not possible to use them in INSERTINTO&amp;hellip;VALUES clauses. This means that the user cannot insert datainto a complex datatype column using the INSERT INTO&amp;hellip;VALUESclause.</description></item><item><title>[OpenUI5] 自定义控件属性支持的数据类型</title><link>https://mryqu.github.io/post/openui5_%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6%E5%B1%9E%E6%80%A7%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Sat, 08 Aug 2015 08:05:21 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6%E5%B1%9E%E6%80%A7%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>创建一个OpenUI5控件时免不了声明几个属性，例如：
metadata: { properties: { &amp;#34;msg&amp;#34; : {type : &amp;#34;string&amp;#34;, defaultValue : &amp;#34;kx123&amp;#34;}, &amp;#34;byProxy&amp;#34; : {type : &amp;#34;boolean&amp;#34;, defaultValue : true} }, publicMethods: [ ], events: { complete : {enablePreventDefault : true} } } 可是属性都支持那些数据类型呢？搜了一下OpenUI5 开发指南，并没有找到什么有用的信息。还是得从代码里面寻觅，结果发现答案就在sap.ui.base.DataType里。
var mTypes = { &amp;#34;any&amp;#34; : createType(&amp;#34;any&amp;#34;, { defaultValue : null, isValid : function(vValue) { return true; } }), &amp;#34;boolean&amp;#34; : createType(&amp;#34;boolean&amp;#34;, { defaultValue : false, isValid : function(vValue) { return typeof vValue === &amp;#34;boolean&amp;#34;; } }), &amp;#34;int&amp;#34; : createType(&amp;#34;int&amp;#34;, { defaultValue : 0, isValid : function(vValue) { return typeof vValue === &amp;#34;number&amp;#34; &amp;amp;&amp;amp; Math.</description></item><item><title>[JavaScript] 判断jQuery版本</title><link>https://mryqu.github.io/post/javascript_%E5%88%A4%E6%96%ADjquery%E7%89%88%E6%9C%AC/</link><pubDate>Thu, 06 Aug 2015 05:52:03 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E5%88%A4%E6%96%ADjquery%E7%89%88%E6%9C%AC/</guid><description>学习了一下如何判断jQuery版本：
if (window.jQuery) { jQuery().jquery; } 测试：</description></item><item><title>在jQuery AJAX中使用statusCode</title><link>https://mryqu.github.io/post/%E5%9C%A8jquery_ajax%E4%B8%AD%E4%BD%BF%E7%94%A8statuscode/</link><pubDate>Wed, 05 Aug 2015 05:49:50 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8jquery_ajax%E4%B8%AD%E4%BD%BF%E7%94%A8statuscode/</guid><description>jQuery.ajax中提供了statusCode设置，以便根据响应状态值进行相应处理。
var data = JSON.stringify({ name: &amp;#34;mryqu&amp;#34;, count: 123 }); $.ajax({ //cache: false, url: &amp;#34;/test&amp;#34;, type: &amp;#34;post&amp;#34;, contentType: &amp;#34;application/json&amp;#34;, dataType: &amp;#34;json&amp;#34;, data: data, beforeSend: function (xhr) { console.log(&amp;#34;beforeSend called&amp;#34;); }, statusCode: { 401: function() { console.log(&amp;#34;statusCode 401 called&amp;#34;); }, 449: function() { console.log(&amp;#34;statusCode 449 called&amp;#34;); } }, error: function (oResult, textStatus, errorThrown) { if (oResult.status !==401 &amp;amp;&amp;amp; oResult.status !==449) { console.log(&amp;#34;error called&amp;#34;); } }, success: function (oResult) { console.log(&amp;#34;success called&amp;#34;); } }); 有时候发现statusCode不被调用，所以我更喜欢用下面这种更保险的方式。</description></item><item><title>Consul服务设置实践</title><link>https://mryqu.github.io/post/consul%E6%9C%8D%E5%8A%A1%E8%AE%BE%E7%BD%AE%E5%AE%9E%E8%B7%B5/</link><pubDate>Tue, 04 Aug 2015 05:54:36 +0000</pubDate><guid>https://mryqu.github.io/post/consul%E6%9C%8D%E5%8A%A1%E8%AE%BE%E7%BD%AE%E5%AE%9E%E8%B7%B5/</guid><description>在向Consul注册/注销外部服务节点中，我实践对Consul节点注册和注销，本帖我实践一些对Consul服务的查看和注销。
查看当前数据中心所有注册的服务：
curl http://localhost:8500/v1/catalog/services 查看当前数据中心注册的服务foo的信息：
curl http://localhost:8500/v1/catalog/service/foo 注销服务节点foo上关联的检查service:foo-192-168-0-123：
curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;{&amp;#34;Node&amp;#34;: &amp;#34;kexiao&amp;#34;, &amp;#34;CheckID&amp;#34;: &amp;#34;service:foo-192-168-0-123&amp;#34;}&amp;#39; http://localhost:8500/v1/catalog/deregister 注销服务节点foo上关联的服务foo-192-168-0-123：
curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;{&amp;#34;Node&amp;#34;: &amp;#34;kexiao&amp;#34;, &amp;#34;ServiceID&amp;#34;: &amp;#34;foo-192-168-0-123&amp;#34;}&amp;#39; http://localhost:8500/v1/catalog/deregister 参考 Consul - Catalog HTTP Endpoint</description></item><item><title>[Spring Boot] 创建超媒体驱动的Mail服务</title><link>https://mryqu.github.io/post/spring_boot_%E5%88%9B%E5%BB%BA%E8%B6%85%E5%AA%92%E4%BD%93%E9%A9%B1%E5%8A%A8%E7%9A%84mail%E6%9C%8D%E5%8A%A1/</link><pubDate>Mon, 03 Aug 2015 06:46:47 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_%E5%88%9B%E5%BB%BA%E8%B6%85%E5%AA%92%E4%BD%93%E9%A9%B1%E5%8A%A8%E7%9A%84mail%E6%9C%8D%E5%8A%A1/</guid><description>Spring与Mail的集成 Spring框架为邮件发送提供了一个有用的工具库，可为用户屏蔽底层邮件系统细节，并负责代表客户端负责低层资源处理。 org.springframework.mail包是Spring框架邮件支持的根级包。发送邮件的核心接口是MailSender 接口；封装了简单邮件_from_和_to_等属性的简单对象类是 SimpleMailMessage 。该包也包含对底层邮件系统进行更高级抽象的分层检查异常，其根异常为MailException。 org.springframework.mail.javamail.JavaMailSender 接口MailSender为添加了专业的_JavaMail_ 功能，例如MIME消息支持。JavaMailSender 也为JavaMailMIME消息提供了回调接口org.springframework.mail.javamail.MimeMessagePreparator。
Spring HATEOAS HATEOAS (Hypermedia as the Engine of ApplicationState，超媒体即应用状态引擎)是REST应用架构的一个约束。Spring HATEOAS是一个用于支持实现超媒体驱动的RESTWeb服务的开发库。它提供一些API用于同Spring特别是SpringMVC一起使用时轻松创建遵循HATEOAS原则的REST表述，其试图解决的核心问题是链接创建和表述装配。功能：
用于链接、资源表述模型的模型类 用于指向Spring MVC控制器方法的链接建造者API 对HAL之类的多媒体格式的支持 示例 Application.java package com.yqu.mail; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } MailServerVO.java package com.yqu.mail; import org.springframework.hateoas.ResourceSupport; import java.io.Serializable; import java.util.Properties; public class MailServerVO extends ResourceSupport implements Serializable { private String host; private Integer port; private String userName; private String password; private String defaultEncoding; private Properties properties; public MailServerVO() {} public MailServerVO( String host, Integer port, String userName, String password, String defaultEncoding, Properties properties) { this.</description></item><item><title>Java Mail</title><link>https://mryqu.github.io/post/java_mail/</link><pubDate>Sun, 02 Aug 2015 09:22:37 +0000</pubDate><guid>https://mryqu.github.io/post/java_mail/</guid><description>JavaMail API JavaMail最新版本为1.5.4。 支持的邮件协议有：
SMTP：简单邮件传输协议（Simple Mail Transfer Protocol），由RFC 821 定义，定义了发送电子邮件的机制。在JavaMailAPI环境中，基于JavaMail的程序将和公司或因特网服务供应商的SMTP服务器通信。SMTP 服务器会中转消息给接收方 SMTP服务器以便最终让用户经由 POP 或 IMAP 获得。这不是要求SMTP服务器成为开放的中继，尽管SMTP服务器支持身份验证，不过还是得确保它的配置正确。JavaMailAPI不支持像配置服务器来中继消息或添加/删除邮件账号这类任务的实现。 POP：邮局协议（Post Office Protocol）。目前用的是版本 3，也称POP3，由RFC 1939定义。本协议主要用于支持使用客户端远程管理在服务器上的电子邮件。POP协议支持“离线”邮件处理。其具体过程是：邮件发送到服务器上，电子邮件客户端调用邮件客户机程序以连接服务器，并下载所有未阅读的电子邮件。使用POP时，用户熟悉的许多性能并不是由POP协议支持的，如查看有几封新邮件消息这一性能。这些性能内建于如Eudora或Microsoft Outlook之类的程序中，它们能记住一些事，诸如最近一次收到的邮件，还能计算出有多少是新的。所以当使用JavaMailAPI时，如果您想要这类信息，您就必须自己算。 IMAP： 因特网消息访问协议（Internet Message Access Protocol）。目前用的是版本 4，也称IMAP4。由RFC 2060定义，是更高级的用于接收消息的协议。它与POP3协议的主要区别是用户可以不用把所有的邮件全部下载，可以通过客户端直接对服务器上的邮件进行操作。IMAP4改进了POP3的不足，用户可以通过浏览信件头来决定是否收取、删除和检索邮件的特定部分，还可以在服务器上创建或更改文件夹或邮箱。它除了支持POP3协议的脱机操作模式外，还支持联机操作和断连接操作。它为用户提供了有选择的从邮件服务器接收邮件的功能、基于服务器的信息处理功能和共享信箱功能。IMAP4的脱机模式不同于POP3，它不会自动删除在邮件服务器上已取出的邮件，其联机模式和断连接模式也是将邮件服务器作为“远程文件服务器”进行访问，更加灵活方便。IMAP4支持多个邮箱。 MIME：多用途因特网邮件扩展标准（Multipurpose Internet MailExtensions）。它不是邮件传输协议。但对传输内容的消息、附件及其它的内容定义了格式。这里有很多不同的有效文档：RFC 822、RFC 2045、RFC 2046 和 RFC 2047。作为一个 JavaMailAPI的用户，您通常不必对这些格式操心。无论如何，一定存在这些格式而且程序会用到它。
JavaMail API不在Java JDK中，javax.mail.jar包含了JavaMailAPI及Sun的参考设计，其中包括SMTP、IMAP和POP3协议提供者。 JavaMail API 类包:
javax.mail： The JavaMailTM API提供为邮件系统建模的类。 javax.mail.event： 用于JavaMail API的监听器和事件。 javax.mail.internet：特定互联网邮件系统的类。 javax.mail.search：用于JavaMail API的消息搜索术语。 javax.mail.util： JavaMail API工具类。Sun参考设计的类包: com.sun.mail.dsn：支持创建和解析传递状态通知。 com.sun.mail.gimap： 支持Gmail特定IMAP协议扩展的实验性IMAP协议提供者。 com.sun.mail.imap：用于访问IMAP消息存储的IMAP协议提供者。 com.sun.mail.pop3：用于访问POP3消息存储的POP3协议提供者。 com.sun.mail.smtp：用于访问SMTP服务器的SMTP协议提供者。 com.sun.mail.util： 用于JavaMail API的工具类。 com.sun.mail.util.logging： 包含用于JavaTM平台核心日志功能的JavaMailTM扩展。 Apache Commons Email Apache Commons Email是构建在JavaMail API之上的工具库，旨在简化设计，当前版本1.</description></item><item><title>向Consul注册/注销外部服务节点</title><link>https://mryqu.github.io/post/%E5%90%91consul%E6%B3%A8%E5%86%8C%E6%88%96%E6%B3%A8%E9%94%80%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%8A%82%E7%82%B9/</link><pubDate>Sat, 01 Aug 2015 07:00:25 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%90%91consul%E6%B3%A8%E5%86%8C%E6%88%96%E6%B3%A8%E9%94%80%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%8A%82%E7%82%B9/</guid><description>已有一个docker上的微服务节点foo，但是有可能需要使用系统外部的foo服务集群。 切换到系统外部的foo服务集群的操作过程如下：
docker-compose stop foo docker-compose rm foo curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;{&amp;#34;Node&amp;#34;: &amp;#34;foo&amp;#34;, &amp;#34;Address&amp;#34;: &amp;#34;foo.cluster.yqu.com&amp;#34;, &amp;#34;Service&amp;#34;: {&amp;#34;Service&amp;#34;:&amp;#34;foo&amp;#34;, &amp;#34;tags&amp;#34;: [&amp;#34;controller&amp;#34;], &amp;#34;port&amp;#34;: 12221}}&amp;#39; http://localhost:8500/v1/catalog/register docker-compose restart consul 切换回系统内部过程的foo服务节点操作过程如下：
curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;{&amp;#34;Node&amp;#34;: &amp;#34;foo&amp;#34;}&amp;#39; http://localhost:8500/v1/catalog/deregister docker-compose up -d foo docker-compose restart consul 注销foo服务节点操作过程如下：
curl -X PUT -H &amp;#39;application/json&amp;#39; -d &amp;#39;{&amp;#34;Node&amp;#34;: &amp;#34;foo&amp;#34;}&amp;#39; http://localhost:8500/v1/catalog/deregister docker-compose stop foo docker-compose rm foo docker-compose restart consul 参考 Consul Guide：Registering An External Service</description></item><item><title>[Hive] Hive JDBC实践</title><link>https://mryqu.github.io/post/hive_hive_jdbc%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 30 Jul 2015 05:35:26 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive_jdbc%E5%AE%9E%E8%B7%B5/</guid><description>HiveJdbcClient.java 使用参考一中的示例代码:
import java.sql.SQLException; import java.sql.Connection; import java.sql.ResultSet; import java.sql.Statement; import java.sql.DriverManager; public class HiveJdbcClient { private static String driverName = &amp;#34;org.apache.hive.jdbc.HiveDriver&amp;#34;; public static void main(String[] args) throws SQLException { try { Class.forName(driverName); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); System.exit(1); } //&amp;#34;hadoop&amp;#34; is the name of the user the queries should run as in my cluster. Connection con = DriverManager.getConnection( &amp;#34;jdbc:hive2://localhost:10000/default&amp;#34;, &amp;#34;hadoop&amp;#34;, &amp;#34;{PASSWORD_OF_USER_HADOOP}&amp;#34;); Statement stmt = con.</description></item><item><title>[Hive] HCatalog和WebHCat学习</title><link>https://mryqu.github.io/post/hive_hcatalog%E5%92%8Cwebhcat%E5%AD%A6%E4%B9%A0/</link><pubDate>Wed, 29 Jul 2015 05:39:31 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hcatalog%E5%92%8Cwebhcat%E5%AD%A6%E4%B9%A0/</guid><description>HCatalog 访问数据的常见方法之一是通过表抽象，该方法通常用于访问关系型数据库，并且为许多开发者所熟知(和广泛采用)。一些流行的Hadoop系统，例如Hive和Pig，也采用了这种方法。这种抽象解除了数据如何存储(HDFS文件、HBase表)与应用程序如何处理数据(表格式)之间的耦合。此外，它允许从较大的数据语料库中&amp;quot;过滤&amp;quot;感兴趣的数据。 Hadoop的元数据服务HCatalog扩展了Hive的元存储，同时保留了HiveDDL中用于表定义的组件。其结果是，Hive的表抽象(当使用了HCatalog时)可以用于Pig和MapReduce应用程序，这带来了以下一些主要优势：
它使得数据消费者不必知道其数据存储的位置和方式。 它允许数据生产者修改物理数据存储和数据模型，同时仍然支持以旧格式存储的现有数据，从而数据消费者不需要修改他们的处理流程。 它为Pig、Hive和MapReduce提供了共享的结构和数据模型。 HCatalog支持读写任何SerDe支持的文件格式。默认情况下，HCatalog支持RCFile、CSV、JSON、SequenceFile和ORC文件格式。如果使用订制格式，必须提供InputFormat、OutputFormat和SerDe。 WebHCat WebHCat是WebHCat的REST API。这样应用无需使用Hadoop API就可以通过HTTP请求访问HadoopMapReduce (或YARN)、Pig、Hive及HCatalog DDL。WebHCat所使用的代码和数据必须存放在HDFS中。HCatalogDDL命令在请求后即直接执行，MapReduce、Pig和Hive作业则放置在WebHCat(Templeton)服务器的队列中，并监控进展过程或按需停止。程序员指定Pig、Hive和MapReduce结果存放的HDFS位置。 使用 HCatalog和WebHCat都已随Hive安装，所以可以直接使用
使用HCatalog HCatalog CLI与Hive CLI功能大致一样：
cd $HIVE_HOME ./hcatalog/bin/hcat 使用WebHCat 在.bashrc中添加PYTHON_CMD：
export PYTHON_CMD=/usr/bin/python 启动WebHCat服务器：
cd $HIVE_HOME ./hcatalog/sbin/webhcat_server.sh start 参考 HCatalog
HCatalog CLI
WebHCat
GitHub: apache/hcatalog
GitHub: apache/hive/hcatalog
apache/hive/hcatalog/webhcat</description></item><item><title>[Hive] Hive CLI和Beeline学习</title><link>https://mryqu.github.io/post/hive_hive_cli%E5%92%8Cbeeline%E5%AD%A6%E4%B9%A0/</link><pubDate>Tue, 28 Jul 2015 05:59:51 +0000</pubDate><guid>https://mryqu.github.io/post/hive_hive_cli%E5%92%8Cbeeline%E5%AD%A6%E4%B9%A0/</guid><description>Hive CLI学习 Hive CLI使用手册很简单，但是看完了对有些参数还是不太理解，所以就翻翻Hive CLI源码对照学习吧。
-f和-i选项的区别 Hive CLI使用手册说-i指定的是初始化SQL文件，-f指定的是SQL脚本文件。 通过阅读源码可知，所谓的初始化SQL文件就是你期望每次执行HiveCLI都要在其他操作之前运行的一些SQL命令。执行完初始化SQL，可以接着执行-e选项中的SQL命令、-f选项中的SQL脚本文件或交互输入的命令；而-f选项和-e选项二者只能存在其一，执行完-f选项后退出CLI。
hiverc文件 当没有指定-i参数时，CLI会尝试加载$HIVE_HOME/bin/.hiverc、$HIVE_CONF_DIR/.hiverc和$HOME/.hiverc作为初始化文件。只要存在，这些.hiverc都会被加载执行。 通过CliDriver类的processInitFiles方法可知，执行初始化SQL时始终采用静默模式，即不显示执行进度信息，只显示最后结果；执行-f选项中SQL脚本时是否采用静默模式由-S选项控制。
Hive CLI如何处理shell命令、Hive命令和SQL的？ HiveCLI既可以处理一个SQL脚本文件、也可以处理多个SQL命令。它通过处理多行命令，以&amp;quot;;&amp;ldquo;为分隔符，获取单个命令列表。一个单个命令，即可能是&amp;ndash;开头的注释行，也可能是!开头的shell命令，此外SQL命令和Hive自身支持的命令。
对于shell命令，Hive CLI是通过ShellCmdExecutor执行的； 对于SQL命令，Hive CLI是通过org.apache.hadoop.hive.ql.Driver执行的； 对于Hive命令，HiveCLI通过SetProcessor、ResetProcessor、DfsProcessor、AddResourceProcessor、ListResourceProcessor、DeleteResourceProcessor、CompileProcessor、ReloadProcessor、CryptoProcessor这些处理进行执行。 &amp;ndash;hiveconf、&amp;ndash;define (-d)、&amp;ndash;hivevar之间的关系 首先我们看一下OptionsProcessor类，它通过Apache Commons CLI解析Hive CLI命令参数:
其process_stage1方法将&amp;ndash;hiveconf参数置入系统属性中，将&amp;ndash;define和&amp;ndash;hivevar参数置入CliSessionState对象的hiveVariables字段 其process_stage2方法将&amp;ndash;hiveconf参数置入CliSessionState对象的cmdProperties字段 接下来看一下CliSessionState对象的hiveVariables字段和cmdProperties字段使用情况:
CliDriver.run方法将CliSessionState对象的cmdProperties字段中的键值对覆盖HiveConf对象，然后置入CliSessionState对象的overriddenConfigurations字段 CliSessionState对象的hiveVariables字段主要用于变量替换，包括替换提示符（CliDriver.run）、替换source命令所跟文件路径及shell命令（CliDriver.processCmd）、替换SQL（Driver.compile）、替换Hive命令（DfsProcessor.run、&amp;hellip;&amp;hellip;） 总之：
&amp;ndash;hiveconf参数在命令行中设置Hive的运行时配置参数，优先级高于hive-site.xml,但低于Hive交互Shell中使用Set命令设置。 &amp;ndash;define (-d)和&amp;ndash;hivevar没有区别，都是用于变量替换的。 hivehistory文件 Hive CLI会创建$HOME/.hivehistory文件，并在其中记录命令历史记录。
-v参数打印出的SQL语句是变量替换后的吗？ 不是，打印的是原始SQL语句。 看了Hive CLI源码后的疑惑 CliDriver类主函数实例化一个CliDriver对象，而在executeDriver方法中不用自身实例，偏偏又实例化一个CliDriver对象cli来，为啥？ &amp;ndash;hiveconf参数会被放入CliSessionState对象的cmdProperties字段和overriddenConfigurations字段，难道不能合并成一份么？ Hive Beeline学习 BeeLine类的dispatch负责将特定命令行分发给适合的CommandHandler。
其中以!起始的SQLLine命令由execCommandWithPrefix方法处理，具体实现见Commands类的同名方法。 其他命令则由Commands类的sql方法处理 参考 Hive LanguageManual CLI
Hive LanguageManual VariableSubstitution
Hive CLI source code
Beeline – Command Line Shell
Hive Beeline CLI source code</description></item><item><title>[Gradle] 列举插件</title><link>https://mryqu.github.io/post/gradle_%E5%88%97%E4%B8%BE%E6%8F%92%E4%BB%B6/</link><pubDate>Mon, 27 Jul 2015 06:17:30 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%88%97%E4%B8%BE%E6%8F%92%E4%BB%B6/</guid><description>下列方法可以列举出当前build.gradle牵涉的插件:
project.plugins.each { println it }</description></item><item><title>[Ambari] 了解Ambari</title><link>https://mryqu.github.io/post/ambari_%E4%BA%86%E8%A7%A3ambari/</link><pubDate>Sun, 26 Jul 2015 07:35:28 +0000</pubDate><guid>https://mryqu.github.io/post/ambari_%E4%BA%86%E8%A7%A3ambari/</guid><description>今天看到一篇帖子《Ambari——大数据平台的搭建利器》介绍了Apache Ambari的使用。感觉Ambari确实不错，很便捷地支持Apache Hadoop集群的配置、管理和监控，堪称利器！
Ambari对系统管理员提供如下功能：
配置Hadoop集群 Ambari提供逐步的的安装向导在任意多台机器上安装Hadoop集群。 Ambari处理集群中Hadoop服务的配置。 管理Hadoop集群 Ambari提供对整个集群范围内启动、停止和重新配置Hadoop服务的集中管理。 监控Hadoop集群 Ambari提供仪表盘用于监控Hadoop集群（HDFS、MapReduce、HBase、Hive和HCatalog）的健康和状态。 Ambari通过Ambari 运维指标系统收集指标。 Ambari提供用于系统告警的Ambari告警框架，可在需要时（例如节点宕机、剩余磁盘空间不足等）通知你。 Ambari对应用开发者和系统集成者提供如下功能：
通过Ambari REST APIs轻松将Hadoop配置、管理和监控功能与自己的应用集成。 Ambari当前可在一些64位Linux系统上安装。
另，Ambari中文为洋麻。</description></item><item><title>[Hive] 遇到Relative path in absolute URI:${system:java.io.tmpdir}/${system:user.name}</title><link>https://mryqu.github.io/post/hive_%E9%81%87%E5%88%B0relative_path_in_absolute_uri%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 25 Jul 2015 07:33:55 +0000</pubDate><guid>https://mryqu.github.io/post/hive_%E9%81%87%E5%88%B0relative_path_in_absolute_uri%E9%97%AE%E9%A2%98/</guid><description>安装问Hive，启动一下CLI试一下效果。结果直接崩了，错误提示：Relative path in absolute URI:${system:java.io.tmpdir}/${system:user.name}。 Hive AdminManual Configuration里面的例子是将hive.exec.scratchdir设定为/tmp/mydir。即使按照示例来配置，还是会报hive.downloaded.resources.dir属性错误。后来看到网上有人说主要是Hadoop路径不支持带&amp;quot;:&amp;quot;，所以会报错。
解决方法：
hive.exec.local.scratchdir: /tmp/${user.name} hive.downloaded.resources.dir: /tmp/${user.name}_resources 可以登入Hive Shell了！</description></item><item><title>[Hive] 安装Hive 1.2.x</title><link>https://mryqu.github.io/post/hive_%E5%AE%89%E8%A3%85hive_1.2.x/</link><pubDate>Fri, 24 Jul 2015 05:37:23 +0000</pubDate><guid>https://mryqu.github.io/post/hive_%E5%AE%89%E8%A3%85hive_1.2.x/</guid><description>我的Hadoop集群为node50064、node50069和node51054。本文的Hive和MySQL软件仅在node50064上安装。
安装Hive-内嵌元数据存储模式 Hive驱动、元数据存储接口和数据库(derby)使用相同的JVM。元数据保持在内嵌的derby数据库，只允许一个会话连接到数据库。 下载并解压缩Hive wget http://apache.cs.utah.edu/hive/hive-1.2.x/apache-hive-1.2.x-bin.tar.gz tar -xzf apache-hive-1.2.x-bin.tar.gz sudo mv apache-hive-1.2.x-bin /usr/local/hive sudo chown -R &amp;#34;hadoop:hadoop&amp;#34; /usr/local/hive 环境变量设置 export HADOOP_HOME=/usr/local/hadoop export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_PREFIX/lib/native export HADOOP_OPTS=&amp;#34;$HADOOP_OPTS -Djava.library.path=$HADOOP_PREFIX/lib/native&amp;#34; export HIVE_HOME=/usr/local/hive export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin:$HIVE_HOME/bin 最后通过source~/.bashrc刷新配置文件。
conf/hive-env.sh 首先通过cd $HIVE_HOME/conf;cp hive-env.sh.template hive-env.sh;chmod 774hive-env.sh创建并设置hive-env.sh执行权限。 修改后的主要部分内容如下：
# Set HADOOP_HOME to point to a specific hadoop install directory export HADOOP_HOME=${HADOOP_HOME:-/usr/local/hadoop} # Hive Configuration Directory can be controlled by: export HIVE_CONF_DIR=/usr/local/hive/conf # Folder containing extra ibraries required for hive compilation/execution can be controlled by: export HIVE_AUX_JARS_PATH=/usr/local/hive/lib conf/hive-site.</description></item><item><title>选择候选样式表</title><link>https://mryqu.github.io/post/%E9%80%89%E6%8B%A9%E5%80%99%E9%80%89%E6%A0%B7%E5%BC%8F%E8%A1%A8/</link><pubDate>Thu, 23 Jul 2015 06:19:30 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%80%89%E6%8B%A9%E5%80%99%E9%80%89%E6%A0%B7%E5%BC%8F%E8%A1%A8/</guid><description>有的浏览器提供选择如下的候选层叠样式表。
IE Firefox Firefox可以通过F10调出菜单。
Chrome 不支持。</description></item><item><title>[Pig] 安装Pig 0.15.0</title><link>https://mryqu.github.io/post/pig_%E5%AE%89%E8%A3%85pig_0.15.0/</link><pubDate>Mon, 20 Jul 2015 06:35:42 +0000</pubDate><guid>https://mryqu.github.io/post/pig_%E5%AE%89%E8%A3%85pig_0.15.0/</guid><description>安装Pig 我的Hadoop集群为node50064、node50069和node51054。本文的Pig软件仅在node50064上安装。
下载并解压缩Pig wget http://apache.cs.utah.edu/pig/pig-0.15.0/pig-0.15.0.tar.gz tar -xzf pig-0.15.0.tar.gz sudo mv pig-0.15.0 /usr/local/pig sudo chown -R &amp;#34;hadoop:hadoop&amp;#34; /usr/local/pig 环境变量设置 export HADOOP_HOME=/usr/local/hadoop export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_PREFIX/lib/native export HADOOP_OPTS=&amp;#34;$HADOOP_OPTS -Djava.library.path=$HADOOP_PREFIX/lib/native&amp;#34; export PIG_HOME=/usr/local/pig export PIG_CLASSPATH=$HADOOP_HOME/conf export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin:$PIG_HOME/bin 最后通过source~/.bashrc刷新配置文件。
conf/pig.properties pig.properties用于配置Pig各种参数。参数说明如下： 运行Pig控制台 参考 你用pig分析access_log日志中ip访问次数</description></item><item><title>为Artifactory设置proxy和remote repository</title><link>https://mryqu.github.io/post/%E4%B8%BAartifactory%E8%AE%BE%E7%BD%AEproxy%E5%92%8Cremote_repository/</link><pubDate>Sun, 19 Jul 2015 00:09:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%BAartifactory%E8%AE%BE%E7%BD%AEproxy%E5%92%8Cremote_repository/</guid><description>设置proxy 我一上来先设置代理，否则连不上远程仓库呀。 设置remote repository 远程仓库已经默认设置了jcenter，估计很少需要其他仓库了。 但不管三七二十一，还是把mavenCentral和gradlePlugins加上吧。全部勾选了Suppress POMConsistency Checks，取消勾选Handle Snapshots。
mavenCentral: http://repo1.maven.org/maven2/ gradlePlugins: https://plugins.gradle.org/m2/ 测试结果显示，所需构件实际上都是从jcenter下载的，其他两个暂时还没用到。</description></item><item><title>整理贴：八卦一下CoreOS</title><link>https://mryqu.github.io/post/%E6%95%B4%E7%90%86%E8%B4%B4%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bcoreos/</link><pubDate>Fri, 17 Jul 2015 06:10:11 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B4%E7%90%86%E8%B4%B4%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bcoreos/</guid><description>CoreOS是一个轻量级容器化Linux发行版，专为大型数据中心而设计，旨在通过轻量的系统架构和灵活的应用程序部署能力简化数据中心的维护成本和复杂度。
CoreOS的历史 2013年2月，美国的dotCloud公司发布了一款新型的Linux容器软件Docker，并建立了一个网站发布它的首个演示版本（见Docker第一篇官方博客）。而几乎同时，2013年3月，美国加州，年轻的帅小伙Alex Polvi正在自己的车库开始他的第二次创业。此前，他的首个创业公司Cloudkick卖给了云计算巨头Rackspcace（就是OpenStack的东家）。 有了第一桶金的Alex这次准备干一票大的，他计划开发一个足以颠覆传统的服务器系统的Linux发行版。为了提供能够从任意操作系统版本稳定无缝地升级到最新版系统的能力，Alex急需解决应用程序与操作系统之间的耦合问题。因此，当时还名不见经传的Docker容器引起了他的注意，凭着敏锐直觉，Alex预见了这个项目的价值，当仁不让地将Docker做为了这个系统支持的第一套应用程序隔离方案。不久以后，他们成立了以自己的系统发行版命名的组织：CoreOS。事实证明，采用Docker这个决定，后来很大程度上成就了CoreOS的生态系统。 CoreOS特点 首先，CoreOS没有提供包管理工具，而是通过容器化的运算环境向应用程序提供运算资源。应用程序之间共享系统内核和资源，但是彼此之间又互不可见。这样就意味着应用程序将不会再被直接安装到操作系统中，而是通过Docker 运行在容器中。这种方式使得操作系统、应用程序及运行环境之间的耦合度大大降低。相对于传统的部署方式而言，在 CoreOS集群中部署应用程序更加灵活便捷，应用程序运行环境之间的干扰更少，而且操作系统自身的维护也更加容易。 其次， CoreOS 采用双系统分区 (dual root partition)设计。两个分区分别被设置成主动模式和被动模式并在系统运行期间各司其职。主动分区负责系统运行，被动分区负责系统升级。一旦新版本的操作系统被发布，一个完整的系统文件将被下载至被动分区，并在系统下一次重启时从新版本分区启动，原来的被动分区将切换为主动分区，而之前的主动分区则被切换为被动分区，两个分区扮演的角色将相互对调。同时在系统运行期间系统分区被设置成只读状态，这样也确保了CoreOS 的安全性。CoreOS 的升级过程在默认条件下将自动完成，并且通过 cgroup对升级过程中使用到的网络和磁盘资源进行限制，将系统升级所带来的影响降至最低。 另外，CoreOS 使用 Systemd 取代 SysV 作为系统和服务的管理工具。与 SysV 相比，Systemd不但可以更好的追踪系统进程，而且也具备优秀的并行化处理能力，加之按需启动等特点，并结合 Docker 的快速启动能力，在 CoreOS集群中大规模部署 Docker容器与使用其他操作系统相比在性能上的优势将更加明显。Systemd 的另一个特点是引入了“target” 的概念，每个 target 应用于一个特定的服务，并且可以通过继承一个已有的 target扩展额外的功能，这样使得操作系统对系统上运行的服务拥有更好的控制力。 通过对系统结构的重新设计，CoreOS剔除了任何不必要的软件和服务。在一定程度上减轻了维护一个服务器集群的复杂度，帮助用户从繁琐的系统及软件维护工作中解脱出来。虽然CoreOS最初源自于Google ChromeOS，但是从一开始就决定了 CoreOS更加适合应用于一个集群环境而不是一个传统的服务器操作系统。 CoreOS相关工具 除了操作系统之外，CoreOS 团队和其他团队还提供了若干工具帮助用户管理 CoreOS 集群以及部署Docker容器。
etcd 在CoreOS 集群中处于骨架地位的是 etcd。 etcd 是一个分布式 key/value存储服务，CoreOS 集群中的程序和服务可以通过 etcd 共享信息或做服务发现 。etcd 基于非常著名的 raft一致性算法：通过选举形式在服务器之中选举 Lead 来同步数据，并以此确保集群之内信息始终一致和可用。etcd 以默认的形式安装于每个CoreOS 系统之中。在默认的配置下，etcd使用系统中的两个端口：4001和7001，其中4001提供给外部应用程序以HTTP+Json的形式读写数据，而7001则用作在每个etcd 之间进行数据同步。用户更可以通过配置 CA Cert让 etcd 以 HTTPS的方式读写及同步数据，进一步确保数据信息的安全性。
fleet fleet 是一个通过Systemd对CoreOS 集群中进行控制和管理的工具。fleet 与 Systemd 之间通过 D-Bus API 进行交互，每个fleet agent 之间通过 etcd 服务来注册和同步数据。fleet提供的功能非常丰富，包括查看集群中服务器的状态、启动或终止 Docker容器、读取日志内容等。更为重要的是 fleet可以确保集群中的服务一直处于可用状态。当出现某个通过 fleet创建的服务在集群中不可用时，如由于某台主机因为硬件或网络故障从集群中脱离时，原本运行在这台服务器中的一系列服务将通过fleet被重新分配到其他可用服务器中。虽然当前 fleet 还处于非常早期的状态，但是其管理 CoreOS集群的能力是非常有效的，并且仍然有很大的扩展空间，目前已提供简单的 API 接口供用户集成。</description></item><item><title>阅读《微服务资源指南》</title><link>https://mryqu.github.io/post/%E9%98%85%E8%AF%BB%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90%E6%8C%87%E5%8D%97/</link><pubDate>Wed, 15 Jul 2015 05:42:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%98%85%E8%AF%BB%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%B5%84%E6%BA%90%E6%8C%87%E5%8D%97/</guid><description>Martin Fowler近日发布了《Microservices Resource Guide》，介绍的是Martin自己和别人的书/文章汇集，一开头回顾了微服务的特征，接着谈到了对微服务和单块架构的权衡，最后大篇幅列举了很多公司开发微服务的经验教训。
微服务特征 通过服务进行组件化 围绕业务能力进行组织服务 团队为产品而不是项目工作 智能端点和哑管道：取其Unix思想，REST协议或消息总线仅仅是管道，服务才是智能的 去中心化治理 去中心化数据管理 基础设施自动化 故障设计：服务故障检测、自恢复 演进式设计 微服务与单块架构之间的权衡 微服务带来收益… 强模块边界: 微服务增强模块结构，这对大的团队尤为重要。 独立的部署: 简单服务更易于部署，由于它们都是自治的，服务出现问题不容易导致系统故障。 技术多样性: 使用微服务可以混合多种编程语言、开发框架和数据存储技术。 …也伴随着代价 分布: 由于远程调用慢并一直具有故障风险。很难开发分布式系统代码。 最终一致性: 对于分布式系统维护强一致性非常困难，这意味着必须管理最终一致性。 运维复杂: 需要一个成熟的运维团队来管理很多经常需要重新部署的服务。 微服务与单块架构的生产率 经验教训（略） 先看完《Build Microservices》，然后再读一遍所有列举资料，再单开新的博客帖子介绍吧。</description></item><item><title>Gradle Docker Plugin介绍</title><link>https://mryqu.github.io/post/gradle_docker_plugin%E4%BB%8B%E7%BB%8D/</link><pubDate>Tue, 14 Jul 2015 05:57:33 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_docker_plugin%E4%BB%8B%E7%BB%8D/</guid><description>gradle-docker-plugin gradle-docker-plugin是由《Gradle实战》作者BenjaminMuschko实现的Gradle插件，用来管理Docker镜像和容器。gradle-docker-plugin实际上包括两个插件：
com.bmuschko.docker-remote-api:提供通过远程API与Docker进行交互的定制任务 com.bmuschko.docker-java-application:为Java应用创建和上传Docker镜像 build.gradle buildscript { repositories { jcenter() } dependencies { classpath &amp;#39;com.bmuschko:gradle-docker-plugin:2.4.1&amp;#39; } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;application&amp;#39; apply plugin: &amp;#39;com.bmuschko.docker-java-application&amp;#39; apply plugin: &amp;#39;com.bmuschko.docker-remote-api&amp;#39; 参考 GitHub：bmuschko/gradle-docker-plugin</description></item><item><title>执行Gradle artifactoryPublish任务时碰到HTTP 409 Conflict错误</title><link>https://mryqu.github.io/post/%E6%89%A7%E8%A1%8Cgradle_artifactorypublish%E4%BB%BB%E5%8A%A1%E6%97%B6%E7%A2%B0%E5%88%B0http_409_conflict%E9%94%99%E8%AF%AF/</link><pubDate>Mon, 13 Jul 2015 06:10:00 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%89%A7%E8%A1%8Cgradle_artifactorypublish%E4%BB%BB%E5%8A%A1%E6%97%B6%E7%A2%B0%E5%88%B0http_409_conflict%E9%94%99%E8%AF%AF/</guid><description>这篇博文算是《尝试Artifactory》的姐妹篇。我打算将《尝试Artifactory》中的&amp;rsquo;libs-snapshot-local&amp;rsquo;和&amp;rsquo;libs-snapshot&amp;rsquo;换成&amp;rsquo;libs-release-local&amp;rsquo;和&amp;rsquo;libs-release&amp;rsquo;，以便将我的构件发布到发布版仓库里。结果遭遇如下错误：
C:\test123\HelloArtifactory&amp;gt;gradlew artifactoryPublish [buildinfo] Not using buildInfo properties file for this build. :generatePomFileForMavenJavaPublication :compileJava 查看Artifactory日志，才知道根本原因在于创建的是SNAPSHOT而libs-release-local只处理发布版构建。The repository &amp;rsquo;libs-release-local&amp;rsquo; rejected the artifact&amp;rsquo;libs-release-local:com/yqu/HelloArtifactory/0.1.0-SNAPSHOT/HelloArtifactory-0.1.0-SNAPSHOT.jar&amp;rsquo;due to its snapshot/release handling policy。 解决方案有如下两种：
修改libs-release-local属性，勾选Handle Snapshots选择框（工作流不正规啦） 将gradle.properties中的version由0.1.0-SNAPSHOT改成0.1.0即可</description></item><item><title>Gradle Git Plugin介绍</title><link>https://mryqu.github.io/post/gradle_git_plugin%E4%BB%8B%E7%BB%8D/</link><pubDate>Sun, 12 Jul 2015 21:15:17 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_git_plugin%E4%BB%8B%E7%BB%8D/</guid><description>Grgit和gradle-git Git是一个很流行的分布式版本管理工具。能在构建过程中与Git进行交互，可以提供更强大和更一致的结果。
JGit提供了与Git仓库交互的强大JavaAPI。然而，在Groovy上下本使用它会笨重，需要在所要执行的表达式包一堆换七八糟的东东。Grgit是Andre wOberstar实现的JGit封装器，为基于Groovy的工具与Git仓库交互提供了更简洁流畅的API。 gradle-git同样是由Andrew Oberstar实现的一系列Gradle插件：
org.ajoberstar.grgit - 提供一个Grgit实例，允许与Gradle项目所在的Git仓库交互 org.ajoberstar.github-pages - 向Github仓库的gh-pages分支发布文件 org.ajoberstar.release-base -提供用于从项目状态和所在Git仓库推断当前项目版本和创建新版本的通用结构 org.ajoberstar.release-opinion -用于org.ajoberstar.release-base的默认选项，遵从语义版本控制（Semantic Versioning）下面是一个Gradle任务示例，用于从Git仓库克隆项目。 build.gradle buildscript { repositories { mavenCentral() } dependencies { classpath &amp;#39;org.ajoberstar:gradle-git:1.2.0&amp;#39; } } import org.ajoberstar.gradle.git.tasks.* task cloneGitRepo(type: GitClone) { def destination = file(&amp;#34;destination_folder&amp;#34;) uri = &amp;#34;your_git_repo_uri&amp;#34; destinationPath = destination bare = false enabled = !destination.exists() //to clone only once } 参考 GitHub：ajoberstar/gradle-git
GitHub：ajoberstar/grgit</description></item><item><title>[Spring Boot] 监控和管理Spring Boot应用</title><link>https://mryqu.github.io/post/spring_boot_%E7%9B%91%E6%8E%A7%E5%92%8C%E7%AE%A1%E7%90%86spring_boot%E5%BA%94%E7%94%A8/</link><pubDate>Sat, 11 Jul 2015 06:53:41 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_%E7%9B%91%E6%8E%A7%E5%92%8C%E7%AE%A1%E7%90%86spring_boot%E5%BA%94%E7%94%A8/</guid><description>本博文在[Spring Boot] Hello Spring LDAP 基础上稍作修改，尝试一下监控和管理Spring Boot应用。
application.properties改动 server.context-path=/HelloSpringLdapOdm server.port=8080 spring.profiles.active=test,dev # spring.dao.exceptiontranslation.enabled=false yqu.ldap.url=ldap://127.0.0.1:18880 yqu.ldap.userDN=uid=admin,ou=system yqu.ldap.password=secret yqu.ldap.base=dc=jayway,dc=se yqu.ldap.clean=true management.port=8081 management.address=127.0.0.1 endpoints.shutdown.enabled=true applicationDefaultJvmArgs: [ &amp;#34;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=55558&amp;#34; ] 测试 autoconfig: Displays an auto-configuration report showing allauto-configuration candidates and the reason why they ‘were’ or‘were not’ applied. beans: Displays a complete list of all the Spring beans in yourapplication. configprops: Displays a collated list of all@ConfigurationProperties. dump: Performs a thread dump. env: Exposes properties from Spring’sConfigurableEnvironment.</description></item><item><title>如何链接并执行GitHub上的JavaScript文件</title><link>https://mryqu.github.io/post/%E5%A6%82%E4%BD%95%E9%93%BE%E6%8E%A5%E5%B9%B6%E6%89%A7%E8%A1%8Cgithub%E4%B8%8A%E7%9A%84javascript%E6%96%87%E4%BB%B6/</link><pubDate>Fri, 10 Jul 2015 00:28:30 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A6%82%E4%BD%95%E9%93%BE%E6%8E%A5%E5%B9%B6%E6%89%A7%E8%A1%8Cgithub%E4%B8%8A%E7%9A%84javascript%E6%96%87%E4%BB%B6/</guid><description>想要玩一下jquery-mockjax，其原始文件为https://raw.githubusercontent.com/jakerella/jquery-mockjax/master/dist/jquery.mockjax.js ，加入我的html文件进行测试。结果却遇到下列问题：
Refused to execute script from ... because its MIME type (text/plain) is not executable, and strict MIME type checking is enabled. 查到了StackOverflow上的一个帖子Link and execute external JavaScript file hosted on GitHub ，原来GitHub开始使用X-Content-Type-Options:nosniff以令更多的现代浏览器执行严格MIME类型检查，之后返回原始文件的MIME类型故意让浏览器不能使用。帖子中提到的临时解决方法是将raw.githubusercontent.com替换为rawgit.com。我将上一链接替换成https://rawgit.com/jakerella/jquery-mockjax/master/dist/jquery.mockjax.js ，解决问题！</description></item><item><title>[Spring Boot] Hello CommandLineRunner</title><link>https://mryqu.github.io/post/spring_boot_hello_commandlinerunner/</link><pubDate>Wed, 08 Jul 2015 06:02:53 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_hello_commandlinerunner/</guid><description>通过CommandLineRunner，可在所有Spring Bean和ApplicationContext被创建后执行一些可以访问命令行参数的任务。如想指定多个CommandLineRunnerBean的执行顺序，可以实现org.springframework.core.Ordered接口或添加org.springframework.core.annotation.Order注解。
示例代码 Application.java package com.yqu.cmdlinerunner; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.boot.Banner; import org.springframework.boot.CommandLineRunner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.DependsOn; import org.springframework.core.annotation.Order; import org.springframework.core.annotation.OrderUtils; import java.util.Arrays; @SpringBootApplication public class Application { private static final Logger log = LoggerFactory.getLogger(Application.class); public static void main(String[] args) { SpringApplication app = new SpringApplication(Application.class); app.setWebEnvironment(false); app.setShowBanner(false); app.run(args); } @Bean(name=&amp;#34;demo1&amp;#34;) @DependsOn(&amp;#34;demo2&amp;#34;) @Order(8) public CommandLineRunner demo1() { return (args) -&amp;gt; { log.info(&amp;#34;demo1:order=&amp;#34;+ OrderUtils.getOrder(this.getClass())+ &amp;#34;:args=&amp;#34;+Arrays.toString(args)); //log.info(getStacks()); }; } @Bean(name=&amp;#34;demo2&amp;#34;) @Order(1) public CommandLineRunner demo2() { return (args) -&amp;gt; { log.</description></item><item><title>[Spring Boot] Hello Spring LDAP</title><link>https://mryqu.github.io/post/spring_boot_hello_spring_ldap/</link><pubDate>Mon, 06 Jul 2015 06:20:32 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_hello_spring_ldap/</guid><description>这个帖子设定了标题后，一直忙于其他事情，拖延了两个月终于能够结贴了。
部分示例代码 LdapConfiugration.java package com.yqu.ldap.odm; import com.yqu.ldap.odm.dao.*; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.*; import org.springframework.core.env.Environment; import org.springframework.ldap.core.LdapTemplate; import org.springframework.ldap.core.support.LdapContextSource; import javax.annotation.PostConstruct; @Configuration @ComponentScan(basePackages={&amp;#34;com.yqu.ldap.odm&amp;#34;}) public class LdapConfiugration { @Autowired private Environment _environment; private static Log log = LogFactory.getLog(LdapConfiugration.class); @PostConstruct private void init() { log.debug(&amp;#34;environment: yqu.ldap.url:&amp;#34; + _environment.getProperty(&amp;#34;yqu.ldap.url&amp;#34;)); log.debug(&amp;#34;environment: yqu.ldap.userDN:&amp;#34; + _environment.getProperty(&amp;#34;yqu.ldap.userDN&amp;#34;)); log.debug(&amp;#34;environment: yqu.ldap.password:&amp;#34; + _environment.getProperty(&amp;#34;yqu.ldap.password&amp;#34;)); log.debug(&amp;#34;environment: yqu.ldap.base:&amp;#34; + _environment.getProperty(&amp;#34;yqu.ldap.base&amp;#34;)); } @Bean(name=&amp;#34;ldapContextSource&amp;#34;) public LdapContextSource ldapContextSource() { String url = _environment.getProperty(&amp;#34;yqu.ldap.url&amp;#34;); String user = _environment.</description></item><item><title>apt-get在基于Ubuntu基础镜像Dockerfile中的常见用法</title><link>https://mryqu.github.io/post/apt-get%E5%9C%A8%E5%9F%BA%E4%BA%8Eubuntu%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8Fdockerfile%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/</link><pubDate>Sun, 05 Jul 2015 21:32:25 +0000</pubDate><guid>https://mryqu.github.io/post/apt-get%E5%9C%A8%E5%9F%BA%E4%BA%8Eubuntu%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8Fdockerfile%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/</guid><description>首先，在Ubuntu的Docker官方镜像中是没有缓存Apt的软件包列表的。因此在做其他任何基础软件的安装前，都需要至少先做一次apt-get update。 有时为了加快apt-get安装软件的速度，还需要修改Apt源的列表文件/etc/apt/sources.list。相应的操作用命令表示如下：
# 使用Ubuntu官方的Apt源，也可以根据实际需要修改为国内源的地址 echo &amp;#34;deb http://archive.ubuntu.com/ubuntu trusty main universe\n&amp;#34; &amp;gt; /etc/apt/sources.list echo &amp;#34;deb http://archive.ubuntu.com/ubuntu trusty-updates main universe\n&amp;#34; &amp;gt;&amp;gt; /etc/apt/sources.list 在容器构建时，为了避免使用apt-get install安装基础软件的过程中需要进行的交互操作，使用-y参数来避免安装非必须的文件，从而减小镜像的体积。
apt-get -y --no-install-recommends install 使用apt-get autoremove命令移除为了满足包依赖而安装的、但不再需要的包；使用apt-get clean命令清除所获得包文件的本地仓库。 DEBIAN_FRONTEND这个环境变量，告知操作系统应该从哪儿获得用户输入。如果设置为&amp;quot;noninteractive&amp;quot;，你就可以直接运行命令，而无需向用户请求输入（所有操作都是非交互式的）。这在运行apt-get命令的时候格外有用，因为它会不停的提示用户进行到了哪步并且需要不断确认。非交互模式会选择默认的选项并以最快的速度完成构建。请确保只在Dockerfile中调用的RUN命令中设置了该选项，而不是使用ENV命令进行全局的设置。因为ENV命令在整个容器运行过程中都会生效，所以当你通过BASH和容器进行交互时，如果进行了全局设置那就会出问题。
# 正确的做法 - 只为这个命令设置ENV变量 RUN DEBIAN_FRONTEND=noninteractive apt-get install -y python3 # 错误地做法 - 为接下来的任何命令都设置ENV变量，包括正在运行地容器 ENV DEBIAN_FRONTEND noninteractive RUN apt-get install -y python3 我的示例如下：
FROM ubuntu:trusty MAINTAINER mryqu RUN \ DEBIAN_FRONTEND=noninteractive apt-get update &amp;amp;&amp;amp; \ DEBIAN_FRONTEND=noninteractive apt-get -y install wget curl &amp;amp;&amp;amp; \ DEBIAN_FRONTEND=noninteractive apt-get -y autoremove &amp;amp;&amp;amp; \ DEBIAN_FRONTEND=noninteractive apt-get clean 参考 Ubuntu manuals: apt-get man page</description></item><item><title>Docker的镜像存储在哪里和长什么样子</title><link>https://mryqu.github.io/post/docker%E7%9A%84%E9%95%9C%E5%83%8F%E5%AD%98%E5%82%A8%E5%9C%A8%E5%93%AA%E9%87%8C%E5%92%8C%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90/</link><pubDate>Sun, 05 Jul 2015 00:27:30 +0000</pubDate><guid>https://mryqu.github.io/post/docker%E7%9A%84%E9%95%9C%E5%83%8F%E5%AD%98%E5%82%A8%E5%9C%A8%E5%93%AA%E9%87%8C%E5%92%8C%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90/</guid><description>接触docker后，我就有个疑问：我们用docker pull镜像后，该镜像是存储在哪里的？是以一个特俗的二进制类型存储的么？后来阅读了Docker的镜像存储在哪里这篇博文，得以解惑，并进行了验证。 Docker的镜像存储在/var/lib/docker目录下，存储方式有点像Git那样有reference和实际的objects，并且是实际内容是diff那样的增量存放。 Docker的镜像存储在哪里 有个疑问就是我们用docker pull镜像后，该镜像是存储在哪里的？ 当你仅仅是使用docker启动一个实例的时候，是超级简单的，但是当你制作自己的Dockerfile时，可能会有一些迷惑，那就是我的docker镜像存储在哪里了。这个听起来让我感觉有点一筹莫展，对于dockerimage的存储我还是一无所知。最后你只能把镜像发布到公共DockerIndex上面，但是，在过去一段时间内你是无法删除它的，但是现在你可以通过官方的WEB界面来删除它了。
Image VS Dockerfile 这个看起来有点混淆，但是它们是有差别的，docke使用images运行你的代码，而不是Dockerfile。Dockerfile是你用dockerbuild命令来构建image的。如果你在浏览器中浏览DockerIndex，你会发现有很多images显示在上面，但是你不能看见构建它们的Dockerfile。当你使用dockerpush命令发布image时，它不会发布你的源代码，它只会发布从你源代码构建出来的镜像。
Registry VS Index 下一个混淆的是Registry和Index，它们是怎么样区分的？index是管理公共web接口上的accounts、permission、search、tagging和所有精细的方面的。而registry是存储和提供实际image的，它委托index进行身份验证。当你运行dockersearch命令的时候，它搜索的是index，而不是registry。实际上，它可能搜索的是index知道的多个registry。当你运行dockerpush或者dockerpull命令时，index决定你是否有权限访问和修改images，当index同意你操作后，registry是提供images存储的地方，index会计算出哪个registry有你需要的镜像，并把请求转发过去。当你在本地运行dockerimages命令时，你可能是同时和index和registry进行交互。
Repository docker&amp;rsquo;s使用镜像就像使用GitHub一样容易，但是有三个混淆的地方：
repository和registry之间的区别 repository和image之间的区别 repository和index username之间的区别 其实repository并不是其中任何一个组件，而是指所有的组件。当你运行dockerimages命令时，你会看到如下： images列表看起来像repositories列表？实际上images是GUIDs，但这并不是如何和他们交互。当你执行dockerbuild或者dockercommit命令时，你可以指定image的名称，这个名称的格式是username/image_name，但这并不一定，它可以是任何形式的，他甚至可以是你已经知道的发布的镜像名称。当你执行dockerpush的时候，index会查看镜像名称，检查该镜像是否在repository中，如果在，接着检查你是否有权限访问该repository，如果有权限，则允许你push新版本的image到该repository上。因此，一个registry保留了它收集到的repository的名称，它本身跟踪收集到的images的GUIDs。thisis also where tags comein，你可以tag一个image，并且存储多个版本使用不同的GUIDs在同一个repository中，访问不同的标记的版本image，可以使用username/image_name:tag。 从上图中你可以看到我们有三个不同版本的image叫ubuntu12，每个的tag都是不同的，repository使用ubuntu12的名称来保存这些，因此，当我们看到ubuntu12的时候，它像一个image名称，但是实际上它使repository名称，repository名称有特殊的设计架构，index可以从第一部分解析出username，并且找出他在哪里。因此，当出现一个guol/ubuntu时会产生混淆，官方的repository名称是类似username/image_name这样的，我们想当然的认为repository名称是image_name，但是根据docker的文档发现repository的名称有时指的是全部的名称，有时指的是image_name。比如就像ubuntu，它就没有username，是不是有点乱了&amp;hellip;&amp;hellip;&amp;hellip;
Local Storage on the Docker Host 我们已经了解完如何和远程存储进行交互了，但是当你运行dockerimages的时候，仅仅给你看到的是你的机器上有哪些image。这些镜像在哪里呢？第一个要查看的地方是/var/lib/docker/。 查看repositories-aufs文件的内容，它的内容是在你本机上的repositories。 看看，它完全匹配了docker images的输出内容。 现在我们来看看/var/lib/docker/graph/的内容。 我倒，显示的非常不友好啊，看看docker是怎样跟踪这些镜像的，是基于repositories-aufs文件，构建了一个映射到repository名称和tag的关系表。我们看看ubuntu12的仓库，它有三个镜像，标记分别是12.04、precise、latest。采用的是IDd431f556799d35dfae1278a1ee41a393db70058dedb9a7fc554b0506b5b241cb，我们看看这个目录里面有什么。 只有两个文件：
json：保存image的metadata layersize：只是一个数字，表明layer的大小 主要镜像的差异在/var/lib/docker/aufs/diff/目录下，每次都会把镜像改变的部分存储在该目录下的相关ID目录里面。 参考：Where are Docker images stored?</description></item><item><title>断路器（CircuitBreaker）设计模式</title><link>https://mryqu.github.io/post/%E6%96%AD%E8%B7%AF%E5%99%A8circuitbreaker%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link><pubDate>Sat, 04 Jul 2015 06:47:53 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%96%AD%E8%B7%AF%E5%99%A8circuitbreaker%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid><description>断路器是电器时代的一个重要组成部分，后面总是有保险丝熔断或跳闸的断路器是安全的重要保障。 微服务最近几年成为软件架构的热门话题，其益处多多。但需要知道的是，一旦开始将单块系统进行分解，就上了分布式系统的山头。 在云或分布式系统环境中，任何对一致性或可靠性的表述就是谎言。我们必须假设微服务的行为或其服务器位置会经常变动，其结果就是组件有时会提供低质量服务甚至可能彻底无法提供服务。这些微服务的故障如果没有处理好，将导致整个系统的故障。 微服务的故障可能是瞬时故障：如慢的网络连接、超时，资源过度使用而暂时不可用；也可能是不容易预见的突发事件的情况下需要更长时间来纠正的故障。 分布式服务的容错是一个不得不考虑的问题，通常的做法有两种：
重试机制：对于预期的短暂故障问题，通过重试模式是可以解决的。 断路器（CircuitBreaker）模式：将受保护的服务封装在一个可以监控故障的断路器对象中，当故障达到一定门限，断路器将跳闸（trip），所有后继调用将不会发往受保护的服务而由断路器对象之间返回错误。对于需要更长时间解决的故障问题，不断重试就没有太大意义了，可以使用断路器模式。 断路器模式设计状态机 注意事项 在决定如何实现这个模式时，您应考虑以下几点：
**异常处理。**通过断路器调用操作的应用程序必须能够处理在操作不可用时可能被抛出的异常，该类异常的处理方式都是应用程序特有的。例如，应用程序会暂时降级其功能，调用备选操作尝试相同的任务或获取相同的数据，或者将异常通知给用户让其稍后重试。 **异常类型。**一个请求可能由于各种原因失败，其中有一些可能表明故障严重类型高于其他故障。例如，一个请求可能由于需要几分钟才能恢复的远程服务崩溃而失败，也可能由于服务暂时超载造成的超时而失败。断路器有可能可以检查发生的异常类型，并根据这些异常本质调整策略。例如，促使切换到开状态（跳闸）的服务超时异常个数要远多于服务完全不可用导致的故障个数。 **日志记录。**一个断路器应记录所有失败的请求（如果可能的话记录所有请求），以使管理员能够监视它封装下受保护操作的运行状态。 **可恢复性。**应该配置断路器成与受保护操作最匹配的恢复模式。例如，如果断路器设定出入开状态的时间很长，即使底层操作故障已经解决它还会返回错误。如果开状态到半开状态切换过快，底层操作故障还没解决它就会再次调用受保护操作。 **测试失败的操作。**在开状态下，断路器可能不用计时器来确定何时切换到半开状态，而是通过周期性地查验远程服务或资源以确定它是否已经再次可用。这个检查可能采用上次失败的操作的形式，也可以使用由远程服务提供的专门用于测试服务健康状况的特殊操作。 **手动复位。**在一个系统中，如果一个失败的操作的恢复时间差异很大，提供一个手动复位选项以使管理员能够强行关闭断路器（和复位故障计数器）可能是有益的。同样，如果受保护操作暂时不可用，管理员可以强制断路器进入放状态（并重新启动超时定时器）。 **并发。**同一断路器可以被应用程序的大量并发实例访问。断路器实现不应阻塞并发请求或对每一请求增加额外开销。 **资源分化。**当断路器使用某类可能有多个底层独立数据提供者的资源时需要特别小心。例如，一个数据存储包含多个分区(shard)，部分分区出现暂时的问题，其他分区可能完全工作正常。如果该场景中的错误响应是合并响应，应用程序在部分故障分区很可能会阻塞整个请求时仍会试图访问某些工作正常的分区。 **加速断路。**有时失败响应对于断路器实现来说包含足够的信息用于判定应当立即跳闸并保持最小时间量的跳闸状态。例如，从过载共享资源的错误响应可能指示不推荐立即重试，且应用程序应当隔几分钟时间之后重试。如果一个请求的服务对于特定Web服务器不可用，可以返回HTTP协议定义的“HTTP 503 ServiceUnavailable”响应。该响应可以包含额外的信息，例如预期延迟持续时间。 **重试失败请求。**在开状态下，断路器可以不是快速地简单返回失败，而是将每个请求的详细信息记录日志并在远程资源或服务重新可用时安排重试。 **对外部服务的不恰当超时。**当对外部服务配置的超时很大时，断路器可能无法保护其故障操作，断路器内的线程在指示操作失败之前仍将阻塞到外部服务上，同时很多其他应用实例仍会视图通过断路器调用服务。 断路器模式业界Java实现 GitHub：jrugged：CircuitBreaker类源代码
GitHub：Netflix/hystrix
参考 Martin Fowler：CircuitBreaker
MSDN：Circuit Breaker Pattern
Protect your software with the Circuit Breaker design pattern</description></item><item><title>聊聊mavenCenter和JCenter</title><link>https://mryqu.github.io/post/%E8%81%8A%E8%81%8Amavencenter%E5%92%8Cjcenter/</link><pubDate>Fri, 03 Jul 2015 06:22:25 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%81%8A%E8%81%8Amavencenter%E5%92%8Cjcenter/</guid><description>Gradle支持从maven中央仓库和JCenter上获取构件，那这两者有什么区别呢？
maven中央仓库（http://repo1.maven.org/maven2/）是由Sonatype公司提供的服务，它是ApacheMaven、SBT和其他构建系统的默认仓库，并能很容易被ApacheAnt/Ivy、Gradle和其他工具所使用。开源组织例如Apache软件基金会、Eclipse基金会、JBoss和很多个人开源项目都将构件发布到中央仓库。maven中央仓库已经将内容浏览功能禁掉了，可在http://search.maven.org/查询构件。
https://jcenter.bintray.com）是由JFrog公司提供的Bintray中的Java仓库。它是当前世界上最大的Java和Android开源软件构件仓库。所有内容都通过内容分发网络（CDN）使用加密https连接获取。JCenter是Goovy Grape内的默认仓库，Gradle内建支持（jcenter()仓库），非常易于在（可能除了Maven之外的）其他构建工具内进行配置。
JCenter相比mavenCenter构件更多，性能也更好。但还是有些构件仅存在mavenCenter中。</description></item><item><title>ICU4J介绍</title><link>https://mryqu.github.io/post/icu4j%E4%BB%8B%E7%BB%8D/</link><pubDate>Thu, 02 Jul 2015 00:08:26 +0000</pubDate><guid>https://mryqu.github.io/post/icu4j%E4%BB%8B%E7%BB%8D/</guid><description>ICU (International Components for Unicode)是为软件应用提供Unicode和全球化支持的一套成熟、广泛使用的C/C++和Java类库集，可在所有平台的C/C++和Java软件上获得一致的结果。 ICU首先是由Taligent公司开发的，Taligent公司被合并为IBM公司全球化认证中心的Unicode研究组后，ICU由IBM和开源组织合作继续开发。开始ICU只有Java平台的版本，后来这个平台下的ICU类被吸纳入SUN公司开发的JDK1.1，并在JDK以后的版本中不断改进。 C++和C平台下的ICU是由JAVA平台下的ICU移植过来的，移植过的版本被称为ICU4C，来支持这C/C++两个平台下的国际化应用。ICU4J和ICU4C区别不大，但由于ICU4C是开源的，并且紧密跟进Unicode标准，ICU4C支持的Unicode标准总是最新的；同时，因为JAVA平台的ICU4J的发布需要和JDK绑定，ICU4C支持Unicode标准改变的速度要比ICU4J快的多。 ICU的功能主要有:
代码页转换:对文本数据进行Unicode、几乎任何其他字符集或编码的相互转换。ICU的转化表基于IBM过去几十年收集的字符集数据，在世界各地都是最完整的。 排序规则（Collation）:根据特定语言、区域或国家的管理和标准比较字数串。ICU的排序规则基于Unicode排序规则算法加上来自公共区域性数据仓库（Commonlocale data repository）的区域特定比较规则。 格式化:根据所选区域设置的惯例，实现对数字、货币、时间、日期、和利率的格式化。包括将月和日名称转换成所选语言、选择适当缩写、正确对字段进行排序等。这些数据也取自公共区域性数据仓库。 时间计算: 在传统格里历基础上提供多种历法。提供一整套时区计算API。 Unicode支持:ICU紧密跟进Unicode标准，通过它可以很容易地访问Unicode标准制定的很多Unicode字符属性、Unicode规范化、大小写转换和其他基础操作。 正则表达式: ICU的正则表达式全面支持Unicode并且性能极具竞争力。 Bidi: 支持不同文字书写顺序混合文字（例如从左到右书写的英语，或者从右到左书写的阿拉伯文和希伯来文）的处理。 文本边界: 在一段文本内定位词、句或段落位置、或标识最适合显示文本的自动换行位置。 下面的示例是使用ICU4J检测文本编码：
package com.yqu.icu4j; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import com.ibm.icu.text.CharsetDetector; import com.ibm.icu.text.CharsetMatch; public class EncodingDetector { public static void tryEncoding(String fileName) throws IOException { System.out.println(&amp;#34;===Getting encoding of &amp;#34; + fileName); Path path = Paths.get(fileName); byte[] data = Files.readAllBytes(path); CharsetDetector detector = new CharsetDetector(); detector.setText(data); CharsetMatch match = detector.</description></item><item><title>Java解析YAML</title><link>https://mryqu.github.io/post/java%E8%A7%A3%E6%9E%90yaml/</link><pubDate>Wed, 01 Jul 2015 05:37:02 +0000</pubDate><guid>https://mryqu.github.io/post/java%E8%A7%A3%E6%9E%90yaml/</guid><description>继前博文YAML介绍了YAML语法，本文将着重研究Java解析YAML。当前还在维护的YAML解析器/生成器有：
SnakeYAML 完整的YAML 1.1解析器，尤其是SnakeYAML能够分析来自于规范的所有示例 支持Unicode，包括UTF-8/UTF-16的输入/输出 为序列化和反序列化本地的Java对象提供了高级API 支持YAML类型库中的所有类型 比较理性的错误信息 YamlBeans：支持YAML 1.0和1.1 FasterXML/jackson-dataformat-yaml：处于原型阶段 SnakeYAML和YamlBeans都在GoogleCode仓库时，SnakeYAML的使用人数和提交者均优于YamlBeans。目前大多数帖子还是推荐选用SnakeYAML，而SpringBoot读取YAML配置采用的就是SnakeYAML。为了测试SnakeYAML，我首先创建了一个HelloSnakeYAML项目。
conf.yaml spring: application: name: cruncher datasource: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost/test server: port: 9000 Contact.java package com.yqu.yaml; import java.util.List; public class Contact { private String name; private int age; private List phoneNumbers; public Contact(String name, int age, List phoneNumbers) { this.name = name; this.age = age; this.phoneNumbers = phoneNumbers; } public String getName() { return name; } public void setName(String name) { this.</description></item><item><title>在线工具</title><link>https://mryqu.github.io/post/%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7/</link><pubDate>Tue, 30 Jun 2015 12:36:32 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7/</guid><description>smallpdf 坛子里提到一个PDF工具网站http://smallpdf.com/cn，有人试用了说不错。支持如下功能：
PDF压缩:大幅压缩PDF文件大小 JPG转PDF:将图片转换成如您所需的PDF文件 PDF转JPG:将页面转换成图片，或从PDF文件提取图片 PDF转Word:将PDF转换成具有最佳质量的Word文件 PDF转Excel:将PDF格式的电子表格转成可编辑的Excel文件 PDF转PPT:将PDF格式的幻灯片转成Powerpoint演示文件 Word转PDF:WORD文件转PDF格式 Excel转PDF:Excel表格转PDF PPT转PDF:PPT演示文件转PDF文件 合并PDF:将数个PDF文件合并为一个文件 PDF分割:从所选页面创建新文件 PDF解密:针对受密码保护的文件进行解密 新浪微博.短网址 http://sina.lt/提供如下功能：
网址压缩 短网址还原 外链图库 LaTeX 编译器 JaxEdit</description></item><item><title>尝试Artifactory</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95artifactory/</link><pubDate>Tue, 30 Jun 2015 06:28:36 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95artifactory/</guid><description>Artifactory简介 首先，JFrogArtifactory是统一构件仓库管理器，全面支持任何语言或技术创建的软件包。Artifactory是一个适合企业的仓库管理器，支持安全、集群和高可用的Docker注册。与所有主流CI/CD和DevOps工具进行集成，Artifactory提供了端到端的自动化的解决方案用以追踪从开发阶段到生产环境阶段中的构件。 安装Artifactory 在https://www.jfrog.com/open-source/下载开源版的jFrogArtifactory，按照JFrog Artifactory用户指南即可轻松安装和使用。 发布构件 使用Gradle构建脚本生成器 gradle.properties artifactory_contextUrl=http://localhost:8081/artifactory artifactory_user=admin artifactory_password=password group = com.yqu version = 0.1.0-SNAPSHOT description = Hello artifactory build.gradle buildscript { repositories { maven { url &amp;#34;https://plugins.gradle.org/m2/&amp;#34; } } dependencies { //Check for the latest version here: // http://plugins.gradle.org/plugin/com.jfrog.artifactory classpath &amp;#34;org.jfrog.buildinfo:build-info-extractor-gradle:+&amp;#34; } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#39;maven-publish&amp;#39; apply plugin: &amp;#34;com.jfrog.artifactory&amp;#34; jar { baseName = &amp;#39;HelloArtifactory&amp;#39; } artifacts { archives jar } publishing { publications { maven { from components.</description></item><item><title>[Gradle] buildScript块与allprojects块及根级别的repositories区别</title><link>https://mryqu.github.io/post/gradle_buildscript%E5%9D%97%E4%B8%8Eallprojects%E5%9D%97%E5%8F%8A%E6%A0%B9%E7%BA%A7%E5%88%AB%E7%9A%84repositories%E5%8C%BA%E5%88%AB/</link><pubDate>Mon, 29 Jun 2015 00:03:59 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_buildscript%E5%9D%97%E4%B8%8Eallprojects%E5%9D%97%E5%8F%8A%E6%A0%B9%E7%BA%A7%E5%88%AB%E7%9A%84repositories%E5%8C%BA%E5%88%AB/</guid><description>一直对为什么buildScript块里定义了repositories而allprojects段或根还定义repositories没有思考过，偶然有了念头想要探究一下。
build.gradle：
buildscript { repositories { ... } dependencies { ... } } allprojects { repositories { ... } dependencies { ... } }repositories { ... } dependencies { ... } buildScript块主要是为了Gradle脚本自身的执行，获取脚本依赖插件。我在写的一篇博客《尝试Artifactory》中Gradle脚本需要com.jfrog.artifactory插件才能执行成功，而这个插件是从URL为https://plugins.gradle.org/m2/的Maven仓库获得。 根级别的repositories主要是为了当前项目提供所需依赖包，比如log4j、spring-core等依赖包可从mavenCentral仓库获得。 allprojects块的repositories用于多项目构建，为所有项目提供共同所需依赖包。而子项目可以配置自己的repositories以获取自己独需的依赖包。
参考 What&amp;rsquo;s the difference between buildscript and allprojects in build.gradle?
Gradle buildscript dependencies
Gradle: Project</description></item><item><title>[Spring Data] 调试H2数据库</title><link>https://mryqu.github.io/post/spring_data_%E8%B0%83%E8%AF%95h2%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Sun, 28 Jun 2015 01:00:55 +0000</pubDate><guid>https://mryqu.github.io/post/spring_data_%E8%B0%83%E8%AF%95h2%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>我将Spring的两个入门指南Building a RESTful Web Service和Accessing Data with JPA融到一起，测试成功。那接下来的一个问题就是怎么查看H2数据库内容并进行调试？
配置H2 Web控制台 为了解决这个问题，我首先增加了src/resources/application.properties配置文件，内容如下：
spring.profiles.active=dev spring.h2.console.enabled=true 在H2 Web控制台上操作 启动Spring Boot应用，在浏览器中进入http://localhost:8080/h2_console/即可进入H2数据库的Web控制台了。 配置IDEA IntelliJ数据源 如果不使用H2 Web控制台的话，在IDEA IntelliJ集成开发环境中也可以通过配置H2数据源进行数据库操作。 解决数据库表不存在问题 上面的玩法有个问题，那就是没看到Accessing Data with JPA里面创建的CUSTOMER表，对不对？为了解决这个问题，在src/resources/application.properties配置文件增加如下内容：
spring.profiles.active=dev spring.h2.console.enabled=true spring.datasource.url=jdbc:h2:~/test;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE spring.datasource.driverClassName=org.h2.Driver spring.datasource.username=sa spring.datasource.password= 搞定，收工！
参考 Using H2’s web console in Spring Boot
Common application properties for Spring Boot
H2 Console</description></item><item><title>制作JavaSE8的chm版本JavaDoc</title><link>https://mryqu.github.io/post/%E5%88%B6%E4%BD%9Cjavase8%E7%9A%84chm%E7%89%88%E6%9C%ACjavadoc/</link><pubDate>Thu, 25 Jun 2015 05:50:57 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%B6%E4%BD%9Cjavase8%E7%9A%84chm%E7%89%88%E6%9C%ACjavadoc/</guid><description>Java8文档 在线版Java8文档: http://docs.oracle.com/javase/8/docs/ 下载版Java文档链接：http://www.oracle.com/technetwork/java/javase/downloads/index.html#docs
JavaSE6文档下载链接: http://www.oracle.com/technetwork/java/javase/downloads/jdk-6u25-doc-download-355137.html JavaSE7文档下载链接: http://www.oracle.com/technetwork/java/javase/documentation/java-se-7-doc-download-435117.html JavaSE8文档下载链接: http://www.oracle.com/technetwork/java/javase/documentation/jdk8-doc-downloads-2133158.html 工具 Github：subchen/javadoc.chm
制作过程 将javadoc.chm-master.zip的javadoc.chm-2.1.0.jar和lib目录解压缩到当前目录 将jdk-8u45-docs-all.zip的docs目录解压缩到当前目录 java -Xms256m -Xmx512m -cp javadoc.chm-2.1.0.jar;lib/commons-lang-2.6.jar;lib/commons-io-2.4.jar;lib/commons-collections-3.2.1.jar;lib/commons-logging-1.1.1.jar;lib/log4j-1.2.17.jar;lib/velocity-1.7.jar jerbrick.tools.chm.Application docs/api 执行docs/api/build.bat生成chm文件</description></item><item><title>了解Registrator</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3registrator/</link><pubDate>Thu, 18 Jun 2015 05:50:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3registrator/</guid><description>支持 DNS和基于HTTP发现机制的服务发现工具Consul让我们印象深刻。它提供了定制化的注册服务健康检查并标记不健康实例的功能远胜于其他类似的工具。更多时兴的工具与Consul的集成使其功能更加强大。在使用Docker的场景里，有了Registrator的帮助，只需要很小的工作量就可以自动化地向Consul注册Docker容器，使得管理基于容器技术的配置更加容易。 Registrator通过检查Docker容器是否上线，自动为Docker容器注册/注销服务。Registrator支持可插拔服务注册中心，当前包括Consul、etcd和SkyDNS 2。
用法 运行Consul容器 $ docker run -d --name=consul --net=host consul-server -bootstrap 运行Registrator容器 Registrator被设计为在每个主机运行一次。也可以在每个集群仅运行一个Registrator，但是通过确保Registrator运行在每个主机上可以获得更好的伸缩性和更简化的配置。假定使用某种程度的自动化，在所有地方都运行反而讽刺性地比某个地方运行更简单。 $ docker run -d \ --name=registrator \ --net=host \ --volume=/var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator:latest \ consul://localhost:8500 &amp;ndash;volume=/var/run/docker.sock:/tmp/docker.sock可以让Registrator访问DockerAPI； &amp;ndash;net=host有助于Registrator获得主机级IP和主机名； consul://localhost:8500是服务注册中心URI。 运行其他服务的容器 $ docker run -d -P --name=redis redis Registrator通过Docker API可以监听Docker容器的启动/关闭，并自动注册/注销服务: $ curl $(boot2docker ip):8500/v1/catalog/services {&amp;#34;consul&amp;#34;:[],&amp;#34;redis&amp;#34;:[]} $ curl $(boot2docker ip):8500/v1/catalog/service/redis [{&amp;#34;Node&amp;#34;:&amp;#34;boot2docker&amp;#34;,&amp;#34;Address&amp;#34;:&amp;#34;10.0.2.15&amp;#34;,&amp;#34;ServiceID&amp;#34;:&amp;#34;boot2docker:redis:6379&amp;#34;,&amp;#34;ServiceName&amp;#34;:&amp;#34;redis&amp;#34;,&amp;#34;ServiceTags&amp;#34;:null,&amp;#34;ServiceAddress&amp;#34;:&amp;#34;&amp;#34;,&amp;#34;ServicePort&amp;#34;:32768}] 参考 Github：gliderlabs/registrator
Registrator Quickstart
Docker Hub：gliderlabs/registrator
Scalable Architecture DR CoN: Docker, Registrator, Consul, Consul Template and Nginx</description></item><item><title>了解Consul template</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3consul_template/</link><pubDate>Wed, 17 Jun 2015 06:22:19 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3consul_template/</guid><description>支持 DNS 和基于HTTP发现机制的服务发现工具Consul让我们印象深刻。它提供了定制化的注册服务健康检查并标记不健康实例的功能远胜于其他类似的工具。更多时兴的工具与Consul的集成使其功能更加强大。ConsulTemplate守护进程提供了一个便捷方式直接使用Consul的信息来填充配置文件。 consul-template 查询一个Consul实例并对文件系统任意数量模板进行更新。此外，consul-template 在更新过程结束后可选地执行任意多个命令。 consul-template 项目提供了一些例子，通过Consul信息生成负载均衡器HAProxy、缓存引擎Varnish和web服务器Apachehttpd的配置文件。
参考 Github：hashicorp/consul-template Scalable Architecture DR CoN: Docker, Registrator, Consul, Consul Template and Nginx</description></item><item><title>使用Consul的十二要素应用（Twelve-Factor App）</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8consul%E7%9A%84%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8twelve-factor_app/</link><pubDate>Tue, 16 Jun 2015 05:36:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8consul%E7%9A%84%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8twelve-factor_app/</guid><description>十二要素应用（The Twelve-Factor App）主张web应用应该从环境变量里获取其配置。这一实践很快被现代PaaS服务采用以用于允许简单的配置变更。 使用Consul，很容易将这一实践用于你自己的数据中心。如果你基础架构的某些方面部分使用PaaS，Consul是配置数据中心化的一个很好的方式。 在这篇文章中，我们将展示Consul和envconsul如何在不修改应用程序的情况下被用于设置配置值和在配置变更时触发自动重启。
为什么使用环境变量? 根据十二要素应用，web应用配置应该使用环境变量。跟配置文件或Java系统属性这样的机制比，环境变量有很多优点：
环境变量是一个与开发语言和操作系统无关的标准。 环境变量更难被意外提交到代码库。 环境变量跟易于在development、staging、QA这样不同的环境之间改变。 无论如何部署，环境变量易于设置和更新。 例如Heroku这样的完整PaaS解决方案公开一些有用的API以用于为应用自动设置/读取环境变量。 当手动部署应用时，以往这样的事会更复杂一些。而使用Consul，程序员就可以很容易地设置和读取配置，运营工程师就可以很容易地提供支持和维护。
Consul键值对和Envconsul Consul能够存储键值对数据。对于设置和获取键值对数据，Consul拥有简单的API和美丽且直观的web界面。对于存储配置数据来说，它是完美的。 很容易看到如何设置和读取配置数据，但是对于配置数据如何变成应用的环境变量还不是很清楚。envconsul是一个解决该类问题的轻量级解决方案。 使用envconsul，环境变量存储在ConsulKV中并具有某些（以&amp;quot;/&amp;ldquo;分割的）前缀。例如，为了配置服务&amp;quot;foo&amp;rdquo;，我们可能存储如下配置：
$ curl -X PUT -d &amp;#39;false&amp;#39; http://localhost:8500/v1/kv/foo/enabled true 这会在键foo/enabled中存储值false。 之后，使用envconsul, 我们可以将这些键转换为环境变量：
$ envconsul foo env ENABLED=false envconsul是一个对UNIX非常友好的应用。他有两个必需的参数：一个用于查找数据的KV前缀和一个应用及其可选参数。在上例中，我们告诉envconsul配置位于前缀foo下，且我们想运行应用env，该应用仅仅是输出环境变量。 在示例结果中，我们可以清楚地看到ENABLED如我们在ConsulKV中所设置的false。
如果将env改成你自己的应用，那么环境变量将暴露给你的应用。例如，为了运行一个Rails服务器你可能做如下操作。注意在真实生产场景中，你可能不直接运行Rails内建服务器，但是它不失为一个好案例：
$ envconsul foo bin/rails server ... 自动重载 使用PaaS，当你修改任何配置时你的应用将自动重启。我们可以以最小的代价通过Consul和Envconsul实现相同效果。 通过对envconsul添加-reload标志，一旦配置键发生增删改，envconsul将中断(SIGTERM)并重启你的应用：
$ envconsul -reload foo bin/rails server ... 注：该功能已经在0.4.0版本移除。 Consul HTTP API支持对给定前缀KV中的变更进行长轮询。一旦KV中发生变更，Envconsul通过这种方式可以高效地进行检测。
改良流程 对应用配置使用Consul和envconsul可以将PaaS化应用配置易用性带入你自己的原生环境。 对于开发者而言，他们可以无需跟运营工程师沟通或重新部署应用就可以设置配置。 对于运营来说，Consul对整个基础架构的服务发现和配置提供了统一的解决方案。Consul自动复制数据并存储在磁盘上以方便备份，运营工程师也可以高枕无忧了。
我的实践 Envconsul获取的环境变量既可以直接给启动服务器的命令使用（例如上面启动Rails内建服务器的bin/rails命令）；也可以通过python之类的脚本存成Java系统属性文件，通过chpst这样可以加载环境变量/系统属性文件的命令间接给Java命令使用。
envconsul \ -once \ -log-level info \ -consul localhost:8500 \ -upcase=false \ -prefix config/foo/jvm \ foo env /usr/local/tomcat/bin/catalina.</description></item><item><title>Vagrant运行Docker的几种方法</title><link>https://mryqu.github.io/post/vagrant%E8%BF%90%E8%A1%8Cdocker%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 15 Jun 2015 06:15:31 +0000</pubDate><guid>https://mryqu.github.io/post/vagrant%E8%BF%90%E8%A1%8Cdocker%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/</guid><description>Vagrant的docker provisioner能够自动安装Docker、下载Docker容器、随着vagrant up命令自动运行容器。 Vagrantfile Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.provision &amp;#34;docker&amp;#34; do |d| d.pull_images &amp;#34;consul&amp;#34; d.run &amp;#34;consul&amp;#34; d.pull_images &amp;#34;rabbitmq&amp;#34; d.run &amp;#34;rabbitmq&amp;#34; end end 仅使用Vagrant的docker provisioner安装Docker，使用脚本下载并运行Docker容器 Vagrantfile # Install Docker config.vm.provision &amp;#34;docker&amp;#34; # Download Docker images, create and start containers config.vm.provision :shell, :path =&amp;gt; &amp;#34;runMyDockers.sh&amp;#34; runMyDockers.sh #!/bin/bash docker rm -f consul 2&amp;gt;/dev/null docker create --hostname consul --name consul -v /data/consul1:/data --dns 127.0.0.1 --restart always -p 8500:8500 --env CONSUL_OPTIONS=-bootstrap consul:dev docker start consul docker rm -f rabbitmq 2&amp;gt;/dev/null docker create --name rabbitmq --hostname rabbitmq -p 5672:5672 -v /data/rabbitmq:/data --dns 127.</description></item><item><title>Consul实践</title><link>https://mryqu.github.io/post/consul%E5%AE%9E%E8%B7%B5/</link><pubDate>Sun, 14 Jun 2015 23:08:40 +0000</pubDate><guid>https://mryqu.github.io/post/consul%E5%AE%9E%E8%B7%B5/</guid><description>Consul简介 最近除了在用Hashicorp公司的Vagrant，也使用了Consul。Consul是一款以跨数据中心、高可用的方式提供服务注册、发现、配置和编排的工具。Consul可以用来回答一个企业的基础设施中，诸如下列这些问题：
“服务X在哪里” “服务Y的实例是否健康” “当前正在运行的服务是什么” “服务Z的配置是怎样的” “在我的平台上是否还有其他人在执行操作A？” Consul通过DNS或HTTP API提供服务发现功能，同时支持跨数据中心的内部服务或外部服务的发现。使用shell脚本实现了健康检查，并允许创建自定义的服务验证协议。Consul还提供了高可用的键值对存储，由此可以暴露一致的存储值，用于配置参数的调优，而不必非要执行配置管理工具。可调优的操动实例包括指定服务的位置、指明系统处于维护模式，或者设置服务的QoS参数。Consul还提供了一套编排原语、通过UDP协议跨数据中心广播异步“事件”、通过TCP协议让指定的计算机同步执行“exec”指令，以及通过实现长轮询、react、事件机制或者其他操作实现定制化的监控。
安装Consul echo Installing dependencies... sudo apt-get install -y unzip curl echo Fetching Consul... cd /tmp/ wget https://dl.bintray.com/mitchellh/consul/0.5.2_linux_amd64.zip -O consul.zip echo Installing Consul... unzip consul.zip sudo chmod +x consul sudo mv consul /usr/mryqu/consul echo Fetching Consul UI... cd /tmp/ wget https://dl.bintray.com/mitchellh/consul/0.5.2_web_ui.zip -O dist.zip echo Installing Consul UI... unzip dist.zip sudo chmod +x dist sudo mv dist /usr/mryqu/consul/dist 引导一个数据中心 首先以服务器模式运行第一个Consul代理。Consul需要使用-bootstrap-expect指定集群节点个数，使用-data-dirparameter指定一个数据目录名，使用-ui-dir参数指定Consul UI目录:
$&amp;gt;consul agent -server -bootstrap-expect 1 -data-dir /usr/mryqu/consul/consuldata -ui-dir /usr/mryqu/consul/dist UI默认地址是http://localhost:8500/ui 如果UI没有启动，需要添加额外的-client 0.</description></item><item><title>[OpenUI5] sap.ui.core.ResizeHandler</title><link>https://mryqu.github.io/post/openui5_sap.ui.core.resizehandler/</link><pubDate>Sun, 14 Jun 2015 09:10:23 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_sap.ui.core.resizehandler/</guid><description>OpenUI5里窗口大小放生变化，各个控件如何收到通知跟着相应变化的呢？
sap.ui.core.Core 首先我们看一下sap.ui.core.Core的源代码：
Core._I_INTERVAL = 200; ResizeHandler.prototype.I_INTERVAL = Core._I_INTERVAL; Core.prototype.attachIntervalTimer = function(fnFunction, oListener) { if (!this.oTimedTrigger) { var IntervalTrigger = sap.ui.requireSync(&amp;#34;sap/ui/core/IntervalTrigger&amp;#34;); this.oTimedTrigger = new IntervalTrigger(Core._I_INTERVAL); } this.oTimedTrigger.addListener(fnFunction, oListener); }; sap.ui.core.Core里面会起一个定时器，以200毫秒间隔周期触发。
sap.ui.core.ResizeHandler 接下来我们看一下sap.ui.core.ResizeHandler的源代码：
function initListener(){ if (!this.bRegistered &amp;amp;&amp;amp; this.aResizeListeners.length &amp;gt; 0) { this.bRegistered = true; sap.ui.getCore().attachIntervalTimer(this.checkSizes, this); } } ResizeHandler.prototype.checkSizes = function() { var bDebug = log.isLoggable(); if ( bDebug ) { log.debug(&amp;#34;checkSizes:&amp;#34;); } jQuery.each(this.aResizeListeners, function(index, oResizeListener){ if (oResizeListener) { var bCtrl = !</description></item><item><title>[OpenUI5] 通过sap.ui.core.Core的registerElement和deregisterElement函数监控View和控件的构造和析构</title><link>https://mryqu.github.io/post/openui5_%E9%80%9A%E8%BF%87sap.ui.core.core%E7%9A%84registerelement%E5%92%8Cderegisterelement%E5%87%BD%E6%95%B0%E7%9B%91%E6%8E%A7view%E5%92%8C%E6%8E%A7%E4%BB%B6%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E6%9E%90%E6%9E%84/</link><pubDate>Sat, 13 Jun 2015 21:47:32 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E9%80%9A%E8%BF%87sap.ui.core.core%E7%9A%84registerelement%E5%92%8Cderegisterelement%E5%87%BD%E6%95%B0%E7%9B%91%E6%8E%A7view%E5%92%8C%E6%8E%A7%E4%BB%B6%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E6%9E%90%E6%9E%84/</guid><description>在sap.ui.core.Core中有registerElement和deregisterElement函数，它们可用于在调试中监控Element（包括View和控件）的构造和析构。
registerElement：在控件构造时被调用 deregisterElement：在控件析构时被调用 通过下面的代码可知，Core类的mElements存储着元素Id和元素的散列表：
Core.prototype.registerElement = function(oElement) { var sId = oElement.getId(), oldElement = this.mElements[sId]; if ( oldElement &amp;amp;&amp;amp; oldElement !== oElement ) { if ( oldElement._sapui_candidateForDestroy ) { jQuery.sap.log.debug(&amp;#34;destroying dangling template &amp;#34; + oldElement + &amp;#34; when creating new object with same ID&amp;#34;); oldElement.destroy(); } else { // duplicate ID detected =&amp;gt; fail or at least log a warning if (this.oConfiguration.getNoDuplicateIds()) { jQuery.sap.log.error(&amp;#34;adding element with duplicate id &amp;#39;&amp;#34; + sId + &amp;#34;&amp;#39;&amp;#34;); throw new Error(&amp;#34;Error: adding element with duplicate id &amp;#39;&amp;#34; + sId + &amp;#34;&amp;#39;&amp;#34;); } else { jQuery.</description></item><item><title>使用Vagrant创建开发环境</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8vagrant%E5%88%9B%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link><pubDate>Fri, 12 Jun 2015 22:46:10 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8vagrant%E5%88%9B%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid><description>用思维导图写了一篇[Packt Publishing] Creating Development Environments with Vagrant读书笔记。</description></item><item><title>通过环境变量修改VAGRANT BOX参数</title><link>https://mryqu.github.io/post/%E9%80%9A%E8%BF%87%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%BF%AE%E6%94%B9vagrant_box%E5%8F%82%E6%95%B0/</link><pubDate>Fri, 12 Jun 2015 06:14:24 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%80%9A%E8%BF%87%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%BF%AE%E6%94%B9vagrant_box%E5%8F%82%E6%95%B0/</guid><description>在如下示例Vagrantfile文件片段，VAGRANTBOX的内存和CPU核数首先查询环境变量，如果没有设相关环境变量的话则使用默认值。
config.vm.provider &amp;#34;virtualbox&amp;#34; do |v| v.memory = ENV.has_key?(&amp;#39;VAGRANTBOX_MEM&amp;#39;) ? ENV[&amp;#39;VAGRANTBOX_MEM&amp;#39;].to_i : 1024 v.cpus = ENV.has_key?(&amp;#39;VAGRANTBOX_CPUS&amp;#39;) ? ENV[&amp;#39;VAGRANTBOX_CPUS&amp;#39;].to_i : 2 v.customize [&amp;#34;modifyvm&amp;#34;, :id, &amp;#34;--natdnshostresolver1&amp;#34;, &amp;#34;on&amp;#34;] v.customize [&amp;#34;modifyvm&amp;#34;, :id, &amp;#34;--cpuexecutioncap&amp;#34;, &amp;#34;75&amp;#34;] end 参考 Vagrant VirtualBox Configuration</description></item><item><title>cAdvisor实践</title><link>https://mryqu.github.io/post/cadvisor%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 11 Jun 2015 00:40:08 +0000</pubDate><guid>https://mryqu.github.io/post/cadvisor%E5%AE%9E%E8%B7%B5/</guid><description>cAdvisor (Container Advisor)为运行容器的用户提供出色的资源使用和性能特征。这是一个运行守护进程，能够搜集、集料、处理和导出运行中的容器的信息。特别需要指出，每个容器都有资源隔离参数、历史资源使用、以及完整历史数据的柱状图。 cAdvisor目前支持Docker容器和lmctfy容器。
运行cAdvisor容器 配置boot2docker与宿主机之间的端口转移 查看cAdvisor 参考 GitHub：cAdvisor</description></item><item><title>DockerUI实践</title><link>https://mryqu.github.io/post/dockerui%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 10 Jun 2015 06:08:47 +0000</pubDate><guid>https://mryqu.github.io/post/dockerui%E5%AE%9E%E8%B7%B5/</guid><description>DockerUI是Docker远程API的Web接口,它是由下列技术栈构成的纯客户端，因此很容易连接和管理Docker。
Angular.js Bootstrap Gritter Spin.js Golang Vis.js 运行DockerUI容器 配置boot2docker与宿主机之间的端口转移 另一种方式是在启动容器之前执行：
boot2docker ssh -L 9000:localhost:9000 查看DockerUI 直接使用Docker远程API 参考 GitHub：crosbymichael/dockerui
Docker Remote API</description></item><item><title>Spring FileUpload限制调整笔记</title><link>https://mryqu.github.io/post/spring_fileupload%E9%99%90%E5%88%B6%E8%B0%83%E6%95%B4%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 08 Jun 2015 06:42:28 +0000</pubDate><guid>https://mryqu.github.io/post/spring_fileupload%E9%99%90%E5%88%B6%E8%B0%83%E6%95%B4%E7%AC%94%E8%AE%B0/</guid><description>Tomcat配置 HTTP Connector - maxPostSize配置 maxPostSize: 在POST请求中容器FORMURL参数解析所能处理的最大字节数。该参数可以通过设置为小于零的负值禁掉该限制。如果没有设置，该属性为2097152(2M字节)。 该配置可在$CATALINA_BASE/conf/server.xml内修改: Tomcat 7.0.63之前maxPostSzie=&amp;ldquo;0&amp;quot;视为禁掉该限制。
multipart-config配置 max-file-size: 单个上传文件允许的最大字节数。默认-1，无限制。 max-request-size: 真个请求允许的最大字节数。默认-1，无限制。
这两个配置可在web.xml内修改： 如果上传文件超过限制，则会抛出Exception。示例：
org.apache.tomcat.util.http.fileupload.FileUploadBase$SizeLimitExceededException: the request was rejected because its size (61198097) exceeds the configured maximum (20971520) at org.apache.tomcat.util.http.fileupload.FileUploadBase$FileItemIteratorImpl.(FileUploadBase.java:811) at org.apache.tomcat.util.http.fileupload.FileUploadBase.getItemIterator(FileUploadBase.java:256) at org.apache.tomcat.util.http.fileupload.FileUploadBase.parseRequest(FileUploadBase.java:280) at org.apache.catalina.connector.Request.parseParts(Request.java:2730) at org.apache.catalina.connector.Request.parseParameters(Request.java:3064) at org.apache.catalina.connector.Request.getParameter(Request.java:1093) at org.apache.catalina.connector.RequestFacade.getParameter(RequestFacade.java:380) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:70) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:68) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.</description></item><item><title>Docker Compose笔记</title><link>https://mryqu.github.io/post/docker_compose%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 06 Jun 2015 05:33:22 +0000</pubDate><guid>https://mryqu.github.io/post/docker_compose%E7%AC%94%E8%AE%B0/</guid><description>Docker Compose概述 **DockerCompose**
**前身 Fig**
Compose是用于在Docker内定义和运行多容器应用程序的工具。使用Compose，可以在一个文件内定义多容器应用程序，然后使用一个命令运行应用。 Compose对开发环境、交付准备服务器（stagingservers）和持续集成（CI）很有帮助，不建议用于生产环境。 使用Compose基本上是三步流程： - 通过一个`Dockerfile`定义应用环境，以便在其他地方复制； - 在`docker-compose.yml`中定义组成应用的服务，因此他们可以在一个隔离的环境一起运行； - 最后，运行`docker-compose up`，Compose将启动并运行整个应用。 docker-compose.yml大概是这个样子的:
web: build: . ports: - &amp;#34;5000:5000&amp;#34; volumes: - .:/code links: - redis redis: image: redis Compose包含管理应用整个生命周期的命令:
启动、停止和重建服务 查看运行的服务状态 对运行的服务的日志输出生成数据流 对一个服务运行一次性命令 Docker Compose安装 curl -L https://github.com/docker/compose/releases/download/VERSION_NUM/docker-compose-`uname -s`-`uname -m` &amp;gt; /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose Docker Compose命令 更新整个应用 mryqu$ docker-compose stop # stop the containers mryqu$ docker-compose pull # download updated images mryqu# docker-compose up -d # creates new containers and starts them 更新单个服务 mryqu$ docker-compose stop foo # stop the foo service mryqu$ docker-compose pull foo # download foo service mryqu$ docker-compose up -d foo # start the new foo service 参考 Overview of Docker Compose</description></item><item><title>[OpenUI5] 自定义控件示例</title><link>https://mryqu.github.io/post/openui5_%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6%E7%A4%BA%E4%BE%8B/</link><pubDate>Fri, 05 Jun 2015 05:42:01 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6%E7%A4%BA%E4%BE%8B/</guid><description>最近在写一个OpenUI5自定义控件，参考了如下文章，搞定。
需要注意的是，控件内的property在init函数内不会获得构造函数的属性值。通过源码可知，EventProvider.extend.constructor内先回调用init函数，然后再调用applySettings将构造函数内的属性设置进去。
constructor : function(sId, mSettings, oScope) { EventProvider.call(this); // no use to pass our arguments if (typeof (sId) != &amp;#34;string&amp;#34; &amp;amp;&amp;amp; arguments.length &amp;gt; 0) { // shift arguments in case sId was missing, but mSettings was given oScope = mSettings; mSettings = sId; if (mSettings &amp;amp;&amp;amp; mSettings.id) { sId = mSettings[&amp;#34;id&amp;#34;]; } else { sId = null; } } if (!sId) { sId = this.getMetadata().uid() || jQuery.sap.uid(); } else { var preprocessor = ManagedObject.</description></item><item><title>使用Docker的现代十二要素应用</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8docker%E7%9A%84%E7%8E%B0%E4%BB%A3%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8/</link><pubDate>Thu, 04 Jun 2015 05:26:36 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8docker%E7%9A%84%E7%8E%B0%E4%BB%A3%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8/</guid><description>【编者的话】“十二要素应用”为开发SaaS应用提供了方法上的指导，而Docker能够提供打包依赖，解耦后端服务等特性，使得两者非常吻合。这篇文章介绍了Docker特性怎样满足了开发“十二要素应用”的对应要点。Docker非常适合开发“十二要素应用”。
“十二要素应用”为构建SaaS应用提供了方法论，是由知名PaaS云计算平台Heroku的创始人AdamWiggins提出的。请参考这篇[文章](http://www.infoq.com/cn/news/2012/09/12-factor-app)。 Dockerfile与docker-compose.yml正在成为用代码定义服务的标准，通过它们可以定义服务的所有内容：依赖、环境、端口、各种进程以及后端服务。Docker镜像和容器为操作系统提供了保证，使得开发环境和生产环境可以有效地保持一致。这篇文章简单地介绍了Docker是怎样满足“十二要素应用”的核心要点的。它解释了用Docker开发一个典型的“Rails/Postgres/Redis/web/worker”所应用的技术。后续文章将通过代码深入介绍如何应用这些技术。
II. 依赖—显示地声明和隔离依赖关系 Docker镜像基于显示的Dockerfile构建，而Docker容器作为独立的运行环境。Dockerfile提供了显示声明基础操作系统的方法（FROM）,而且通过运行命令来安装附加的系统包以及应用的依赖包（RUN）。通过这些方法，你可以声明你需要ubuntu 14.04、Ruby 2.2.2、Node 0.11，然后一次性安装。
III. 配置—在环境中储存配置 Docker容器非常依赖Linux的环境变量进行配置。docker-compose.yml有一个环境变量的哈希表，你可以通过它显示的定义容器的环境变量。这些默认的或者未定义的值将在运行时从主机中继承。另外，还有Dokckerfile的ENV命令以及『docker run –env=[]』和『docker run–env-file=[]』运行选项可以设置环境变量。通过这些方法，你可以声明你的应用需要环境变量GITHUB_AUTH_TOKEN。 VII. 端口绑定—通过端口绑定来提供服务 Docker非常依赖端口绑定。docker-compose.yml有一个端口阵列，可以通过它显示的定义“主机:容器”的端口绑定。『docker run –pHOST:CONTAINER』让你可以在运行时定义端口绑定。通过这些方法，你可以声明你的应用的网络服务器将监听端口5000，而且你可以通过主机的端口5000获取服务。
IV. 后端服务—把后端服务当作附加资源 Docker容器与其它容器几乎完全隔离，所以需要通过网络与后端服务进行通信。docker-compse.yml有一个链接哈希表，你可以通过它指定你的应用所需要依赖的其他容器服务。‘docker-composeup’命令将首先开启这些后端服务，然后配置应用容器中网络连接信息的环境变量。通过这些方法，你可以声明你的应用需要Postgres 9.4和Redis3.0服务，让你的应用通过主机名和端口号与他们建立连接。
VI. 进程—以一个或者多个无状态进程运行应用 默认情况下，Docker容器是不带储存的进程。docker-compose.yml定义了一系列服务，每一个服务都有自己的镜像或者构建文件(Dockerfile)以及命令。通过这些方法，你可以声明你的应用同时有一个网络进程和工作进程。
XII. 管理进程—后台管理任务当做一次性进程运行 Docker镜像可以很容易地运行一次性进程。‘docker run myapp CMD’可以在与你的网络进程一致的环境中运行任意命令。通过这些方法，你可以基于你的Postgres数据库运行交互式的bash或者运行一次性的’rakedb:migrate’进程。
现有技术 若没有Docker，OS X的开发工具链是这样的：Homebrew作为系统依赖包， Postgres和Redis作为开发服务,Ruby的Bundler作为跨平台开发依赖，一系列的Shell脚本和foreman让所有工具在本地同时运行起来，以及一个独立的基于Linux的构建服务负责将应用打包到生产环境。这样的工作流并没有错误，但是Docker提供一个更简洁的方式。有了Dockerfile和docker-compose.yml文件，我们将不再需要任何OSX系统依赖，服务包或者跨平台的语言依赖。一个简单的“dicker-composeup”命令可以提供一个完整的Linux开发环境，并且能够轻易地将“十二要素应用”移植到生产机器。
原英文链接：Modern Twelve-Factor Apps With Docker
原译文链接：现代“十二要素应用”与Docker</description></item><item><title>读八种Docker开发模式</title><link>https://mryqu.github.io/post/%E8%AF%BB%E5%85%AB%E7%A7%8Ddocker%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 03 Jun 2015 06:22:55 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%AF%BB%E5%85%AB%E7%A7%8Ddocker%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/</guid><description>Eight Docker Development Patterns（原文）
八种Docker开发模式（译文）
八种Docker开发模式（介绍）
目前，我对可重用的基础容器和支持共享文件夹的开发容器这两种模式接触的多一些。</description></item><item><title>Docker速查笔记</title><link>https://mryqu.github.io/post/docker%E9%80%9F%E6%9F%A5%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 02 Jun 2015 22:16:06 +0000</pubDate><guid>https://mryqu.github.io/post/docker%E9%80%9F%E6%9F%A5%E7%AC%94%E8%AE%B0/</guid><description>常用命令 登入运行的docker容器内 docker exec -it $dockerContainerName /bin/bash 查看docker日志 docker logs --tail=&amp;#34;5&amp;#34; -f $dockerContainerName 清除容器及镜像 docker stop $(docker ps -a -q) #停止所有容器 docker rm $(docker ps -a -q) #删除所有容器 docker rmi $(docker images -q) #删除所有镜像 参考 Docker Cheat Sheet Docker Command Line Dockerfile reference The Docker Book</description></item><item><title>Spring Boot Example：Rest Exception Handling</title><link>https://mryqu.github.io/post/spring_boot_examplerest_exception_handling/</link><pubDate>Tue, 02 Jun 2015 00:14:40 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_examplerest_exception_handling/</guid><description>要给同事做个Rest异常处理的演示，顺便用用Spring Boot和Gradle构建。 首先新建一个项目：rest-exception-handling。
rest-exception-handling/src/main/java/com/yqu/rest目录 Application.java package com.yqu.rest; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } GreetingController.java package com.yqu.rest; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.*; import org.springframework.web.servlet.ModelAndView; @RestController public class GreetingController { @Autowired private GreetingService service; @RequestMapping(value = &amp;#34;/&amp;#34;, method = RequestMethod.GET) public ModelAndView home(Model m){ System.out.println(&amp;#34;home&amp;#34;); return new ModelAndView(&amp;#34;index&amp;#34;); } @RequestMapping(value = &amp;#34;/greeting&amp;#34;, method = RequestMethod.GET) public @ResponseBody GreetingVO greeting(@RequestParam(value=&amp;#34;name&amp;#34;) String name) throws GreetingException { System.</description></item><item><title>Vagrant base box列表</title><link>https://mryqu.github.io/post/vagrant_base_box%E5%88%97%E8%A1%A8/</link><pubDate>Thu, 28 May 2015 05:28:59 +0000</pubDate><guid>https://mryqu.github.io/post/vagrant_base_box%E5%88%97%E8%A1%A8/</guid><description>Vagrant的basebox都是打包了最小安装版操作系统(仅有一些跟Vagrant通讯必需的工具)的虚拟机镜像。vagrantbox.es列出了很多Vagrant的basebox，其中既有官方的box也有很多非官方的box。 有的box名是lucid32.box、lucid64.box、precise32.box、precise64.box，一开始不明白怎么回事，后来知道用的是Ubuntu的英文代码。
Ubuntu各种版本的英文代码 |版本|英文代号|中译 |&amp;mdash;&amp;ndash; |Ubuntu 4.10|Warty Warthog|多疣的疣猪 |Ubuntu 5.04|Hoary Hedgehog|白发的刺猬 |Ubuntu 5.10|Breezy Badger|活泼的獾 |Ubuntu 6.06|Dapper Drake|整洁的公鸭 |Ubuntu 6.10|Edgy Eft|尖利的小蜥蜴 |Ubuntu 7.04|Feisty Fawn|烦躁不安的鹿 |Ubuntu 7.10|Gutsy Gibbon|胆大的长臂猿 |Ubuntu 8.04|Hardy Heron|坚强的鹭 |Ubuntu 8.10|Intrepid Ibex|无畏的羱羊 |Ubuntu 9.04|Jaunty Jackalope|活泼的鹿角兔 |Ubuntu 9.10|Karmic Koala|幸运的树袋熊 |Ubuntu 10.04|Lucid Lynx|清醒的猞猁 |Ubuntu 10.10|Maverick Meerkat|标新立异的的狐獴 |Ubuntu 11.04|Natty Narwhal|敏捷的独角鲸 |Ubuntu 11.10|Oneiric Ocelot|有梦的虎猫 |Ubuntu 12.04|Precise Pangolin|精准的穿山甲 |Ubuntu 12.10|Quantal Quetzal|量子的格查尔鸟 |Ubuntu 13.04|Raring Ringtail|铆足了劲的环尾猫熊 |Ubuntu 13.10|Saucy Salamander|活泼的蝾螈 |Ubuntu 14.04|Trusty Tahr|可靠的塔尔羊 |Ubuntu 14.10|Utopic Unicorn|乌托邦的独角兽 |Ubuntu 15.04|Vivid Vervet|活泼的长尾黑颚猴 |Ubuntu 15.</description></item><item><title>玩一下gradle-jvmsrc-plugin</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bgradle-jvmsrc-plugin/</link><pubDate>Wed, 27 May 2015 05:51:01 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bgradle-jvmsrc-plugin/</guid><description>玩了一下gradle-jvmsrc-plugin插件，使用这个插件后执行gradlecreateJvmSrcDirs可以根据Gradle项目的JVM语言插件（(java、groovy、scala、android等），自动创建默认的源代码、测试和资源包目录。例如：
src/main/resources src/main/java/ src/main/groovy/ src/test/java/ src/test/groovy/ src/test/resources 刚上手总是报错，看了一下CreateJvmSourceDirs.groovy，定位到packageToDirectoryPath方法：
* What went wrong: Execution failed for task &amp;#39;:HelloJvmsrc:createJvmSrcDirs&amp;#39;. &amp;gt; character to be escaped is missing 按照如下gradle-jvmsrc-plugin的说明，要配置基础包名。可是真按它介绍的带有.分割的包名就会出错，简单改成&amp;quot;com&amp;quot;这种没有.分割的包名就可以避免错误。
jvmsrc { packageName &amp;#34;com.mycompany.myproject.mymodule&amp;#34; } 此外，gradle-jvmsrc-plugin对空目录默认生成.gitkeep文件。 总体来说，用处不是很大，可以偷点懒！</description></item><item><title>[OpenUI5] sap.m.Input的change回调</title><link>https://mryqu.github.io/post/openui5_sap.m.input%E7%9A%84change%E5%9B%9E%E8%B0%83/</link><pubDate>Tue, 26 May 2015 05:27:41 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_sap.m.input%E7%9A%84change%E5%9B%9E%E8%B0%83/</guid><description>用sap.m.Input的change回调，当值在输入界面被修改后就会调用。今天试了一下，如果通过Model设置改变值的话，其change回调不会被调用。
这种特性正好用于判断是否为界面手工修改。在我的用例中，有一个表名和一个表表述。如果改动表名，表描述跟着相应更新；但是一旦用户手工输入表描述后，上述规则不再生效。</description></item><item><title>[Hadoop] 使用TeraSort测试集群性能</title><link>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8terasort%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD/</link><pubDate>Mon, 25 May 2015 06:04:00 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8terasort%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD/</guid><description>Terasort是Hadoop自带的用于集群性能基准测试的工具，其源码位于https://github.com/apache/hadoop/tree/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort下。
TeraSort用法 该性能基准测试工具针对Hadoop集群的HDFS和MapReduce层进行综合测试。完整的测试步骤为：
使用TeraGen程序生成官方GraySort输入数据集。(注：SortBenchmark是JimGray自98年建立的一项排序竞技活动，其对排序的输入数据制定了详细规则，要求使用其提供的gensort工具生成输入数据。而Hadoop的TeraGen数据生成工具的算法与gensort一致。） 在输入数据上运行真正的TeraSort性能基准测试工具 通过TeraValidate程序验证排序后的输出数据 TeraGen程序生成数据的格式为（详见TeraSort.generateRecord方法实现）：
10字节键：一个16字节随机数的高10字节 2字节常量：0x0011 32字节rowid 4字节常量：0x8899AABB 48字节填充：由一个16字节随机数的低48比特生成 4字节常量:0xCCDDEEFF 也就是说TeraGen程序生成的一行数据有100字节。TeraGen程序参数需要指定行数，可指定单位：
t：1000,000,000,000 b：1000,000,000 m：1000,000 k：1000 TeraSort测试 依次运行teragen、terasort和teravalidate：
hadoop@node50064:~$ yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.x.jar teragen 5m /user/hadoop/teragen-data hadoop@node50064:~$ yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.X.jar terasort /user/hadoop/teragen-data /user/hadoop/terasort-data 15/05/24 08:29:03 INFO terasort.TeraSort: starting 15/05/24 08:29:04 INFO input.FileInputFormat: Total input paths to process : 2 Spent 123ms computing base-splits. Spent 2ms computing TeraScheduler splits. Computing input splits took 127ms Sampling 4 splits of 4 Making 1 from 100000 sampled records Computing parititions took 558ms Spent 686ms computing partitions.</description></item><item><title>[Hadoop] 使用ChainMapper和ChainReducer运行MapReduce作业链</title><link>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8chainmapper%E5%92%8Cchainreducer%E8%BF%90%E8%A1%8Cmapreduce%E4%BD%9C%E4%B8%9A%E9%93%BE/</link><pubDate>Sun, 24 May 2015 00:07:44 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8chainmapper%E5%92%8Cchainreducer%E8%BF%90%E8%A1%8Cmapreduce%E4%BD%9C%E4%B8%9A%E9%93%BE/</guid><description>启动多个MapReduce作业并实现作业控制，大概有以下几种方式：
在Driver中通过waitForCompletion方法同步启动并运行作业，根据执行结果同样同步启动并运行后继作业。作业控制逻辑完全是自己实现，仅适用于作业不多的应用。 使用ChainMapper和ChainReducer运行MapReduce作业链 使用Oozie管理复杂MapReduce工作流 本文将针对第二种方式进行学习总结。 使用MapReduce作业链模式的数据和执行流如下：
一或多个mapper shuffle阶段 一个reducer 零或多个mapper 即，mapper可以输出给mapper，也可以输出给reducer；reducer只能输出给mapper；reducer之前必有shuffle阶段。 JobChaining示例 JobChainingDemo.java源码 londonbridge.txt London Bridge is falling down, Falling down, falling down. London Bridge is falling down, My fair lady. Build it up with wood and clay, Wood and clay, wood and clay, Build it up with wood and clay, My fair lady. Wood and clay will wash away, Wash away, wash away, Wood and clay will wash away, My fair lady.</description></item><item><title>[Hadoop] 使用DFSIO测试集群I/O性能</title><link>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8dfsio%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4io%E6%80%A7%E8%83%BD/</link><pubDate>Sat, 23 May 2015 09:12:41 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8dfsio%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4io%E6%80%A7%E8%83%BD/</guid><description>DFSIO是Hadoop自带的用于集群分布式I/O性能基准测试的工具，其源码为https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestDFSIO.java。
DFSIO 用法 hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.X-tests.jar TestDFSIO 15/05/22 19:50:22 INFO fs.TestDFSIO: TestDFSIO.1.8 Missing arguments. Usage: TestDFSIO [genericOptions] -read [-random | -backward | -skip [-skipSize Size]] | -write | -append | -truncate | -clean [-compression codecClassName] [-n rFiles N] [-size Size[B|KB|MB|GB|TB]] [-resFile resultFileName] [-bufferSize Bytes] DFSIO可以测试写操作和读操作，以MapReduce作业的方式运行，返回整个集群的I/O性能报告。DFSIO读写测试的位置在hdfs://namendoe:8020/benchmarks/TestDFSIO/io_data，其中读测试不会自己产生数据，必须先执行DFSIO写测试。
-read：读测试，对每个文件读-size指定的字节数 -write：写测试，对每个文件写-size指定的字节数 -append：追加测试，对每个文件追加-size指定的字节数 -truncate：截断测试，对每个文件截断至-size指定的字节数 -clean：清除TestDFSIO在HDFS上生成数据 -n：文件个数 -size：每个文件的大小 -resFile：生成测试报告的本地文件路径 -bufferSize：每个mapper任务读写文件所用到的缓存区大小，默认为1000000字节。 DFSIO测试 写10个100MB的文件 hadoop@node50064:~$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.X-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 100MB -resFile /tmp/DFSIO-write.out 查看写测试结果 本地文件/tmp/DFSIO-write.out包含写测试性能报告：</description></item><item><title>YAML</title><link>https://mryqu.github.io/post/yaml/</link><pubDate>Fri, 22 May 2015 22:55:52 +0000</pubDate><guid>https://mryqu.github.io/post/yaml/</guid><description>简介 YAML是一个可读性高的数据序列化格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822。ClarkEvans在2001年首次发表了这种语言 ，另外Ingy d?t Net与OrenBen-Kiki也是这语言的共同设计者。目前已经有数种编程语言或脚本语言支援（或者说解析）这种语言。 _YAML_是&amp;quot;YAML Ain&amp;rsquo;t a Markup Language&amp;quot;（YAML不是一种标记语言）的递回缩写。在开发的这种语言时，_YAML_的意思其实是：&amp;ldquo;Yet Another Markup Language&amp;rdquo;（仍是一种标记语言），但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重新命名。
功能 YAML的语法和其他高阶语言类似，并且可以简单表达列表、哈希表，标量等数据形式。它使用空白符号缩排和大量依赖外观的特色，特别适合用来表达或编辑数据结构、各种配置文件、调试时的转储内容、文件标题（例如：许多电子邮件标题格式和YAML非常接近）。尽管它比较适合用来表达分层数据，不过也有紧凑的语法可以表示关联性数据。由于YAML使用空白字符和分行来分隔数据，使得它特别适合用grep／Python／Perl／Ruby操作。其让人最容易上手的特色是巧妙避开各种封闭符号，如：引号、各种括号等，这些符号在嵌套结构时会变得复杂而难以辨认。
范例 简单的文件 数据结构可以用类似大纲的缩排方式呈现
--- receipt: Oz-Ware Purchase Invoice date: 2007-08-06 customer: given: Dorothy family: Gale items: - part_no: A4786 descrip: Water Bucket (Filled) price: 1.47 quantity: 4 - part_no: E1628 descrip: High Heeled &amp;#34;Ruby&amp;#34; Slippers price: 100.27 quantity: 1 bill-to: &amp;amp;id001 street: | 123 Tornado Alley Suite 16 city: East Westville state: KS ship-to: *id001 specialDelivery: &amp;gt; Follow the Yellow Brick Road to the Emerald City.</description></item><item><title>[Gradle] 在子项目中共享项目属性</title><link>https://mryqu.github.io/post/gradle_%E5%9C%A8%E5%AD%90%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%85%B1%E4%BA%AB%E9%A1%B9%E7%9B%AE%E5%B1%9E%E6%80%A7/</link><pubDate>Fri, 22 May 2015 06:09:34 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%9C%A8%E5%AD%90%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%85%B1%E4%BA%AB%E9%A1%B9%E7%9B%AE%E5%B1%9E%E6%80%A7/</guid><description>build.gradle:
buildscript { repositories { mavenCentral() } } subprojects { apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; repositories { mavenCentral() } sourceCompatibility = 1.8 targetCompatibility = 1.8 ext { HadoopVersion = &amp;#39;2.7.x&amp;#39; JUnitVersion = &amp;#39;4.11&amp;#39; ...... } } HelloHadoopClient/build.gradle：
jar { baseName = &amp;#39;hello-hadoopclient&amp;#39; version = &amp;#39;0.1.0&amp;#39; } dependencies { compile &amp;#34;org.apache.hadoop:hadoop-common:${HadoopVersion}&amp;#34; testCompile &amp;#34;junit:junit:${JUnitVersion}&amp;#34; } HelloMapReduce/build.gradle：
jar { baseName = &amp;#39;hello-mapreduce&amp;#39; version = &amp;#39;0.1.0&amp;#39; } dependencies { compile &amp;#34;org.</description></item><item><title>了解一下io域名</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8Bio%E5%9F%9F%E5%90%8D/</link><pubDate>Wed, 20 May 2015 23:45:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8Bio%E5%9F%9F%E5%90%8D/</guid><description>对我来说最熟悉的io域名莫过于spring.io，最近发现很多开源项目的主页也是io域名。好奇了一把，对io域名稍作一点了解。
域名的种类其实是非常多的，我们大多最熟悉COM域名、CN域名、NET域名等常见的通用域名。但是随着通用域名中好的域名注册资源的日益减少，这就使得人们不得不扩大域名的注册范围了，这期间io域名的出现就很快的进入域名注册者的视线。
io是英属印度洋领地（British Indian OceanTerritory，BIOT）的简写，英属印度洋领地是英国在印度洋的海外領地，包含了查戈斯群岛（ChagosArchipelago）及总数达2300个大大小小的热带岛屿，总土地面积約60平方公里，周边水域面积54400平方公里。io域名为英属印度洋国家顶级域名后缀，于1997年分配使用。全球任何公司、团体和个人均可注册英属印度洋.io域名。
而且io还可以作为[inputoutput]理解，即“输入输出接口”的意思。同时，对全世界所有的人来说，.io也是互联网上能够用来表示信息、知识的最直接、最直观的符号。
这一系列的优势使得io域名价值正在与日俱增真正的全球域名新贵，为因为通用域名注册资源日益减少的拥挤不堪的域名世界开创了一片崭新的天地，为广大域名用户提供多样的选择，而io域名在注册资格上没有任何的限制，这就使得任何一个国家的企业或者个人都可以注册，这就更让io域名受到广大国际用户的支持。</description></item><item><title>[HBase] 查看ZooKeeper服务器</title><link>https://mryqu.github.io/post/hbase_%E6%9F%A5%E7%9C%8Bzookeeper%E6%9C%8D%E5%8A%A1%E5%99%A8/</link><pubDate>Wed, 20 May 2015 06:10:22 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E6%9F%A5%E7%9C%8Bzookeeper%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid><description>使用hbaseorg.apache.hadoop.hbase.zookeeper.ZKServerTool可以很方便查看HBase所使用的ZK服务器列表。</description></item><item><title>Apt-get代理配置</title><link>https://mryqu.github.io/post/apt-get%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Wed, 20 May 2015 00:03:27 +0000</pubDate><guid>https://mryqu.github.io/post/apt-get%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>在公司安装Ubuntu docker后使用apt-get update总是失败，经历了一番周折才成功。
DNS？ 一开始怀疑是DNS问题，可以学习了下面几个帖子：
Docker apt-get update fails Docker - Network calls fail during image build on corporate network How do I set my DNS on Ubuntu 14.04? 检查我ubuntu配置：
cat /etc/resolv.conf 确认DNS没有问题。
Ubuntu官方服务器？ 是不是我的机器连不上欧美的Ubuntu官方服务器，换成中国服务器试试。尝试了Ubuntu 14.04服务器列表上的中国服务器还是不成。
Apt-get代理？ 照着how to install packages with apt-get on a system connected via proxy?设置一番，成功了
设置/etc/apt/apt.conf：
Acquire::http::proxy &amp;#34;http://yourServer:yourPort/&amp;#34;; Acquire::ftp::proxy &amp;#34;ftp://yourServer:yourPort/&amp;#34;; Acquire::https::proxy &amp;#34;https://yourServer:yourPort/&amp;#34;; 如需用户名、密码，则作如下修改：
Acquire::http::proxy &amp;#34;http://yourUsr:yourPwd@yourServer:yourPort/&amp;#34;; Acquire::ftp::proxy &amp;#34;ftp://yourUsr:yourPwd@yourServer:yourPort/&amp;#34;; Acquire::https::proxy &amp;#34;https://yourUsr:yourPwd@yourServer:yourPort/&amp;#34;; 最好将上述配置也存入/etc/apt/apt.conf.d/80proxy中，这样版本升级后这些变更也不会丢。</description></item><item><title>JS 库/UI 积累贴</title><link>https://mryqu.github.io/post/js_%E5%BA%93ui_%E7%A7%AF%E7%B4%AF%E8%B4%B4/</link><pubDate>Tue, 19 May 2015 06:10:19 +0000</pubDate><guid>https://mryqu.github.io/post/js_%E5%BA%93ui_%E7%A7%AF%E7%B4%AF%E8%B4%B4/</guid><description>Bootstrap库： jQuery File Upload Demo
Bootstrap table：示例不错
UI： codrops/TooltipStylesInspiration：工具提示做的很炫
OpenUI5： Welcome to 30 Days of UI5!
UI Framework related</description></item><item><title>尝试boot2docker和Vagrant-boot2docker box</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95boot2docker%E5%92%8Cvagrant-boot2docker_box/</link><pubDate>Sun, 17 May 2015 20:40:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95boot2docker%E5%92%8Cvagrant-boot2docker_box/</guid><description>boot2docker boot2docker是基于Tiny Core Linux的轻量级Linux发布版本虚拟机，专用于运行Docker容器。 功能如下：
3.18.5内核及AUFS文件系统、Docker 1.5.0 容器通过磁盘自动加载在/var/lib/docker目录持久化 SSH密钥通过磁盘自动加载进行持久化 容易访问Docker映射端口的主机模式（Host-only） Vagrant兼容的boot2docker box Vagrant创始人Mitchell Hashimoto使用boot2docker虚拟机创建了一个可被VirtualBox和VMware提供者支持的Vagrant box。当Vagrant被运行于Linux之外的操作系统时，Vagrant的Docker提供者默认使用boot2dockerbox提供Docker功能。 参考 boot2docker官网 GitHub:boot2docker GitHub:boot2docker-cli GitHub:mitchellh/boot2docker-vagrant-box yungsang/boot2docker GitHub:yungsang/boot2docker Using Docker with Vagrant Setting up a development environment using Docker and Vagrant Docker in OSX via boot2docker or Vagrant: getting over the hump</description></item><item><title>了解一下Gerrit与BitBucket集成</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8Bgerrit%E4%B8%8Ebitbucket%E9%9B%86%E6%88%90/</link><pubDate>Sun, 17 May 2015 00:18:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8Bgerrit%E4%B8%8Ebitbucket%E9%9B%86%E6%88%90/</guid><description>在《Gerrit插件配置》中没有找到有关BitBucket的信息。 通过https://marketplace.atlassian.com/search?q=Gerrit在Atlassian市场搜到几个跟Gerrit相关的控件，不过都是为JIRA/BitBucket/Bambooserve增加类似Gerrit的工作流的功能。 结论就是：目前没法用Gerrit为BitBucket进行代码审查。</description></item><item><title>了解用于Gerrit代码审查的GitHub插件</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E7%94%A8%E4%BA%8Egerrit%E4%BB%A3%E7%A0%81%E5%AE%A1%E6%9F%A5%E7%9A%84github%E6%8F%92%E4%BB%B6/</link><pubDate>Sat, 16 May 2015 07:28:57 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E7%94%A8%E4%BA%8Egerrit%E4%BB%A3%E7%A0%81%E5%AE%A1%E6%9F%A5%E7%9A%84github%E6%8F%92%E4%BB%B6/</guid><description>在网上看到了GitHub plugin for Gerrit，学习一下。
对比GitHub与Gerrit的代码审查机制 GitHub一派的代码审查机制主要通过fork一个远程分支，进行本地修改并提交到远程分支，然后通过PULL REQUEST来请求代码审查及合并回原上游远程分支。 Gerrit一派的代码审查机制主要通过checkout一个分支(refs/for/master)。从Gerrit克隆获得本地分支，进行修改并提交到Gerrit的refs/for/master分支，中间还可以通过Amend commit修改之前的提交，经过评审人批准后，代码会提交到&amp;quot;权威&amp;quot;仓库。 GitHub BitBucket GitLab Gitorious阵营 这一派的PULL REQUEST基于两个分支的合并，注释可能会乱一点，有点惹人烦。不考虑将所有原子/相关修改作为一个提交。除了写注释无法知道审查打分情况。 Gerrit GitBlit阵营 这一派的每个提交有其审查结果，可以清晰查看以往历史。Gerrit审查可以强制成仅接受快进（fast-worward）或可rebase的提交。 用于Gerrit代码审查的GitHub插件 https://gerrit-review.googlesource.com/#/admin/projects/plugins/github 优点：
引入Pull Requests -&amp;gt;Gerrit改动/主题 使用Gerrit认证规则重用GitHub账户 复制: 代码继续存在于http://github.com 仓库 防止不可管理的fork激增 避免GitHub垃圾邮件 -&amp;gt;每个改动一封电邮 第一步：为Gerrit在GitHub上注册新的OAUTH应用 第二步：获取Client ID和Client Secret 第三步：下载并安装Gerrit 下载地址：https://gerrit-releases.storage.googleapis.com/index.html 为了确保安装成功，首先使用DEVELOPMENT_BECOME_ANY_ACCOUNT作为认证方式确保能登录进Gerrit。 使用Git Bash启动Gerrit。 登陆后，可以查看到当前安装的插件。 第四步：构建GitHub插件 git clone https://gerrit.googlesource.com/plugins/github &amp;amp;&amp;amp; cd github mvn install 第五步：安装OAUTH过滤器和GitHub插件 第六步：重新配置Gerrit 第七步：完成GitHub认证 参考 GitHub plugin for Gerrit Gerrit vs Github: for code review and codebase management GerritHub Gerrit Code Review or Github’s fork and pull ?</description></item><item><title>数据科学的战争：R vs Python</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%9A%84%E6%88%98%E4%BA%89r_vs_python/</link><pubDate>Thu, 14 May 2015 05:48:20 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%9A%84%E6%88%98%E4%BA%89r_vs_python/</guid><description>R和Python都是用于数据分析任务的流行编程语言，都有各自的拥拓者和反对者。Python经常作为语法简单易懂的通用编程语言广受赞誉。在人们心中，R的功能是由统计学家开发的，因此具有特定领域优势，例如数据可视化上具有的大量功能。 DataCamp上有一篇帖子Choosing R or Python for data analysis? An infographic以信息图的方式从数据科学和统计的角度详细对比了R和Python这两种编程语言。</description></item><item><title>了解构件仓库管理器Artifactory和Nexus</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E6%9E%84%E4%BB%B6%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%99%A8artifactory%E5%92%8Cnexus/</link><pubDate>Wed, 13 May 2015 06:07:11 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E6%9E%84%E4%BB%B6%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%99%A8artifactory%E5%92%8Cnexus/</guid><description>使用Maven，可以从Maven中央仓库下载所需要的构件（artifact），但这通常不是一个好的做法，一般是在企业内部架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间。企业仓库管理器一般可以提供高并发访问、浏览和查询、报表、访问控制、备份、对其他仓库进行代理、RESTAPI等特性 了解一下构件仓库管理器，市场上最好的是JFrog的Artifactory和Sonatype的Nexus，而且这两个产品既有商业版也有免费社区版。 以Artifactory为例，Ant+Ivy、Maven和Gradle这些构建工具都可以自动下载Artifactory里的构件（artifact），此外Jenkins、Bamboo等CI工具也可以通过构建工具将生成的构件（artifact）部署到Artifactory上。 如果将构建结果部署到Artifactory，需要对Maven构建增加如下选项：
deploy -DaltDeploymentRepository=snapshots::default::http://svcartifact.yqu.com:8081/artifactory/snapshots 如果将release构建结果部署到Artifactory，需要对Maven构建增加如下选项：
deploy -DaltDeploymentRepository=release::default::http://svcartifact.yqu.com:8081/artifactory/release 或者在pom.xml中内嵌distributionManagement： 最近网上有一个不错的帖子 Maven Repository Manager Feature Matrix，对比了Archiva、Artifactory和Nexus的功能和价格，可供有需要做Maven仓库管理器技术选型的同学借鉴。
参考 JFrog Artifactory官网 Sonatype Nexus官网 Artifactory – 1 Min Setup Apache Maven Deploy Plugin</description></item><item><title>Swagger实践和总结</title><link>https://mryqu.github.io/post/swagger%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%80%BB%E7%BB%93/</link><pubDate>Mon, 11 May 2015 05:54:33 +0000</pubDate><guid>https://mryqu.github.io/post/swagger%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%80%BB%E7%BB%93/</guid><description>Swagger学习和实践 最近安装并使用了一下Swagger-ui、Swagger-editor和Swagger-codegen，感觉还不错。 Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web服务。Swagger的目标是对RESTAPI定义一个标准的和语言无关的接口，可让人和计算机无需访问源码、文档或网络流量监测就可以发现和理解服务的能力。当通过Swagger进行正确定义，用户可以理解远程服务并使用最少实现逻辑与远程服务进行交互。与为底层编程所实现的接口类似，Swagger消除了调用服务时可能会有的猜测。 Swagger是一组开源项目，其中主要要项目如下：
Swagger-tools:提供各种与Swagger进行集成和交互的工具。例如模式检验、Swagger1.2文档转换成Swagger 2.0文档等功能。 Swagger-core:用于、Servlets和Play框架进行集成。 Swagger-js:用于JavaScript的Swagger实现。 Swagger-node-express:Swagger模块，用于node.js的Express web应用框架。 Swagger-ui：一个无依赖的HTML、JS和CSS集合，可以为Swagger兼容API动态生成优雅文档。 Swagger-codegen：一个模板驱动引擎，通过分析用户Swagger资源声明以各种语言生成客户端代码。 C:\tools\swagger-codegen&amp;gt;mvn package C:\tools\swagger-codegen\modules\swagger-codegen-cli&amp;gt;mvn package C:\tools\swagger-codegen\modules\swagger-generator&amp;gt;mvn package C:\tools\swagger-codegen&amp;gt;java -jar modules/swagger-codegen-cli/target/swagger-codegen-cli.jar generate -i http://petstore.swagger.io/v2/swagger.json -l spring-mvc -o yqu/petstore/spring-mvc C:\tools\swagger-codegen\yqu\petstore\spring-mvc&amp;gt;mvn package 上述操作通过底层使用SpringFox库，会创建带有Swagger注释的SpringMVC框架代码，包括Controller和DTO类。这样将Swagger-ui部署到Web应用内，就可以通过http://server:8002/v2/sdoc.jsp 在线访问API文档了。 Swagger-editor：可让使用者在浏览器里以YAML格式编辑SwaggerAPI规范并实时预览文档。可以生成有效的SwaggerJSON描述，并用于所有Swagger工具（代码生成、文档等等）中。 除了Swagger项目自身支持的Java、Scala和JavaScript语言，Swagger社区中还提供了很多支持其他语言的第三方工具，覆盖了Clojure、ColdFusion/ CFML、Eiffel、Go、Groovy、.Net、Perl、PHP、Python、Ruby等各种编程语言。
Swagger总结 Swagger这类API文档工具可以满足下列需求：
支持API自动生成同步的在线文档 这些文档可用于项目内部API审核 方便测试人员了解API 这些文档可作为客户产品文档的一部分进行发布 支持API规范生成代码，生成的客户端和服务器端骨架代码可以加速开发和测试速度 跟下列其他API文档工具相比，Swagger各有优缺点，但它功能最多、也是最流行的。
RESTful API Modeling Language (RAML) apiary的API Blueprint I/O Docs Web Application Description Language (WADL) 参考 Swagger官网 GitHub：Swagger Swagger规范 SpringFox官网 GitHub：SpringFox Spring Boot &amp;amp; Swagger UI</description></item><item><title>[Spring Boot] 访问JSP</title><link>https://mryqu.github.io/post/spring_boot_%E8%AE%BF%E9%97%AEjsp/</link><pubDate>Fri, 08 May 2015 05:53:04 +0000</pubDate><guid>https://mryqu.github.io/post/spring_boot_%E8%AE%BF%E9%97%AEjsp/</guid><description>需求 我的Spring Boot web应用中用到了JSP，可是访问始终404。
@Controller public class TestController { @RequestMapping(&amp;#34;/test&amp;#34;) public String webapp(Map model) { return &amp;#34;WEB-INF/index.jsp&amp;#34;; } } 解决方案是增加tomcat-embed-jasper依赖，此外可选性地增加了jstl依赖。
Gradle dependencies { ...... // jsps providedRuntime (&amp;#39;org.apache.tomcat.embed:tomcat-embed-jasper&amp;#39;) } Maven</description></item><item><title>定制Vagrant box主机</title><link>https://mryqu.github.io/post/%E5%AE%9A%E5%88%B6vagrant_box%E4%B8%BB%E6%9C%BA/</link><pubDate>Thu, 07 May 2015 21:34:40 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%9A%E5%88%B6vagrant_box%E4%B8%BB%E6%9C%BA/</guid><description>做个笔记，记录一下如何定制Vagrant box主机。
在Vagrantfile中通过一个Vagrant基础box定制box。 启动该定制box后，通过Vagrant package命令输出box文件 编写JSON格式的box元数据文件 将定制box文件及其元数据文件放到web服务器中 将此定制box作为基础box的Vagrantfile中，设置如下 config.vm.box用于匹配上述定制box的名称 config.vm.box_url为box文件的URL或box元数据文件的URL当config.vm.box_url为box文件的URL，该box文件即为基础box；当config.vm.box_url为box元数据文件的URL，可以使用config.vm.box指定名称的某一版本box文件（有config.vm.box_version参数，即使用其约束的特定版本；否则，使用最新版本box文件）作为基础box。 config.vm.box_version指定box的特定版本。 参考 Custom Vagrant Cloud Versioned Box Host Vagrant: CREATING A BASE BOX Vagrant: MACHINE SETTINGS</description></item><item><title>找不到TTY而导致的Vagrant destroy失败</title><link>https://mryqu.github.io/post/%E6%89%BE%E4%B8%8D%E5%88%B0tty%E8%80%8C%E5%AF%BC%E8%87%B4%E7%9A%84vagrant_destroy%E5%A4%B1%E8%B4%A5/</link><pubDate>Wed, 06 May 2015 05:50:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%89%BE%E4%B8%8D%E5%88%B0tty%E8%80%8C%E5%AF%BC%E8%87%B4%E7%9A%84vagrant_destroy%E5%A4%B1%E8%B4%A5/</guid><description>在Windows的Git Bash上想要够过vagrant destroy命令删除一个Vagrant虚拟机，结果碰到了这个错误：
Vagrant is attempting to interface with the UI in a way that requires a TTY. Most actions in Vagrant that require a TTY have configuration switches to disable this requirement. Please do that or run Vagrant with TTY. 据说Windows上的Cygwin以一种奇怪的方式处理stdin导致Ruby以为没有TTY，没想到Git Bash所基于的MinGW也有这样的问题。 权变措施是使用vagrant destroy --force。</description></item><item><title>遭遇由VT-x设置导致的vagrant up失败</title><link>https://mryqu.github.io/post/%E9%81%AD%E9%81%87%E7%94%B1vt-x%E8%AE%BE%E7%BD%AE%E5%AF%BC%E8%87%B4%E7%9A%84vagrant_up%E5%A4%B1%E8%B4%A5/</link><pubDate>Tue, 05 May 2015 06:06:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%81%AD%E9%81%87%E7%94%B1vt-x%E8%AE%BE%E7%BD%AE%E5%AF%BC%E8%87%B4%E7%9A%84vagrant_up%E5%A4%B1%E8%B4%A5/</guid><description>我在同事申请的一台机器上安装Vagrant box，结果vagrant up失败，报如下错误：
The guest machine entered an invalid state while waiting for it to boot. Valid states are 'starting, running'. The machine is in the 'poweroff' state. Please verify everything is configured properly and try again. If the provider you're using has a GUI that comes with it, it is often helpful to open that and watch the machine, since the GUI often has more helpful error messages than Vagrant can retrieve.</description></item><item><title>[OpenUI5] 示例：Accordion with all initial collapsed sections</title><link>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8Baccordion_with_all_initial_collapsed_sections/</link><pubDate>Mon, 04 May 2015 00:01:32 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8Baccordion_with_all_initial_collapsed_sections/</guid><description>sap.ui.commons.Accordion会设置一个默认展开的section。
sap.ui.commons.Accordion.prototype.addSection = function(oSection) { this.addAggregation(&amp;#34;sections&amp;#34;, oSection); //Add a default opened section id if ( (this.getOpenedSectionsId() == null || this.getOpenedSectionsId() == &amp;#34;&amp;#34; ) &amp;amp;&amp;amp; oSection.getEnabled()){ this.setOpenedSectionsId(oSection.getId()); } this.aSectionTitles.push(oSection.getTitle()); }; 如果想让初始化所有section为折叠的，只要将openedSectionsId设为“-1”就可以了。 示例位置: http://jsbin.com/sajoba/1/edit?html,output</description></item><item><title>[OpenUI5] 控件ID实践与总结</title><link>https://mryqu.github.io/post/openui5_%E6%8E%A7%E4%BB%B6id%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%80%BB%E7%BB%93/</link><pubDate>Sun, 03 May 2015 06:53:44 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E6%8E%A7%E4%BB%B6id%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%80%BB%E7%BB%93/</guid><description>显式定义而不是自生成OpenUI5控件ID 为了便于开发和测试，为控件设置一个便于理解的ID尤为重要。我的博文《快速定位OpenUI5问题的一个方法》中的工具函数就是利用控件ID快速定位故障控件的。 在OpenUI5中，可在创建控件实例时使用JSON对象作为控件构造器参数。其中一个可选属性就是&amp;quot;id&amp;quot;，OpenUI5不仅用它（在&amp;quot;注册信息&amp;quot;中）追踪控件，也用在渲染控件的DOM输出。 如果没有显式指定一个控件的ID，OpenUI5框架就会使用基于实例数量的算法自生成控件ID。 自生成ID有两个缺点：
调试的时候，不容易定位使用控件的代码位置。例如，异常跟某个控件相关，如果该类型控件实例很多，很难定位该控件定义在那个视图里。 测试代码相对显式定义ID更加难写。如果对控件使用显式定义ID，相应的测试代码可以很容易通过该ID进行控件查找或验证。 控件ID命名惯例 使用驼峰式写法、有意义且语法正确的ID来反映控件的本质。 例如：
一个表单上的提交按钮，其id=&amp;ldquo;submit&amp;rdquo; 到不同图形设置的导航控件，其id=&amp;ldquo;graphNav&amp;rdquo; OpenUI5控件ID内幕 sap.ui.base.ManagedObject是OpenUI5框架包括控件在内的大部分类的父类，它的构造器里有对ID的处理：
if (!sId) { sId = this.getMetadata().uid() || jQuery.sap.uid(); } else { var preprocessor = ManagedObject._fnIdPreprocessor; sId = (preprocessor ? preprocessor.call(this, sId) : sId); var oType = DataType.getType(&amp;#34;sap.ui.core.ID&amp;#34;); if (!oType.isValid(sId)) { throw new Error(&amp;#34;\&amp;#34;&amp;#34; + sId + &amp;#34;\&amp;#34; is not a valid ID.&amp;#34;); } } this.sId = sId; sap.ui.base.ManagedObjectMetadata的ID生成代码：
(function() { var mUIDCounts = {}; function uid(sId) { jQuery.</description></item><item><title>[OpenUI5] 示例: Sorted, grouped and multi-selectable list</title><link>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8B_sorted_grouped_and_multi-selectable_list/</link><pubDate>Sat, 02 May 2015 08:14:50 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8B_sorted_grouped_and_multi-selectable_list/</guid><description>做了一个可多选、使用定制分组和排序的list示例，示例位置：http://jsbin.com/jetena/1/edit?html,output
var fGrouper = function(oContext) { var v = oContext.getProperty(&amp;#34;workbook&amp;#34;); return { key: v, text: v }; } var oSorter = new sap.ui.model.Sorter(&amp;#34;&amp;#34;, false, fGrouper); oSorter.fnCompare = function(a, b) { // Determine the group and group order var agroup = a.workbook; var bgroup = b.workbook; // Return sort result, by group ... if (agroup &amp;lt; bgroup) return -1; if (agroup &amp;gt; bgroup) return 1; // ... and then within group (when relevant) if (a.</description></item><item><title>非技术视角八卦一下docker</title><link>https://mryqu.github.io/post/%E9%9D%9E%E6%8A%80%E6%9C%AF%E8%A7%86%E8%A7%92%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bdocker/</link><pubDate>Fri, 01 May 2015 10:03:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%9D%9E%E6%8A%80%E6%9C%AF%E8%A7%86%E8%A7%92%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bdocker/</guid><description>2010年，几个大胡子年轻人在旧金山成立了一家做 PaaS平台的公司，起名为dotCloud。dotCloud是YCombinator（创投公司） S10的毕业生。 创始人：Solomon Hykes
2006年毕业于EPITECH - European Institute of Technology(硕士) 2003-2004年做过个人IT教师 2006年曾经在SmartJog担任售后工程师 2010-2013年担任dotCloud的CEO 2013年至今担任dotCloud的CTO dotCloud主要是基于 PaaS 平台为开发者或开发商提供技术服务。PaaS的概念虽好，但是由于认知、理念和技术的局限性，市场的接受度并不高，市场的规模也不够大。除 此之外，还有巨头不断进场搅局，IBM的蓝云，微软的 Azure，Amazon 的 EC2，Google 的 GAE，VMware 的 Cloud Foundry等等，可谓强敌环伺，而且强敌都不差钱，想玩多久就玩多久，想玩多大玩多大。在这种情况下，虽然 dotCloud在2011年初拿到了1000万美元的融资，但依然举步维艰。 Solomon Hykes在这种情况下，决定将自己的核心引擎开源，并让团队的核心成员参与开源项目。这个引擎的名字叫做Docker，以Go语言写成。Docker一经开源立刻得到了「业界」的热烈吹捧。这个容器管理引擎大大降低了容器技术的使用门槛，轻量级，可移植，虚拟化，语言无关，写了程序扔上去做成镜像可以随处部署和运行，Docker迅速从单纯的云端虚机限定资源环境转变成新的代码或应用发布形式，方便有集成开发、快速迭代需求的用户实现多次更新的回退和版本管理，开发、测试和生产环境彻底统一了，还能进行资源管控和虚拟化。 从此以后，他们开始专心研发 Docker 产品和维护相关社区。2013年10月 dotCloud公司更名为Docker股份有限公司，2014年8月Docker宣布把PAAS的业务「dotCloud」出售给位于德国柏林的平台即服务提供商「cloudControl」，dotCloud的历史告一段落。同年8月，Docker内部员工 James Turnbull 发布了面向开发者、运维和系统管理员的 Docker电子书《The DockerBook》。2014年9月，Docker 宣布已获 4000 万美元的 C 轮融资。 2014年6月，Microsoft Open Technology （微软开放技术）宣布 Azure开始支持Docker部署；2014年10月，微软宣布下一个版本的WindowsServer将原生支持Docker；2014年11月，AWS加码押注Docker，推出了高性能容器管理服务EC2Container服务，用户可以在AWS上使用容器轻松地运行和管理分布式应用；2014年12月，Docker宣布发布跨容器的分布式应用编排服务，编排服务可以帮助开发者创建并管理新一代的可移植的分布式应用程序。 Docker的竞争对手是CoreOS公司的容器技术Rocket，现在Rocket得到谷歌、Red Hat以及 VMware等一批大公司的支持。
参考 Docker 传奇之 dotCloud Docker，云时代的程序交付方式 Docker项目研究 Docker之父Solomon Hykes谈项目开发的初衷和挑战 解读2014之Docker篇：才气、勇气、运气 八个Docker的真实应用场景 Google支持Docker的竞争对手，云计算恩怨又起</description></item><item><title>[Hadoop] check FSDataInputStream and its wrapped InputStream implementation</title><link>https://mryqu.github.io/post/hadoop_check_fsdatainputstream_and_its_wrapped_inputstream_implementation/</link><pubDate>Fri, 01 May 2015 01:15:35 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_check_fsdatainputstream_and_its_wrapped_inputstream_implementation/</guid><description>打开一个HDFS文件，获得一个FSDataInputStream对象，其实现类到底是什么？小小探究一下。
package com.yqu.hadoop; import java.io.IOException; import java.io.InputStream; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FSDataInputStream; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; public class LearnFS { public static void main(String[] args) { Configuration config = new Configuration(); FSDataInputStream in = null; Path path = new Path(&amp;#34;/user/hadoop/input/access_log.txt&amp;#34;); try { FileSystem fs = FileSystem.get(config); System.out.println(&amp;#34;Scheme: &amp;#34; + fs.getScheme()); System.out.println(&amp;#34;Uri: &amp;#34; + fs.getUri().toString()); in = fs.open(path); if (in != null) { System.out.println(&amp;#34;FSDataInputStream impl:&amp;#34; + in.getClass().getCanonicalName()); InputStream is = in.getWrappedStream(); if (is !</description></item><item><title>[Hadoop] 安装Hadoop 2.7.x 集群</title><link>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</link><pubDate>Tue, 28 Apr 2015 23:37:27 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</guid><description>集群规划 |节点|角色 |&amp;mdash;&amp;ndash; |node50064|NameNode RessourceManager |node50069|Datanode SecondNameNode |node51054|Datanade
准备工作 （在全部机器上）创建hadoop用户 $ sudo useradd -m hadoop -s /bin/bash $ sudo passwd hadoop $ sudo adduser hadoop sudo （在全部机器上）配置/etc/hosts 10.120.12.135 node50064.mryqu.com node50064 10.120.11.201 node50069.mryqu.com node50069 10.120.14.226 node51054.mryqu.com node51054 （在全部机器上）禁止掉IPv6 参见之前的博文在Ubuntu中禁掉IPv6。
（在全部机器上）关闭防火墙 ufw disable //关闭 sudo apt-get remove ufw //卸载 sudo ufw status //查看 （在全部机器上）安装并配置Java JDK 安装Java JDK：
$ sudo apt-get update $ sudo apt-get install openjdk-7-jre openjdk-7-jdk 通过下列命令确定JDK安装路径为/usr/lib/jvm/java-7-openjdk-amd64： 通过sudovi /etc/profile添加如下内容：
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64 export CLASSPATH=.</description></item><item><title>阅读《Microservice Design Patterns》</title><link>https://mryqu.github.io/post/%E9%98%85%E8%AF%BBmicroservice_design_patterns/</link><pubDate>Tue, 28 Apr 2015 05:51:47 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%98%85%E8%AF%BBmicroservice_design_patterns/</guid><description>Java Code Geeks有一篇文章Microservice Design Patterns，提供了六种微服务架构的设计模式，用于组合微服务。
聚合器微服务设计模式
这是一种最常用也最简单的设计模式，如下图所示：
聚合器调用多个服务实现应用程序所需的功能。它可以是一个简单的Web页面，将检索到的数据进行处理展示。它也可以是一个更高层次的组合微服务，对检索到的数据增加业务逻辑后进一步发布成一个新的微服务，这符合DRY原则。另外，每个服务都有自己的缓存和数据库。如果聚合器是一个组合服务，那么它也有自己的缓存和数据库。聚合器可以沿X轴和Z轴独立扩展。
代理微服务设计模式
这是聚合器模式的一个变种，如下图所示：
在这种情况下，客户端并不聚合数据，但会根据业务需求的差别调用不同的微服务。代理可以仅仅委派请求，也可以进行数据转换工作。一个很好的实例就是针对不同设备的表现层可以封装在代理微服务内。
链式微服务设计模式
这种模式在接收到请求后会产生一个经过合并的响应，如下图所示：
在这种情况下，服务A接收到请求后会与服务B进行通信，类似地，服务B会同服务C进行通信。所有服务都使用同步消息传递。在整个链式调用完成之前，客户端会一直阻塞。因此，服务调用链不宜过长，以免客户端长时间等待。
分支微服务设计模式
这种模式是聚合器模式的扩展，允许同时调用两个微服务链，如下图所示：
数据共享微服务设计模式
自治是微服务的设计原则之一，就是说微服务是全栈式服务。但在重构现有的“单体应用（monolithicapplication）”时，SQL数据库反规范化可能会导致数据重复和不一致。因此，在单体应用到微服务架构的过渡阶段，可以使用这种设计模式，如下图所示：
在这种情况下，部分微服务可能会共享缓存和数据库存储。不过，这只有在两个服务之间存在强耦合关系时才可以。对于基于微服务的新建应用程序而言，这是一种反模式。
异步消息传递微服务设计模式
虽然REST设计模式非常流行，但它是同步的，会造成阻塞。因此部分基于微服务的架构可能会选择使用消息队列代替REST请求/响应，如下图所示：
感兴趣的读者可以参考《微服务中的耦合与自治》一文为自己的微服务选择合适的消息传递模式。</description></item><item><title>了解混合持久化（Polyglot Persistence）</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96polyglot_persistence/</link><pubDate>Mon, 27 Apr 2015 05:58:13 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96polyglot_persistence/</guid><description>开发web程序的最早期时间，最被广泛使用的企业程序架构是将程序的服务器端组件打包为单个单元。很多企业Java应用程序由单个WAR或EAR文件组成。其它语言（比如Ruby，甚至C++）编写的应用程序也大抵如此。这种单体架构模式(monolithicapplication architecturepattern)往往通过一个数据访问层与单一类型的数据库相连接，所有不同用途的数据存储都存储在该数据库内。 数据库环境在过去的十多年里增长巨大。每个新出现的数据库相较于其它数据库，都在某些方面有着优势，但同时它们也做了各种各样的折衷。事实上，根据CAP定理不可能拥有完美的数据库，我们需要根据应用程序来选择哪种折衷是可接受的。带有这些约束的工作场景符合Martin Fowler推广的混合持久化思路。混合持久化的思路是指，你应该根据工作的不同需求选择相应合适的数据库，这样我们就能两者兼得了。 混合持久化的优点显而易见：一个复杂的企业应用程序会使用很多类型的数据，对每种数据采用最适合的存储技术，可以带来性能的提升。随着微服务架构模式（Microservicearchitecturepattern）越来越受欢迎，复杂的企业应用程序将会被分解成很多的微服务，每个微服务内将对所操作的数据采用最适合的存储技术。
混合持久化的缺点也同样鲜明：以增加复杂性为代价。每种数据存储机制都有其学习成本，选择正确的数据存储也有决策成本。需要了解每种数据存储的性能瓶颈并不断迎接挑战。
Martin Fowler建议对战略性的项目采用混合持久化，这样才能通过新技术获得足够收益。
参考 Polyglot Persistence The featuer is: Polyglot Persistence NoSQL精粹 第13章混合持久化</description></item><item><title>Git+Gerrit+Gradle+Jenkins持续集成</title><link>https://mryqu.github.io/post/git+gerrit+gradle+jenkins%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/</link><pubDate>Sun, 26 Apr 2015 07:45:11 +0000</pubDate><guid>https://mryqu.github.io/post/git+gerrit+gradle+jenkins%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/</guid><description>随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile）在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。
Gerrit Gerrit是基于GWT web应用的开源代码审查系统，为使用Git版本控制系统的项目提供在线代码审查。安卓开源项目（AOSP）用其来管理多代码库的庞大项目。Gerrit通过在自身代码库跟踪提交的Git变更集来提供代码审查的。它并排显示新旧文件，让审查者更容易对变更进行审查，并允许审查者添加内嵌注释。 提交的变更既可以被Jenkins这样的自动系统进行审查，也可以由同事进行审查。每个审查者检查代码变更、添加注释，然后将变更标记为“在我看来代码不错”(“没有打分”或“我期望你不要提交代码”)。验证者(例如Jenkins或其他人)通过构建和测试代码来验证变更。如果他们认为代码可行，则设置“在我看来代码不错”标记，Gerrit将尝试将变更合并到公开的“权威”代码库。文章Life of a Patch描述了这一工作流: Gradle 在Java构建工具的世界里，先有了Ant，然后有了Maven。Maven的CoC（约定优于配置）、依赖管理以及项目构建规则重用性等特点，让Maven几乎成为Java构建工具的事实标准。然而，冗余的依赖管理配置、复杂并且难以扩展的构建生命周期，都成为使用Maven的困扰。Gradle作为新的构建工具，是基于Groovy语言的构建工具，既保持了Maven的优点，又通过使用Groovy定义的DSL克服了Maven中使用XML繁冗以及不灵活等缺点，支持依赖管理和多项目，而且它有非常完善的说明文档。目前，SpringSource、Hibernate等都采用Gradle来构建。
Jenkins Jenkins，之前叫做Hudson，是一个开源项目，提供了一种易于使用的持续集成系统，使开发者从繁杂的集成中解脱出来，专注于更为重要的业务逻辑实现上。同时Jenkins能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。Jenkins通过Gerrit触发器插件可在新的Gerrit补丁集创建时开始使用Gerrit代码库中的代码进行构建项目，通过Gradle插件调用Gradle构建脚本，以帮助变更验证。
参考 Git权威指南-第5篇-第32章 Gerrit 代码审核服务器 Git+Gerrit+Gradle+Jenkins持续集成设置</description></item><item><title>《The Art of Scalability》中的三维伸缩性模型</title><link>https://mryqu.github.io/post/the_art_of_scalability%E4%B8%AD%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BC%B8%E7%BC%A9%E6%80%A7%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 25 Apr 2015 15:32:52 +0000</pubDate><guid>https://mryqu.github.io/post/the_art_of_scalability%E4%B8%AD%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BC%B8%E7%BC%A9%E6%80%A7%E6%A8%A1%E5%9E%8B/</guid><description>最近又搜集到Martin L. Abbott和Michael T. Fisher的两本好书：
The Art of Scalability Scalability Rules：50 Principles for Scaling Web Sites 第一本书将近六百页，最近没时间看，就先粗略学习一下其中的三维伸缩性模型： 在该模型中，将应用程序水平复制，通过负载均衡运行应用程序的多个完全一样的副本的方式来实现应用程序伸缩性，这种方式称为X轴伸缩性。这是一种很好的方式来提高应用程序的容量和可用度。 当使用Z轴伸缩性，每个服务器运行代码的一个完全相同的副本。在该方面，它与X轴伸缩性很相似。最大的不同是每个服务器只负责数据的一个子集。该系统的一些组件负责将每个请求路由给适当的服务器。一个常见的路由规则是把请求的一个属性作为被访问的实体的主键，比如分区。另一个常见的路由规则是客户类型。例如，应用程序可以向付费用户提供比免费用户更高的SLA，实现方式是将付费用户的请求路由到具有更高容量的一组服务器上。 Z轴伸缩性与X轴伸缩性类似，提高了应用程序的容量和可用度。然而，没有任何一个方式能够解决不断增加的开发工作和程序复杂度的问题。解决这些问题需要Y轴伸缩性。 伸缩性的第三个维度是针对功能性分解的Y轴伸缩性。Y轴伸缩性与Z轴伸缩性分解事情的方式相似但有不同。在应用程序层级，Y轴伸缩性将单体应用程序拆分成一组服务。每个服务实现了一组相关的功能特性，例如订单管理，客户管理等。 决定如何将系统分割为一组服务更像是一门艺术，但是可借助于一些策略。一种方式是通过动词或使用情况拆分服务。另一个拆分方式是通过名词或资源分割系统。这种服务负责处理给定的实体/资源的所有操作。 Unix提供了大量的工具，比如grep，cat和find。每个工具只做一件事，效果往往非常好，并且可以使用shell脚本组合多个工具以执行复杂的任务。服务分割也应采用类似的策略。</description></item><item><title>阅读《Microservices, Monoliths, and NoOps》</title><link>https://mryqu.github.io/post/%E9%98%85%E8%AF%BBmicroservices_monoliths_and_noops/</link><pubDate>Sat, 25 Apr 2015 00:10:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%98%85%E8%AF%BBmicroservices_monoliths_and_noops/</guid><description>Java Code Geeks有一篇文章Microservices, Monoliths, and NoOps，分析了单体应用与微服务的优缺点，并建议使用微服务重构现有的应用程序。
单体应用 通俗地讲，“单体应用（monolithapplication）”就是将应用程序的所有功能都打包成一个独立的单元，可以是JAR、WAR、EAR或其它归档格式。
单体应用优点 单体应用有如下优点：
为人所熟知：现有的大部分工具、应用服务器、框架和脚本都是这种应用程序； IDE 友好：像NetBeans、Eclipse、IntelliJ这些开发环境都是针对开发、部署、调试这样的单个应用而设计的； 便于共享：单个归档文件包含所有功能，便于在团队之间以及不同的部署阶段之间共享； 易于测试：单体应用一旦部署，所有的服务或特性就都可以使用了，这简化了测试过程，因为没有额外的依赖，每项测试都可以在部署完成后立刻开始； 容易部署：只需将单个归档文件复制到单个目录下。 单体应用缺点 目前为止，单体应用已经很好地服务了我们，未来无疑还会继续发挥重要作用。但是，不管如何模块化，单体应用最终都会因为团队壮大、成员变动、应用范围扩展等出现问题。下面是单体应用的一些不足：
不够灵活：对应用程序做任何细微的修改都需要将整个应用程序重新构建、重新部署。开发人员需要等到整个应用程序部署完成后才能看到变化。如果多个开发人员共同开发一个应用程序，那么还要等待其他开发人员完成了各自的开发。这降低了团队的灵活性和功能交付频率； 妨碍持续交付：单体应用可能会比较大，构建和部署时间也相应地比较长，不利于频繁部署，阻碍持续交付。在移动应用开发中，这个问题会显得尤为严重； 受技术栈限制：对于这类应用，技术是在开发之前经过慎重评估后选定的，每个团队成员都必须使用相同的开发语言、持久化存储及消息系统，而且要使用类似的工具，无法根据具体的场景做出其它选择； 技术债务：“不坏不修（Not broken，don’tfix）”，这在软件开发中非常常见，单体应用尤其如此。系统设计或写好的代码难以修改，因为应用程序的其它部分可能会以意料之外的方式使用它。随着时间推移、人员更迭，这必然会增加应用程序的技术债务。 什么是微服务？ 而随着业务需求的快速发展变化，敏捷性、灵活性和可扩展性需求不断增长，迫切需要一种更加快速高效的软件交付方式。微服务就是一种可以满足这种需求的软件架构风格。单体应用被分解成多个更小的服务，每个服务有自己的归档文件，单独部署，然后共同组成一个应用程序。这里的“微”不是针对代码行数而言，而是说服务的范围限定到单个功能。
微服务的特征 微服务有如下特征：
领域驱动设计：应用程序功能分解可以通过Eric Evans在《领域驱动设计》中明确定义的规则实现，领域驱动设计不是分解应用程序的唯一方法，但肯定是很常用的一种；每个团队负责与一个领域或业务功能相关的全部开发；团队遵循全栈开发方法拥有全系列的开发人员，具备用户界面、业务逻辑和持久化存储等方面的开发技能； 单一职责原则：每个服务应该负责该功能的一个单独的部分，这是SOLID原则之一，Unix工具程序很好地证明这一原则的重要性； 明确发布接口：每个服务都会发布一个定义明确的接口，而且保持不变；服务消费者只关心接口，而对于被消费的服务没有任何运行依赖；服务之间就业务模型、API、负载或其他契约达成一致并使用符合契约的方式进行通信。接口可能会产生新版本，但接口的老版本可以继续使用，且新服务保持后续兼容。不可以通过改变契约破坏兼容性。 独立部署、升级、扩展和替换：每个服务都可以单独部署及重新部署而不影响整个系统。这使得服务很容易升级，例如增加更多的功能点。每个服务都可以沿着《Art of Scalability》一书定义的X轴（水平复制）和Z轴（面向查询的分割，数据分区）进行独立扩展；由于其他服务仅依赖发布的接口，只要发布相同的契约，服务实现甚至是底层技术栈都可以修改； 可以异构/采用多种语言：每个服务的实现细节都与其它服务无关，这使得服务之间能够解耦，团队可以针对每个服务选择最合适的开发语言、持久化存储、工具和方法；一个需要在关系型数据库存储数据的服务可以选择MySQL，另一个需要存储文档的服务可以选择MongoDB。不同的团队可以根据自己的需求选择JavaEE、NodeJS、Python、Vert.x或其他对本团队最有效的技术； 轻量级通信：服务通信使用轻量级的通信协议，例如在HTTP上承载的REST。由于REST本质是同步的，可能会有某些潜在的瓶颈。另一个可选机制是使用支持异步消息的发布/订阅机制。任何符合需求的消息协议，例如AMQP、STOMP、MQTT或WebSocket，都可以使用。简单消息实现，例如ActiveMQ，提供了可靠的异步组构尤其适用于这种用途。每个开发团队可以根据服务的具体需求对同步还是异步消息做适宜的选择，当然也可以混用。 Netflix是微服务的一个典型代表，这里有几篇文章介绍他们对微服务的应用。
Netflix&amp;rsquo;s Viewing Data: How We Know Where You Are in House of Cards A Microscope on Microservices Scalable Microservices at Netflix. Challenges and Tools of the Trade Adopting Microservices at Netflix: Lessons for Architectural Design 很多增强Netflix微服务架构的工具可在netflix.</description></item><item><title>了解OSM和Esri</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3osm%E5%92%8Cesri/</link><pubDate>Wed, 22 Apr 2015 00:15:13 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3osm%E5%92%8Cesri/</guid><description>学习SAS Visual Analytics Explorer时看到了地图提供程序模式竟然没有GoogleMap，而是OpenStreetMap和Esri。对没接触过的东东还比较好奇，搜了一下。
OpenStreetMap 开放街道地图（OpenStreetMap，简称OSM）是一个由地图制作爱好者组成的社区。这些爱好者提供并维护世界各地关于道路、小道、咖啡馆、铁路车站等各种各样的数据，目标是创造一个内容自由且能让所有人编辑的世界地图，并且让一般便宜的移动设备有方便的导航方案。OSM项目由英国人SteveCoast创立，概念启发自维基百科网站，以及英国以及其他地区私有地图数据占尽优势。一如维基百科等网站，OSM网站地图页有“编辑”按钮，亦有纪录修订历史。经注册的用户可上传GPS路径，及可编辑地图的矢量数据，包括使用OSM网站的编辑器或其他自由地理信息系统软件，如JOSM。OSM的地图由用户根据手持GPS设备、航空摄影照片、卫星视频、其他自由内容以至单靠用户由于对有关区域的熟悉而具有的本地知识绘制。地图的矢量数据以开放数据库授权方式授权。OSM网站由英国非营利组织OpenStreetMap基金会赞助维运。
既然有Google和Nokia这样的公司提供很好的地图商业产品，那为什么还需要一个像OpenStreetMap项目了？答案是简单的，作为一个社会，不应当有一家或几家公司在地理信息上进行垄断。地理信息是分享资源，当你将所有的这些权力给予一个单独的实体，你给予他们的权力就不止是告诉他们你的地理位置，更是在塑造它，从自己商业利益的角度显示地图上的内容。而在地图内容方面，OpenStreetMap即是中立的又是透明的。
Esri 美国环境系统研究所公司（Environmental Systems Research Institute,Inc.，简称Esri），是目前世界最大的地理信息系统技术供应商，其地理信息系统软件目前的全球市场占有率最高，公司最知名产品为ArcGIS。ArcGISOnline是一个面向全球用户的公有云GIS平台，是一种全新的GIS软件应用模式。ArcGISOnline包含了全球范围内的底图、地图数据、应用程序，以及可配置的应用模板和开发人员使用的 GIS 工具和 API，可用于创建Web 地图、发布GIS服务、共享地图、数据和应用程序等，以及管理组织的内容和多个用户。
SAS Visual Analysis Explorer里面在Esri模式下还需要选择ArcGISOnline的数据源（例如World Cities、World Street Map）。
参考 OpenStreetMap网站 Esri公司 Wiki: 开放街图 为什么世界需要 OpenStreetMap 开源道路地图 Wiki: 美国环境系统研究所公司</description></item><item><title>Jenkins超时设置</title><link>https://mryqu.github.io/post/jenkins%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE/</link><pubDate>Tue, 21 Apr 2015 05:15:55 +0000</pubDate><guid>https://mryqu.github.io/post/jenkins%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE/</guid><description>Jenkins在构建部署镜像时发生超时：
Build timed out (after 10 minutes). Marking the build as aborted. Build was aborted Finished: ABORTED 解决方法是在Jenkins当前项目下点击Configure菜单后，在BuildEnvironment配置项里修改超时策略。我把超时绝对值改大点就好了。</description></item><item><title>使用Vagrant Box</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8vagrant_box/</link><pubDate>Mon, 20 Apr 2015 06:07:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8vagrant_box/</guid><description>//Download a box to local disk $ vagrant box add my-box /path/to/the/new.box ... $ vagrant init my-box ... $ vagrant up ...</description></item><item><title>[Hadoop] 消除WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform.</title><link>https://mryqu.github.io/post/hadoop_%E6%B6%88%E9%99%A4warn_util.nativecodeloader_unable_to_load_native-hadoop_library_for_your_platform/</link><pubDate>Sun, 19 Apr 2015 06:40:44 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E6%B6%88%E9%99%A4warn_util.nativecodeloader_unable_to_load_native-hadoop_library_for_your_platform/</guid><description>启动DFS或者执行hadoop fs命令总是得到告警util.NativeCodeLoader: Unable to load native-hadooplibrary for your platform&amp;hellip; using builtin-java classes whereapplicable：
hadoop@node50064:~$ start-dfs.sh 15/04/18 01:55:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Starting namenodes on [node50064.mryqu.com] node50064.mryqu.com: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-node50064.out node50069.mryqu.com: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-node50069.out node51054.mryqu.com: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-node51054.out Starting secondary namenodes [node50069.mryqu.com] node50069.mryqu.com: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-node50069.out 15/04/18 01:55:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform.</description></item><item><title>[JPA] 重温CascadeType</title><link>https://mryqu.github.io/post/jpa_%E9%87%8D%E6%B8%A9cascadetype/</link><pubDate>Sat, 18 Apr 2015 00:18:50 +0000</pubDate><guid>https://mryqu.github.io/post/jpa_%E9%87%8D%E6%B8%A9cascadetype/</guid><description>今天看了一篇帖子A beginner’s guide to JPA and Hibernate Cascade Types，对JPA/Hibernate中OneToOne、OneToMany、Many-To-Many关系下CascadeType的使用讲的很详尽，有代码示例也有SQL输出。作者VladMihalcea，著有High-Performance Java Persistence一书，应该淘一本学习学习。</description></item><item><title>[Gradle] 输出依赖包</title><link>https://mryqu.github.io/post/gradle_%E8%BE%93%E5%87%BA%E4%BE%9D%E8%B5%96%E5%8C%85/</link><pubDate>Thu, 16 Apr 2015 06:13:52 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E8%BE%93%E5%87%BA%E4%BE%9D%E8%B5%96%E5%8C%85/</guid><description>下面我以https://spring.io/guides/gs/spring-boot/中的gs-spring-boot项目为例，使用Gradle输出依赖包。
首先对build.gradle做如下修改：
buildscript { repositories { mavenCentral() } dependencies { classpath(&amp;#34;org.springframework.boot:spring-boot-gradle-plugin:1.2.2.RELEASE&amp;#34;) } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#39;spring-boot&amp;#39; jar { baseName = &amp;#39;gs-spring-boot&amp;#39; version = &amp;#39;0.1.0&amp;#39; } repositories { mavenCentral() } sourceCompatibility = 1.8 targetCompatibility = 1.8 task copyToLib(type: Copy) { print configurations into &amp;#34;$buildDir/dep-libs&amp;#34; from configurations.runtime } build.dependsOn(copyToLib) dependencies { compile(&amp;#34;org.springframework.boot:spring-boot-starter-web&amp;#34;) // tag::actuator[] compile(&amp;#34;org.springframework.boot:spring-boot-starter-actuator&amp;#34;) // end::actuator[] // tag::tests[] testCompile(&amp;#34;org.springframework.boot:spring-boot-starter-test&amp;#34;) // end::tests[] } 首先可以在命令行中看到：</description></item><item><title>[Gradle] 执行Java类</title><link>https://mryqu.github.io/post/gradle_%E6%89%A7%E8%A1%8Cjava%E7%B1%BB/</link><pubDate>Wed, 15 Apr 2015 18:32:08 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E6%89%A7%E8%A1%8Cjava%E7%B1%BB/</guid><description>需求 我想用Gradle脚本执行下列Java类Hello123.java：
import java.util.Arrays; public class Hello123 { public static void main(String[] args) { System.out.println(&amp;#34;args:&amp;#34;+ Arrays.toString(args)); } } 测试一：创建execute任务 build.gralde apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; task execute(type: { main = System.getProperty(&amp;#34;exec.mainClass&amp;#34;) classpath = sourceSets.main.runtimeClasspath systemProperties System.getProperties() if(System.getProperty(&amp;#34;exec.args&amp;#34;)) args System.getProperty(&amp;#34;exec.args&amp;#34;).split() } sourceCompatibility = 1.8 targetCompatibility = 1.8 测试结果 测试二：重写run任务 build.gralde apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; apply plugin: &amp;#34;application&amp;#34; mainClassName = &amp;#34;NonExistentClass&amp;#34; task run (type: { main = System.</description></item><item><title>[Gradle] 阻止build任务执行测试任务</title><link>https://mryqu.github.io/post/gradle_%E9%98%BB%E6%AD%A2build%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E6%B5%8B%E8%AF%95%E4%BB%BB%E5%8A%A1/</link><pubDate>Tue, 14 Apr 2015 05:53:30 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E9%98%BB%E6%AD%A2build%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E6%B5%8B%E8%AF%95%E4%BB%BB%E5%8A%A1/</guid><description>在执行gradle build时想要阻止执行测试任务，方法如下：
第一种方法：如Gradle用户指南的14.8 Skipping tasks所说，在build.gradle里设置&amp;quot;test.enabled=false&amp;quot;，执行gradle build 第二种方法：在build.gradle里设置&amp;quot;check.dependsOn.remove(test)&amp;quot;，执行gradle build 第三种方法：执行gradle build -x test</description></item><item><title>[Gradle] 强制重新下载依赖</title><link>https://mryqu.github.io/post/gradle_%E5%BC%BA%E5%88%B6%E9%87%8D%E6%96%B0%E4%B8%8B%E8%BD%BD%E4%BE%9D%E8%B5%96/</link><pubDate>Mon, 13 Apr 2015 05:49:35 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%BC%BA%E5%88%B6%E9%87%8D%E6%96%B0%E4%B8%8B%E8%BD%BD%E4%BE%9D%E8%B5%96/</guid><description>强制Gradle重新下载依赖的方式有两种：
在Gradle命令中加入&amp;ndash;refresh-dependencies选项。该选项会让Gradle忽略已解析模块和构件的所有缓存项，对所配置的仓库重新进行解析，动态计算版本、更新模块和下载构件。 删除Gralde的缓存目录~/.gradle/caches。这个有点过于粗暴。 示例：
gradlew clean --refresh-dependencies build bootRun</description></item><item><title>学习Gradle</title><link>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0gradle/</link><pubDate>Sun, 12 Apr 2015 00:08:35 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0gradle/</guid><description>当前参与的SAS Workflow2.0原型开发项目，美国那边的项目组经营将代码编译脚本从Ant切换成Gradle了。此外我司已经在去年就将Gradle列入了技术雷达的正式采用象限，感觉有必要学习一下Gradle，扩充自己的开发能力。 Gradle官网上提供的图书信息链接中有两本免费O&amp;rsquo;Reilly出版社图书：
Building and Testing With Gradle Gradle Beyond the Basics一般软件官网文档质量不错的情况下，我优先阅读最新的官网文档，所以我先看了《Gradle入门》和《Gradle用户指南》。 参考 Gradle官网 Gradle文档 Spring提供的Gradle入门 Gradle用户指南 Groovy官网 Groovy++ Java Build Tools: Ant vs Maven vs Gradle</description></item><item><title>尝试Bootply和Codeply</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95bootply%E5%92%8Ccodeply/</link><pubDate>Sat, 11 Apr 2015 00:28:19 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95bootply%E5%92%8Ccodeply/</guid><description>Bootply Bootply被称为是Bootstrap的活动平台。它不但是一个Bootstrap的编辑器和生成器，同时也拥有非常广泛的代码库。Bootply编辑器可以让你拖拽Bootstrap组件并可以编辑你自己的代码。 Bootply同时整合了其他流行的Bootstrap插件、微型代码库和框架。你也可以借助其他工具的使用像FontAwesome, jQuery + jQuery UI, Bootstrap Select, FuelUX, AngularJS,Google Maps 等等。 Codeply Codeply是
一个HTML/CSS/JavaScript编辑器 一个响应式设计活动平台和开发工具 一个Web设计者和前段开发者的社区 一个代码片段和示例的代码仓库 Codeply编辑器也可以让你拖拽Bootstrap组件并可以编辑你自己的代码。 Codeply也整合了很多响应式框架和代码库。 响应式框架 Bootstrap3 Foundation Kube MaterializeCSS NoFramework PureCSS SemanticUI Skeleton Unsemantic 可用的JS和CSS库 Angular AngularAnimate AngularAria AngularMaterial AngularUI AngularUI Bootstrap AnimateCSS Backbone BootstrapDatepicker BootstrapSelect DropZone Ember Ember.js FastClick FontAwesome FullCalendar GoogleMaps API Hammer.js Handlebars.js Ionic Isotope Jasny jQueryUI Knockout Masonry Minicolors PrototypeJs Raphael RequireJs UnderscoreJs 此外，Codeply还能针对不同大小的屏幕进行测试。 参考 Bootply网站
Codeply网站
15 Best Bootstrap Tools for Designers</description></item><item><title>GoJS国际化和本地化支持</title><link>https://mryqu.github.io/post/gojs%E5%9B%BD%E9%99%85%E5%8C%96%E5%92%8C%E6%9C%AC%E5%9C%B0%E5%8C%96%E6%94%AF%E6%8C%81/</link><pubDate>Fri, 10 Apr 2015 05:50:49 +0000</pubDate><guid>https://mryqu.github.io/post/gojs%E5%9B%BD%E9%99%85%E5%8C%96%E5%92%8C%E6%9C%AC%E5%9C%B0%E5%8C%96%E6%94%AF%E6%8C%81/</guid><description>查了一下GoJS国际化支持文档，藏的还挺深，放在GoJS 部署里了。
GoJS应用可以显示非拉丁语文本。示例可见Japanese Family Tree. GoJS不操作货币值、日期值或地址，因此对这些数据类型没有本地化问题；GoJS不包含任何自己的图标（图像）或光标。 GoJS不显示任何内建文本字符串，因此无需转换工作。用于往控制台输出的错误和告警消息仅用于程序员调试，而不会面向最终用户。当读写JSON、几何路径字符串或CSS颜色时，其中的数值读写仅用于内部使用且为非本地化格式。 所有用户可见文本都完全在程序员的控制之下。为了本地化，可以很方便地使用Binding中的转换函数。TextEditingTool使用HTMLTextArea元素实现原地文本输入和编辑，从而利用浏览器对输入法编辑器的支持。
GoJS不像OpenUI5那样根据Locale相应从I18Nproperties文件获取本地化文本，而是通过下列方式提供国际化和本地化支持：
提供显示非拉丁语文本的能力 将自身摘出来，确保自身实现没有国际化和本地化的要求 将一切国际化的工作推出去，程序员可以直接设置国际化显示文本，也可以实现Binding(targetprop,sourceprop, conv)中的转换工具方法在客户端进行本地化。</description></item><item><title>GoJS中的类</title><link>https://mryqu.github.io/post/gojs%E4%B8%AD%E7%9A%84%E7%B1%BB/</link><pubDate>Thu, 09 Apr 2015 06:06:24 +0000</pubDate><guid>https://mryqu.github.io/post/gojs%E4%B8%AD%E7%9A%84%E7%B1%BB/</guid><description>GoJS中的类 GoJS API文档介绍了GoJS中的类，不过在调试GoJS时发现有3个类不是通过go对象访问的。此外有14个类有介绍，但没有显示在左侧导航栏里。GoJS的很多类、方法和属性名都是经过混淆的，不过起码这一层还是很好对上号的。 Diagram ClassesAdornmentAdornmentAnimationManager&amp;nbsp;CommandHandlerCommandHandlerDiagramDiagramDiagramEventDiagramEventGraphObjectGraphObjectGroupGroupInputEventInputEventLayerLayerLinkLinkNodeNodeOverviewOverviewPalettePalettePanelPanelPartPartPicturePicturePlaceholderPlaceholderRowColumnDefinitionRowColumnDefinitionShapeShapeTextBlockTextBlockGeometry ClassesBrushBrushGeometryGeometryMarginMarginPathFigurePathFigurePathSegmentPathSegmentPointPointRectRectSizeSizeSpotSpotModel ClassesBindingBindingChangedEventChangedEventGraphLinksModelGraphLinksModelModelModelTransactionTransactionTreeModelTreeModelUndoManagerUndoManagerLayout ClassesCircularLayoutCircularLayoutCircularNetworkCircularVertexCircularEdgeForceDirectedLayoutForceDirectedLayoutForceDirectedNetworkForceDirectedVertexForceDirectedEdgeGridLayoutGridLayoutLayeredDigraphLayoutLayeredDigraphLayoutLayeredDigraphNetworkLayeredDigraphVertexLayeredDigraphEdgeLayoutLayoutLayoutNetworkLayoutNetworkLayoutVertexLayoutEdgeTreeLayoutTreeLayoutTreeNetworkTreeVertexTreeEdgeTool ClassesActionToolActionToolClickCreatingToolClickCreatingToolClickSelectingToolClickSelectingToolContextMenuToolContextMenuToolDraggingToolDraggingToolDragSelectingToolDragSelectingToolLinkingBaseToolLinkingBaseToolLinkingToolLinkingToolLinkReshapingToolLinkReshapingToolPanningToolPanningToolRelinkingToolRelinkingToolResizingToolResizingToolRotatingToolRotatingToolTextEditingToolTextEditingToolToolToolToolManagerToolManagerCollection ClassesIterableIteratorListListMapMapSetSet GoJS类图</description></item><item><title>图表工具JS库</title><link>https://mryqu.github.io/post/%E5%9B%BE%E8%A1%A8%E5%B7%A5%E5%85%B7js%E5%BA%93/</link><pubDate>Wed, 08 Apr 2015 05:53:33 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9B%BE%E8%A1%A8%E5%B7%A5%E5%85%B7js%E5%BA%93/</guid><description>由于目前工作用到GoJS，所有也关注一下图表工具JS库。 10 JavaScript libraries to draw your own diagrams一文给出了10个JS库的功能分析和比较图表。
|库|许可|语言 / 基础架构|高/低级|内建编辑器|Github (04/02/2015) |&amp;mdash;&amp;ndash; |JointJS|MPL|HTMLJavascriptSVG|高|无|1388星265分支（fork） |Rappid|商业1 500,00 €|HTMLJavascriptSVG|高|有| |Mxgraph|商业4300.00 €|HTMLJavascriptSVG|高|有| |GoJS|商业$1,350.00|HTMLCanvasJavascript|高|有| |Raphael|MIT|HTMLJavascriptSVG|低|无|7105星1078分支（fork） |Draw2D|GPL2商业|HTMLJavascriptSVG|中|无| |D3|BSD|HTMLJavascriptSVG|低|无|36218星9142分支（fork） |FabricJS|MIT|HTMLCanvasjavasript|低|无|4127星705分支（fork） |paperJS|MIT|HTMLCanvasjavascript|低|无|4887星496分支（fork） |JsPlumb|MIT/GPL2|HTMLJavascript|中|无|2161星563分支（fork）
这里面D3在数据科学领域成绩比计突出，是数据可视化的一个重要工具。此外我在接触过的开源项目有几个用到了Raphael（包括Activiti）。其他库还没有接触过。 我为什么选择 D3.js一文中将D3和Raphael进行了对比。Raphael是一个矢量图的API，专注于对矢量图形的操作。D3是一个数据可视化展示的API，通过数据与图形进行绑定。 图表工具JS库除了上面帖子提及的外，还有很多。如果有机会的话，我会在GoJS之外更多关注D3和Raphael。</description></item><item><title>[Gradle] 设置项目属性的三种方式</title><link>https://mryqu.github.io/post/gradle_%E8%AE%BE%E7%BD%AE%E9%A1%B9%E7%9B%AE%E5%B1%9E%E6%80%A7%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</link><pubDate>Tue, 07 Apr 2015 05:36:16 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E8%AE%BE%E7%BD%AE%E9%A1%B9%E7%9B%AE%E5%B1%9E%E6%80%A7%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid><description>命令行 gradle bootRun -PyquPropKey=yquPropValue build.properties yquPropKey=yquPropValue gradle.properties 添加ext块：
ext { yquPropKey=yquPropValue }</description></item><item><title>Python: installing pymongo with Anaconda</title><link>https://mryqu.github.io/post/python_installing_pymongo_with_anaconda/</link><pubDate>Sat, 04 Apr 2015 00:06:03 +0000</pubDate><guid>https://mryqu.github.io/post/python_installing_pymongo_with_anaconda/</guid><description>在Anaconda发行版Python上通过conda install pymongo安装MongoDBpython驱动，结果失败了，最终通过conda install -c https://conda.binstar.org/anaconda pymongo安装成功。
BinstarBinstar和Anaconda都是同一家的产品，是Continuum Analytics推出的一个包管理服务，托管公开的pip和conda。 安装记录如下：
C:\tools\Anaconda&amp;gt;conda list # packages in environment at C:\tools\Anaconda: # _license 1.1 py27_0 anaconda 2.0.1 np18py27_0 argcomplete 0.6.7 py27_0 astropy 0.3.2 np18py27_0 atom 0.3.7 py27_0 backports.ssl-match-hostname 3.4.0.2 beautiful-soup 4.3.1 py27_0 beautifulsoup4 4.3.1 binstar 0.5.3 py27_0 bitarray 0.8.1 py27_1 blaze 0.5.0 np18py27_1 blz 0.6.2 np18py27_0 bokeh 0.4.4 np18py27_1 boto 2.28.0 py27_0 casuarius 1.1 py27_0 cdecimal 2.3 py27_1 chaco 4.4.1 np18py27_0 colorama 0.2.7 py27_0 conda 3.</description></item><item><title>[Hadoop] Windows平台编译Hadoop2.6.0笔记</title><link>https://mryqu.github.io/post/hadoop_windows%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91hadoop2.6.0%E7%AC%94%E8%AE%B0/</link><pubDate>Thu, 02 Apr 2015 05:25:54 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_windows%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91hadoop2.6.0%E7%AC%94%E8%AE%B0/</guid><description>环境 64位虚拟机及64位 Windows Server 2008 R2
所需工具 JDK7 Maven .NET Framework 4 Microsoft Windows SDK 7.1 安装前一定要先卸载比Microsoft Visual C++ 2010 x86Redistributable - 10.0.30319 更高的版本。 Microsoft Visual C++ 2010 Service Pack 1 Compiler Update for the Windows SDK 7.1 Cygwin (x64) Protocol Buffers 2.5.0 CMake 3.2.1 安装时选择添加CMake到所有用户的PATH环境变量。 hadoop-2.6.0源文件压缩包 解压至c:\hadoop-2.6.0-src 编译Hadoop2.6.0 进入Windows SDK 7.1 Command Prompt 在c:\执行buildHadoop.bat，其内容如下： setlocal set Platform=x64 set CYGWIN_ROOT=C:\cygwin64 set JAVA_HOME=C:\tools\Java\jdk7 set M2_HOME=C:\tools\apache-maven set MS_BUILD_PATH=C:\Windows\Microsoft.NET\Framework64\v4.0.30319 set MS_SDK=C:\Program Files\Microsoft SDKs\Windows\v7.1 set CMAKE_PATH=C:\tools\CMake set PROTOBUF_PATH=C:\tools\protoc-2.</description></item><item><title>粗览基于Eclipse RCP架构的Activiti Designer实现(图文版)</title><link>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88%E5%9F%BA%E4%BA%8Eeclipse_rcp%E6%9E%B6%E6%9E%84%E7%9A%84activiti_designer%E5%AE%9E%E7%8E%B0%E5%9B%BE%E6%96%87%E7%89%88/</link><pubDate>Tue, 31 Mar 2015 06:08:51 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88%E5%9F%BA%E4%BA%8Eeclipse_rcp%E6%9E%B6%E6%9E%84%E7%9A%84activiti_designer%E5%AE%9E%E7%8E%B0%E5%9B%BE%E6%96%87%E7%89%88/</guid><description>org.activiti.designer.feature contains an Eclipse feature definition, which groups the variousprojects into the installable Activiti Designer feature.
org.activiti.designer.eclipse plug-in contains the main extensions of Eclipse extension points and a lotof shared code for working with the model, saving resources andutilities.
org.activiti.designer.eclipse.extension.ExportMarshallerextension-point Activiti Designer Export Marshaller: Use this extension point toprovide custom output marshallers when Activiti diagrams areexported.
org.activiti.designer.eclipse.extension.ProcessValidatorextension-point Activiti Designer Process Validator: Use this extension point toprovide validation when Activiti diagrams are validated.</description></item><item><title>粗览基于Eclipse RCP架构的Activiti Designer实现（思维导图版）</title><link>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88%E5%9F%BA%E4%BA%8Eeclipse_rcp%E6%9E%B6%E6%9E%84%E7%9A%84activiti_designer%E5%AE%9E%E7%8E%B0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%E7%89%88/</link><pubDate>Mon, 30 Mar 2015 05:02:44 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88%E5%9F%BA%E4%BA%8Eeclipse_rcp%E6%9E%B6%E6%9E%84%E7%9A%84activiti_designer%E5%AE%9E%E7%8E%B0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%E7%89%88/</guid><description/></item><item><title>函数式编程笔记</title><link>https://mryqu.github.io/post/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 29 Mar 2015 05:39:20 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/</guid><description>澄清概念 面向对象编程(OOP)对应的是面向过程编程(POP)。其区别在于模块化和如何对事物进行抽象：
POP中程序可被分解成函数，OOP中程序可被分解成对象； POP侧重于过程及其执行顺序，OOP侧重于数据而不是过程； POP自顶向下解决问题，OOP自底向上解决问题； POP可以自由地在函数之间传递数据，OOP中对象需要通过成员方法传递数据和彼此通信； OOP更容易添加新数据和函数，有POP所没有的（public、private、protected等）访问修饰符、数据隐藏、方法覆写等特性。 函数式编程(Functional Programming)对应的是命令式编程(Imperativeprogramming)。
普林斯顿的科学家阿隆左·丘奇（Alonzo Church）、阿兰·图灵（Alan Turing）、约翰·冯·诺依曼（Johnvon Neumann）和库尔特·冈特（KurtGodel）都对形式系统很感兴趣，致力于解决抽象的数学难题。这些难题的共同之处就是计算：如果计算机能有无限的计算能力，哪些问题可以被解决？哪些问题可以被自动解决？哪些问题依旧无法解决？为什么不能被解决？基于不同设计的各种计算机是否具有相同的计算能力？ 阿隆左·丘奇提出了一个被称为lambda演算的形式系统。这个系统本质上是一种程序设计语言。它可以运行在具有无限计算能力的机器上。lambda演算由一些函数构成，这些函数的输入输出也是函数。函数用希腊字母lambda标识，因此整个形式系统也叫lambda。通过这一形式系统，阿隆左就可以对上述诸多问题进行推理并给出结论性的答案。在同一时间，阿兰·图灵也在进行着相似的工作。他提出了一个完全不同的形式系统（现在被称为图灵机），并使用这一系统得出了和阿隆左相似的结论。事后证明，图灵机和lambda的演算能力是等价的。 1949年，第一台电子计算机EDVAC被推出并获得了巨大的成功。这是冯·诺依曼架构的第一个具体实现，实际上也是图灵机的第一个实现。而与此同时，阿隆左·丘奇则没有那么幸运。直到二十世纪五十年代，一位MIT的教授JohnMcCarthy对阿隆左·丘奇的工作产生了兴趣。1958年，他发布了Lisp语言。Lisp的不同之处在于，它在冯·诺依曼计算机上实现了阿隆左·丘奇的lambda演算！很多计算机科学家开始意识到Lisp的表达能力。1973年，MIT人工智能实验室的一帮程序员开发了被称为Lisp机器的硬件，于是阿隆左的lambda演算系统终于在硬件上实现了！函数式编程更加现代一些的例子包括scheme、Haskell、Clean、Erlang和Miranda等。1980年代末期，集函数式编程研究成果于大成的Haskell发布。命令式编程是图灵机思想的一种实现，对应地函数式编程则是lambda演算思想的一种实现。但并非所有的lambda演算都被实现了，因为lambda演算原本不是为有物理限制的计算机设计的。
|特征|命令式编程|函数式编程 |&amp;mdash;&amp;ndash; |程序员关注点|任务（算法）如何被执行及状态变化如何被追踪|所要得到的信息及所需转换 |状态变化|很重要|不存在状态变化 |执行顺序|很重要|不是很重要 |基本流控制|循环、条件分支和函数调用|包括递归在内的函数调用 |基本操作单元|结构体或类的对象|作为头等对象的函数、数据集合
定义 在维基百科中，已经对函数式编程有了很详细的介绍，其定义如下：
函数式编程或称函数程序设计，又称泛函编程，是一种编程范型，它将电脑运算视为数学上的函数计算，并且避免使用程序状态以及易变对象。函数编程语言最重要的基础是λ演算（lambda calculus）。而且λ演算的函数可以接受函数当作输入（引数）和输出（传出值）。 概念 支持闭包和高阶函数 函数在函数式编程中是所谓的&amp;quot;头等公民&amp;quot;，函数与其他数据类型一样处于平等地位，有时称为闭包或者仿函数（functor）对象。实质上，闭包是起函数的作用并可以像对象一样操作的对象。与此类似，函数式编程语言支持高阶函数。高阶函数可以用另一个函数（间接地，用一个表达式）作为其输入参数，在某些情况下，它甚至返回一个函数作为其输出参数。这两种结构结合在一起使得可以用优雅的方式进行模块化编程，这是使用函数式编程的最大好处。
纯函数 所谓“纯”函数式(或表达式)就是实现了lambda演算并且不包含与Church范式矛盾的特性，它没有(内存或I/O)副作用。
变量的不可变性：函数式编程的变量都是不可变的，函数保持独立，不能修改外部变量的值，所有功能就是返回一个新的值。在命令式编程中，变量往往用来保存&amp;quot;状态&amp;quot;（state）,变量会影响函数的输出。在函数式编程中，不能修改变量，意味着状态不能保存在变量中。函数式编程使用函数参数保存状态，函数参数是影响函数返回值的唯一途径。如果一个编程语言中变量都是不可变的好处是： 可以去掉很多情况的锁操作, 并发处理速度会更快. 可以简化垃圾回收GC 函数的确定性或引用透明性（Referentialtransparency）：指的是函数的运行不依赖于外部变量或&amp;quot;状态&amp;quot;，只依赖于输入的参数，任何时候只要参数相同，引用函数所得到的返回值总是相同的。这使您可以从形式上推断程序行为，因为表达式的意义只取决于其子表达式而不是计算顺序或者其他表达式的副作用。这有助于验证正确性、简化算法，甚至有助于找出优化它的方法。 递归 函数式编程还有一个特点是用递归做为控制流程的机制。递归最大的好处就简化代码，他可以把一个复杂的问题用很简单的代码描述出来。注意：递归的精髓是描述问题，而这正是函数式编程的精髓。
懒惰计算 懒惰计算需要编译器的支持。表达式不是在绑定到变量时立即计算，而是在求值程序需要产生表达式的值时进行计算。延迟的计算使您可以编写可能潜在地生成无穷输出的函数。因为不会计算多于程序的其余部分所需要的值，所以不需要担心由无穷计算所导致的out-of-memory错误。一个懒惰计算的例子是生成无穷Fibonacci列表的函数，但是对第n个Fibonacci数的计算相当于只是从可能的无穷列表中提取一项。 C类和ML类的语言都是非懒惰的（饥饿求值），而Haskell和Miranda都是懒惰的。OCaml是缺省非懒惰，但是在需要的时候支持懒惰的风格。
模式匹配 模式匹配不是什么新特性。事实上它和函数式编程的关系不大。为什么总是把它当做函数式编程的一个特性呢？这是因为函数式语言已经支持模式匹配一段时间了，而现代命令式语言还不行。 用一个例子来进一步了解模式匹配。下面是Java实现的斐波那契函数：
int fib(int n) { if(n == 0) return 1; if(n == 1) return 1; return fib(n - 2) + fib(n - 1); } 如果用我们上文构造的并且支持模式匹配的Java来写，实现如下
int fib(0) { return 1; } int fib(1) { return 1; } int fib(int n) { return fib(n - 2) + fib(n - 1); } 两者有什么区别？编译器为我们实现了分支。</description></item><item><title>Activiti Designer开发环境配置</title><link>https://mryqu.github.io/post/activiti_designer%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</link><pubDate>Fri, 27 Mar 2015 08:51:10 +0000</pubDate><guid>https://mryqu.github.io/post/activiti_designer%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</guid><description>Download eclipse-modeling-juno-SR2-win32-x86_64.zip,eclipse-rcp-juno-SR2-win32-x86_64.zip and extract to the sameeclipse folder Use Eclipse juno instead of kepler which can easily consume your day!!! Add Eclipse Graphiti SDK 0.10.1 from update site http://archive.eclipse.org/graphiti/updates/0.10.1/ Add the following location as source code repository: https://github.com/Activiti/Activiti-Designer Import Maven project - Activiti Designer Open a console and navigate to the directory of your Eclipseworkspace and then into the org.activiti.designer.parent directory,which is of course the directory of the project with the same name.</description></item><item><title>[OpenUI5] set required field in form element</title><link>https://mryqu.github.io/post/openui5_set_required_field_in_form_element/</link><pubDate>Thu, 19 Mar 2015 19:27:48 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_set_required_field_in_form_element/</guid><description>对FormElement中的sap.m.Input设置了required属性，但是界面上的标签并没有显示星号*。
new FormElement({ label: &amp;#34;name&amp;#34;, fields: [ new sap.m.Input({ id: sFormId+&amp;#34;-name&amp;#34;, type: sap.m.InputType.Text, value: &amp;#34;{/name}&amp;#34;, required: true, layoutData: new GridData({span: &amp;#34;L3 M5 S6&amp;#34;}) }) ] }) 通过阅读Q: UI5 Setting field as required得知，需要对label属性赋值一个带有required为true的Label控件。
new FormElement({ label: new sap.m.Label({ text:&amp;#34;name&amp;#34;, required:true }), fields: [ new sap.m.Input({ id: sFormId+&amp;#34;-name&amp;#34;, type: sap.m.InputType.Text, value: &amp;#34;{/name}&amp;#34;, required: true, layoutData: new GridData({span: &amp;#34;L3 M5 S6&amp;#34;}) }) ] })</description></item><item><title>[HBase] 使用ImportTsv命令导入数据</title><link>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8importtsv%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/</link><pubDate>Mon, 16 Mar 2015 20:16:13 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8importtsv%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/</guid><description>ImportTsv简介 ImportTsv是一款用于将TSV格式数据导入HBase的工具。它有两种用法：
通过Put将TSV格式数据导入HBase 通过批量导入数据的方式生成用于加载进HBase的存储文件 下面看一下ImportTsv的使用说明： ImportTsv参数 -Dimporttsv.skip.bad.lines=false - 若遇到无效行则失败 &amp;lsquo;-Dimporttsv.separator=|&amp;rsquo; - 使用特定分隔符| -Dimporttsv.timestamp=currentTimeAsLong - 使用导入时的时间戳 -Dimporttsv.mapper.class=my.Mapper -使用用户自定义Mapper类替换TsvImporterMapper -Dmapreduce.job.name=jobName - 对导入使用特定mapreduce作业名 -Dcreate.table=no - 避免创建表，注：如设为为no，目标表必须存在于HBase中 -Dno.strict=true - 忽略HBase表列族检查。默认为false
ImportTsv测试 准备数据 hadoop@node50064:~$ hadoop fs -cat /user/hadoop/tsv_input/sales2013.csv Name,Sex,Age,Height,Weight Alfred,M,14,69,112.5 Alice,F,13,56.5,84 Barbara,F,13,65.3,98 Carol,F,14,62.8,102.5 Henry,M,14,63.5,102.5 James,M,12,57.3,83 Jane,F,12,59.8,84.5 Janet,F,15,62.5,112.5 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Joyce,F,11,51.3,50.5 Judy,F,14,64.3,90 Louise,F,12,56.3,77 Mary,F,15,66.5,112 Philip,M,16,72,150 Robert,M,12,64.8,128 Ronald,M,15,67,133 Thomas,M,11,57.5,85 William,M,15,66.5,112 准备目标表 hbase(main):001:0&amp;gt; create &amp;#39;sales2013&amp;#39;, &amp;#39;info&amp;#39; 0 row(s) in 4.5730 seconds =&amp;gt; Hbase::Table - sales2013 hbase(main):002:0&amp;gt; create &amp;#39;sales2013bulk&amp;#39;, &amp;#39;info&amp;#39; 0 row(s) in 2.</description></item><item><title>[OpenUI5] sap.ui.core.format.DateFormat使用</title><link>https://mryqu.github.io/post/openui5_sap.ui.core.format.dateformat%E4%BD%BF%E7%94%A8/</link><pubDate>Sun, 15 Mar 2015 17:02:46 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_sap.ui.core.format.dateformat%E4%BD%BF%E7%94%A8/</guid><description>使用javascript的Date类型，想要输出国际化的字符串，可以使用toLocaleString函数，但是需要自己往里设locale，并且输出结果随操作系统和浏览器不同而变化。
最后还是用OpenUI5的DateFormat，既可以固定格式有可以自动国际化。
var oDateFormat = sap.ui.core.format.DateFormat.getDateTimeInstance({ pattern: &amp;#34;EEEE, MMMM d, yyyy HH:mm:ss a z&amp;#34; }); oDateFormat.format(new Date());</description></item><item><title>[OpenUI5] 将布尔型数据在数据表中显示为checkbox</title><link>https://mryqu.github.io/post/openui5_%E5%B0%86%E5%B8%83%E5%B0%94%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%9C%A8%E6%95%B0%E6%8D%AE%E8%A1%A8%E4%B8%AD%E6%98%BE%E7%A4%BA%E4%B8%BAcheckbox/</link><pubDate>Sat, 14 Mar 2015 18:09:18 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%B0%86%E5%B8%83%E5%B0%94%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%9C%A8%E6%95%B0%E6%8D%AE%E8%A1%A8%E4%B8%AD%E6%98%BE%E7%A4%BA%E4%B8%BAcheckbox/</guid><description>看了一下OpenUI5、Datatables和Vaadin中将布尔型数据在数据表中显示为checkbox的示例： OpenUI5 example: DataTable
Datatables example: Always shown checkbox Vaadin table: How to display Boolean as checkboxes with editable=false
感觉还是OpenUI5更灵活，不过小项目用OpenUI5又太重了！</description></item><item><title>Retrieve the status of an process instance in Activiti</title><link>https://mryqu.github.io/post/retrieve_the_status_of_an_process_instance_in_activiti/</link><pubDate>Fri, 13 Mar 2015 19:42:33 +0000</pubDate><guid>https://mryqu.github.io/post/retrieve_the_status_of_an_process_instance_in_activiti/</guid><description>Retrieve the status of an running process instance Use the executionQuery() or processInstanceQuery() to find out ifany result is returned or not when querying execution/process byId.
runtimeService.createProcessInstanceQuery().processInstanceId(specifiedProcessInstanceId).singleResult() runtimeService.createExecutionQuery().executionId(specifiedExecutionId).singleResult() Specially when the history capabilities of Activiti engine isenabled:
Specified process/execution instance id: ProcessInstance inst = historyService.createHistoricProcessInstanceQuery().processInstanceId(specifiedProcessInstanceId).singleResult(); inst.isEnd() Unspecified process/execution instance id: historyService.createHistoricProcessInstanceQuery().finished().list() historyService.createHistoricProcessInstanceQuery().unfinished().list() Retrieve the active node of an running process instance RuntimeService provide the API to retrieve the active node of anrunning process instance:</description></item><item><title>粗览Activiti Explorer源代码</title><link>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_explorer%E6%BA%90%E4%BB%A3%E7%A0%81/</link><pubDate>Thu, 12 Mar 2015 08:52:17 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_explorer%E6%BA%90%E4%BB%A3%E7%A0%81/</guid><description>ActivitiExplorer的应用程序为org.activiti.explorer.ExplorerApp，其界面配置文件为Activiti\modules\activiti-webapp-explorer2\src\main\resources\activiti-ui-context.xml。通过该配置文件创建主窗口org.activiti.explorer.ui.MainWindow类实例，并通过org.activiti.explorer.ViewManagerFactoryBean创建实现org.activiti.explorer.ViewManager接口的org.activiti.explorer.DefaultViewManager或org.activiti.explorer.ui.alfresco.AlfrescoViewManager类实例。 在Activiti演示中采用的是org.activiti.explorer.DefaultViewManager类实例，它对主窗口进行视图管理，完成视图切换、对应导航栏和功能菜单的设置。 主窗口org.activiti.explorer.ui.MainWindow类实例通过org.activiti.explorer.ui.mainlayout.MainLayout类进行界面布局。
下面列举了Activiti Explorer两级导航栏所对应的页面实现类。
Tasks Inboxorg.activiti.explorer.ui.task.InboxPage My Tasksorg.activiti.explorer.ui.task.TasksPage Queuedorg.activiti.explorer.ui.task.QueuedPage Involvedorg.activiti.explorer.ui.task.InvolvedPage Archivedorg.activiti.explorer.ui.task.ArchivedPage Processes My Instancesorg.activiti.explorer.ui.process.MyProcessInstancesPage Deployed process definitionsorg.activiti.explorer.ui.process.ProcessDefinitionPage Model workspaceorg.activiti.editor.ui.EditorProcessDefinitionPage Reports Generate reportsorg.activiti.explorer.ui.reports.RunReportsPage Saved reportsorg.activiti.explorer.ui.reports.SavedReportsPage Manage Databaseorg.activiti.explorer.ui.management.db.DatabasePage Deploymentsorg.activiti.explorer.ui.management.deployment.DeploymentPage Active Processesorg.activiti.explorer.ui.management.processdefinition.ActiveProcessDefinitionPage Suspend Processesorg.activiti.explorer.ui.management.processdefinition.SuspendedProcessDefinitionPage Jobsorg.activiti.explorer.ui.management.job.JobPage Usersorg.activiti.explorer.ui.management.identity.UserPage Groupsorg.activiti.explorer.ui.management.identity.GroupPage Administrationorg.activiti.explorer.ui.management.admin.AdministrationPage Crystalballorg.activiti.explorer.ui.management.crystalball.CrystalBallPage</description></item><item><title>GoJS BPMN元素界面实现分析</title><link>https://mryqu.github.io/post/gojs_bpmn%E5%85%83%E7%B4%A0%E7%95%8C%E9%9D%A2%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/</link><pubDate>Wed, 11 Mar 2015 20:10:35 +0000</pubDate><guid>https://mryqu.github.io/post/gojs_bpmn%E5%85%83%E7%B4%A0%E7%95%8C%E9%9D%A2%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/</guid><description>GoJS BPMN里面的BPMN元素采用过不是PNG/JPEG这样的静态图标，而是通过GoJS在Cavas绘出来的。 由BPMN.js可知，一个BPMN元素是一个go.Node，内部大致包含go.Panel、go.Shape、go.TextBlock等对象，用于绘制外层的正方形、填充内部颜色、添加图标和文字。 如果创建自己定制的BPMN元素，最麻烦的就是图标了。现在我来看一下GoJS BPMN扩展里面的图标是怎么保存和绘制的。 GoJS BPMN扩展里面大部分的图标都已经在go.js里面以源代码的形式定义了，只有四个是在BPMN.js里面通过go.Shape.defineFigureGenerator方法定制的，分别是Empty、Annotation、BpmnTaskManual和BpmnTaskService。这四个图标的内容是GoJS geometry的格式保存的。 所有这些图标可以通过与go.Shape的figure进行绑定，由GoJS驱动完成底层绘制。我自己做了一个简单样例，对这些内嵌图标和BPMN定制图标稍微玩了点花样 http://jsfiddle.net/mryqu/mywy0nhz/ 显示效果如下：</description></item><item><title>了解Apache Accumulo</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3apache_accumulo/</link><pubDate>Tue, 10 Mar 2015 20:12:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3apache_accumulo/</guid><description>Apache Accumulo是一个可靠的、可伸缩的、高性能的排序分布式的Key-Value存储解决方案，提供了基于单元的访问控制以及可在数据处理过程中多个控制点修改键值对的服务器端编程机制。使用GoogleBigTable设计思路，基于ApacheHadoop、Zookeeper和Thrift构建。 Accumulo由美国国家安全局（NSA）于2008年开始研发，2011年捐赠给Apache基金会。Accumulo现已成为Apache基金会的顶级项目，并被评过第三大最受欢迎的NoSQL数据库引擎。 目前，Accumulo技术已经得到美国政府层面的全面认可，NSA已将该技术作为内部组织架构运行的核心部分，在对来源于各方面的庞大海量数据进行分析处理时，所应用的运算程序基本都运行在Accumulo技术上，即NSA“大多数监控和分析应用程序的后台都是Accumulo技术”。基于Hadoop的Accumulo技术已在实质上被视为美国国家安全战略的关键。 据2014年9月份的文章介绍，已经有几十家不同类型的美国企业安装了Accumulo技术系统，其中，美国20强企业中已有3家安装，50强企业中有5家安装，还有不少企业已表示对此有兴趣。 我一碰到KV存储方案，总想跟我用过的GemFire和MongoDB做个比较。vsChart.com - The Comparision Wiki上已经有现成的比较(见参考3和4)，值得学习。
参考 Apache Accumulo官网 Accumulo: Why The World Needs Another NoSQL Database Apache Accumulo vs. GemFire Apache Accumulo vs. MongoDB NOSQL中文网：Apache Accumulo用户手册</description></item><item><title>MongoDB 3.0新特性、提升与兼容性改变</title><link>https://mryqu.github.io/post/mongodb_3.0%E6%96%B0%E7%89%B9%E6%80%A7%E6%8F%90%E5%8D%87%E4%B8%8E%E5%85%BC%E5%AE%B9%E6%80%A7%E6%94%B9%E5%8F%98/</link><pubDate>Sat, 07 Mar 2015 22:01:45 +0000</pubDate><guid>https://mryqu.github.io/post/mongodb_3.0%E6%96%B0%E7%89%B9%E6%80%A7%E6%8F%90%E5%8D%87%E4%B8%8E%E5%85%BC%E5%AE%B9%E6%80%A7%E6%94%B9%E5%8F%98/</guid><description>MONGODB 3.0
WHAT’S NEW IN MONGODB 3.0
Release Notes for MongoDB 3.0
Compatibility Changes in MongoDB 3.0
MongoDB3.0发布&amp;ndash;新特性</description></item><item><title>粗览Activiti Modeler属性显示和设置代码</title><link>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_modeler%E5%B1%9E%E6%80%A7%E6%98%BE%E7%A4%BA%E5%92%8C%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%A0%81/</link><pubDate>Fri, 06 Mar 2015 08:47:29 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_modeler%E5%B1%9E%E6%80%A7%E6%98%BE%E7%A4%BA%E5%92%8C%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%A0%81/</guid><description>我的博文粗览Activiti Modeler操作和源代码介绍了Activiti ModelEditor组件的常用操作和对应源代码分析，本文接着介绍一下ActivitiModeler里BPMN元素属性的显示和设置。 粗览Activiti Modeler操作和源代码里提到的stencilset.json除了含有每个BPMN元素应该使用什么图标，也定义了每个BPMN元素的所有属性。以UserTask元素为例，它含有以下的属性包：
&amp;ldquo;overrideidpackage&amp;rdquo; &amp;ldquo;namepackage&amp;rdquo; &amp;ldquo;documentationpackage&amp;rdquo; &amp;ldquo;asynchronousdefinitionpackage&amp;rdquo; &amp;ldquo;exclusivedefinitionpackage&amp;rdquo; &amp;ldquo;executionlistenerspackage&amp;rdquo; &amp;ldquo;multiinstance_typepackage&amp;rdquo; &amp;ldquo;multiinstance_cardinalitypackage&amp;rdquo; &amp;ldquo;multiinstance_collectionpackage&amp;rdquo; &amp;ldquo;multiinstance_variablepackage&amp;rdquo; &amp;ldquo;multiinstance_conditionpackage&amp;rdquo; &amp;ldquo;isforcompensationpackage&amp;rdquo; &amp;ldquo;usertaskassignmentpackage&amp;rdquo; &amp;ldquo;formkeydefinitionpackage&amp;rdquo; &amp;ldquo;duedatedefinitionpackage&amp;rdquo; &amp;ldquo;prioritydefinitionpackage&amp;rdquo; &amp;ldquo;formpropertiespackage&amp;rdquo; &amp;ldquo;tasklistenerspackage&amp;rdquo; [tomcat]\webapps\activiti-explorer\editor-app\configuration\properties.js里提供了对各类BPMNstencil的所需要包含的HTML页面。 [tomcat]\webapps\activiti-explorer\editor-app\stencil-controller.js中对ORYX.CONFIG.EVENT_SELECTION_CHANGED事件注册了匿名函数监听器。当某一BPMN元素被选中后，该监听器会设置$scope.selectedItem和$scope.selectedShape，其中包含BPMN元素的所有属性，每个属性都有对应的stencilreadModeTemplateUrl、writeModeTemplateUrl和templateUrl。 [tomcat]\webapps\activiti-explorer\editor-app\editor.html是ActivitiModelEditor组件的显示页面，其ID为propertiesHelpWrapper的DIV元素内对所选择的BPMN元素的每个属性放置templateUrl、readModeTemplateUrl或writeModeTemplateUrl对应的HTML子页面用于显示和设置stencil属性。 用于设置BPMNstencil属性的页面都位于[tomcat]\webapps\activiti-explorer\editor-app\configuration\properties\下。 这些页面和Anjugar.JS控制器为：</description></item><item><title>GoJS对浏览器和移动设备的支持</title><link>https://mryqu.github.io/post/gojs%E5%AF%B9%E6%B5%8F%E8%A7%88%E5%99%A8%E5%92%8C%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E7%9A%84%E6%94%AF%E6%8C%81/</link><pubDate>Wed, 04 Mar 2015 19:47:40 +0000</pubDate><guid>https://mryqu.github.io/post/gojs%E5%AF%B9%E6%B5%8F%E8%A7%88%E5%99%A8%E5%92%8C%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E7%9A%84%E6%94%AF%E6%8C%81/</guid><description>在其官网上没有发现GoJS对浏览器和移动设备的支持的详细报告，仅在http://www.nwoods.com/products/gojs/ 有粗略介绍：
GoJS takes advantage of the HTML Canvas to supporthigh-performance diagrams. For creating static documents andprintable resources, GoJS supports exporting Diagrams to images and SVG.
GoJS supports all modern browsers (IE9+), including mobilebrowsers.</description></item><item><title>Activiti与GoJS BPMN支持的BPMN元素对比</title><link>https://mryqu.github.io/post/activiti%E4%B8%8Egojs_bpmn%E6%94%AF%E6%8C%81%E7%9A%84bpmn%E5%85%83%E7%B4%A0%E5%AF%B9%E6%AF%94/</link><pubDate>Tue, 03 Mar 2015 23:00:11 +0000</pubDate><guid>https://mryqu.github.io/post/activiti%E4%B8%8Egojs_bpmn%E6%94%AF%E6%8C%81%E7%9A%84bpmn%E5%85%83%E7%B4%A0%E5%AF%B9%E6%AF%94/</guid><description>首先抱怨一下,GoJS BPMN扩展中有两个图标和标题是一样的,我看了又看还是分不清. ActivitiGoJS BPMNStartEventsStart Event Start Timer Event Start Signal Event Start Message Event Start Error Event ActivitiesAll Activiti activities support compensation optionAll GoJS BPMN activities support "Add Email Event", "Add TimerEvent", "Add Escalation Event" and "Add Error Event" options.User Task Service Task Looping Service TaskScript Task Business Rule Task Receive Task Manual Task Mail Task Camel Task Mule Task Generic TaskStructuralSub Process Event Sub Process Call Activity GatewaysExclusive Gateway Parallel Gateway Inclusive Gateway Event Gateway BoundaryEventsBoundary Error Event Boundary Timer Event Boundary Signal Event Boundary Message Event Intermediate Catching EventsIntermediate Timer Catching Event Intermediate Signal Catching Event Intermediate Message Catching Event Intermediate Throwing EventsIntermediate None Throwing Events Intermediate Signal Throwing Events EndEventsEnd Event End Error Event ?</description></item><item><title>浏览器的本地存储在GoJS BPMN样例中的使用</title><link>https://mryqu.github.io/post/%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8%E5%9C%A8gojs_bpmn%E6%A0%B7%E4%BE%8B%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 02 Mar 2015 20:06:19 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8%E5%9C%A8gojs_bpmn%E6%A0%B7%E4%BE%8B%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>GoJS BPMN样例中可以存储BPMN模型，它采用的存储媒体是浏览器的本地存储。Web Storage(W3C WebApps Working Group)中定义了如下的Storage接口：
interface Storage { readonly attribute unsigned long length; DOMString key(unsigned long index); getter DOMString getItem(DOMString key); setter creator void setItem(DOMString key, DOMString value); deleter void removeItem(DOMString key); void clear(); }; GoJS BPMN样例采用的方法如下：
function checkLocalStorage() { return (typeof (Storage) !== &amp;#34;undefined&amp;#34;) &amp;amp;&amp;amp; (window.localStorage !== undefined); } window.localStorage.setItem(key, value) window.localStorage.getItem(key) window.localStorage.removeItem(key) 我的测试是存储一个名为yqu_GoJSBPMN_Samp1的模型。 如果想清除我的小测试所用的本地存储，可以通过chrome://settings/cookies#cont页面来完成： 参考 MDN：DOM Storage guide DOM Storage</description></item><item><title>[C++] 编译OpenSSL和libCurl</title><link>https://mryqu.github.io/post/c++_%E7%BC%96%E8%AF%91openssl%E5%92%8Clibcurl/</link><pubDate>Sun, 01 Mar 2015 23:05:26 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E7%BC%96%E8%AF%91openssl%E5%92%8Clibcurl/</guid><description>准备工作 登录一台Linux服务器，并完成下列工作：
在目录/home/mryqu/创建子目录out，在out目录下创建子目录ssl和curl； 从OpenSSL项目下载openssl-1.0.2.tar.gz，并解压； 从curl项目下载curl-7.40.0.tar.gz，并解压 编译OpenSSL 进入openssl-1.0.2目录; 完成OpenSSL配置，仅支持静态库不支持动态库： ./config no-shared --openssldir=/home/mryqu/out/ssl 对Makefile文件中的FGLAG和DEPFLAG变量进行修改，增加-fPIC。 编译： make depend make make install 编译产生如下内容： 编译libCurl 进入curl-7.40.0目录; 首先设定pkg-config路径，指定为上一步OpenSSL编译结果。由于我们的OpenSSL编译结果不在编译器/链接器默认搜索路径，通过pkg-config路径和&amp;ndash;with-ssl让libCurl查找到OpenSSL。通过&amp;ndash;without-zlib禁止掉即时解压缩。 export PKG_CONFIG_PATH=/home/mryqu/out/ssl/lib/pkgconfig ./configure --prefix=/home/mryqu/out/curl --with-ssl --without-zlib make make install 编译产生如下内容： 参考 OpenSSL Compilation and Installation how to install curl and libcurl OpenSSL Cookbook Everything curl</description></item><item><title>[OpenUI5] Grid layout for responsive design</title><link>https://mryqu.github.io/post/openui5_grid_layout_for_responsive_design/</link><pubDate>Sun, 01 Mar 2015 09:29:25 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_grid_layout_for_responsive_design/</guid><description>OpenUI5的Grid机制位于sap.ui.layout库内，它在12列流布局中定位子控件位置。取决于当前屏幕尺寸，子控件可以指定可变的列数，从而实现响应式设计。 在上图示例中，无论屏幕大小，子控件1都占满12列，从而其他子控件无法跟它位于同一行内。 在大屏幕和中等屏幕尺寸下，子控件2和3共同占满12列，可以置于一行内；而在小屏幕尺寸下，二者需要列数超过12，只能分置于两行了。
参考 Responsive Web Design UI5 features for building responsive Fiori apps jsDoc: sap.ui.layout.GridData MDN: CSS Grid Layout MDN: Using CSS multi-column layouts</description></item><item><title>Activiti Modeler中sid生成机制</title><link>https://mryqu.github.io/post/activiti_modeler%E4%B8%ADsid%E7%94%9F%E6%88%90%E6%9C%BA%E5%88%B6/</link><pubDate>Sat, 28 Feb 2015 19:28:15 +0000</pubDate><guid>https://mryqu.github.io/post/activiti_modeler%E4%B8%ADsid%E7%94%9F%E6%88%90%E6%9C%BA%E5%88%B6/</guid><description>昨天跟同事说Activiti Modeler中的sid比GoJS中的元素ID讲究，估计是由时戳和随机数混合生成的。 今天看了一下，发现原来就是一个纯随机数。
[tomcat]\webapps\activiti-explorer\editor-app\editor.html里对类为stencil-item的HTML元素设置的拖拽处理函数在[tomcat]\webapps\activiti-explorer\editor-app\stencil-controller.js中定义。 sid生成方法在[tomcat]\webapps\activiti-explorer\editor-app\editor\oryx.debug.js中定义。
ORYX.Editor.provideId = function() { var res=[], hex=&amp;#39;0123456789ABCDEF&amp;#39;; for(var i=0; i&amp;lt;36; i ) res[i]=Math.floor(Math.random()*0x10); res[14]=4; res[19]=(res[19] &amp;amp; 0x3) | 0x8; for(var i=0; i&amp;lt;36; i ) res[i] = hex[res[i]]; res[8] = res[13] = res[18] = res[23] = &amp;#39;-&amp;#39;; return &amp;#34;sid-&amp;#34; res.join(&amp;#39;&amp;#39;); }; 当然，GoJSBPMN样例中的ID就更简单的不得了，全都是预定义的简单数字。例如，userTask的key预定义为7，当一个BPMN元素加入GoJSmodel时，GoJS会让model中的key变成唯一的（代码混淆过，我猜估计没混淆前叫makeUniqueKeyFunction）。在我的小测试中，第一个userTask的key仍然为7，第二个userTask的key被改成了-3。 感觉要是借鉴MongoDB的ObjectId生成机制，ID的冲撞概率可能会更低。</description></item><item><title>将GoJS和Activiti Explorer熬成一锅粥</title><link>https://mryqu.github.io/post/%E5%B0%86gojs%E5%92%8Cactiviti_explorer%E7%86%AC%E6%88%90%E4%B8%80%E9%94%85%E7%B2%A5/</link><pubDate>Fri, 27 Feb 2015 20:05:26 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%86gojs%E5%92%8Cactiviti_explorer%E7%86%AC%E6%88%90%E4%B8%80%E9%94%85%E7%B2%A5/</guid><description>熬粥时，一开始创建一个跟editor-app平行的独立目录gojs-editor-app，结果我的Chrome浏览器报“Resourceinterpreted as stylesheet but transferred with MIME typetext/html”错误，GoJS的所有Javascript和stylesheet文件(例如BPMN.js和BPMN.css)都被加了料从Tomcat发给浏览器变成了html格式。 看了下面两个帖子，没有丝毫头绪： http://stackoverflow.com/questions/3467404/chrome-says-resource-interpreted-as-script-but-transferred-with-mime-type-tex
thttp://stackoverflow.com/questions/22631158/resource-interpreted-as-stylesheet-but-transferred-with-mime-type-text-html-see
搜了一下ActivitiExplorer的配置，看到org.activiti.explorer.filter.ExplorerFilter里有六个路径(&amp;quot;/ui&amp;quot;、&amp;quot;/VAADIN&amp;quot;、&amp;quot;/modeler.html&amp;quot;、&amp;quot;/editor-app&amp;quot;、&amp;quot;/service&amp;quot;、&amp;quot;/diagram-viewer&amp;quot;)走了特殊的过滤器。只好将GoJS的内容都转到Activiti已有的editor-app目录，这下齐活了。</description></item><item><title>试用GoJS BPMN生成Activiti支持的process.bpmn.xml</title><link>https://mryqu.github.io/post/%E8%AF%95%E7%94%A8gojs_bpmn%E7%94%9F%E6%88%90activiti%E6%94%AF%E6%8C%81%E7%9A%84process.bpmn.xml/</link><pubDate>Thu, 26 Feb 2015 16:37:24 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%AF%95%E7%94%A8gojs_bpmn%E7%94%9F%E6%88%90activiti%E6%94%AF%E6%8C%81%E7%9A%84process.bpmn.xml/</guid><description>我在Activiti中建立一个简单的仅有startEvent、userTask和endEvent的BPMN模型，导出的process.bpmn.xml内容如下： 前一博文玩玩GoJS BPMN样例中我给出了类似 BPMN模型的JSON数据。通过分析可知，除了两者的ID生成机制不同（GoJSBPMN生成的ID太简单，很容易重复），完全可以通过GoJS的JSON数据构造上面的process.bpmn.xml文件内容。 试了一下在Javascript中生成上面的process.bpmn.xml文档，大致可行。从MDN查到的资料可知，仅支持IE9+浏览器。不支持低版本IE浏览器，估计现在不算什么问题。目前生成的XML文档有些瑕疵，第一个使用createElement_x方法创建的节点会自动添加命名空间xmlns=http://www.w3.org/1999/xhtml，但是应该可以避免。
|Chrome|Firefox (Gecko)|Internet Explorer|Opera|Safari |&amp;mdash;&amp;ndash; |(Yes)|1.0 (1.7 or earlier)|9.0|(Yes)|(Yes)
JS代码如下：</description></item><item><title>玩玩GoJS BPMN样例</title><link>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9gojs_bpmn%E6%A0%B7%E4%BE%8B/</link><pubDate>Wed, 25 Feb 2015 19:50:09 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9gojs_bpmn%E6%A0%B7%E4%BE%8B/</guid><description>玩一玩GoJS，GoJS是Northwoods Software的产品。Northwoods Software创立于1995年，专注于交互图控件和类库。旗下四款产品：
GoJS：用于在HTML上创建交互图的纯javaSCript库，GoJS支持复杂的模板定义和数据绑定。 GoDiagram：用于WinForms的.NET图控件。 GoXam：用于WPF/Silverlight的图控件。 JGo：用于Swing/SWT中创建交互图的java库。 试了一下GoJS的BPMN样例，很容易导出SVG或PNG/JPEG等格式的图像数据。其中：
由于GoJS是经过代码混淆的，不能对makeSVG方法进行确定的分析，大概是采用HTMLCanvasElement.getContext(&amp;lsquo;2d&amp;rsquo;).drawImage(&amp;hellip;).getImageData(&amp;hellip;)获得的 makeImage和makeImageData方法通过HTMLCanvasElement.toDataURL()方法实现的 在控制台执行window.myDiagram.model.toJson()，返回如下结果：
{ &amp;#34;class&amp;#34;: &amp;#34;go.GraphLinksModel&amp;#34;, &amp;#34;linkFromPortIdProperty&amp;#34;: &amp;#34;fromPort&amp;#34;, &amp;#34;linkToPortIdProperty&amp;#34;: &amp;#34;toPort&amp;#34;, &amp;#34;nodeDataArray&amp;#34;: [ { &amp;#34;category&amp;#34;: &amp;#34;activity&amp;#34;, &amp;#34;item&amp;#34;: &amp;#34;User task&amp;#34;, &amp;#34;key&amp;#34;: 7, &amp;#34;loc&amp;#34;: &amp;#34;388.33645784919577 140.35229369949943&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;User Task&amp;#34;, &amp;#34;taskType&amp;#34;: 2, &amp;#34;boundaryEventArray&amp;#34;: [ ], &amp;#34;size&amp;#34;: &amp;#34;120 80&amp;#34; }, { &amp;#34;category&amp;#34;: &amp;#34;event&amp;#34;, &amp;#34;item&amp;#34;: &amp;#34;End&amp;#34;, &amp;#34;key&amp;#34;: 104, &amp;#34;loc&amp;#34;: &amp;#34;569.86545617508 140.90913111767696&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;End&amp;#34;, &amp;#34;eventType&amp;#34;: 1, &amp;#34;eventDimension&amp;#34;: 8 }, { &amp;#34;category&amp;#34;: &amp;#34;event&amp;#34;, &amp;#34;item&amp;#34;: &amp;#34;start&amp;#34;, &amp;#34;key&amp;#34;: 101, &amp;#34;loc&amp;#34;: &amp;#34;183.42028795985397 135.34075693590137&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;Start&amp;#34;, &amp;#34;eventType&amp;#34;: 1, &amp;#34;eventDimension&amp;#34;: 1 } ], &amp;#34;linkDataArray&amp;#34;: [ { &amp;#34;from&amp;#34;: 101, &amp;#34;to&amp;#34;: 7, &amp;#34;fromPort&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;toPort&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;points&amp;#34;: [ 204.</description></item><item><title>[HBase] 启动内置ZooKeeper过程</title><link>https://mryqu.github.io/post/hbase_%E5%90%AF%E5%8A%A8%E5%86%85%E7%BD%AEzookeeper%E8%BF%87%E7%A8%8B/</link><pubDate>Tue, 24 Feb 2015 07:00:09 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E5%90%AF%E5%8A%A8%E5%86%85%E7%BD%AEzookeeper%E8%BF%87%E7%A8%8B/</guid><description> start-hbase.sh hbase-daemons.sh start zookeeper zookeepers.sh --hosts /usr/local/hbase/conf/regionservers--config /usr/local/hbase/conf cd /usr/local/hbase;/usr/local/hbase/bin/hbase-daemon.sh --config /usr/local/hbase/confstart zookeeper 检查配置HBASE_MANAGES_ZK，若不为true则终止处理。 ssh node51054 cd /usr/local/hbase;/usr/local/hbase/bin/hbase-daemon.sh --config /usr/local/hbase/confstart zookeeper hbase zookeeper start java org.apache.hadoop.hbase.zookeeper.HQuorumPeer</description></item><item><title>粗览Activiti Modeler操作和源代码</title><link>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_modeler%E6%93%8D%E4%BD%9C%E5%92%8C%E6%BA%90%E4%BB%A3%E7%A0%81/</link><pubDate>Sun, 15 Feb 2015 20:24:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%B2%97%E8%A7%88activiti_modeler%E6%93%8D%E4%BD%9C%E5%92%8C%E6%BA%90%E4%BB%A3%E7%A0%81/</guid><description>Activiti Model Editor组件 我的了解Activiti Explorer及其Vaadin实现方式博文里提到ActivitiExplorer使用的是Vaadin架构，但是Activiti 模型编辑器组件却没用使用Vaadin架构，而是采用Angular.JS的MVC模式。Activiti模型编辑器组件的客户端代码位于Activiti\modules\activiti-webapp-explorer2\src\main\webapp\editor-app\。 该目录下的editor.html是Activiti Modeler Editor的主界面HTML代码 其中palette区是通过Angular.JS使用stencilsets\bpmn2.0\icons下多个子目录内的PNG图像形成的多组列表。其节点层次关系获取相关代码为：
stencil-controller.js Activiti\modules\activiti-modeler\src\main\java\org\activiti\rest\editor\main\StencilsetRestResource.java Activiti\modules\activiti-webapp-explorer2\src\main\resources\stencilset.json editor.html中的视图与两个控制器进行了绑定:
stencil-controller.js：处理对canvas中BPMN元素的操作，很多处理是通过editor目录下的QRYX库完成的 toolbar-controller.js：处理对工具栏的操作，很多处理由configuration\toolbar-default-actions.js完成 保存模型操作 保存模型操作，是通过toolbar-default-actions.js中的SaveModel方法完成的，它需要将三部分信息传给服务器：
模型的元数据：例如模型名称、分类、创建时间、最后一次更新时间等等 模型JSON数据：将canvas内的图像数据转换成JSON数据UTF8字符串 { &amp;#34;resourceId&amp;#34;: 53, &amp;#34;properties&amp;#34;: { &amp;#34;process_id&amp;#34;: &amp;#34;process&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;documentation&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;process_author&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;process_version&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;process_namespace&amp;#34;: &amp;#34;http://www.activiti.org/processdef&amp;#34;, &amp;#34;executionlisteners&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;eventlisteners&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;stencil&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;BPMNDiagram&amp;#34; }, &amp;#34;childShapes&amp;#34;: [ { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-4F7484B9-11EC-4FCE-8950-FEFFB723D88B&amp;#34;, &amp;#34;properties&amp;#34;: { &amp;#34;overrideid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;documentation&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;executionlisteners&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;initiator&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;formkeydefinition&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;formproperties&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;stencil&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;StartNoneEvent&amp;#34; }, &amp;#34;childShapes&amp;#34;: [], &amp;#34;outgoing&amp;#34;: [ { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-B589A0D9-FA79-4C12-95B7-253E72480384&amp;#34; } ], &amp;#34;bounds&amp;#34;: { &amp;#34;lowerRight&amp;#34;: { &amp;#34;x&amp;#34;: 259, &amp;#34;y&amp;#34;: 139 }, &amp;#34;upperLeft&amp;#34;: { &amp;#34;x&amp;#34;: 229, &amp;#34;y&amp;#34;: 109 } }, &amp;#34;dockers&amp;#34;: [] }, { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-1A762474-62B9-4F3D-A81C-1ADD46AF7D2F&amp;#34;, &amp;#34;properties&amp;#34;: { &amp;#34;overrideid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;documentation&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;asynchronousdefinition&amp;#34;: &amp;#34;false&amp;#34;, &amp;#34;exclusivedefinition&amp;#34;: &amp;#34;false&amp;#34;, &amp;#34;executionlisteners&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;multiinstance_type&amp;#34;: &amp;#34;None&amp;#34;, &amp;#34;multiinstance_cardinality&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;multiinstance_collection&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;multiinstance_variable&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;multiinstance_condition&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;isforcompensation&amp;#34;: &amp;#34;false&amp;#34;, &amp;#34;usertaskassignment&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;formkeydefinition&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;duedatedefinition&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;prioritydefinition&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;formproperties&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;tasklisteners&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;stencil&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;UserTask&amp;#34; }, &amp;#34;childShapes&amp;#34;: [], &amp;#34;outgoing&amp;#34;: [ { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-4134C10E-B589-42FF-AACC-463D35D52016&amp;#34; } ], &amp;#34;bounds&amp;#34;: { &amp;#34;lowerRight&amp;#34;: { &amp;#34;x&amp;#34;: 746, &amp;#34;y&amp;#34;: 172 }, &amp;#34;upperLeft&amp;#34;: { &amp;#34;x&amp;#34;: 646, &amp;#34;y&amp;#34;: 92 } }, &amp;#34;dockers&amp;#34;: [] }, { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-B22A5CAB-94D0-419E-BB1E-E8538C6A7283&amp;#34;, &amp;#34;properties&amp;#34;: { &amp;#34;overrideid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;documentation&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;executionlisteners&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;stencil&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;EndNoneEvent&amp;#34; }, &amp;#34;childShapes&amp;#34;: [], &amp;#34;outgoing&amp;#34;: [], &amp;#34;bounds&amp;#34;: { &amp;#34;lowerRight&amp;#34;: { &amp;#34;x&amp;#34;: 1089, &amp;#34;y&amp;#34;: 138 }, &amp;#34;upperLeft&amp;#34;: { &amp;#34;x&amp;#34;: 1061, &amp;#34;y&amp;#34;: 110 } }, &amp;#34;dockers&amp;#34;: [] }, { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-B589A0D9-FA79-4C12-95B7-253E72480384&amp;#34;, &amp;#34;properties&amp;#34;: { &amp;#34;overrideid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;documentation&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;conditionsequenceflow&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;executionlisteners&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;defaultflow&amp;#34;: &amp;#34;false&amp;#34; }, &amp;#34;stencil&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;SequenceFlow&amp;#34; }, &amp;#34;childShapes&amp;#34;: [], &amp;#34;outgoing&amp;#34;: [ { &amp;#34;resourceId&amp;#34;: &amp;#34;sid-1A762474-62B9-4F3D-A81C-1ADD46AF7D2F&amp;#34; } ], &amp;#34;bounds&amp;#34;: { &amp;#34;lowerRight&amp;#34;: { &amp;#34;x&amp;#34;: 645.</description></item><item><title>Activiti 5.17 JNDI数据源配置</title><link>https://mryqu.github.io/post/activiti_5.17_jndi%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</link><pubDate>Thu, 12 Feb 2015 20:18:53 +0000</pubDate><guid>https://mryqu.github.io/post/activiti_5.17_jndi%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</guid><description>Activiti演示环境采用的是h2内存数据库。为了便于研究代码，所以将其迁移到我已有的MySQL/PostgreSQL数据库上去。
MySQL MySQL配置 activiti数据库DDL文件位于activiti-engine-5.17.0.jar\org\activiti\db\create\，MySQL 5.6.4及其之后版本与之前的版本使用的是不同的DDL文件。将下列用于MySQL5.6.4+的DDL文件提取保存到某一目录下。
activiti.mysql.create.engine.sql activiti.mysql.create.identity.sql activiti.mysql.create.history.sql MySQL命令如下：
create database ActivitiDB character set utf8 collate utf8_general_ci; use ActivitiDB; source c:/activiti.mysql.create.engine.sql; source c:/activiti.mysql.create.identity.sql; source c:/activiti.mysql.create.history.sql; Tomcat配置 删除下列MyBatis配置文件：
apache-tomcat-7\webapps\activiti-explorer\WEB-INF\classes\db.properties apache-tomcat-7\webapps\activiti-rest\WEB-INF\classes\db.properties 修改下列Spring配置文件：
apache-tomcat-7\webapps\activiti-explorer\WEB-INF\classes\activiti-custom-context.xml apache-tomcat-7\webapps\activiti-rest\WEB-INF\classes\activiti-custom-context.xml 去掉XMl注释，删除&amp;quot;dbProperties&amp;quot;bean，将&amp;quot;dataSource&amp;quot;bean改成JNDI数据源。 修改下列Tomcat上下文，配置Tomcat JNDI资源：
apache-tomcat-7\webapps\activiti-explorer\META-INF\context.xml apache-tomcat-7\webapps\activiti-rest\META-INF\context.xml PostgreSQL PostgreSQL配置 activiti数据库DDL文件位于activiti-engine-5.17.0.jar\org\activiti\db\create\，将下列用于PostgreSQL的DDL文件提取保存到某一目录下。
activiti.postgres.create.engine.sql activiti.postgres.create.identity.sql activiti.postgres.create.history.sql PostgreSQL命令如下：
CREATE DATABASE ActivitiDB WITH ENCODING &amp;#39;UTF8&amp;#39; TEMPLATE=template0; \c ActivitiDB; \i c:/activiti.postgres.create.engine.sql; \i c:/activiti.postgres.create.identity.sql; \i c:/activiti.postgres.create.history.sql; Tomcat配置 删除下列MyBatis配置文件：
apache-tomcat-7\webapps\activiti-explorer\WEB-INF\classes\db.properties apache-tomcat-7\webapps\activiti-rest\WEB-INF\classes\db.properties 修改下列Spring配置文件：
apache-tomcat-7\webapps\activiti-explorer\WEB-INF\classes\activiti-custom-context.xml apache-tomcat-7\webapps\activiti-rest\WEB-INF\classes\activiti-custom-context.xml 去掉XMl注释，删除&amp;quot;dbProperties&amp;quot;bean，将&amp;quot;dataSource&amp;quot;bean改成JNDI数据源。 修改下列Tomcat上下文，配置Tomcat JNDI资源：
apache-tomcat-7\webapps\activiti-explorer\META-INF\context.xml apache-tomcat-7\webapps\activiti-rest\META-INF\context.</description></item><item><title>Activiti模型编辑器之前前身：Oryx editor</title><link>https://mryqu.github.io/post/activiti%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%BE%91%E5%99%A8%E4%B9%8B%E5%89%8D%E5%89%8D%E8%BA%ABoryx_editor/</link><pubDate>Wed, 11 Feb 2015 21:57:18 +0000</pubDate><guid>https://mryqu.github.io/post/activiti%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%BE%91%E5%99%A8%E4%B9%8B%E5%89%8D%E5%89%8D%E8%BA%ABoryx_editor/</guid><description>我的The history and commercial version of Activiti Modeler博文里提到Activiti建模器组件是由Signavio捐赠的Signavio Core Components project， 可以说Activiti模型组件的前身是Signavio Core Components project， 那么Signavio Core Components project的前身又是什么呢？ Signavio (wiki)里面提到了Signavio是德国波茨坦大学哈索普莱特纳研究院（HPI）毕业生团队创建的。在Signavio之前，Signavio的这些创始人在HPI从2006年开始开发了世界上第一个用于BPMN的web建模器Oryx，一个学术性开源项目。Oryx就是Signavio Core Components project开源版和Signavio Process Editor商业版的蓝图。随着Signavio公司的产生，Oryx项目被废弃了、不再进行维护。 Oryx开发团队
答案就是：Signavio Core Componentsproject的前身，即Activiti模型编辑器之前前身是Oryx。Oryx里面有一些设计文档，对学习Activiti建模器组件仍然有一定的帮助。
参考 http://en.wikipedia.org/wiki/Signavio http://bpt.hpi.uni-potsdam.de/Oryx/News https://github.com/Activiti http://code.google.com/p/signavio-core-components/ https://code.google.com/p/oryx-editor/</description></item><item><title>The history and commercial version of Activiti Modeler</title><link>https://mryqu.github.io/post/the_history_and_commercial_version_of_activiti_modeler/</link><pubDate>Wed, 11 Feb 2015 20:06:15 +0000</pubDate><guid>https://mryqu.github.io/post/the_history_and_commercial_version_of_activiti_modeler/</guid><description>The history of Activiti Modeler Activiti Modeler component is as part of the Activiti projectfrom the start. This Modeler was donated by Signavio as part of the Signavio Core Components project. This project was not maintained anymoresince 2011 (Activiti 5.7) and Activiti team no longer considered it‘core’ to Activiti. Tijs Rademakers (the author of Activiti in Action) has spentquite some in his spare time to master, enhance and tweak the ‘oldcode base’, fork the Signavio Core Components project and create acompletely new, maintainable codebase.</description></item><item><title>业务流程建模标注工具比较</title><link>https://mryqu.github.io/post/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E5%BB%BA%E6%A8%A1%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E6%AF%94%E8%BE%83/</link><pubDate>Tue, 10 Feb 2015 20:03:36 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E5%BB%BA%E6%A8%A1%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E6%AF%94%E8%BE%83/</guid><description>原文http://en.wikipedia.org/wiki/Comparison_of_Business_Process_Modeling_Notation_tools ，留着学习参考、技术选型。
General NameCreatorPlatform / OSBPMN VersionFeaturesFirst ReleaseLatest ReleaseSoftware licenseActiviti ModelerAlfresco&amp;nbsp;and theActiviti communityCross-platformBPMN 2.0Modeler,&amp;nbsp;Simulation,&amp;nbsp;Execution2010-05-17[1]2014-10-16[2]Apache License&amp;nbsp;2.0[3]ActiveVOSInformaticaWindows,&amp;nbsp;LinuxBPMN 2.0Modeling, Testing and Execution with open standards.20052014ProprietaryADONIS (software)BOC Information Technologies Consulting AGWindowsBPMN 2.0Business Process Analysis (BPA) tool supporting businessprocess management allowing process modeling, analysis, simulation,evaluation, publishing and automation. Freeware Community Editionavailable.19952012Proprietary/FreewareAgiles BPMS &amp;amp; ECMIMAGE Technology S.A.Windows,&amp;nbsp;Linux,MacBPMN 2.0Modeler,&amp;nbsp;Execution,2003-Oct2013-SepProprietaryAltova&amp;nbsp;UModelAltovaWindowsBPMN&amp;nbsp;1.1, 2.0Includes BPMN,&amp;nbsp;UML,&amp;nbsp;SysML, C#and&amp;nbsp;Java&amp;nbsp;round trip code generation,documentation, collaboration (includingwith&amp;nbsp;MetaTeam) and database modeling20052013-06-12Proprietary[4]ARCWAY CockpitARCWAY AGWindows,&amp;nbsp;Mac&amp;nbsp;(Linuxunofficially)BPMN 2.0BPMN Collaboration Diagrams, EPC, Petri Nets, integratedwith&amp;nbsp;FMC&amp;nbsp;Blockdiagramsfor business and IT architecture,&amp;nbsp;UML&amp;nbsp;Class diagramsfor data models and&amp;nbsp;Requirements management20052014Proprietary, free single user (Designer) editionARIS ExpressSoftware AGWindows&amp;nbsp;(andLinux,&amp;nbsp;Macunofficially)BPMN 2.</description></item><item><title>了解Activiti Explorer及其Vaadin实现方式</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3activiti_explorer%E5%8F%8A%E5%85%B6vaadin%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</link><pubDate>Tue, 10 Feb 2015 16:04:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3activiti_explorer%E5%8F%8A%E5%85%B6vaadin%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</guid><description>通过ActivitiModeler架构图可知，Activiti Explorer采用的是Vaadin框架。 Vaadin 是一种 Java Web 应用程序的开发框架, 其设计目标是便利地创建和维护高质量的 Web UI 应用程序.Vaadin 支持两种不同的开发模式: 服务器端开发和客户端开发. 服务器端开发方式是这二者中更为强大的一种. 它能帮助开发者忘记Web 程序的各种实现细节, 使得 Web 应用程序的开发变得就象过去使用便利的Java开发工具(如AWT, Swing,SWT)来开发桌面应用程序一样, 甚至更简单。 Vaadin 应用程序中基本上所有的逻辑都是运行在服务器端的 Java Servlet API 上的，如下图中Vaadin的运行时结构图所示，Vaadin运行时结构主要由服务器端框架和客户端引擎两部分构成。服务器端框架包含了用来与客户端引擎通讯的服务器端集成层以及一系列的 server端 UI 组件。客户端引擎则由 Google Web toolkit(GWT) 页面渲染模块和客户端集成层两部分组成。 ActivitiExplorer的代码位于Activiti\modules\activiti-explorer下： 参考资料 vaadin官方网站 book of vaadin 中文版 Vaadin - 来自北欧的 Web 应用开发利器，第 1 部分: Vaadin 的基本概况和基础开发 Vaadin - 来自北欧的 Web 应用开发利器，第 2 部分: Vaadin 的体系结构和功能扩展</description></item><item><title>搭建Activiti的IntelliJ IDEA开发调试环境</title><link>https://mryqu.github.io/post/%E6%90%AD%E5%BB%BAactiviti%E7%9A%84intellij_idea%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83/</link><pubDate>Mon, 09 Feb 2015 20:03:46 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%90%AD%E5%BB%BAactiviti%E7%9A%84intellij_idea%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83/</guid><description>准备工作 在搭建Activiti的IntelliJ IDEA开发调试环境前，确保下列软件已经安装：
JDK 1.6 ant Maven IntelliJ IDEA 导入Activiti Import Project 通过Activiti的Maven pom.xml导入IntelliJ IDEA项目。 Import Modules 导入IntelliJ IDEA项目后，仅有几个Activiti模块变成了IntelliJIDEA项目中的模块。为了可以调试所有模块，通过ProjectStructure菜单简单粗暴地将剩余的Activiti模块导入IntelliJ模块。 对每个手工导入的模块设置源代码、资源、测试代码和测试资源。 Frameworks Dection 手工导入所有模块后，重启IntelliJ IDEA，它会自动检测所有模块的类型，例如Spring、WEB、JPA和GWT等。 构建Activiti Activiti项目可以通过下面的ant命令构建：
.....\wfgitws\Activiti\distro&amp;gt;ant -Dnodocs=true clean distro 也可以在IntelliJ IDEA IDE中构建： 本地调试 To make sure that the necessary application server plugin isenabled 本测试中使用Apache Tomcat服务器。 Defining application servers in IntelliJ IDEA Check and configure artifacts in IntelliJ IDEA Add run/local configuration in IntelliJ IDEA Run in IntelliJ IDEA Add Jetbrain IDE plugin in Chrome 远程调式 Remote Debugging Configuration 通过Run-Edit Configuration菜单命令，添加一个远程调试配置。 该调试配置需要同Tomcat保持一致 Remote Debugging 设置断点，在Activiti Explorer上的操作触发断点，该Activiti的IntelliJIDEA开发调试环境已经可以工作了。</description></item><item><title>了解Activiti组件</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3activiti%E7%BB%84%E4%BB%B6/</link><pubDate>Sat, 07 Feb 2015 18:19:05 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3activiti%E7%BB%84%E4%BB%B6/</guid><description>Activiti 简介 Activiti作为一个遵从 Apache许可的工作流和业务流程管理开源平台，其核心是基于 Java 的超快速、超稳定的 BPMN 2.0流程引擎，强调流程服务的可嵌入性和可扩展性，同时更加强调面向业务人员。Activiti可以运行在任何JAVA程序中：单机、服务器、集群或云上。
Activiti 组件 Activiti Modeler—建模器Activiti建模器是基于开源的Signavio流程编辑器的一个定制版本，可以使用浏览器图形化地编辑BPMN2.0兼容流程，流程文件被存储在数据库模型仓库内。Activiti团队已经停止Activiti建模器的活跃开发，目前仍保留在ActivitiExplorer内。 Activiti Designer—设计器Activiti设计器是Eclipse插件形式的，除了可以建模BPMN2.0流程，还支持Activiti特定的扩展，可以发挥Activiti流程和引擎的全部潜能。 Activiti Kickstart—基于表格的流程设计在Activiti Explorer的Model workspace里新建模型时选择Table-drivendefination时就是所谓的ActivitiKickstart，现在Activiti Designer里也包含这一功能。 Activiti ExplorerExplorer是流程引擎的Web用户控制台。使用它来进行任务管理、流程实例检查、管理和基于历史统计数据查看报表等等。它不是一个的最终客户可用的成熟监控和管理应用程序，仅用于演示Activiti如何用于用户的应用中。 Activiti RestActiviti引擎的 REST API。此外，曾经存在过下面两个组件（至少 Activiti 5.0-alpha4版本）： ActivitiProbe：一个对流程引擎运行期实例提供管理及监控的web应用程序。包含部署的管理、流程定义的管理、数据库表的检视、日志查看、事务的平均执行时间、失败多次的工作等功能。已经变成ActivitiExplorer的一部分 Activiti Cycle：BPM协作用具，改用camunda Cycle了 参考 Activiti官方网站 Activiti用户指南 Activiti组件 Activiti开发指南 Activiti Javadoc Activiti源代码(GitHub) Adhoc workflow with Activiti: introducing Activiti KickStart Activiti Cycle explained Easy Workflows - Activiti Kickstart Activiti - 新一代的开源 BPM 引擎</description></item><item><title>[OpenUI5] 第三方JavaScript库加载</title><link>https://mryqu.github.io/post/openui5_%E7%AC%AC%E4%B8%89%E6%96%B9javascript%E5%BA%93%E5%8A%A0%E8%BD%BD/</link><pubDate>Fri, 06 Feb 2015 20:28:33 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E7%AC%AC%E4%B8%89%E6%96%B9javascript%E5%BA%93%E5%8A%A0%E8%BD%BD/</guid><description>SAP often put 3rd JavaScript libraries at \resources\sap\ui\thirdparty, then load as below:
jQuery.sap.require(&amp;#34;sap/ui/thirdparty/d3&amp;#34;); 样例： OpenUI5: D3.js based custom control and table
Custom SAPUI5 Visualization Controls with D3.js</description></item><item><title>Activiti相关帖子汇总</title><link>https://mryqu.github.io/post/activiti%E7%9B%B8%E5%85%B3%E5%B8%96%E5%AD%90%E6%B1%87%E6%80%BB/</link><pubDate>Thu, 05 Feb 2015 20:07:13 +0000</pubDate><guid>https://mryqu.github.io/post/activiti%E7%9B%B8%E5%85%B3%E5%B8%96%E5%AD%90%E6%B1%87%E6%80%BB/</guid><description>咖啡兔 :《Activiti实战》作者闫洪磊Activiti相关博文 iteye - pyzheng的博客工作流相关博文 csdn - howareyoutodaysoft的博客Activiti相关博文 新浪博客 - 微笑浆糊-xerllentbpm工作流相关博文 网易博客 - homeland520 工作流引擎相关博文 csdn - fanfan159357的专栏Activiti designer源码研究相关博文 csdn - 白乔专栏工作流activiti的一些概念Activiti源码浅析：Activity与TaskActiviti源码浅析：Activiti的活动授权机制activiti 源码笔记之startProcess[转]Activiti源码分析（框架、核心类。。。）[转]activiti源码解读之心得整编在Activiti官方源码上提交的两个bugfix csdn - 宋三丝的专栏Activiti相关博文 iteye - jhaij的博客集成activiti-modeler 到 自己的业务系统(集成流程跟踪-完美支持IE)activiti taskservice addComment Provided id is nullactiviti 用户任务 iteye站内Activiti相关博文
csdn站内Activiti相关博文
开源中国社区（oschina.net）站内Activiti相关博文</description></item><item><title>[算法] 实证分析</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E5%AE%9E%E8%AF%81%E5%88%86%E6%9E%90/</link><pubDate>Tue, 03 Feb 2015 19:53:35 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E5%AE%9E%E8%AF%81%E5%88%86%E6%9E%90/</guid><description>最近又重温了一下算法课中的实证分析。
首先针对不同大小的输入获取运行时长。 可以通过标准坐标图或双对数坐标图查看运行时常与输入大小的关系。 通过成倍增加输入量，可以更便利地估算T(N)与N之间的幂指数关系。 lg( T(N) ) = b lg( N ) + c 即 T(N) = a Nb, 其中 a = 2c b = ( lg( T(2N1) ) - lg( T(N1)) ) ) / ( lg(2N1)) - lg( N1) ) ) = lg( T(2N1)) ) -lg( T(N1)) ) a = T(2N1)) / (2N1))b 可以教程上第二行就可以计算出b，这就有点不对头了。时常为零，意味着取对数的结果是-∞。返回数值是以毫秒为单位的，因此一般时长也应该是为毫秒为单位的。估计教程上时常实际精度为三位而显示精度为一位，导致不一致的。 下图是我用Excel根据教程显示数据计算的结果：</description></item><item><title>[OpenUI5] 数据绑定模式</title><link>https://mryqu.github.io/post/openui5_%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 02 Feb 2015 00:24:09 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%E6%A8%A1%E5%BC%8F/</guid><description>OpenUI5数据绑定模式概念 OpenUI5开发指南-数据绑定模式介绍了OpenUI5数据绑定模式概念和不同模型的默认值。
绑定模式 绑定模式定义了数据源如何绑定。不同模型实现需要特定绑定模式。例如资源模型仅支持模型到视图的一次性绑定。 SAPUI5提供如下绑定模式：
单向绑定：单向绑定意味着模型到视图的绑定；模型中的数据变化将更新相应的绑定和视图。 双向绑定：双向绑定意味着模型到视图及视图到模型的绑定；模型/视图中的数据变化将更新相应的绑定和视图/模型。 一次性绑定：一次性绑定意味着模型到视图的绑定。 下表展示了不同模型分别支持的绑定模式：
|模型|一次性绑定|双向绑定|单向绑定 |&amp;mdash;&amp;ndash; |资源模型|&amp;ndash;|&amp;ndash;|X |JSON模型|X|X|X |XML模型|X|X|X |OData模型|X|X|X
资源模型仅处理静态文本，所以仅支持一次性绑定模式
模型的默认绑定模式 当模型实例被创建后，该实例具有一个默认绑定模式。该模型实例的所有绑定会采用他们自己默认绑定模式。 下表展示了不同模式实现的默认绑定模式。
|模型|默认绑定模式 |&amp;mdash;&amp;ndash; |资源模型|一次性绑定 |JSON模型|双向绑定 |XML模型|双向绑定 |OData模型|单向绑定
OpenUI5数据绑定模式范例 OpenUI5开发指南-数据绑定入门介绍了数据绑定使用范例。
OpenUI5数据绑定模式源代码研究 数据绑定模式在sap.ui.model.BindingMode中定义。 通过如上类图可知，JSON模型类和XML模型类继承自客户端模型类，资源模型和OData模型直接继承自模型类。 客户端模型具有额外的setData方法。客户端模型相对模型类多了一层客户端数据，可以存储视图属性变化相应的数据，应此能够在不跟服务器端交互的情况下实现双向绑定。网上的很多演示采用客户端模型，就是因为无需搭建服务器，易于实现。 模型类原型有一个checkUpdate方法，用于在模型数据发生变化后，检查模型的所有绑定是否需要更新以实现模型到视图的绑定。其调用情况如下：
JSON模型和XML模型：被setData和setProperty方法调用 OData模型：被loadData、setProperty和refresh方法调用 资源模型：无调用 视图到模型的绑定，主要在sap.ui.base.ManagedObject类实现。 ManagedObject是所有视图控件的祖宗类，ManagedObject原型的_bindProperty方法判别绑定模式是否是一次性绑定，是的话就将绑定上的事件和模型数据变化处理程序卸载掉。 ManagedObject原型的updateModelProperty方法判别绑定模式是否是双向绑定，是的话就将视图属性变化写入绑定，从而将数据写入模型。
参考 OpenUI5 API参考指南
sap.ui.model包源代码 - GitHub</description></item><item><title>[Hadoop] YARN中的AuxiliaryService</title><link>https://mryqu.github.io/post/hadoop_yarn%E4%B8%AD%E7%9A%84auxiliaryservice/</link><pubDate>Sun, 01 Feb 2015 12:39:55 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_yarn%E4%B8%AD%E7%9A%84auxiliaryservice/</guid><description>一个附属服务（AuxiliaryService）是由YARN中节点管理器（NM）启动的通用服务。该服务由YARN配置&amp;ldquo;yarn.nodemanager.aux-services&amp;rdquo;定义。默认值为mapreduce_shuffle，即MRv2中的ShuffleHandler。 AuxiliaryService是节点管理器内的服务，接收应用/容器初始化和停止事件并作相应处理。 MRv2提供了一个叫做org.apache.hadoop.mapred.ShuffleHandler的内建AuxiliaryService，用于将节点内map输出文件提供给reducer(上图中除ShuffleHandler之外的其他AuxiliaryService子类均为测试类)。 节点管理器可能有多个AuxiliaryService，类AuxServices用于处理此类服务集合。 当AuxServices对象启动，它从YarnConfiguration.NM_AUX_SERVICES（即&amp;quot;yarn.nodemanager.aux-services&amp;quot;）获得附属服务名，从YarnConfiguration.NM_AUX_SERVICE_FMT（即&amp;quot;yarn.nodemanager.aux-services.%s.class&amp;quot;）获得对应的服务类名。例如&amp;quot;yarn.nodemanager.aux-services.mapreduce_shuffle.class&amp;quot;对应ShuffleHandler类。之后它将服务置入serviceMap并调用init()方法对服务进行初始化。 Hadoop实现是一个事件驱动系统。AuxServices既是ServiceStateChangeListener也是EventHandler，用于处理AuxServicesEventType事件。
public enum AuxServicesEventType { APPLICATION_INIT, APPLICATION_STOP, CONTAINER_INIT, CONTAINER_STOP } public class AuxServicesEvent extends AbstractEvent { private final String user; private final String serviceId; private final ByteBuffer serviceData; private final ApplicationId appId; private final Container container; } public abstract class AbstractEvent&amp;gt; implements Event { private final TYPE type; private final long timestamp; } 在handle(AuxServicesEventevent)方法中，每个事件与AuxiliaryService中的一个API调用相关连。例如，只要AuxServices收到一个APPLICATION_INIT事件，对应AuxiliaryService的initializeApplication()方法就会被调用。 那一个事件如何被传递给AuxServices的？ NodeManager类包含一个ContainerManagerImpl对象变量，而ContainerManagerImpl类包含一个AuxServices对象变量。此外ContainerManagerImpl类有自己的AsyncDispatcher,它会向AuxServices分发所有AuxServicesEventType类型事件。 AuxServicesEventType.APPLICATION_STOP事件在ApplicationImpl类中被创建，节点管理器中应用表述的状态机触发。 其他三个的AuxServicesEventType事件，例如APPLICATION_INIT、CONTAINER_INIT和CONTAINER_STOP，在ContainerImpl类中随着容器的生命周期被创建。
参考 AuxiliaryService in Hadoop 2 Implementing a Custom Shuffle and a Custom Sort</description></item><item><title>[JavaScript] Open/SaveAs File</title><link>https://mryqu.github.io/post/javascript_%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E5%92%8C%E5%8F%A6%E5%AD%98%E6%96%87%E4%BB%B6/</link><pubDate>Sat, 31 Jan 2015 12:42:22 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E5%92%8C%E5%8F%A6%E5%AD%98%E6%96%87%E4%BB%B6/</guid><description>看了一下HTML5应用中如何打开文件或另存文件。与Swing/EclipseRCP应用不同，有些操作由于安全的原因无法在HTML5应用内使用，而是浏览器与客户交互。例如HTML5应用往本地写文件。下面的显示了在新窗口打开文件、在当前窗口打开文件以及a标签的download属性。 学习了下面链接中的代码和文章，其中FileSaver.js是一个跨浏览器的JS库，但是在各个浏览器上保存文件的用户体验却不相同。目前为止，我还没发现更好的跨浏览器/设备的另存文件解决方案。 Google HTML5 Download Demo
An HTML5 saveAs() FileSaver implementation
New HTML5 Attributes for Hyperlinks: download, media, and ping
Save files on disk using JavaScript or JQuery!
JavaScript Question:Opening Save As Dialog
Internet media type</description></item><item><title>[Git] Create patch with untracked files</title><link>https://mryqu.github.io/post/git_create_patch_with_untracked_files/</link><pubDate>Tue, 27 Jan 2015 20:10:27 +0000</pubDate><guid>https://mryqu.github.io/post/git_create_patch_with_untracked_files/</guid><description>前一博文Create patch with untracked files using Git format-patch/diff/stash中的方案比较绕，今天有了一个更好一点的法子:
git add . git diff --cached &amp;gt; yqu.patch git reset origin/master</description></item><item><title>[Git] Create patch with untracked files using Git format-patch/diff/stash</title><link>https://mryqu.github.io/post/git_create_patch_with_untracked_files_using_git_format-patch_diff_stash/</link><pubDate>Mon, 26 Jan 2015 20:03:22 +0000</pubDate><guid>https://mryqu.github.io/post/git_create_patch_with_untracked_files_using_git_format-patch_diff_stash/</guid><description>Setup testing environment I created 123.txt at branch master, then modified 123.txt and added321.txt at branch yqu
C:\test&amp;gt;mkdir GitTest C:\test&amp;gt;cd GitTest C:\test\GitTest&amp;gt;git init Initialized empty Git repository in C:/test/GitTest/.git/ C:\test\GitTest&amp;gt;echo &amp;#34;this is a file at mast branch&amp;#34; &amp;gt; 123.txt C:\test\GitTest&amp;gt;git add 123.txt C:\test\GitTest&amp;gt;git commit -m &amp;#34;initial commit&amp;#34; [master (root-commit) f140825] initial commit 1 file changed, 1 insertion(+) create mode 100644 123.txt C:\test\GitTest&amp;gt;git push origin HEAD:master C:\test\GitTest&amp;gt;git checkout -b yqu Switched to a new branch &amp;#39;yqu&amp;#39; C:\test\GitTest&amp;gt;echo &amp;#34;bye&amp;#34; &amp;gt;&amp;gt; 123.</description></item><item><title>[C] 了解printf中的%.s</title><link>https://mryqu.github.io/post/c_%E4%BA%86%E8%A7%A3printf/</link><pubDate>Thu, 22 Jan 2015 20:59:59 +0000</pubDate><guid>https://mryqu.github.io/post/c_%E4%BA%86%E8%A7%A3printf/</guid><description>偶尔看到C代码printf(&amp;quot;%.*s&amp;quot;,dataL,data);，对printf中的格式化字符串&amp;quot;%.*s&amp;quot;有点不解。
查看了http://www.cplusplus.com/reference/cstdio/printf/文档后，有所理解。
| width |description |&amp;mdash;&amp;ndash; | (number) |Minimum number of characters to be printed. If the value tobe printed is shorter than this number, the result is padded withblank spaces. The value is not truncated even if the result islarger. | * |The width is not specified in the format string, but as an additional integer value argument preceding theargument that has to be formatted.
| .precision |description |&amp;mdash;&amp;ndash; | .</description></item><item><title>WebDAV Javascript库</title><link>https://mryqu.github.io/post/webdav_javascript%E5%BA%93/</link><pubDate>Tue, 20 Jan 2015 08:57:36 +0000</pubDate><guid>https://mryqu.github.io/post/webdav_javascript%E5%BA%93/</guid><description>需要用JS库对WebDAV进行CRUD操作，找了一堆备选JS库。
IT Hit WebDAV Ajax Library：http://www.webdavsystem.com/ajax/programming https://github.com/sandro-pasquali/jquery.dav https://github.com/evert/davclient.js https://github.com/matthewp/webdav https://github.com/aslakhellesoy/webdavjs https://github.com/dom111/webdav-js https://github.com/sara-nl/js-webdav-client</description></item><item><title>Spring3 REST can't solve list of object generated by Javascript</title><link>https://mryqu.github.io/post/spring3_rest_cant_solve_list_of_object_generated_by_javascript/</link><pubDate>Fri, 16 Jan 2015 21:21:44 +0000</pubDate><guid>https://mryqu.github.io/post/spring3_rest_cant_solve_list_of_object_generated_by_javascript/</guid><description>最近遭遇Spring3REST无法解析对象数组这么一个问题。为了排除客户端Javascript代码嫌疑，我通过GET操作从Spring RestfulWeb服务获取一个复杂对象，然后通过POST操作将其原封不动返给Spring Restful Web服务，问题依旧重现。
客户端代码 var meatadata=&amp;#39;[{&amp;#34;varName&amp;#34;:&amp;#34;id&amp;#34;,&amp;#34;varTitle&amp;#34;:&amp;#34;The Id&amp;#34;,&amp;#34;varIndex&amp;#34;:1},{&amp;#34;varName&amp;#34;:&amp;#34;name&amp;#34;,&amp;#34;varTitle&amp;#34;:&amp;#34;The Name&amp;#34;,&amp;#34;varIndex&amp;#34;:2},{&amp;#34;varName&amp;#34;:&amp;#34;age&amp;#34;,&amp;#34;varTitle&amp;#34;:&amp;#34;The Age&amp;#34;,&amp;#34;varIndex&amp;#34;:3}]&amp;#39;; $.ajax({ url: &amp;#34;configure&amp;#34;, type: &amp;#34;POST&amp;#34;, data: metadata, dataType: &amp;#34;json&amp;#34;, contentType: &amp;#34;application/json&amp;#34;, success: function (res) { $(&amp;#39;#cfgContent&amp;#39;).text(JSON.stringify(res)); $(&amp;#39;#cfgError&amp;#39;).text(&amp;#34;&amp;#34;); }, error: function (res) { $(&amp;#39;#cfgContent&amp;#39;).text(&amp;#34;&amp;#34;); $(&amp;#39;#cfgError&amp;#39;).text(res.responseText); } }); 中间层代码 package com.yqu.rest; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.*; import org.springframework.web.servlet.ModelAndView; import java.util.ArrayList; import java.util.List; @RestController public class ConfigurationController { @RequestMapping(value = &amp;#34;/&amp;#34;, method = RequestMethod.GET) public ModelAndView home(Model m){ System.out.println(&amp;#34;home&amp;#34;); return new ModelAndView(&amp;#34;index&amp;#34;); } @RequestMapping(value = &amp;#34;/configure&amp;#34;, method = RequestMethod.</description></item><item><title>Spring REST can't solve nested object array generated by JavaScript</title><link>https://mryqu.github.io/post/spring_rest_cant_solve_nested_object_array_generated_by_javascript/</link><pubDate>Thu, 15 Jan 2015 21:27:22 +0000</pubDate><guid>https://mryqu.github.io/post/spring_rest_cant_solve_nested_object_array_generated_by_javascript/</guid><description>最近遭遇SpringREST无法解析嵌套对象数组这么一个问题。为了排除客户端Javascript代码嫌疑，我通过GET操作从Spring RestfulWeb服务获取一个复杂对象，然后通过POST操作将其原封不动返给Spring Restful Web服务，问题依旧重现。
所操作的复杂对象 客户端POST响应 中间层代码 package com.yqu.rest; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.*; import org.springframework.web.servlet.ModelAndView; import java.util.ArrayList; import java.util.List; @RestController public class ConfigurationController { @RequestMapping(value = &amp;#34;/&amp;#34;, method = RequestMethod.GET) public ModelAndView home(Model m){ System.out.println(&amp;#34;home&amp;#34;); return new ModelAndView(&amp;#34;index&amp;#34;); } @RequestMapping(value = &amp;#34;/configure&amp;#34;, method = RequestMethod.GET) public @ResponseBody SheetVO getConfiguration() { List columns = new ArrayList(); columns.add(new ColumnVO(&amp;#34;id&amp;#34;,&amp;#34;The Id&amp;#34;,1)); columns.add(new ColumnVO(&amp;#34;name&amp;#34;,&amp;#34;The Name&amp;#34;,2)); columns.add(new ColumnVO(&amp;#34;age&amp;#34;,&amp;#34;The Age&amp;#34;,3)); SheetVO metadata = new SheetVO(SheetVO.</description></item><item><title>[OpenUI5] 示例: open dialog which content is a form defined in another view</title><link>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8B_open_dialog_which_content_is_a_form_defined_in_another_view/</link><pubDate>Sun, 11 Jan 2015 21:11:32 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E7%A4%BA%E4%BE%8B_open_dialog_which_content_is_a_form_defined_in_another_view/</guid><description>使用OpenUI5做了一个例子，在一个JSVIEW中定义的dialog的内容是另外一个JSVIEW中定义的form。 示例位置: http://jsbin.com/fotepu/1/edit?html,output 此外，通过学习http://stackoverflow.com/questions/25510090/sapui5-attach-chart-to-dialog ，了解到dialog内容为图表时有可能需要使用invalidate()函数。</description></item><item><title>[OpenUI5] 获得当前页面语言</title><link>https://mryqu.github.io/post/openui5_%E8%8E%B7%E5%BE%97%E5%BD%93%E5%89%8D%E9%A1%B5%E9%9D%A2%E8%AF%AD%E8%A8%80/</link><pubDate>Sat, 10 Jan 2015 15:33:19 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E8%8E%B7%E5%BE%97%E5%BD%93%E5%89%8D%E9%A1%B5%E9%9D%A2%E8%AF%AD%E8%A8%80/</guid><description>获得当前页面语言的方法：
javascript:document.getElementsByTagName('html')[0].getAttribute('lang') jQuery: $('html').attr('lang') OpenUI5: sap.ui.getCore().getConfiguration().getLanguage() 示例：</description></item><item><title>[OpenUI5] 快速定位OpenUI5问题的一个方法</title><link>https://mryqu.github.io/post/openui5_%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8Dopenui5%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95/</link><pubDate>Fri, 09 Jan 2015 16:30:12 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8Dopenui5%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95/</guid><description>sap.ui.base.Object是所有OpenUI5对象的父类，它的某些方法对快速定位OpenUI5问题很有帮助。我写了一个小函数通过OpenUI5对象的元数据获得类名，并且获得OpenUI5对象的ID信息。
traceUI5Object: function(obj) { if(obj instanceof sap.ui.base.Object) console.log(obj.getMetadata().getName()+&amp;#34;{id:\&amp;#39;&amp;#34;+obj.getId()+&amp;#34;\&amp;#39;}&amp;#34;); } traceUI5EventProviders: function(obj) { var that = obj; while (that &amp;amp;&amp;amp; that instanceof sap.ui.base.EventProvider) { console.log(that.getMetadata().getName()+&amp;#34;{id:\&amp;#39;&amp;#34;+that.getId()+&amp;#34;\&amp;#39;}&amp;#34;); that = that.getEventingParent(); } } traceUI5EventProviders函数运行结果示例： sap.ui.commons.CheckBox{id:&amp;#39;check1&amp;#39;} sap.ui.commons.Panel{id:&amp;#39;panel1&amp;#39;} sap.ui.core.mvc.JSView{id:&amp;#39;leftView&amp;#39;} sap.ui.commons.Splitter{id:&amp;#39;Splitter1&amp;#39;} sap.ui.core.mvc.JSView{id:&amp;#39;__jsview0&amp;#39;} sap.ui.core.UIArea{id:&amp;#39;content&amp;#39;} 在编写和调试OpenUI5时，有时会有Exception抛出。 假定上面图中代码会抛出Exception，通过this我们看到的的是一个Factory，通过sId我们可以找到发生问题的定义了ID的控件。但是如果控件ID是自生成的，就不太容易了。我们可以通过监视表达式获取（组件链上所有的）组件类名及ID，这样就可以更快定位导致抛出Exception的OpenUI5视图/控件了。</description></item><item><title>[OpenUI5] MVC和EventBus示例</title><link>https://mryqu.github.io/post/openui5_mvc%E5%92%8Ceventbus%E7%A4%BA%E4%BE%8B/</link><pubDate>Fri, 09 Jan 2015 12:11:23 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_mvc%E5%92%8Ceventbus%E7%A4%BA%E4%BE%8B/</guid><description>昨天发了一个帖子[OpenUI5] MVC：访问其他View/Controller的方法，里面的示例是用违反MVC原则的方式演示一下效果，今天又在jsbin上做了个OpenUI5MVC &amp;amp; EventBus示例：http://jsbin.com/nixomo/1/edit?html,output。 sap.ui.core.EventBus使用起来很简单。
通过var bus = sap.ui.getCore().getEventBus() 获得消息总线 接收方首先在某个消息通道上订阅消息时间并注册消息监听器listener 发送方在这个消息通道上发布消息，接收方就会去处理 通过阅读代码可知，EventBus一个实例对应一个消息通道，EventBus的_defaultChannel和_mChannels都是sap.ui.base.EventProvider实例，用于事件注册与分发、将数据与事件的绑定/解绑。上图中就是消息通道&amp;quot;rightViewChannel&amp;quot;对应的EventBus实例，已经注册了两个事件setRightPanelVisible和doSomething。</description></item><item><title>[OpenUI5] MVC：访问其他View/Controller的方法</title><link>https://mryqu.github.io/post/openui5_mvc%E8%AE%BF%E9%97%AE%E5%85%B6%E4%BB%96view%E6%88%96controller%E7%9A%84%E6%96%B9%E6%B3%95/</link><pubDate>Thu, 08 Jan 2015 19:42:03 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_mvc%E8%AE%BF%E9%97%AE%E5%85%B6%E4%BB%96view%E6%88%96controller%E7%9A%84%E6%96%B9%E6%B3%95/</guid><description>访问其他视图/控件的方法 在创建视图/控件实例时，设置ID：
var oViewLeft = sap.ui.jsview(&amp;#34;leftView&amp;#34;, &amp;#34;com.yqu.view.Left&amp;#34;); var oPanelRight = new sap.ui.commons.Panel(&amp;#34;panel2&amp;#34;); 通过sap.ui.getCore().byId(&amp;ldquo;compID&amp;rdquo;)获取上述视图/控件。控制器可以通过getView()函数获取自身对应的视图，但是该视图内部的控件还得通过这种方式获取：
var refViewLeft = sap.ui.getCore().byId(&amp;#34;leftView&amp;#34;); var refPanelRight = sap.ui.getCore().byId(&amp;#34;panel2&amp;#34;); 需要注意的是，上面讲的是JS视图最简单的一种情况。 对于使用了静态视图ID的XML、HTML和JSON视图，其内部的控件ID会自动添加视图ID做前缀。JS视图中，在动态实例化控件时通过oController.createId(&amp;ldquo;ID&amp;rdquo;)也可以生成用视图ID做前缀的唯一ID。
var refSubView = oViewParent.byId(&amp;#34;subViewId&amp;#34;); refSubView.byId(&amp;#34;ctrId&amp;#34;); JS、XML、HTML和JSON片断(Fragment)是更轻量级的分割和UI重用单元，每个片段示例化时为了保证唯一性，即使没有定义片段ID也会自动生成，其内部的控件ID会自动添加视图ID和片段ID做前缀。
当没有给定片段ID：myControl = sap.ui.getCore().byId(&amp;ldquo;myControl&amp;rdquo;) 当给定片段ID &amp;ldquo;myFrag&amp;rdquo; ：myControl =sap.ui.core.Fragment.byId(&amp;ldquo;myFrag&amp;rdquo;, &amp;ldquo;myControl&amp;rdquo;) 访问其他Controller的方法 最简单的方法是使用一个全局变量引用所需控制器 不推荐 通过获取其他控制器对应的视图来访问该控制器的函数：sap.ui.getCore().byId(&amp;ldquo;viewId&amp;rdquo;).getController().method(); 直接调用控制器的函数：sap.ui.controller(&amp;ldquo;namespace.Controllername&amp;rdquo;).method(); 最推荐的是在控制器(或应用组件)之间的通信使用sap.ui.core.EventBus，这种事件/消息总线模式可以更好进行解耦。 在jsbin上做了个Retrive other component示例：http://jsbin.com/xufeyo/1/edit?html,output 这个示例演示了一个视图如何控制另外一个视图的控件是否显示，一个视图调用了另外一个视图控制器的方法。但是它完全违反了我以前有篇学习帖子重温MVC:一个很好的MVC中的规则，不可以在实际工作中使用！
此外通过调试找到了sap.ui.core.Core里面ID与组件的映射表。</description></item><item><title>[OpenUI5] MVC示例:JSView embedding JSVIEW</title><link>https://mryqu.github.io/post/openui5_mvc%E7%A4%BA%E4%BE%8Bjsview_embedding_jsview/</link><pubDate>Wed, 07 Jan 2015 23:47:47 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_mvc%E7%A4%BA%E4%BE%8Bjsview_embedding_jsview/</guid><description>OpenUI5 SDK的演示程序里面有一个视图嵌套另外一个视图，但是通过Componentcontainer和Component.js实现的。一直对视图直接嵌套另外一个视图觉得理所当然但是有点顾虑，此外也担心外层视图的数据模型如何传递给内部视图。当然内外两层视图可以使用不同的数据模型，但是如果不知道共享一份数据视图是否可行?
在jsbin上做了一个示例：http://jsbin.com/jirogo/1/edit?html,output，结果显示担忧是多余的</description></item><item><title>两个HTML线上工具：jsbin和jsfiddle</title><link>https://mryqu.github.io/post/%E4%B8%A4%E4%B8%AAhtml%E7%BA%BF%E4%B8%8A%E5%B7%A5%E5%85%B7jsbin%E5%92%8Cjsfiddle/</link><pubDate>Wed, 07 Jan 2015 19:30:02 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%A4%E4%B8%AAhtml%E7%BA%BF%E4%B8%8A%E5%B7%A5%E5%85%B7jsbin%E5%92%8Cjsfiddle/</guid><description>最近做HTML5开发，关注了两个HTML线上工具，都可以编辑、测试、验证、存档和分享HTML、JavaScript和CSS代码，还可以引入一些常用的外部JS库，例如jQuery、Bootstrap、YUI、AngularJS&amp;hellip;,感觉都很不错。
http://jsbin.com/ http://jsfiddle.net/ 这两个线上工具使用方便简单，网上也有很详细的介绍贴：介紹好用工具：JS Bin ( 網站前端工程師的學習利器 )、介紹好用工具：jsFiddle - Online Editor for the Web。
对于OpenUI5演示，jsbin更好用，因为它没有jsfiddle那些限制（HTML区域不允许有header、meta，JavaScript区域不允许有scipt标签和参数等等）。
附上一个我在jsbin上做的sap.ui.table.TableMVC示例：http://jsbin.com/jojeta/1/edit?html,output</description></item><item><title>[OpenUI5] 调节元素间距</title><link>https://mryqu.github.io/post/openui5_%E8%B0%83%E8%8A%82%E5%85%83%E7%B4%A0%E9%97%B4%E8%B7%9D/</link><pubDate>Mon, 05 Jan 2015 20:31:26 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E8%B0%83%E8%8A%82%E5%85%83%E7%B4%A0%E9%97%B4%E8%B7%9D/</guid><description>在使用OpenUI5时，有时两个元素间距不合预期，我大体可用两种方式进行改进：
一种方式是添加自己定制的CSS类，然后通过addStyleClass方法对控件设置自己定制的CSS类 ​另一种方法土点，就是对需要调整间距的两个元素上增加一个HBox/VBox控件，然后在两个之间加一个定宽/高的控件调节间距。``` //在oControl1和oControl2之间增加15px的间距 new VBox({ items: [ oControl1, new HBox({ height: &amp;ldquo;15px&amp;rdquo;, fitContainer: true }), oControl2 ] }) ​</description></item><item><title>HTML Busy Indicator</title><link>https://mryqu.github.io/post/html_busy_indicator/</link><pubDate>Sun, 04 Jan 2015 20:13:28 +0000</pubDate><guid>https://mryqu.github.io/post/html_busy_indicator/</guid><description>看了一下OpenUI5的LocalBusyIndicator效果，感觉跟自己想的转圈圈的那种spinner不一样:https://sapui5.hana.ondemand.com/sdk/test-resources/sap/ui/core/demokit/LocalBusyIndicator.html 想看看bootstrap的busy indicator，竟然没有，不过找到了开发组的讨论：https://github.com/twbs/bootstrap/issues/12598 不止一次有人建议开发busy indicator，不过Mark Otto（Bootstrap是Mark Otto和JacobThornton共同开发的）没同意。因为满足不了下列条件：
It needs to be retina-ready Needs to work in IE8+ Needs to work on light backgrounds and dark—alphatransparencywould be bomb Would be cool if it was a font, but PNG or GIF is fine,too Available in multiple sizes 开发一款满意的控件容易吗！！！还好我就用用而已 下面是我找到的一些Busy Indicator资源： http://fgnass.github.io/spin.js/
http://semantic-ui.com/elements/loader.html
http://w3lessons.info/2014/01/26/showing-busy-loading-indicator-during-an-ajax-request-using-jquery/</description></item><item><title>YCSB相关博文</title><link>https://mryqu.github.io/post/ycsb%E7%9B%B8%E5%85%B3%E5%8D%9A%E6%96%87/</link><pubDate>Sat, 03 Jan 2015 11:33:29 +0000</pubDate><guid>https://mryqu.github.io/post/ycsb%E7%9B%B8%E5%85%B3%E5%8D%9A%E6%96%87/</guid><description>使用YCSB测试MongoDB的微分片性能
使用YCSB测试Mongodb性能的方法简介
NoSQL数据库压力测试工具YCSB使用
使用YCSB对HBase进行测试
性能测试：SequoiaDB vs. MongoDB vs. Cassandra vs. HBase</description></item><item><title>Java的Base64编解码</title><link>https://mryqu.github.io/post/java%E7%9A%84base64%E7%BC%96%E8%A7%A3%E7%A0%81/</link><pubDate>Thu, 01 Jan 2015 11:30:21 +0000</pubDate><guid>https://mryqu.github.io/post/java%E7%9A%84base64%E7%BC%96%E8%A7%A3%E7%A0%81/</guid><description>Base64编码是网络上最常见的用于传输8Bit字节代码的编码方式之一，用基于64个可打印字符[大小写字母52个字符、数字10个字符、+和/2个字符(对于URL为-和_)，补全用=]来表示二进制数据的一种表示方法。相关协议可见：
RFC4648 The Base16, Base32, and Base64 Data Encodings RFC2045 MIME Part One: Format of Internet Message Bodies RFC2046 MIME Part Two: Media Types RFC2047 MIME Part Three: Message Header Extensions for Non-ASCII Text RFC2048 MIME Part Four: Registration Procedures RFC2049 MIME Part Five: Conformance Criteria and Examples 因为有些网络传送渠道不支持所有的字节，例如传统的邮件只支持可见字符的传送，像ASCII码的控制字符就不能通过邮件传送。通过Base64编码可以把不可打印的字符也能用可打印字符来表示。
Java6之前 在Java6之前，JDK核心类一直没有Base64的实现类。除了使用Sun内部实现sun.misc.BASE64Encoder、sun.misc.BASE64Decoder或com.sun.org.apache.xerces.internal.impl.dv.util.Base64外，就需要使用第三方类库了。 Java6 Java6中添加了Base64的实现：javax.xml.bind.DatatypeConverter两个静态方法parseBase64Binary和 printBase64Binary。
import javax.xml.bind.DatatypeConverter; public class HelloBase64 { public static void main(String[] args) { String me = &amp;#34;blog.sina.com.cn/yandongqu&amp;#34;; byte[] plainContent; String base64Str = DatatypeConverter.</description></item><item><title>[CSS] 图片叠加效果</title><link>https://mryqu.github.io/post/css_%E5%9B%BE%E7%89%87%E5%8F%A0%E5%8A%A0%E6%95%88%E6%9E%9C/</link><pubDate>Thu, 25 Dec 2014 17:37:32 +0000</pubDate><guid>https://mryqu.github.io/post/css_%E5%9B%BE%E7%89%87%E5%8F%A0%E5%8A%A0%E6%95%88%E6%9E%9C/</guid><description>今天接着折腾OpenUI5。我们原有的客户端是EclipseRCP富客户端，有些菜单上的图标是叠加出来的，很不幸sap.ui.commons.MenuItem仅支持一个图片文件的URL，不支持多个图片进行叠加。 玩一下使用CSS做图片叠加效果。 代码如下：</description></item><item><title>[Swing]图片叠加效果</title><link>https://mryqu.github.io/post/swing_%E5%9B%BE%E7%89%87%E5%8F%A0%E5%8A%A0%E6%95%88%E6%9E%9C/</link><pubDate>Thu, 25 Dec 2014 08:20:49 +0000</pubDate><guid>https://mryqu.github.io/post/swing_%E5%9B%BE%E7%89%87%E5%8F%A0%E5%8A%A0%E6%95%88%E6%9E%9C/</guid><description>玩一下使用Java做图片叠加效果。 代码如下：
package com.yqu.swing.img; import java.awt.Component; import java.awt.Graphics; import java.awt.image.BufferedImage; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import javax.imageio.ImageIO; import javax.swing.GrayFilter; import javax.swing.Icon; import javax.swing.ImageIcon; public class OverlayIcon implements Icon{ private int maxWidth = -1, maxHeight = -1; private List icons; public OverlayIcon(String[] iconPaths) { if(iconPaths != null &amp;amp;&amp;amp; iconPaths.length &amp;gt;0) { icons = new ArrayList(iconPaths.length); for (String iconPath : iconPaths) { Icon icon = makeIcon(iconPath, false); icons.add(icon); int width = icon.</description></item><item><title>[OpenUI5] 打开web应用调试模式的方法</title><link>https://mryqu.github.io/post/openui5_%E6%89%93%E5%BC%80web%E5%BA%94%E7%94%A8%E8%B0%83%E8%AF%95%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 22 Dec 2014 23:27:31 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E6%89%93%E5%BC%80web%E5%BA%94%E7%94%A8%E8%B0%83%E8%AF%95%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%96%B9%E6%B3%95/</guid><description>OpenUI5 web应用调试模式无需服务器端支持，完全可在浏览器上进行设置。下面列举了四种打开调试模式的方法：
URL指定参数sap-ui-debug=true例如：http://localhost:8080/fmwebstudio/?sap-ui-debug=true 在浏览器控制台执行jQuery.sap.debug(true) 在加载了OpenUI5 web应用页面执行CTRL-SHIFT-ALT-P快捷键调出技术信息进行设置。 在加载了OpenUI5web应用页面执行CTRL-SHIFT-ALT-S快捷键调出OpenUI5诊断页面进行设置。</description></item><item><title>[IntelliJ] 与Eclipse的Back/Forward等同功能</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E7%9A%84back%E5%92%8Cforward%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</link><pubDate>Fri, 19 Dec 2014 05:55:55 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E7%9A%84back%E5%92%8Cforward%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</guid><description>当查找一个方法的调用者后，可能还想退回到该方法进行研究，Eclipse的Back/Forward功能相应快捷键Alt + Left 和 Alt + Right是很便利的。
使用IntelliJ IDEA进行开发时，可以使用Navigate | Back和Navigate |Forward菜单或快捷键Ctrl + Alt + Left 和 Ctrl + Alt + Right实现相同的功能。 不过在我的机器中存在热键冲突，Intel显卡控制面板也使用相同的快捷键，禁掉Intel显卡控制面板的快捷键就好了。</description></item><item><title>[IntelliJ] 与Eclipse Open Type Hierarchy等同功能</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_open_type_hierarchy%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</link><pubDate>Thu, 18 Dec 2014 06:08:03 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_open_type_hierarchy%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</guid><description>使用Eclipse进行开发时，我喜欢用F4快捷键打开类型层次视图查看类层次关系，或者用Ctrl + T快捷键打开快速类型层次对话框查看类层次关系。 使用IntelliJ IDEA进行开发时，可以使用Navigate | Type Hierarchy菜单或Ctrl + H快捷键打开类层次视图，此外使能了“UMLSupport”插件后还可以使用Ctrl + Alt + U快捷键打开类型层次关系UML图。</description></item><item><title>[IntelliJ] 导入项目</title><link>https://mryqu.github.io/post/intellij_%E5%AF%BC%E5%85%A5%E9%A1%B9%E7%9B%AE/</link><pubDate>Wed, 17 Dec 2014 06:15:40 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E5%AF%BC%E5%85%A5%E9%A1%B9%E7%9B%AE/</guid><description>如果在IntelliJ IDEA没有打开任何项目的话，欢迎界面里有Import Project和Check out fromVersion Control两个菜单。
有一段时间为了导入新项目，我都老老实实关闭所有已打开的项目，去欢迎界面里操作。终于有一天觉得自己太老土，才搜了搜，发现原来这两个功能当有项目打开的时候是二级菜单而已。
File | New | Project from Existing Sources File | New | Project from Version Control</description></item><item><title>[IntelliJ] 与Eclipse Organize Imports等同功能</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_organize_imports%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</link><pubDate>Tue, 16 Dec 2014 05:30:48 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_organize_imports%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</guid><description>使用Eclipse进行开发时，我喜欢用Ctrl+ Shift + O快捷键管理Java类的导入，它可以导入所需的Java类，去除不需要的Java类。 Eclipse的Organize Imports偏好配置： 使用IntelliJ IDEA进行开发时，可以使用Code | OptimizeImports菜单或 Ctrl + Alt + O快捷键优化Java类的导入。它仅能去除不需要的Java类，无法像Eclipse那样自动导入所需的Java类。 IntelliJ IDEA的Optimize Imports偏好配置：</description></item><item><title>[IntelliJ] 处理Unhandled Exception</title><link>https://mryqu.github.io/post/intellij_%E5%A4%84%E7%90%86unhandled_exception/</link><pubDate>Mon, 15 Dec 2014 05:23:32 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E5%A4%84%E7%90%86unhandled_exception/</guid><description>当在IntelliJ IDEA出现&amp;quot;Unhandled Exception&amp;quot;时，处理方法很简单。在有问题的代码行按下快捷键Ctrl+ ANTER即会出现下列处理选项：
Add exception to method signature Surround with try/catch</description></item><item><title>Web调试工具:Fiddler</title><link>https://mryqu.github.io/post/web%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7fiddler/</link><pubDate>Sun, 14 Dec 2014 21:08:47 +0000</pubDate><guid>https://mryqu.github.io/post/web%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7fiddler/</guid><description>今天看网上有介绍Web调试工具Fiddler的，顺风搂一眼。比我原来用wireshark调试客户端与服务器端web通信强，值得学习。 Fiddler是最强大最好用的Web调试工具之一，它能记录所有客户端和服务器的http和https请求，允许你监视，设置断点，甚至修改输入输出数据.使用Fiddler无论对开发还是测试来说，都有很大的帮助。
资料： 慕课网：Fiddler工具使用
Fiddler 教程
Fiddler Script 用法
Fiddler Composer创建和发送HTTP Request
Fiddler 实现手机的抓包</description></item><item><title>[IntelljJ] 文件修改提示和自动保存功能</title><link>https://mryqu.github.io/post/intelljj_%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9%E6%8F%90%E7%A4%BA%E5%92%8C%E8%87%AA%E5%8A%A8%E4%BF%9D%E5%AD%98%E5%8A%9F%E8%83%BD/</link><pubDate>Sun, 14 Dec 2014 15:22:51 +0000</pubDate><guid>https://mryqu.github.io/post/intelljj_%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9%E6%8F%90%E7%A4%BA%E5%92%8C%E8%87%AA%E5%8A%A8%E4%BF%9D%E5%AD%98%E5%8A%9F%E8%83%BD/</guid><description>Eclipse中文件修改后没有保存前文件都会有星号提示，IntelljJ IDEA默认没有提示，但是可以通过如下设置完成：Settings -&amp;gt; Editor -&amp;gt; General -&amp;gt; Editor Tabs: Check &amp;ldquo;Markmodified tabs with asterisk&amp;rdquo;IntelljJ IDEA关于文件自动保存功能主要有两种方式：
切换到其他应用时保存变化（默认使能）设置路径：Settings -&amp;gt; Apperance &amp;amp; Behavior -&amp;gt; Save files onframe deactivation 如果应用空闲则自动保存变化（默认禁止）设置路径：Settings -&amp;gt; Apperance &amp;amp; Behavior -&amp;gt; Save filesautomatically if application is idle for &amp;hellip; sec.</description></item><item><title>[IntelliJ] 与Eclipse工作集近似的功能</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E5%B7%A5%E4%BD%9C%E9%9B%86%E8%BF%91%E4%BC%BC%E7%9A%84%E5%8A%9F%E8%83%BD/</link><pubDate>Sat, 13 Dec 2014 12:02:21 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E5%B7%A5%E4%BD%9C%E9%9B%86%E8%BF%91%E4%BC%BC%E7%9A%84%E5%8A%9F%E8%83%BD/</guid><description>Eclipse鼓励将不同的功能模块划分为独立的项目存在，这样不但结构清晰，组织起来还非常灵活，因为我们可以用feature对这些项目进行不同的组合，输出后得到具有不同功能的产品。 不过这样一来项目浏览器里的项目会以更快的速度增加，当你面对几十上百个项目时，工作效率必然大打折扣。幸好Eclipse提供了工作集（WorkingSet）的功能，它可以用来对项目进行分组，并且可以项目浏览器里指定显示所有项目或者特定工作集下的项目。 具体操作可以参考Eclipse帮助文档工作集概念和项目浏览器显示/隐藏文件。
IntelliJ IDEA与Eclipse术语对比如下：
|Eclipse|IntelliJ IDEA |&amp;mdash;&amp;ndash; |A number of projects, a workspace|Project |Project|Module |Project-specific JRE|Module SDK |User library|Global library |Classpath variable|Path variable |Project dependency|Module dependency |Library|Module library
由此可知在IntelliJ IDEA中近似功能应该在module一层，就我查找的资料来看最近似的功能就是模块组（modulegroup）了。 具体操作可以参考IntelliJ IDEA帮助文档对模块分组。Eclipse可选择对某个工作集下的所有项目进行集中编译；同样IntelliJ IDEA也可选择对模块组下的所有模块集中编译。Eclipse可以显示工作空间下所有项目，或仅显示某个工作集下的项目以隐藏其他项目；IntelliJIDEA只能对模块组进行折叠来隐藏其下的模块。这一点两者的行为有一定差异。</description></item><item><title>调试Javascript</title><link>https://mryqu.github.io/post/%E8%B0%83%E8%AF%95javascript/</link><pubDate>Fri, 12 Dec 2014 23:30:00 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%B0%83%E8%AF%95javascript/</guid><description>为了调试Javascript，下载了Firefox developer edition，但是没感觉有什么不同，接着下载Firebug，使用感觉有点说不出来的别扭。 还是接着用Chrome调试吧，感觉挺好的，这次conditional break出了不少力！ https://developer.chrome.com/devtools/docs/javascript-debugging</description></item><item><title>[IntelliJ] 与Eclipse Quick Outline等同功能</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_quick_outline%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</link><pubDate>Fri, 12 Dec 2014 20:34:09 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_quick_outline%E7%AD%89%E5%90%8C%E5%8A%9F%E8%83%BD/</guid><description>使用Eclipse进行开发时，我喜欢用Ctrl+ O快捷键打开快速概要对话框查找或浏览当前类变量和方法。
使用IntelliJ IDEA进行开发时，可以使用Navigate | FileStructure菜单或Ctrl + F12快捷键打开文件结构视图查找或浏览当前类的变量或方法。 此外如果在整个项目内查找变量或方法，可以使用Navigate | Symbol菜单或 Ctrl + Alt + Shift + N快捷键打开符号查找对话框进行查找。</description></item><item><title>[IntelliJ] 与Eclipse关于Call Hierarchy和Find Reference功能比较</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E5%85%B3%E4%BA%8Ecall_hierarchy%E5%92%8Cfind_reference%E5%8A%9F%E8%83%BD%E6%AF%94%E8%BE%83/</link><pubDate>Thu, 11 Dec 2014 19:46:23 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse%E5%85%B3%E4%BA%8Ecall_hierarchy%E5%92%8Cfind_reference%E5%8A%9F%E8%83%BD%E6%AF%94%E8%BE%83/</guid><description>&amp;ldquo;Call Hierarchy&amp;quot;功能比较 Eclipse的&amp;quot;CallHierarchy&amp;quot;可以查看一个Java方法或类成员变量的调用树（caller和callee两个方向）。 IntelliJ IDEA中可以在主菜单中选择Navigate | CallHierarchy命令查看一个Java方法调用树（caller和callee两个方向），但是不像Eclipse那样可以查看类成员变量的调用树。 IntelliJ IDEA中可以在主菜单中选择Analyze | Dataflow from/toHere两个命令查看表达式、变量和方法参数的传递关系树。 Eclipse的&amp;quot;Call Hierarchy&amp;quot;命令的功能，在IntelliJIDEA中被划分到了三个命令，增加了一点点记忆成本，不过IntelliJ IDEA中的处理范围更广，相对功能更强一些。
&amp;ldquo;Find Reference&amp;quot;功能比较 Eclipse的&amp;quot;Find Reference&amp;quot;可以查看一个Java类、方法或变量的直接使用情况。 IntelliJ IDEA的&amp;quot;Find Usage&amp;quot;具有相同的功能。在我的体验中，IntelliJIDEA中的功能更强一些，可以分析Sping配置文件中对Java类或方法的使用情况。
参考 https://www.jetbrains.com/idea/help/building-call-hierarchy.html
https://www.jetbrains.com/idea/help/analyzing-data-flow.html</description></item><item><title>[IntelliJ] Javascript code inspection</title><link>https://mryqu.github.io/post/intellij_javascript_code_inspection/</link><pubDate>Wed, 10 Dec 2014 19:34:48 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_javascript_code_inspection/</guid><description/></item><item><title>接触字体图标(Icon Font)</title><link>https://mryqu.github.io/post/%E6%8E%A5%E8%A7%A6%E5%AD%97%E4%BD%93%E5%9B%BE%E6%A0%87icon_font/</link><pubDate>Tue, 09 Dec 2014 19:47:38 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%8E%A5%E8%A7%A6%E5%AD%97%E4%BD%93%E5%9B%BE%E6%A0%87icon_font/</guid><description>最近玩SAP的OpenUI5，碰到了sap-icon://协议，接触了字体图标。 字体图标流行了有两年了，现在已经不是什么新鲜概念啦。主要是因为 CSS3 增加了一个非常实用的属性@font-face。传统的网页中的字体设置，使用font-family属性来定义，而且受限于浏览者电脑上所安装的字体，如果浏览者电脑上没有安装对应字体，那么网页渲染起来就会使用其他字体来代替。而新增的@font-face改变了这一现状，使用该属性，可以指定服务器上的一个字体，当浏览者访问的时候，会优先下载服务器上的字体，然后再使用该字体渲染网页。这样就可以发挥设计师的想象，灵活的任意应用字体，同时不需要考虑不同平台的差异。该属性的兼容性也非常好。详细兼容性见http://caniuse.com/#feat=fontface 。 @font-face功能不仅仅可以用在改变文章的字体样式上，还可以来做字体图标。字体其实就是一种图标，把对应的基础的文字，渲染成有棱有角的文字。如果某个文字的字体，并不设计成那个文字的变形，而设计成截然不同的图标，那么当网页中出现这个文字，就会渲染出一个图标。
字体图标与像素位图的对比 优点：
兼容性：各个平台浏览器基本都可以使用，而且在某些老版本浏览器中，效果比图片更好。 轻量性：相对于同效果的位图相比，体积要小。一旦图标字体加载了，图标就会马上渲染出来，不需要下载一个图像。可以减少HTTP请求，增强前端性能，还可以配合HTML5离线存储做性能优化。 灵活性：图标字体可以用过font-size属性设置其任何大小，还可以加各种文字效果，包括颜色、Hover状态、透明度、阴影和翻转等效果。可以在任何背景下显示。使用位图的话，必须得为每个不同大小和不同效果的图像输出一个不同文件。 劣势：
图标字体只能被渲染成单色或者CSS3的渐变色。 免费开源的精美字体图标资源还是不够多。 创作自已的字体图标很费时间，重构人员后期维护的成本偏高。 常用字库文件格式 TTF(TrueTypeFont)格式：TTF是Apple公司和Microsoft公司推出的字体文件格式,随着windows的流行,已经变成最常用的一种字体文件表示方式。truetype字体的最大优点是可以很方便地把字体轮廓转换成曲线，可以对曲线进行填充，制成各种颜色和效果，字款丰富。 OTF(OpenType Font)格式：OpenType，是一种可缩放字型（scalablefont），微软公司与Adobe公司联合开发，用来替代TrueType字型的新字型。 WOFF格式：Web开放字体格式（Web Open FontFormat，简称WOFF），是一种网页所采用的字体格式标准。此字体格式不但能够有效利用压缩来减少档案大小，并且不包含加密。WOFF得到许多主要字体制造公司的支持。 EOT格式：EOT是一种压缩字库，目的是解决在网页中嵌入特殊字体的难题。例如：网页前端开发人员在网页中使用了很多种特殊的精美的字体，当网友浏览时，却因没有安装相应的字库，只能看到默认的宋体字，效果惨不忍睹。利用EOT字库即可解决此难题。 网上一些字体图标资源 OpenUI5 Icon Explorer
confont.cn：由阿里巴巴UX部门推出的矢量图标管理网站，也是国内首家推广Webfont形式图标的平台。
Font Awesome：An iconic font and CSS framework project at GitHub
在OpenUI5里使用字体图标 SAPUI5提供了sap.ui.core.icon控件和sap.ui.core.IconPool力提供的一套预定义图标。通过学习https://github.com/SAP/openui5/blob/master/src/sap.ui.core/src/sap/ui/core/IconPool.js ，大致可以找到OpenUI5里的字体库。
/resources/sap/ui/core/themes/base/fonts/SAP-icons.eot /resources/sap/ui/core/themes/base/fonts/SAP-icons.ttf /resources/sap/ui/core/themes/sap_bluecrystal/fonts/bluecrystal_icons.ttf /resources/sap/ui/core/themes/sap_bluecrystal/fonts/SAP-icons.eot /resources/sap/ui/core/themes/sap_bluecrystal/fonts/SAP-icons.ttf /resources/sap/ui/core/themes/sap_goldreflection/fonts/SAP-icons.eot /resources/sap/ui/core/themes/sap_goldreflection/fonts/SAP-icons.ttf /resources/sap/ui/core/themes/sap_hcb/fonts/SAP-icons.eot /resources/sap/ui/core/themes/sap_hcb/fonts/SAP-icons.ttf</description></item><item><title>[IntelliJ] 与Eclipse Link with Editor等价功能设置</title><link>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_link_with_editor%E7%AD%89%E4%BB%B7%E5%8A%9F%E8%83%BD%E8%AE%BE%E7%BD%AE/</link><pubDate>Sun, 07 Dec 2014 13:35:19 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E4%B8%8Eeclipse_link_with_editor%E7%AD%89%E4%BB%B7%E5%8A%9F%E8%83%BD%E8%AE%BE%E7%BD%AE/</guid><description>Link With Editor是Eclipse内置功能中十分小巧，但却异常实用的一个功能。这个开关按钮 (ToggleButton) 出现在各式导航器视图 ( 例如 Resource Explorer, Package Explorer 等 )的右上角。点击时能根据当前打开的文件，相应地展开导航器视图，并迅速关联到该结点。 IntelliJ IDEA中也有等价功能，即项目视图中&amp;quot;Autoscroll from source&amp;quot;设置。</description></item><item><title>WebStorm与IntelliJ IDEA的区别</title><link>https://mryqu.github.io/post/webstorm%E4%B8%8Eintellij_idea%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Sat, 06 Dec 2014 16:35:23 +0000</pubDate><guid>https://mryqu.github.io/post/webstorm%E4%B8%8Eintellij_idea%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>WebStorm与IntelliJ IDEA都被很多JS开发者誉为“Web前端开发神器”、“最强大的HTML5编辑器”、“最智能的JavaScriptIDE”等，用了一点IntelliJ IDEA，还真不知道两者有什么联系和区别。网上搜了一下，WebStorm FAQ和PhpStorm FAQ解答了我的疑问。JetBrains旗下的产品：
IntelliJ IDEA偏重于Java开发，旗舰产品，它可以通过（捆绑的或可下载的）插件的方式提供WebStorm和PhpStorm所有的功能。支持Scala和Groovy开发，也可以通过插件支持Ruby和Python语言。 PhpStorm侧重于PHP开发 WebStorm侧重于JS开发 RubyMine侧重于Ruby和Rails开发 PyCharm侧重于Python和Djanjo开发WebStorm与IntelliJ IDEA相比，功能少，集中于JS开发这一块，更加轻量级，新项目配置起来更简单。 下面两个链接是WebStorm和IntelliJ IDEA的官方报价，WebStorm的价格大概是IntelliJIDEA的五分之一。
https://www.jetbrains.com/webstorm/buy/ https://www.jetbrains.com/idea/buy/</description></item><item><title>[IntelliJ] 添加Plugin更新URL并安装</title><link>https://mryqu.github.io/post/intellij_%E6%B7%BB%E5%8A%A0plugin%E6%9B%B4%E6%96%B0url%E5%B9%B6%E5%AE%89%E8%A3%85/</link><pubDate>Fri, 05 Dec 2014 18:50:54 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E6%B7%BB%E5%8A%A0plugin%E6%9B%B4%E6%96%B0url%E5%B9%B6%E5%AE%89%E8%A3%85/</guid><description> 选择菜单 File -&amp;gt; Setting2) Setting对话框内选择plugins，点击Browse Repositories -&amp;gt; ManageRepositories -&amp;gt; Add Repository添加完所要安装的插件更新URL，然后就可以安装了。</description></item><item><title>[IntelliJ] 格式化代码</title><link>https://mryqu.github.io/post/intellij_%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</link><pubDate>Wed, 03 Dec 2014 19:52:39 +0000</pubDate><guid>https://mryqu.github.io/post/intellij_%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</guid><description>用了多年的Eclipse后，转而用IntelliJ IDEA，觉得很多简单的功能都不会了，感觉是一个囧呀。 刚碰到的就是不知道如何去格式化代码。
作为一个非快捷键达人的码农，在Eclipse中都是右键菜单，然后找Source-&amp;gt;Format。
但是在IntelliJ中，右键菜单里面真没这功能。后来还是找了一会，终于在菜单里发现了！</description></item><item><title>我的IntelliJ IDEA配置</title><link>https://mryqu.github.io/post/%E6%88%91%E7%9A%84intellij_idea%E9%85%8D%E7%BD%AE/</link><pubDate>Sat, 29 Nov 2014 20:19:20 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%88%91%E7%9A%84intellij_idea%E9%85%8D%E7%BD%AE/</guid><description> 安装完IntelliJIDEA，我首先切换到64位模式： 安装文件生成的快捷方式默认指向的是idea.exe，更改为idea64.exe。 更改默认内存配置：修改IntelliJ&amp;quot;bin&amp;quot;目录下的idea64.exe.vmoptions文件。 &amp;ldquo;-Xms&amp;quot;和&amp;rdquo;-Xmx&amp;quot;定义了Java分配给IntelliJ的最小和最大堆空间，将其更改为&amp;quot;-Xms256m&amp;quot;和&amp;quot;-Xmx1600m&amp;quot; 启动IntelliJ IDEA，通过File-&amp;gt;Setting菜单做如下修改： 更改编译器的构建过程堆大小为1024 设置代理为总动检测</description></item><item><title>Eclipse用户IntelliJ IDEA入门指南</title><link>https://mryqu.github.io/post/eclipse%E7%94%A8%E6%88%B7intellij_idea%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</link><pubDate>Sat, 29 Nov 2014 10:50:26 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse%E7%94%A8%E6%88%B7intellij_idea%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</guid><description>除了IntelliJ IDEA帮助文档 （https://www.jetbrains.com/idea/help/intellij-idea.html），发现一个IntelliJIDEA不错的入门教程： Getting Started with IntelliJ IDEA as an Eclipse User（http://zeroturnaround.com/rebellabs/getting-started-with-intellij-idea-as-an-eclipse-user/）
Introduction: Why IntelliJ IDEA? Chapter I: Getting your first IntelliJ IDEA project set up Chapter II: Getting comfortable with IDEA’s Keymap, Navigation and Settings Chapter III: Getting productive with Tests, Deployments and Artifacts Chapter IV: Summary, Conclusion and Goodbye Comic ;-) 其他参考: IntelliJ Idea 常用快捷键列表</description></item><item><title>玩一会IPython Notebook</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%BC%9Aipython_notebook/</link><pubDate>Wed, 26 Nov 2014 23:20:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%BC%9Aipython_notebook/</guid><description>晚上想写两行python代码，懒得打开eclipse，也不想玩SublimeText2，就试用了一下Anaconda带的IPython Notebook。 支持函数自动补全，很多快捷键，功能还真不错！以后打算作为主力用了。
资料： IPython Notebook简介1
ipython notebook——超级强大的工具
第三课 Ipython &amp;amp; Ipython Notebook
IPython: Python at your fingertips</description></item><item><title>[OpenUI5] logging</title><link>https://mryqu.github.io/post/openui5_logging/</link><pubDate>Sun, 16 Nov 2014 09:21:34 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_logging/</guid><description>jQuery.sap.log是客户端Javascript日志API。 通过上图可知，其日志级别分别为ALL、DEBUG、ERROR、FATAL、INFO、NONE、TRACE和WARNING，默认日志级别为ERROR。
如果要显示所有日志信息，可以执行:
jQuery.sap.log.setLevel(6)</description></item><item><title>了解Google Closure Tools</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3google_closure_tools/</link><pubDate>Sat, 15 Nov 2014 09:48:03 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3google_closure_tools/</guid><description>hello一个html5-openui5项目，公司的编译系统在googlecc.xml（ant脚本）报了一个错，用googlecc做关键词搜了半天没弄清是什么东西，后来才发现是GoogleClosure Compiler。 不同于个人的小项目，企业级Web应用里面可能存在大量的Javascript代码。JS文件很多，文件块头还不小。不管是静态引入还是GoogleClosureLibrary/require.js这种模块化动态异步加载，下载时间长了，都会给Web用户带来不好的感知性能体验。很多Javascript压缩工具可以帮助减小JS文件大小，GoogleClosure Compiler就是其中一款。 谷歌2009年开源了其内部使用的JavaScript开发工具，Google Closure Tools，希望帮助程序员更高效地开发出富客户端Web应用程序。该工具集由如下工具组成：
Closure Compiler:该优化器将JavaScript优化成紧凑、高性能的代码。它通过去除无用死代码、空格和注释、缩短长的局部变量名等方法压缩代码，检查语法、变量引用和变量类型，并对常见的JavaScript陷阱给出警告。 Closure Library：功能广泛的，经过良好测试的，模块化的，跨浏览器的JavaScript库 Closure Templates：客户端和服务器端模板系统，可以有助于动态生成可重用的HTML和UI元素。ClosureTemplates摒弃了一个页面使用一个(大)模板，而是针对单个小组件使用(小)模板，以便复用。该模板可生成JavaScript或Java代码，因此同一模板可在客户端或者服务端使用。 Closure Linter：按照《谷歌JavaScript编程风格指南》 里面的指导方针对JavaScript代码进行编程风格检查和修复的工具 Closure Stylesheets：支持很多谷歌扩展的增强格式表语言系统。可以定义和使用变量、函数、条件，以使格式表可读性增强、更易于维护。内建的工具可以将其编译成标准CSS。 阅读列表： 闭包：权威指南(Closure：The Definitive Guide) 部分翻译 前言 1 2 3 4 5
Google Closure Compiler &amp;ndash;js压缩优化
Closure Compiler vs. YUICompressor
应用 closure compiler 高级模式
Closure Compiler 高级模式及更多思考
知乎为什么要选择 Closure Library 来作为 JavaScript 库，而不选择更流行的 jQuery 之流呢？
Google Closure Library介绍</description></item><item><title>[OpenUI5] JSView的createContent和Controller的onInit孰先孰后？</title><link>https://mryqu.github.io/post/openui5_jsview%E7%9A%84createcontent%E5%92%8Ccontroller%E7%9A%84oninit%E5%AD%B0%E5%85%88%E5%AD%B0%E5%90%8E/</link><pubDate>Fri, 14 Nov 2014 20:06:02 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_jsview%E7%9A%84createcontent%E5%92%8Ccontroller%E7%9A%84oninit%E5%AD%B0%E5%85%88%E5%AD%B0%E5%90%8E/</guid><description>首先在这个两个函数设置断点，很容易知道JSView的createContent先于Controller的onInit被调用。 通过sap.ui.core.mvc.View源码片段可知，View的_initCompositeSupport函数中首先调用createAndConnectController函数创建Controller,之后调用的onControllerConnected函数会调用createContent函数，最后调用的fireAfterInit函数会触发Controller的onInit函数回调。
View.prototype._initCompositeSupport = function(mSettings) { // init View with constructor settings // (e.g. parse XML or identify default controller) // make user specific data available during view instantiation this.oViewData = mSettings.viewData; // remember the name of this View this.sViewName = mSettings.viewName; // remember the preprocessors this.mPreprocessors = mSettings.preprocessors || {}; //check if there are custom properties configured for this view, //and only if there are, create a settings preprocessor applying these if (sap.</description></item><item><title>[OpenUI5] 十分钟了解sap.ui.table.Table</title><link>https://mryqu.github.io/post/openui5_%E5%8D%81%E5%88%86%E9%92%9F%E4%BA%86%E8%A7%A3sap.ui.table.table/</link><pubDate>Wed, 12 Nov 2014 20:00:19 +0000</pubDate><guid>https://mryqu.github.io/post/openui5_%E5%8D%81%E5%88%86%E9%92%9F%E4%BA%86%E8%A7%A3sap.ui.table.table/</guid><description>转发一篇SAP community network的好帖子：http://scn.sap.com/docs/DOC-54075
Introduction sap.ui.table.Table is commonly used inOpenUI5 desktop application. Many questions (related to thiscontrol) that are posted in this group, it is evident thatdocumentation for this control is lacking and we (developers) haveto dive deep into debugging its source code to figure things out.It is fortunate that Javascript source code is always available;modern browsers provide debugging capability and personally, I amfortunate to have the opportunity to work with someone in SAPUI5team while using this control.</description></item><item><title>Web安全</title><link>https://mryqu.github.io/post/web%E5%AE%89%E5%85%A8/</link><pubDate>Tue, 11 Nov 2014 21:11:16 +0000</pubDate><guid>https://mryqu.github.io/post/web%E5%AE%89%E5%85%A8/</guid><description>学习OpenUI5程序员指南里关于Web安全的章节，在网上也搜了一下资料，下面是这次的学习笔记。
浏览器安全 跨站脚本攻击（Cross-Site Scripting， XSS） XSS指的是恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页之时，嵌入其中Web里面的html代码会被执行，从而达到恶意用户的特殊目的。例如，如果某些无需登录即可访问的公共页面区域有提交表单，攻击者可以在提交内容里面注入恶意javascript脚本（原理类似与SQL注入攻击），提交后的页面内容可能就含有这样的可执行恶意脚本。当其他登录用户访问这个页面后，就有可能泄漏自己的会话cookie信息。一般的防御手段是使用HTMLSanitization工具对用户输入信息做检查，过滤其提交内容；或者cookie记录登录ip，仅允许该ip使用此cookie。
点击劫持（clickjacking） 点击劫持指的是通过欺骗用户点击看似正常的恶意网页来获得机密信息或远程控制其电脑。例如，攻击者想要攻击某网页，可以发布一个网址与原网址及其近似的恶意网页，恶意网页通过iframe嵌入原网页。当用户被欺骗到恶意网页，界面和操作都与原网页一模一样，但操作实际上是与恶意网页交互。另外一个例子是攻击者发布一个恶意flash游戏，当用户玩游戏时，点击会被引导到恶意链接上，进而控制用户的摄像头和麦克风，用户的个人隐私遭到泄漏。一般的防御手段是Framebusting：正常网页中添加X-FRAME-OPTIONS=DENY(拒绝任何域加载)的http头，以及通过javascript脚本判别顶级frame是否被修改并将覆盖在自身上面的&amp;quot;恶意&amp;quot;frame重新定向会self.location。
HTML5 localStorage 所有浏览器都提供本地存储API，可用于存储有限数量的数据。仅运行在与存储数据相同域上的JavaScript代码可被执行进行数据访问。浏览器的本地存储不是安全存储，所以仅能用于存储静态数据，不应该存储应用数据。
WEBGL 越来越多的浏览器默认支持WEBG，WEBG允许访问计算机的底层图形API，这可能导致底层漏洞。
WebSockets WebSockets为web应用的客户端/服务器通信提供了新的方式，但很多浏览器厂商的第一版WebSockets实现就暴露了很多安全问题。RGC6455中的WebSockets标准化已经稳定，并且Chrome16、Firefox 11和IE10都实现了WebSockets。即使浏览器自身的WebSockets实现被证明是安全的，使用WebSockets时客户端仍需要额外的安全措施。
Postmessage/Onmessage postMessage允许浏览器窗口之间的跨域通信，这可能会导致安全问题。应用程序应该检查消息的发送域并仅处理来自受信域的消息。
会话安全 HTTP通信是无状态的和非加密的，客户端和服务器之间的数据传输是不安全的，因此有必要使用SSL进行加密，并使用cookie或URL地址重写进行会话处理。即使使用SSL对数据传输进行加密，仍有可能发生会话劫持。跨域请求伪造和会话固定攻击就是这类攻击中突出的两个例子。
WEB认证基础知识 用户访问需要认证的网站。 用户提供一个用户名和口令进行验证。 网站验证用户口令，如果通过，则准许用户登录进入，并将一个cookie提供给用户的浏览器。此cookie用于唯一的标识会话。 用户继续访问网站。在用户请求一个新网页时，浏览器都会发送cookie和用户请求，提醒Web服务器：该请求是前面的认证连接的一部分。在多数情况下，Web开发人员和网站管理员都会使用HTTPS加密来保护这个过程的第二步，他们都知道如果其它人员能够访问其他用户的用户名和口令，就可以轻易地获得访问权。在许多情况下，他们会转而使用一个不加密的HTTP连接，以便于实现Web通信的其余部分，其中也包括cookie的交换。 火羊（Firesheep） Firesheep是一个火狐（Firefox）插件，它在不安全的无线网络中自动操作会话劫持攻击。这个插件（plug-in）本质上是一个数据包嗅探器，它监测并分析Wi-Fi上终端用户之间的流量，并获取正在交换的cookie。西雅图的软件开发工程师EricButler研发了Firesheep并在2010年10月的ToorCon黑客会议上宣布了它的发行。Firesheep非常容易使用，下载插件，登陆公用的WIFI点，按一下按钮就可以获取网络中各种人的用户名和图像（例如：Facebook、Twitter、Flickr、bit.ly、Google和Amazon），双击图像攻击者就可以用受害人的身份登陆了。一般的防御手段是仅允许通过SSL来发送cookie；要限制能够利用cookie的应用程序；限制cookies仅能使用HTTPS。
跨域请求伪造(Cross-site request forgery, CSRF或XSRF) 跨域请求伪造指的是恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页之时，在用户毫不知情的情况下以用户名义伪造请求发送给受攻击站点，从而在并未授权的情况下执行在权限保护之下的操作。例如，恶意网页中有转账请求的恶意链接，当有用户被骗访问网站并点击了带有恶意链接的图片或广告，该请求会附带用户浏览器的cookie一起发往银行。大多数情况下，该请求会失败，因为它要求用户的认证信息。但是如果用户当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的会话尚未过期，浏览器的cookie之中含有用户的认证信息。这时，转账请求就被处理。一般的防御手段是验证HTTP的Referer字段；在所有页面加入同步令牌模式(Synchronizer tokenpattern)并要求在请求地址中添加令牌并验证；在强调安全的操作前重复用户认证。
会话固定攻击(session fixation) 会话固定攻击是利用服务器的session不变机制，借他人之手获得认证和授权，然后冒充他人。例如，攻击者访问http://vulnerable.example.com/ ，并从服务器响应(Set-Cookie:SID=0D6441FEA4496C2)获得会话ID，他发送给受害者一个链接http://vulnerable.example.com/?SID=0D6441FEA4496C2。受害者登录的话，会使用这个固定会话标识符SID=0D6441FEA4496C2。攻击者这时访问http://vulnerable.example.com/?SID=0D6441FEA4496C2就可以不受限地访问受害者的账户了。一般的防御手段是用户登录后更改会话ID；仅接受服务器生成的会话ID；超时或退出登录后删除会话；强调安全的操作使用SSL会话ID；每次请求更新会话ID。
参考 Busting Frame Busting: a Study of Clickjacking Vulnerabilities on Popular Sites 使用 HTML5 WebSocket 构建实时 Web 应用 应用 HTML5 的 WebSocket 实现 BiDirection 数据交换 HTML5 postMessage 和 onmessage API 详细应用 urlrewrite使用小结 怎样应对会话劫持：以Firesheep为例 CSRF 攻击的应对之道 Spring Security如何防止会话固定攻击(session fixation attack) 黑客攻防技术宝典: Web实战篇</description></item><item><title>开玩OpenUI5</title><link>https://mryqu.github.io/post/%E5%BC%80%E7%8E%A9openui5/</link><pubDate>Sun, 09 Nov 2014 14:43:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%BC%80%E7%8E%A9openui5/</guid><description>OpenUI5是SAP推出的开源HTML5Javascript用户界面库，网址为http://sap.github.io/openui5/index.html 前不久SAP宣布我司成了签署OpenUI5企业贡献者许可协议的第一个组织(BjornGoerkee的Tweet)，从此我司产品中的Flex就要纷纷下岗，让位HTML5了。 据说SAP在UI框架上的选择纠结了十多年了，甚至投奔过微软的silverlight，后来才成为HTML5的拥拓。 我司的富客户端技术用过Swing，中间打算换成Eclipse RCP，再后来决定全面采用Flex技术，兜了一圈又一圈，花了时间费了钱，最后决定采用HTML5。 虽然各浏览器厂商还在HTML5上进行利益博弈，W3C与WHATWG分道扬镳，Facebook和Linkedin抛弃HTML5转投原生App应用，但是为了将我司的产品转向云应用，HTML5对于我们这种企业级应用来说还算是很靠谱的了。 今天下载了openui5-sdk-1.24.3.zip，直接解压到Tomcat的webapps目录下，开始学文档做demo。</description></item><item><title>JavaScript中的点符号和方括号符号</title><link>https://mryqu.github.io/post/javascript%E4%B8%AD%E7%9A%84%E7%82%B9%E7%AC%A6%E5%8F%B7%E5%92%8C%E6%96%B9%E6%8B%AC%E5%8F%B7%E7%AC%A6%E5%8F%B7/</link><pubDate>Sat, 08 Nov 2014 09:18:27 +0000</pubDate><guid>https://mryqu.github.io/post/javascript%E4%B8%AD%E7%9A%84%E7%82%B9%E7%AC%A6%E5%8F%B7%E5%92%8C%E6%96%B9%E6%8B%AC%E5%8F%B7%E7%AC%A6%E5%8F%B7/</guid><description>JavaScript中对象可以通过点符号(dot notation)或方括号符号(square bracketnotation)访问属性。
a = {}; b = function() { alert(&amp;#34;Thanks!&amp;#34;); }; c = function() { alert(&amp;#34;Bye!&amp;#34;); }; a[&amp;#34;Hello&amp;#34;] = b; a.bye = c; a.hello(); a.bye(); 两者相同之处: 当属性不存在时返回undefined。两者的区别是:
点符号访问方式更快，代码阅读起来更清晰。 方括号符号访问方式可以访问包含特殊字符的属性，属性选择可以使用变量。JSLint会对方括号符号访问进行告警。</description></item><item><title>又被Mining Massive Datasets的老师伤了！</title><link>https://mryqu.github.io/post/%E5%8F%88%E8%A2%ABmining_massive_datasets%E7%9A%84%E8%80%81%E5%B8%88%E4%BC%A4%E4%BA%86/</link><pubDate>Fri, 07 Nov 2014 20:42:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8F%88%E8%A2%ABmining_massive_datasets%E7%9A%84%E8%80%81%E5%B8%88%E4%BC%A4%E4%BA%86/</guid><description>Mining Massive Datasets这周的课讲聚类和计算广告学：二分图匹配。课后的作业好几个都是一眼看不出来，只好写程序算。
其中有一道题是这个样子： We wish to cluster the following set of points: into 10 clusters. We initially choose each of the green points(25,125), (44,105), (29,97), (35,63), (55,63), (42,57), (23,40),(64,37), (33,22), and (55,20) as a centroid. Assign each of thegold points to their nearest centroid. (Note: the scales of thehorizontal and vertical axes differ, so you really need to applythe formula for distance of points; you can&amp;rsquo;t just &amp;ldquo;eyeball&amp;rdquo; it.)Then, recompute the centroids of each of the clusters.</description></item><item><title>igraph包的cliques函数总也不返回</title><link>https://mryqu.github.io/post/igraph%E5%8C%85%E7%9A%84cliques%E5%87%BD%E6%95%B0%E6%80%BB%E4%B9%9F%E4%B8%8D%E8%BF%94%E5%9B%9E/</link><pubDate>Wed, 29 Oct 2014 20:14:57 +0000</pubDate><guid>https://mryqu.github.io/post/igraph%E5%8C%85%E7%9A%84cliques%E5%87%BD%E6%95%B0%E6%80%BB%E4%B9%9F%E4%B8%8D%E8%BF%94%E5%9B%9E/</guid><description>做社交网络分析课的作业时碰到一个小麻烦，igraph包的cliques函数总也不返回，最后只能强行终止但是数据量也不大，而且largest.cliques和clique.number都是立刻返回，不解呀！
&amp;gt; library(igraph) &amp;gt; g = read.graph(&amp;#34;wikipedia.gml&amp;#34;,format=&amp;#34;gml&amp;#34;) &amp;gt; cliques(as.undirected(g)) &amp;gt; largest.cliques(as.undirected(g)) [[1]] [1] 26526 247 370 2119 6625 7826 8277 10019 11773 11801 13289 15758 [13] 16845 16885 16937 18925 22144 22644 23318 24585 24654 25487 &amp;gt; clique.number(as.undirected(g)) [1] 22</description></item><item><title>A Short Tutorial on Graph Laplacians, Laplacian Embedding, and Spectral Clustering</title><link>https://mryqu.github.io/post/a_short_tutorial_on_graph_laplacians_laplacian_embedding_and_spectral_clustering/</link><pubDate>Fri, 24 Oct 2014 20:12:08 +0000</pubDate><guid>https://mryqu.github.io/post/a_short_tutorial_on_graph_laplacians_laplacian_embedding_and_spectral_clustering/</guid><description>http://csustan.csustan.edu/~tom/Lecture-Notes/Clustering/GraphLaplacian-tutorial.pdf</description></item><item><title>创建MySQL表失败，“show tables”命令显示表存在却无法删除</title><link>https://mryqu.github.io/post/%E5%88%9B%E5%BB%BAmysql%E8%A1%A8%E5%A4%B1%E8%B4%A5show_tables%E5%91%BD%E4%BB%A4%E6%98%BE%E7%A4%BA%E8%A1%A8%E5%AD%98%E5%9C%A8%E5%8D%B4%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4/</link><pubDate>Sun, 19 Oct 2014 07:41:26 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%9B%E5%BB%BAmysql%E8%A1%A8%E5%A4%B1%E8%B4%A5show_tables%E5%91%BD%E4%BB%A4%E6%98%BE%E7%A4%BA%E8%A1%A8%E5%AD%98%E5%9C%A8%E5%8D%B4%E6%97%A0%E6%B3%95%E5%88%A0%E9%99%A4/</guid><description>在MySQL表中创建一个表table_c失败了，返回错误ERROR 1146(42S02)；结果发现MySQL显示有这个表，却无法查询和删除。```
mysql&amp;gt; create table table_c (&amp;hellip;&amp;hellip;&amp;hellip;); ERROR 1146 (42S02): Table &amp;lsquo;yqutesting.table_c&amp;rsquo; doesn&amp;rsquo;t exist mysql&amp;gt; show tables; +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ | Tables_in_yqutesting | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ | table_a | | table_b | | table_c | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ 3 rows in set (0.00 sec)
mysql&amp;gt; select * from table_c; ERROR 1146 (42S02): Table &amp;lsquo;yqutesting.table_c&amp;rsquo; doesn&amp;rsquo;t exist mysql&amp;gt; drop table table_c; ERROR 1051 (42S02): Unknown table &amp;rsquo;table_c&amp;rsquo;
结果还是drop掉yqutesting数据库，修正了table_c的定义重新创建数据库和所有表完事。 参考：[ MySQL Create Table Error - Table Doesn&amp;#39;t Exist](http://stackoverflow.com/questions/18034485/mysql-create-table-error-table-doesnt-exist)[ MySQL &amp;gt; Table doesn&amp;#39;t exist.</description></item><item><title>[Hadoop] Map Reduce Slot</title><link>https://mryqu.github.io/post/hadoop_map_reduce_slot/</link><pubDate>Fri, 17 Oct 2014 19:29:17 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_map_reduce_slot/</guid><description>MR1 在MR1中，每个节点可以启动的并发map和reduce任务数(即slot数)由管理员通过mapred-site.xml中mapred.tasktracker.map.tasks.maximum (MR2中为mapreduce.tasktracker.map.tasks.maximum )和mapred.tasktracker.reduce.tasks.maximum (MR2中为mapreduce.tasktracker.reduce.tasks.maximum )配置指定。(下面的参考帖子提到过作业级参数mapred.map.tasks.maximum和mapred.reduce.tasks.maximum，但是在HADOOP-4295并没有通过。)
此外，管理员通过mapred.child.配置设置mapper或reducer默认的内存分配量。</description></item><item><title>[社交网络分析课] 笔记</title><link>https://mryqu.github.io/post/social-network-analysis/</link><pubDate>Wed, 08 Oct 2014 20:57:50 +0000</pubDate><guid>https://mryqu.github.io/post/social-network-analysis/</guid><description>本文为Social Network Analysis学习笔记，课程地址为https://www.coursera.org/course/sna。
第一讲：SNA工具 Gephi https://gephi.github.io/ 用于网络、复杂系统和动态封层图形的交互式可视化及研究平台，支持度、介数、紧密性等网络中心性指标以及密度、路径长度、网络直径、模块度、集聚系数等指标，支持GDF(GUESS)、GraphML (NodeXL)、GML、NET (Pajek)、GEXF等文件格式。 开源，支持Windows、Linux和Mac OS X平台 Gephi指南 使用Gephi可视化twitter网络 Twitter上的埃及革命 NetLogo https://ccl.northwestern.edu/netlogo/index.shtml 多主体仿真建模工具。可用于模拟各种社会现象和自然现象，通过设置个体行为并使多个个体自由运行来研究个体行为对于复杂系统的影响和变化。 开源，支持Windows、Linux和Mac平台 NetLogo帮助文档 Lada的多个特定网络属性演示 iGraph http://igraph.org/ 网络分析工具库，侧重于执行效率、可移植性和易用性，可被R、Python和C/C++调用。 开源，支持Windows、Linux和Mac OS X平台 R iGraph帮助文档 Python iGraph帮助文档 C iGraph帮助文档 Pajek http://pajek.imfm.si/doku.php 网络分析和可视化工具，功能丰富，通过下拉菜单进行各种操作。 免费，支持Windows平台，也可以在Linux（64）和Mac平台上仿真（Wine）运行 Pajek参考手册 UCINet https://sites.google.com/site/ucinetsoftware/ 社交网络数据分析软件包，功能丰富。 商业软件，支持Windows平台 UCINet文档 NodeXL http://nodexl.codeplex.com/ 交互式网络可视化和分析工具，以MS Excel模板的形式利用MSExcel作为数据展示和分析平台。可以定制图像外观、无损缩放、移动图像，动态过滤顶点和边，提供多种布局方式，查找群和相关边，支持多种数据格式输入和输出。 开源，支持Windows Excel 2007/2010/2013 NodeXL文档 其他 R R的SNA库(见统计软件杂志上关于sna包的文章)：功能丰富，偏于统计 如果使用Gephi的话，可以看一下用于读写Gephi gexf图形文件的rgexf库。 Python NetworkX：开源Python包，用于复杂网络的创建、操作和复杂网络的结构、动力学和功能方面的研究。 Sage：开源基于Web的数学计算环境，包含NetworkX以及自己的图形库。这里有三篇重要文档，通用图参考文档、 无向图参考文档 和 有向图参考文档。 graph-tool：高效python模块，用于图/网络的操作和统计分析。 Newt Java Jung（Java Universal Network/Graph Framework）：Java平台网络/图应用开发的一种通用基础架构。其目的在于为开发关于图或网络结构的应用程序提供一个易用、通用的基础架构。使用JUNG功能调用，可以方便的构造图或网络的数据结构，应用经典算法（如聚类、最短路径，最大流量等），编写和测试用户自己的算法，以及可视化的显示数据的网络图。 Neo4j：图数据库 Blueprints：类似于JDBC，但是用于图数据库 SoNIA（Social Network Image Animator）:用于动态或纵向数据的可视化。 JavaScript D3.</description></item><item><title>[Hadoop] 通过MultipleOutputs生成多输出文件</title><link>https://mryqu.github.io/post/hadoop_%E9%80%9A%E8%BF%87multipleoutputs%E7%94%9F%E6%88%90%E5%A4%9A%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 29 Sep 2014 18:39:27 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E9%80%9A%E8%BF%87multipleoutputs%E7%94%9F%E6%88%90%E5%A4%9A%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6/</guid><description>即前一博文[Hadoop] 通过MultipleInputs处理多输入文件展示如何处理MapReduce多输入问题，本文将展示一下如何处理MapReduce多输出的方法。
MultipleOutputs示例 MultipleOutputsDemo.java源码 Scores.txt Tomas,100 Edward,81 Henry,59 Gordon,60 James,97 Percy,93 Toby,77 Emily,87 Duke,68 Donald,47 Douglas,35 执行 hadoop jar YquMapreduceDemo.jar MultipleOutputsDemo /user/hadoop/mos_input/scores.txt /user/hadoop/mos_output 测试结果 MultipleOutputs分析 普通Driver |API|Job属性 |&amp;mdash;&amp;ndash; |Job.setOutputFormatClass|mapreduce.job.outputformat.class示例：org.apache.hadoop.mapreduce.lib.output.TextOutputFormat |Job.setOutputKeyClass|mapreduce.job.output.key.class示例：org.apache.hadoop.io.Text |Job.setOutputValueClass|mapreduce.job.output.value.class示例：org.apache.hadoop.io.IntWritable
使用MultipleOutputs的Driver |API|Job属性 |&amp;mdash;&amp;ndash; |MultipleOutputs.addNamedOutput|mapreduce.multipleoutputs
示例：pass fail
mapreduce.multipleoutputs.namedOutput.pass.format
示例：org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
mapreduce.multipleoutputs.namedOutput.pass.key
示例：org.apache.hadoop.io.NullWritable
mapreduce.multipleoutputs.namedOutput.pass.value
示例：org.apache.hadoop.io.Text
mapreduce.multipleoutputs.namedOutput.fail.format
示例：org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
mapreduce.multipleoutputs.namedOutput.fail.key
示例：org.apache.hadoop.io.NullWritable
mapreduce.multipleoutputs.namedOutput.fail.value
示例：org.apache.hadoop.io.Text
通过调用org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write方法，根据相应NamedOutput相应的OutputFormat、OutputKeyClass和OutputValueClass创建NamedOutput自己的RecordWriter，完成相应的输出。</description></item><item><title>[Hadoop] 通过MultipleInputs处理多输入文件</title><link>https://mryqu.github.io/post/hadoop_%E9%80%9A%E8%BF%87multipleinputs%E5%A4%84%E7%90%86%E5%A4%9A%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 29 Sep 2014 06:35:57 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E9%80%9A%E8%BF%87multipleinputs%E5%A4%84%E7%90%86%E5%A4%9A%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6/</guid><description>一般MapReduce程序仅处理一个输入文件，但当我们必须处理多个输入文件时，普通MapReduce方法就无能为力了，这时候可以使用org.apache.hadoop.mapreduce.lib.input.MultipleInputs类搞定这一问题。
MultipleInputs示例 MultipleInputsDemo.java源码 people.txt 1,Tomas,1 2,Edward,2 3,Henry,3 4,Gordon,4 5,James,4 6,Percy,3 7,Toby,2 8,Emily,1 9,Duke,3 10,Donald,3 11,Douglas,3 locations.txt 1,China 2,USA 3,Canada 4,New Zealand 执行 hadoop jar YquMapreduceDemo.jar MultipleInputsDemo /user/hadoop/mijoin/people.txt /user/hadoop/mijoin/locations.txt /user/hadoop/mijoin_output 测试结果 MultipleInputs分析 与普通Driver的区别 普通Driver |API|Job属性 |&amp;mdash; |FileInputFormat.addInputPath|mapreduce.input.fileinputformat.inputdir
示例：/user/hadoop/wordcount/book.txt |Job.setMapperClass|mapreduce.job.map.class
示例：WordCount.TokenizerMapper |Job.setInputFormatClass|mapreduce.job.inputformat.class
示例：org.apache.hadoop.mapreduce.lib.input.TextInputFormat
使用MultipleInputs的Driver APIJob属性MultipleInputs.addInputPathmapreduce.input.multipleinputs.dir.formats
示例：/user/hadoop/mijoin/people.txt:o.a.h.m.l.i.TextInputFormat,
/user/hadoop/mijoin/locations.txt:o.a.h.m.l.i.TextInputFormatmapreduce.input.multipleinputs.dir.mappers
示例：/user/hadoop/mijoin/people.txt:MultipleInputsDemo.PersonMapper,
/user/hadoop/mijoin/locations.txt:MultipleInputsDemo.LocationMappermapreduce.job.inputformat.class
示例：org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormatmapreduce.job.map.class
示例：org.apache.hadoop.mapreduce.lib.input.DelegatingMapper 由上可见，MultipleInputs方法不设置mapreduce.input.fileinputformat.inputdir属性，将mapreduce.job.inputformat.class和mapreduce.job.map.class属性设为多输入的委托类，增加了两个专用的属性mapreduce.input.multipleinputs.dir.formats和mapreduce.input.multipleinputs.dir.mappers已用于映射每一输入文件的格式和mapper类。
调用每个输入文件的FileFormat 调用每个输入文件的Mapper 示例流程</description></item><item><title>使用微软的机器学习云Azure ML进行预测分析</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8%E5%BE%AE%E8%BD%AF%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%91azure_ml%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</link><pubDate>Tue, 23 Sep 2014 23:01:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8%E5%BE%AE%E8%BD%AF%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%91azure_ml%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</guid><description>今天看了一个帖子Predictive Analytics with Microsoft Azure Machine Learning。尽管机器学习已经是一项历史悠久而且应用广泛的技术，微软以云服务形式推出希望获得一些市场。AzureML通过拖拽操作在界面上组织数据清理、训练模型、模型打分和评估，最后可以生成C#、R或Python代码。 对云数据进行数据分析，除了用Hadoop/Spark等技术自己搭积木开发实现外，这种通用分析产品还不够丰富。期望早日看到各厂家纷纷推出成熟的旗舰产品那一天，我司（SAS）加油！：）</description></item><item><title>将Ultraedit集成到Windows文件资源管理器</title><link>https://mryqu.github.io/post/%E5%B0%86ultraedit%E9%9B%86%E6%88%90%E5%88%B0windows%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8/</link><pubDate>Wed, 10 Sep 2014 20:58:18 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%86ultraedit%E9%9B%86%E6%88%90%E5%88%B0windows%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8/</guid><description>最近自己的公司电脑换新的了，IT同事给装好了Ultraedit，可是安装时没有在Windows文件资源管理器的菜单加入Ultraedit项，使用起来不便。在配置里设一下，搞定！</description></item><item><title>从TortoiseGit切换到Git Extensions</title><link>https://mryqu.github.io/post/%E4%BB%8Etortoisegit%E5%88%87%E6%8D%A2%E5%88%B0git_extensions/</link><pubDate>Sun, 07 Sep 2014 12:13:06 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BB%8Etortoisegit%E5%88%87%E6%8D%A2%E5%88%B0git_extensions/</guid><description>一开始使用GitHub的服务，除了安装了msysGit&amp;rsquo;s Git for Windows，GUI客户端就是GitHub的Web界面。后来使用bitbucket的服务时，想要安装一个好使又通用的GUI客户端。由于使用TortoiseCVS和TortoiseSVN，自然就选择了TortoiseGit。由于三者界面风格一致，使用无障碍上手。最近开始使用公司的git仓库，公司指定的是Git Extensions。好吧，Bye， TortoiseGit。 好奇了一下，上网搜了两者的对比。貌似相当一部分人使用TortoiseGit的理由跟我一样，不过有一些人更推荐Git Extensions。此外还有一个商业产品SmartGit，但貌似使用的人更少。搜索结果：What is the Best Git GUI (Client) for Windows? TortoiseGit vs Git ExtensionsAsk HN: Best Git GUI For Windows?</description></item><item><title>[Hadoop] MapReduce定制Counter实践</title><link>https://mryqu.github.io/post/hadoop_mapreduce%E5%AE%9A%E5%88%B6counter%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 04 Sep 2014 21:11:13 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_mapreduce%E5%AE%9A%E5%88%B6counter%E5%AE%9E%E8%B7%B5/</guid><description>MapReduce除了有内建的Counter，还支持应用程序自身定制的Counter。实践如下：
CustomCounterDemo.java 执行 JobHistory显示</description></item><item><title>[数据分析与统计推断] 学习笔记</title><link>https://mryqu.github.io/post/data-analysis-and-statistical-inference/</link><pubDate>Tue, 02 Sep 2014 21:43:48 +0000</pubDate><guid>https://mryqu.github.io/post/data-analysis-and-statistical-inference/</guid><description>本文为Data Analysis and Statistical Inference学习笔记，课程地址为https://www.coursera.org/course/statistics。
介绍数据 数据基础 观察值、变量、数据矩阵数据类型:
数字变量：分为连续的和离散的 分类变量：分为有序（ordinal）的和普通无序的变量关系: 关联Assocaited （Dependent）：分为正的和负的 独立Independent 研究方法 观察性研究Observational Study：直接取现实中的数据，探究变量间的相关性 retrospective：依赖以前的数据 prospective：在研究中收集新的数据 实验性研究Experiment: 随机分配对象到实验组；建立因果性连接观察性研究和实验性研究主要区别在于是否人为地施加了干预措施 观察性研究和抽样策略 为什么抽样？
某些个体很难定位和测量； 统计总体很少保持不变抽样偏差源 便利样本Convenience sample：更易于被访问到的用户更可能被包含到采样中 无响应样本Non-response：仅部分被随机采样的被访者填写了调查问卷，这样的采样无法代表统计总体 自发性响应样本Voluntary response：对调查问卷中的问题更感兴趣的人积极主动填写调查问卷抽样方法 简单随机抽样Simple random sample (SRS)：不做控制随机地取样 分层抽样Stratified sample：对人群做分析，按相似性分成若干的阶层，在各阶层内取样 整群抽样cluster sample：随机将统计总体分成若干群，随机取一些群，再在这些群内取样混杂变量 Confounding/lurkvariable：对解释变量和响应变量都有影响的额外变量，使解释变量和响应变量看起来有关系 实验性研究 设计原则 control：比较实验组与对照组 randomize：保证对象在两个组分配的随机性 replicate：足够大的实验量或整个实验可复制 block：消除已知或可疑变量对输出的影响。例子:设计实验研究是否能量胶囊有助于奔跑更快： 实验组treatment：能量胶囊 对照组control:无能量胶囊能量胶囊可能对专业运动员和业余运动员影响不同消除专业状态： 将样本拆分为专业运动员和业余运动员 将专业运动员和业余运动员随机平均分配到实验组和对照组消除变量和解释变量的区别： 解释变量(factors)：施加于实验个体的条件 消除变量：我们需要控制的实验个体自带特征消除与分层很相似，区别在于： 在随机分配过程中消除，用于取得因果性 在随机抽样过程中分层，用于概化generalizability 术语 安慰剂：假处理，经常在药物研究中用作对照组 安慰剂效应：展示使用安慰剂的变化 盲 ：实验个体不知道其所在组 双盲：实验个体和研究者都不知道其所在组在需要从人的主观感受中剥离客观结论的社会性研究（比如药物实验）中，如果被试的主观感受会影响数据结果，就需要给予对照组无实质作用的安慰剂，并且对其隐藏其属于实验组还是对照组的信息，以区分实验组的变化和安慰剂效应，这就叫blindexperiment；更进一步，如果研究者的主观感受也会影响实验结果，则对研究者也隐藏实验与对照的分组信息，这就是通常说的双盲实验 随机抽样和随机分配 数值型数据的可视化 散点图scatterplot 可以从中归纳两个变量的相关性。相关性有几个性质：正/负相关、形状（线性、非线性）、强/弱相关，异常值
直方图histogram 可以给出一个数据密度的视图，并且可以观察：
偏度：描述了数据密度的左右分布，左偏/右偏/对称 形态（modality）：正态分布/均匀分布/双峰分布/多峰分布等等 区间划分不能过宽或过窄 点阵图dotplot 当研究个体值时有用，样本量太大时不太适
箱形图boxplot 在强调异常点、中位数、四分位距(Interquartile range，IQR，即Q3-Q1)时有用。</description></item><item><title>[JavaScript] 继承</title><link>https://mryqu.github.io/post/javascript_%E7%BB%A7%E6%89%BF/</link><pubDate>Wed, 27 Aug 2014 20:41:17 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E7%BB%A7%E6%89%BF/</guid><description>示例：
function BaseClass() {}; BaseClass.prototype.method1 = function() { console.log(&amp;#34;BaseClass#method1&amp;#34;) }; BaseClass.prototype.method2 = function() { console.log(&amp;#34;BaseClass#method2&amp;#34;) }; BaseClass.prototype.method3 = function() { return &amp;#34;BaseClass#method3&amp;#34;; }; ChildClass.prototype = new BaseClass(); function ChildClass() { //BaseClass.call(this); }; ChildClass.prototype.method2 = function() { console.log(&amp;#34;ChildClass#method2&amp;#34;) }; ChildClass.prototype.method3 = function() { console.log(BaseClass.prototype.method3.call(this)+&amp;#34; by ChildClass!&amp;#34;); }; ChildClass.prototype.method4 = function() { console.log(&amp;#34;ChildClass#method4&amp;#34;) }; var myobj = new ChildClass(); myobj.method1(); myobj.method2(); myobj.method3(); myobj.method4(); 测试： 注解：
Javascript的继承要在原型链上进行，没有super()可以调用父类，覆盖父类函数时只能通过父类原型以call或apply函数的形式调用父类的方法。</description></item><item><title>[JavaScript] 字符串与JSON数据互转</title><link>https://mryqu.github.io/post/javascript_%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%8Ejson%E6%95%B0%E6%8D%AE%E4%BA%92%E8%BD%AC/</link><pubDate>Tue, 26 Aug 2014 06:06:26 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%8Ejson%E6%95%B0%E6%8D%AE%E4%BA%92%E8%BD%AC/</guid><description>字符串-&amp;gt;JSON 转换方法有3种:
使用浏览器内置window.JSON.parse方法 原生方法，速度最快，首选方案。老版本浏览器不支持。
|浏览器|支持版本 |&amp;mdash; |Chrome|(Yes) |Firefox (Gecko)|3.5 (1.9.1) |Internet Explorer|8.0 |Opera|10.5 |Safari|4.0 |Android|(Yes) |Chrome for Android|(Yes) |Firefox Mobile (Gecko)|1.0 (1.0) |IE Mobile|(Yes) ||Opera Mobile|(Yes) |Safari Mobile|(Yes)
使用Funtion()构造函数 较eval_r()快
使用 eval_r() 函数 功能强大，能解析任何JS代码,但是执行效率和安全性都不好示例代码：
var jsonStr = &amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;kxeg&amp;#34;,&amp;#34;data&amp;#34;:[{&amp;#34;key&amp;#34;:&amp;#34;Alpha&amp;#34;,&amp;#34;color&amp;#34;:&amp;#34;lightblue&amp;#34;},{&amp;#34;key&amp;#34;:&amp;#34;Beta&amp;#34;,&amp;#34;color&amp;#34;:&amp;#34;orange&amp;#34;}]}&amp;#39;; //JSON.parse() if (window &amp;amp;&amp;amp; window.JSON &amp;amp;&amp;amp; window.JSON.parse) jsonObj1 = window.JSON.parse(jsonStr); //Function 创建一个闭包,返回一个json数据对象 jsonObj2 = (new Function(&amp;#39;return&amp;#39;+jsonStr))(); //eval_r() jsonObj3 = eval_r(&amp;#39;(&amp;#39;+jsonStr+&amp;#39;)&amp;#39;); JSON-&amp;gt;字符串 使用浏览器内置window.JSON.stringify方法
参考 js中字符串数据转为json对象的方法
MDN：JSON</description></item><item><title>[JavaScript] 函数的prototype对象属性</title><link>https://mryqu.github.io/post/javascript_%E5%87%BD%E6%95%B0%E7%9A%84prototype%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7/</link><pubDate>Fri, 22 Aug 2014 21:44:13 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E5%87%BD%E6%95%B0%E7%9A%84prototype%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7/</guid><description>原型（prototype） JavaScript 不包含传统的类继承模型，而是使用原型模型。继承方面，JavaScript中的每个对象都有一个内部私有的链接指向另一个对象，这个对象就是该对象的原型。这个原型对象也有自己的原型，直到对象的原型为 null为止（也就是没有原型）。这种一级一级的链结构就称为原型链。
Function.prototype.toString() toString()方法返回表示函数源代码的字符串。
Function.prototype.bind() 对于给定函数，bind()方法创建具有与原始函数相同主体的绑定函数。 在绑定函数中，this对象将解析为传入的对象。绑定函数具有指定的初始参数。
fun.bind(thisArg[, arg1[, arg2[, ...]]]) JavaScript bind 方法具有几种用法。 通常，它用于为在其他上下文中执行的函数保留执行上下文。
Function.prototype.call()和Function.prototype.apply() call()和apply()方法都是调用一个对象的方法，用另一个对象上下文替换当前对象上下文。两者仅在定义参数方式有所区别：call传递的是参数列表，apply传递的是数组或arguments对象。
fun.call(thisArg[, arg1[, arg2[, ...]]]) 应用call和apply还有一个技巧，就是call和apply应用另外一个函数以后，当前函数就具备了另外一个函数的方法和属性，这也可以称之为“继承”。通过上例可知，extend调用call方法后就继承到了base的方法和属性。
参考 JavaScript函数的Arguments对象属性 Javascript继承机制的设计思想 深入理解JavaScript系列（5）：强大的原型和原型链 Function.prototype.apply() Function.prototype.call() Function.prototype.bind() Function.prototype.toString() Functional JavaScript, Part 3: .apply(), .call(), and the arguments object Bind, Call and Apply in JavaScript</description></item><item><title>[JavaScript] 函数的Arguments对象属性</title><link>https://mryqu.github.io/post/javascript_%E5%87%BD%E6%95%B0%E7%9A%84arguments%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7/</link><pubDate>Thu, 21 Aug 2014 20:53:34 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E5%87%BD%E6%95%B0%E7%9A%84arguments%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7/</guid><description>arguments对象 每个函数表达式在其作用域内都可以访问一个特殊的本地变量：arguments，它是跟数组很类似的对象，同样可以通过下标访问，例如arguments[0]和arguments[1]&amp;hellip;。
arguments.length 传递给函数的参数个数。
arguments.callee 返回当前正在调用的函数。callee属性是arguments对象的一个成员，它表示对函数对象自身的引用，有利于匿名函数的递归或者保证函数的封装性，上例中的sumV2仅调用局部变量arguments的callee属性，较sumV1需要调用全局变量sumV1，封装性更好。值得注意的是，callee也拥有一个length属性。通过上例可知arguments.length反映的是函数的实参长度，arguments.callee.length反映的是函数的形参长度。
arguments.caller (已废弃) arguments.caller并属于标准，且已被废弃。可以使用同样不属于标准但被大多数主流浏览器支持的Function.caller获得调用当前函数的函数。
参考 Arguments object
arguments.callee
arguments.caller
Why was the arguments.callee.caller property deprecated in JavaScript?
Function caller</description></item><item><title>[JavaScript] retrieve data table</title><link>https://mryqu.github.io/post/javascript_retrieve_data_table/</link><pubDate>Wed, 20 Aug 2014 22:06:08 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_retrieve_data_table/</guid><description>想学学怎么提交一个Form中的Table，放狗出去，结果不够给力。 曾经有很多年Table标签被用作格式对齐的工具，这使搜出来的页面很少讲的是数据表格。 看了看DataTables这个JQuery插件，可以加载和更新数据，但是没有找到存储所有表格数据的功能。 看了看ajaxsubmit，必须有formcontent，此外可以有可选的data。由于表格里有很多行，没想好path的设置问题。 最后还是用JS提取所有表格数据，生成JS数组，通过AJAX post函数发送给服务器侧。 JS侧的代码示例：http://jsfiddle.net/mryqu/d7rubzut/ 服务器侧的用于REST的Spring控制器代码如下：
@RequestMapping(params=&amp;#34;action=test&amp;#34;, method = RequestMethod.POST) public @ResponseBody TestResultVO test(HttpServletRequest request, @ModelAttribute(&amp;#34;tqs&amp;#34;)ArrayList tqs) throws Exception { ...... } 运行结果正常</description></item><item><title>50个必用的Bootstrap扩展插件</title><link>https://mryqu.github.io/post/50%E4%B8%AA%E5%BF%85%E7%94%A8%E7%9A%84bootstrap%E6%89%A9%E5%B1%95%E6%8F%92%E4%BB%B6/</link><pubDate>Tue, 19 Aug 2014 23:13:13 +0000</pubDate><guid>https://mryqu.github.io/post/50%E4%B8%AA%E5%BF%85%E7%94%A8%E7%9A%84bootstrap%E6%89%A9%E5%B1%95%E6%8F%92%E4%BB%B6/</guid><description>学习了一下50 Must-have plugins for extending Twitter Bootstrap，对Bootstrap Form Wizard感兴趣。之前看过Twitter Bootstrap Wizard，个人感觉没这个漂亮。</description></item><item><title>消息队列技术选型资料</title><link>https://mryqu.github.io/post/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E8%B5%84%E6%96%99/</link><pubDate>Sat, 02 Aug 2014 21:27:49 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E8%B5%84%E6%96%99/</guid><description>Message Queue Evaluation Notes（10/01/12）
消息队列软件产品大比拼（11/05/16）
RabbitMQ / ActiveMQ or Redis for over 250,000 msg/s（11/09/27）
消息中间件的技术选型心得－RabbitMQ、ActiveMQ和ZeroMQ（13/01/07）
消息队列中间件技术选型分析（13/05/24）
谁才是最快的消息队列:ActiveMQ, RabbitMQ, HornetQ, QPID&amp;hellip;（13/12/22）
activemq-or-rabbitmq-or-zeromq-or（14/02/27）
Alibaba： 消息队列中间件调研文档（14/07/01）
Alibaba：RocketMQ 性能测试报告（14/07/01）
消息中间件选型（15/01/20）
RabbitMq、ActiveMq、ZeroMq、kafka之间的比较,资料汇总（15/08/19）
开源 VS 商业，消息中间件你不知道的那些事（15/11/25）
MQ产品比较-ActiveMQ-RocketMQ（16/03/07）</description></item><item><title>磁盘分区管理工具</title><link>https://mryqu.github.io/post/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 21 Jul 2014 21:15:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid><description>一直以来都用PQMagic硬盘分区大师8.0，忽然有一天意识到它在Win7上不好使了，然后就想升级，结果发现PQMagic这款软件早就over了。根据维基百科的说法，Symantec收购由PowerQuest公司推出的PQMagic于2009年12月8日退役。 搜了一下资料：
目前比较好的商业分区工具是Acronis Disk Director 目前比较好的免费分区工具是AOMEI Partition Assistant Standard 简单情况下，可以Win7自带小工具调整分区大小</description></item><item><title>用Python清理XMind生成的html文件</title><link>https://mryqu.github.io/post/%E7%94%A8python%E6%B8%85%E7%90%86xmind%E7%94%9F%E6%88%90%E7%9A%84html%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 20 Jul 2014 06:42:59 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%94%A8python%E6%B8%85%E7%90%86xmind%E7%94%9F%E6%88%90%E7%9A%84html%E6%96%87%E4%BB%B6/</guid><description>XMind思维导图可以导出成html文件，但是每个Topic都被a标签包着，然后外面再被h1、h2&amp;hellip;h5标题标签包着，看着就难受。此外h1、h2&amp;hellip;h5和p标签都加了class属性，没什么用。 写一段小程序，将XMind生成的html文件进行格式清理。
from bs4 import BeautifulSoup as BeautifulSoup soup = BeautifulSoup(open(&amp;#34;c:/qutemp/123.html&amp;#34;)) for a in soup(&amp;#39;a&amp;#39;): a.parent.string = a.string a.clear() for tag in [&amp;#39;h1&amp;#39;,&amp;#39;h2&amp;#39;,&amp;#39;h3&amp;#39;,&amp;#39;h4&amp;#39;,&amp;#39;h5&amp;#39;,&amp;#39;p&amp;#39;]: for tag in soup(tag): del tag[&amp;#39;class&amp;#39;] print soup</description></item><item><title>MySQL Workbench的安全更新模式</title><link>https://mryqu.github.io/post/mysql_workbench%E7%9A%84%E5%AE%89%E5%85%A8%E6%9B%B4%E6%96%B0%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 16 Jul 2014 21:08:37 +0000</pubDate><guid>https://mryqu.github.io/post/mysql_workbench%E7%9A%84%E5%AE%89%E5%85%A8%E6%9B%B4%E6%96%B0%E6%A8%A1%E5%BC%8F/</guid><description>最近在MySQLWorkbench上使用&amp;quot;DELETE FROM TABLE_E;&amp;ldquo;清空一个表时返回错误： Error Code: 1175. You are using safe update mode and you triedto update a table without a WHERE that uses a KEY column To disablesafe mode, toggle the option in Preferences -&amp;gt; SQL Queries andreconnect.
结果在MySQL命令行上却一切正常。
这是由于MySQL Workbench打开了安全更新模式，其有助于初学者使用DELETE FROM tbl_name 语句但是忘记了WHERE子句造成不必要的麻烦。解决方法就是关闭安全更新模式。
解决方法1：
SET SQL_SAFE_UPDATES = 0; DELETE FROM TABLE_E; SET SQL_SAFE_UPDATES = 1; 解决方法2：
参考： mysql delete under safe mode
mysql Tips</description></item><item><title>了解CAS（集中式认证服务）</title><link>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3cas%E9%9B%86%E4%B8%AD%E5%BC%8F%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1/</link><pubDate>Fri, 11 Jul 2014 21:25:29 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%86%E8%A7%A3cas%E9%9B%86%E4%B8%AD%E5%BC%8F%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1/</guid><description>集中式认证服务（Central AuthenticationService，缩写CAS）是一种针对万维网的单点登录协议。它的目的是允许一个用户访问多个应用程序，而只需提供一次凭证（如用户名和密码）。它还允许web应用程序在没有获得用户的安全凭据（如密码）的情况下对用户进行身份验证。“CAS”也指实现了该协议的软件包。 CAS协议涉及到至少三个方面：客户端Web浏览器、Web应用请求的身份验证和CAS服务器。它还可能涉及一个后台服务（例如数据库服务器），它并没有自己的HTTP接口，但与一个Web应用程序进行通信。 当客户端访问访问应用程序，请求身份验证时，应用程序重定向到CAS。CAS验证客户端是否被授权，通常通过在数据库对用户名和密码进行检查（例如Kerberos、LDAP或ActiveDirectory）。 如果身份验证成功，CAS令客户端返回到应用程序，并传递身份验证票（Securityticket）。然后，应用程序通过安全连接连接CAS，并提供自己的服务标识和验证票。之后CAS给出了关于特定用户是否已成功通过身份验证的应用程序授信信息。 CAS允许通过代理服务器进行多层身份验证。后端服务（如数据库或邮件服务器）可以组成CAS，通过从Web应用程序接收到的信息验证用户是否被授权。因此，网页邮件客户端和邮件服务器都可以实现CAS。 历史 CAS是由耶鲁大学的Shawn Bayern创始的，后来由耶鲁大学的Drew Mazurek维护。CAS1.0实现了单点登录。CAS2.0引入了多级代理认证（Multi-tier proxyauthentication）。CAS其他几个版本已经有了新的功能。 2004年12月，CAS成为Jasig（Java in Administration Special InterestGroup）的一个项目，2008年该组织负责CAS的维护和发展。CAS原名“Yale CAS”，现在则被称为“JasigCAS”。
参考 Wiki：Central Authentication Service
Jasig CAS主页
GitHub：Jasig/java-cas-client
GitHub：Jasig/cas
CAS协议规范 3.0</description></item><item><title>玩一下SQLite3命令</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bsqlite3%E5%91%BD%E4%BB%A4/</link><pubDate>Thu, 10 Jul 2014 20:29:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Bsqlite3%E5%91%BD%E4%BB%A4/</guid><description>SQLite介绍 SQLite是实现自包含、无需服务器、零配置和事务SQL数据库引擎的软件库。它占用资源非常低，既可以用于Windows/Linux/Unix等主流的操作系统，也广泛用于嵌入式产品中。它能够跟很多程序语言相结合，比如Tcl、C#、PHP、Java等，还有ODBC接口。 不像常见的客户-服务器范例，SQLite引擎不是个程序与之通信的独立进程，而是连接到程序中成为它的一个主要部分。所以主要的通信协议是在编程语言内的直接API调用。这在消耗总量、延迟时间和整体简单性上有积极的作用。整个数据库(定义、表、索引和数据本身)都在宿主主机上存储在一个单一的文件中。它的简单的设计是通过在开始一个事务的时候锁定整个数据文件而完成的。
SQLITE常用命令使用 SQLite命令行解释器除了支持SQL语句（大小写不敏感），还支持以.开头、大小写敏感的专有命令。SQLite网站有个帖子Command Line Shell For SQLite介绍了支持的所有命令，这里挑一些常用的玩一下。
.help命令：给出所有命令的帮助介绍 sqlite&amp;gt; .help .prompt：更换提示符 sqlite&amp;gt; .prompt &amp;gt;&amp;gt; &amp;gt;&amp;gt; &amp;gt;&amp;gt;.prompt sqlite&amp;gt; sqlite&amp;gt; .show：显示当前设置 sqlite&amp;gt;.show echo: off eqp: off explain: off headers: off mode: list nullvalue: &amp;#34;&amp;#34; output: stdout separator: &amp;#34;|&amp;#34; stats: off width: .database：显示数据库信息 sqlite&amp;gt;.database seq name file --- --------------- ---------------------------------------------------------- 0 main E:\gitws\datasci_course_materials\assignment2\reuters.db 1 temp .tables：显示表信息 sqlite&amp;gt;.tables Frequency .schema：显示表的创建语句 sqlite&amp;gt;.schema CREATE TABLE Frequency ( docid VARCHAR(255), term VARCHAR(255), count int, PRIMARY KEY(docid, term)); .</description></item><item><title>SQL中的（稀疏）矩阵运算</title><link>https://mryqu.github.io/post/sql%E4%B8%AD%E7%9A%84%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</link><pubDate>Mon, 07 Jul 2014 21:16:01 +0000</pubDate><guid>https://mryqu.github.io/post/sql%E4%B8%AD%E7%9A%84%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</guid><description>前两天在一门课上看到SQL中（稀疏）矩阵的乘法，找到两篇相关帖子，介绍了SQL中的（稀疏）矩阵运算，包含矩阵相等判别、加法、乘法、转置。
Matrix Math in SQL MAD skills: new analysis practices for big data</description></item><item><title>通过Java反射操作注解</title><link>https://mryqu.github.io/post/%E9%80%9A%E8%BF%87java%E5%8F%8D%E5%B0%84%E6%93%8D%E4%BD%9C%E6%B3%A8%E8%A7%A3/</link><pubDate>Sun, 29 Jun 2014 09:47:16 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%80%9A%E8%BF%87java%E5%8F%8D%E5%B0%84%E6%93%8D%E4%BD%9C%E6%B3%A8%E8%A7%A3/</guid><description>注解是Java5加入的特性，它是可以插入Java代码的注释或元数据，可被预编译工具在编译时进行处理，或在运行态通过Java反射进行操作。开发者可以通过元编程（Metaprogramming）等技术提高生产率，注解在其中扮演了核心角色。其思想是通过注解够告诉工具如何生成新代码、转换代码或者决定运行期的行为。
MyAnnotation.java package com.yqu.reflection.annotation; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Retention(RetentionPolicy.RUNTIME) //@Target(ElementType.TYPE) public @interface MyAnnotation { public String name() default &amp;#34;[unknown name]&amp;#34;; public String value() default &amp;#34;[unassigned value]&amp;#34;; } 定义注解类有点类似于定义Java接口类interface，但和一般的接口类比起来，interface前面多了一个@，这样就声明了注解是一个Annotation类。另外，Stringname()和Stringvalue()这个写法是@interface中一个比较独特的地方。它实际上定义的不并是注解类的方法，而是注解类的属性。 @Target指定此注解的作用域：
TYPE：用于类、接口、注解类和枚举 CONSTRUCTOR：用于构造方法 LOCAL_VARIABLE：用于本地变量 FIELD：用于类的属性(包括枚举常量) METHOD：用于方法 PACKAGE：用于包 PARAMETER：用于方法的参数 ANNOTATION_TYPE：用于注解类 TYPE_PARAMETER：使用类型参数，表示注解可以用在Type的声明式前 TYPE_USE： 使用类型注解。表示注解所有使用Type的地方（如泛型、类型转换等）@Retention指定此注解的生命周期： SOURCE：代表此注解仅在代码编译前存活。比如@Deprecated，仅在编译前提供一些提示信息。在编译时，这些注解并不会编译到class文件中。 CLASS：与SOURCE不同，这类标记会编译到class文件中，但不会成为程序的一部分，也不可以通过代码在运行时调用到。 RUNTIME： 这类标记将成为代码的一部分，并会在实际运行时起到作用。 TheClass.java package com.yqu.reflection.annotation; import java.lang.annotation.Annotation; import java.lang.reflect.Field; import java.lang.reflect.Method; @MyAnnotation(name = &amp;#34;classAnnotation&amp;#34;, value = &amp;#34;Hello Class&amp;#34;) // I18NOK:CLS public class TheClass { @MyAnnotation(name = &amp;#34;fieldAnnotation&amp;#34;, value = &amp;#34;Hello Field&amp;#34;) public String theField = null; public TheClass() { } @MyAnnotation(name = &amp;#34;methodAnnotation&amp;#34;, value = &amp;#34;Hello Method&amp;#34;) public void doSomething() { System.</description></item><item><title>lxml.html.soupparser引入BeautifulSoup 4的work-around</title><link>https://mryqu.github.io/post/lxml.md.soupparser%E5%BC%95%E5%85%A5beautifulsoup_4%E7%9A%84work-around/</link><pubDate>Sun, 22 Jun 2014 15:51:50 +0000</pubDate><guid>https://mryqu.github.io/post/lxml.md.soupparser%E5%BC%95%E5%85%A5beautifulsoup_4%E7%9A%84work-around/</guid><description>想用一下python的xpath功能分析一个html文件，lxml是比较不错的xml/html解析库，lxml功能强大，性能也不错，此外也包含了ElementTree，html5lib ，beautfulsoup 等库。 可惜我的html文件格式不是很严谨，lxml的ElementTree处理不了，就转而想用lxml的beautfulsoup来处理。 结果lxml找不到BeautifulSoup库。
查了一下Anaconda装的库里面明明有Beautiful Soup 4.3.1，感觉很奇怪！! lxml.html.soupparser引入BeautifulSoup 4的work-around 原来Beautiful Soup 3目前已经停止开发，Beautiful Soup 4移植到了BS4。
下面的语句就可以引入Beautiful Soup 4了，可是lxml还是无法引入beautfulsoup。
from bs4 import BeautifulSoup stackoverflow有一个帖子import error due to bs4 vs BeautifulSoup讲了一个work-around，可以欺骗lxml从而引入beautfulsoup。测试一下，果然工作正常了。
import sys, bs4 sys.modules[&amp;#39;BeautifulSoup&amp;#39;] = bs4 import lxml.html.soupparser as soupparser</description></item><item><title>Python(x,y)功能实现思维导图</title><link>https://mryqu.github.io/post/pythonxy%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</link><pubDate>Sat, 21 Jun 2014 20:53:59 +0000</pubDate><guid>https://mryqu.github.io/post/pythonxy%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</guid><description>今天浏览Python(x,y)时，发现一个介绍其功能实现的思维导图。对Python(x,y)所实现的功能一目了然，感觉很棒。思维导图在整理自己思绪、知识图谱时用了一些，还没用到项目策划上，以后会督促自己多用多思考。</description></item><item><title>选择Python科学计算发行版</title><link>https://mryqu.github.io/post/%E9%80%89%E6%8B%A9python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%8F%91%E8%A1%8C%E7%89%88/</link><pubDate>Sat, 21 Jun 2014 14:12:03 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%80%89%E6%8B%A9python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%8F%91%E8%A1%8C%E7%89%88/</guid><description>最近重装Python，看了一下Python科学计算发行版，打算多玩一下数据处理和数值计算。
Python用于科学计算的一些常用工具和库 IPython-增强的交互环境：支持变量自动补全，自动缩进，支持 bash shell命令，内置了许多很有用的功能和函数 Spyder、Wing IDE或Eclipse/Pydev：集成开发环境 NumPy-数学计算基础库：N维数组、线性代数计算、傅立叶变换、随机数等。 SciPy-数值计算库：线性代数、拟合与优化、插值、数值积分、稀疏矩阵、图像处理、统计等。 SymPy-符号运算 Pandas-数据分析库：数据导入、整理、处理、分析等。 matplotlib-会图库：绘制二维图形和图表 Chaco-交互式图表 OpenCV-计算机视觉库 TVTK-数据的三维可视化 Cython-Python转C的编译器：编写高效运算扩展库的首选工具 BioPython-生物科学 Python科学计算发行版 Python(x,y)当前最新版本:2.7.6.1 (05/30/2014)，支持Windows和Python2.7.6。其库索引列出了所支持的170+Python27库。 WinPython当前最新版本:2.7.6.4和3.3.5.0 (04/2014)，支持Windows和Python2.7.6、3.3.5。其库索引列出了所支持的60+Python27库。其库索引列出了所支持的60+Python33库。 Enthought Canopy（Enthought Python Distribution）当前最新版本:1.4.1 (06/11/2014)，支持Linux, Windows,Mac平台和Python2.7.6。其库索引列出了所支持的150+测试过的Python库。 Anaconda当前最新版本:2.0.1 (06/12/2014)，支持Linux, Windows, Mac平台和Python2.6、2.7、3.3、3.4。其库索引列出了所支持的195+流行Python库。 Sage不是Python发行版，而是一个由Python和Cython实现的开源数学软件系统，将很多已有的（C、C++、Fortran和Python编写的）数学软件包集成到一个通用接口（记事本文档接口和IPython命令行界面），用户只需了解Python，就可以通过接口或包装器(wrapper)使用NumPy、SciPy、matplotlib、Sympy、Maxima、GAP、FLINT、R和其他已有软件包（具体信息见组件列表），完成代数、组合数学、计算数学和微积分等计算。其最初的目标是创造一个“Magma、Maple、Mathematica和MATLAB的开源替代品”。当前最新版本:6.3(08/10/2014)，支持Linux, Windows, Mac平台和Python2.x。
我的选择和推荐 Python(x,y)和WinPython都是开源项目，其项目负责人都是PierreRaybaut。按Pierre自己的说法是“WinPython不是试图取替Python(x,y)，而是出于不同动机和理念：更灵活、易于维护、可移动、对操作系统侵略性更小，但是用户友好性更差、包更少、没有同Windows资源管理器集成。”。参考1里面说Python(x,y)不是很稳定，此外看它目前的更新不是很频繁，确实有可能Pierre后来的工作重心放在WinPython上了。 Canopy和Anaconda是公司推的，带免费版和商业版/插件。这两款发行版也牵扯到一个人，那就是Travis Oliphant。Travis是SciPy的原始作者，同时也是NumPy的贡献者。Travis在2008年以副总裁身份加入Enthought，2012年以总裁的身份离开，创立了一个新公司continuum.io，并推出了Python的科学计算平台Anaconda。Anaconda相对Canopy支持Python的版本更多，对Python新版本支持跟的很紧（Sage不支持Python3.x的理由是因为其依赖的SciPy还不支持Python3，而Anaconda却实现了支持Python3.3和3.4，这就说明问题了），此外其在Linux平台下（通过conda管理）安装更方便。 不言而喻，我最后选择了安装科学计算发行版Anaconda:)
参考 目前比较流行的Python科学计算发行版
《Python科学计算》 清华大学出版社
Re-packaged Python
Scientific computing with Python</description></item><item><title>[Hadoop] 使用MRUnit进行MapReduce单元测试</title><link>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8mrunit%E8%BF%9B%E8%A1%8Cmapreduce%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</link><pubDate>Sun, 15 Jun 2014 22:59:22 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E4%BD%BF%E7%94%A8mrunit%E8%BF%9B%E8%A1%8Cmapreduce%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</guid><description>MRUnit介绍 MRUnit是一个用于帮助开发者进行HadoopMapReduce作业单元测试的Java库。它是JUnit架构扩展，无需将代码运行在集群上即可在开发环境测试Mapper和Reducer类的功能。MRUnit由Cloudera开发，并在2012年成为Apache基金会顶级项目。 MRUnit使用LocalJobRunner使用样本数据集模拟一次Mapper/Reducer执行过程。通过定义一或多个输入记录，使用LocalJobRunner运行测试代码，判定是否与期望输出相符。如相符，则安静退出；否则，默认抛出异常。
测试代码 本测试代码基于MRUnit指南中示例代码修改而成，使用junit:junit:4.11和org.apache.mrunit:mrunit:1.1.0:hadoop2两个Java库进行编译和测试。
SMSCDR.java SMSCDRMapperReducerTest 执行测试 成功测试演示 失败测试演示 为了演示测试失败情况，我将testReducer方法中期望值改为错误值123。 参考 Apache MRUnit MRUnit Tutorial</description></item><item><title>数据科学：学习路径和图书</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84%E5%92%8C%E5%9B%BE%E4%B9%A6/</link><pubDate>Fri, 06 Jun 2014 20:02:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84%E5%92%8C%E5%9B%BE%E4%B9%A6/</guid><description>转发网上的两个图片，时时对照学习。</description></item><item><title>slidify</title><link>https://mryqu.github.io/post/slidify/</link><pubDate>Tue, 03 Jun 2014 21:19:22 +0000</pubDate><guid>https://mryqu.github.io/post/slidify/</guid><description>Slidify是使用RMarkdown创建、定制和发布（用于可重复性研究的）HTML幻灯片的工具包。 Slidify支持多种生成框架和主题：
|幻灯片生成框架|主题 |&amp;mdash;&amp;ndash; |io2012| |html5slides|default, uulm |html5rocks| |deck.js|web2.0, swiss, neon |dzslides| |landslide|default, tango, clean |shower|ribbon |slidy| |slideous| |beamer| |showoff| 生成的幻灯片可以发布到Github、Dropbox和Rpubs上。命令集成了一些底层操作，所以很简单。见http://slidify.org/publish.html 前一段发布一个幻灯片碰到些麻烦，只好采用git命令行这种老方式。操作步骤参考如下链接： https://github.com/ramnathv/slidify/wiki/Publishing</description></item><item><title>shiny练习</title><link>https://mryqu.github.io/post/shiny%E7%BB%83%E4%B9%A0/</link><pubDate>Mon, 02 Jun 2014 23:29:46 +0000</pubDate><guid>https://mryqu.github.io/post/shiny%E7%BB%83%E4%B9%A0/</guid><description>Shiny是RStudio公司开发的新包，有了它，无需web开发就可以用R语言轻松开发交互式web应用。
我参加数据科学专业课学习，使用shiny完成一个作业，虽然初学乍练，也能感觉到开发起来很快速。 参考 shiny tutorialshiny examples Linear Regressions and Linear Models using the Iris Data</description></item><item><title>[JavaScript] JQuery AJAX在HTTP响应200OK时却调用了errorcallback</title><link>https://mryqu.github.io/post/javascript_jquery_ajax%E5%9C%A8http%E5%93%8D%E5%BA%94200ok%E6%97%B6%E5%8D%B4%E8%B0%83%E7%94%A8%E4%BA%86errorcallback/</link><pubDate>Sun, 25 May 2014 08:02:32 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_jquery_ajax%E5%9C%A8http%E5%93%8D%E5%BA%94200ok%E6%97%B6%E5%8D%B4%E8%B0%83%E7%94%A8%E4%BA%86errorcallback/</guid><description>运行如下代码时，从结果看操作成功，但是总是调用错误处理回调。
myTest = function(server, lib, table, reqParam, reqInfo, successCallback, errorCallback) { var url = &amp;#34;http://localhost/mytest/&amp;#34; + encodeURIComponent(server) + &amp;#34;/libs/&amp;#34; + encodeURIComponent(lib) + &amp;#34;/tables/&amp;#34; + encodeURIComponent(table); if (reqParam!=undefined &amp;amp;&amp;amp; reqParam) { url += &amp;#34;?reqParam=&amp;#34; + encodeURIComponent(reqParam); } $.ajax({ cache: false, url: url, type: &amp;#34;PUT&amp;#34;, data: JSON.stringify(reqInfo), contentType: &amp;#34;application/json&amp;#34;, success: function (data) { if (successCallback!==undefined &amp;amp;&amp;amp; successCallback) { successCallback(data); } else { console.log(&amp;#34;success:&amp;#34;+JSON.stringify(data)); } }, error: function (xhr, status, error) { if (errorCallback!</description></item><item><title>QuickEdit mode of command prompt</title><link>https://mryqu.github.io/post/quickedit_mode_of_command_prompt/</link><pubDate>Sat, 17 May 2014 09:37:28 +0000</pubDate><guid>https://mryqu.github.io/post/quickedit_mode_of_command_prompt/</guid><description>从Windows命令行复制内容每次都需要点击Edit菜单中的Mark子菜单项，颇为不便。
原来这个行为可以通过属性对话框中的QuickEdit mode改变：</description></item><item><title>[Hadoop] 在MapReduce中使用HBase数据</title><link>https://mryqu.github.io/post/hadoop_%E5%9C%A8mapreduce%E4%B8%AD%E4%BD%BF%E7%94%A8hbase%E6%95%B0%E6%8D%AE/</link><pubDate>Sun, 11 May 2014 22:58:25 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%9C%A8mapreduce%E4%B8%AD%E4%BD%BF%E7%94%A8hbase%E6%95%B0%E6%8D%AE/</guid><description>对于MapReduce程序来说，除了可以用HDFS文件系统作为输入源和输出目标，同样可以使用HBase作为输入源和输出目标。下面做一个小练习进行学习。
MapReduceOnHBaseDemo.java rebuild.sh #!/bin/bash CLASSPATH=.:$(hbase classpath):$(hadoop classpath) javac -d classes -cp $CLASSPATH *.java jar -cvf YquMapreduceDemo.jar -C classes/ . 测试 执行下列命令运行MapReduce作业:
HADOOP_CLASSPATH=$(hbase mapredcp):${HBASE_HOME}/conf hadoop jar YquMapreduceDemo.jar MapReduceOnHBaseDemo -libjars $(hbase mapredcp | tr &amp;#39;:&amp;#39; &amp;#39;,&amp;#39;) HBase结果如下: 与普通MapReduce程序的差异 本例中ScoreMapper类继承自抽象类TableMapper。TableMapper是Mapper抽象类的子类，指定输入键类型为ImmutableBytesWritable，输入值类型为Result。因此ScoreMapper类定义仅指定输出键和值类型，而其mapper方法前两个参数为ImmutableBytesWritable和Result类型。 本例中ScoreReducer类继承自抽象类TableReducer。TableReducer是Reduccer抽象类的子类，指定输出值类型为Mutation。因此ScoreReducer定义仅指定输入键和值、输出键的类型。有下图可知，TableReducer输出值类型支持Append、Delete、Increment和Put。 本例中Driver部分通过TableMapReduceUtil类的initTableMapperJob和initTableReducerJob方法合并Hadoop和HBase配置，配置job属性。 参考 HBase and MapReduce</description></item><item><title>JDBC连接池的testQuery/validationQuery设置</title><link>https://mryqu.github.io/post/jdbc%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84testquery%E5%92%8Cvalidationquery%E8%AE%BE%E7%BD%AE/</link><pubDate>Wed, 07 May 2014 21:20:32 +0000</pubDate><guid>https://mryqu.github.io/post/jdbc%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84testquery%E5%92%8Cvalidationquery%E8%AE%BE%E7%BD%AE/</guid><description>在《Tomcat中使用Connector/J连接MySQL的超时问题》帖子中想要增加对连接池中连接的测试/验证，防止数据库认为连接已死而Web应用服务器认为连接还有效的问题，Mysql文档中提到Tomcat文档中的例子中用的是validationQuery，但是网上还有很多帖子写的是testQuery，到底用哪一个呢？ 原来这跟连接池的实现有关：
|连接池实现|该功能属性名 |&amp;mdash;&amp;ndash; |The Tomcat JDBC Connection Pool|validationQuery |The Apache Commons DBCP Connection Pool|validationQuery |c3p0 - JDBC3 Connection and Statement Pooling|preferredTestQuery | Atomikos：Tomcat Spring ActiveMQ MySQL JMX Integration
分析Atomikos数据连接池源码，弄清testQuery|testQuery
此外，测试/验证连接池连接的SQL语句也因数据库而异： Efficient SQL test query or validation query that will work across all (or most) databases DBCP - validationQuery for different Databases
综合上述两个帖子，汇总结果如下：
|数据库|测试/验证查询 |&amp;mdash;&amp;ndash; |MySQL|SELECT 1 |PostgreSQL|SELECT 1 |Microsoft SQL Server|SELECT 1 |SQLite|SELECT 1 |H2|SELECT 1 |Ingres|SELECT 1 |Oracle|select 1 from dual |DB2|select 1 from sysibm.</description></item><item><title>Tomcat中使用Connector/J连接MySQL的超时问题</title><link>https://mryqu.github.io/post/tomcat%E4%B8%AD%E4%BD%BF%E7%94%A8connectorj%E8%BF%9E%E6%8E%A5mysql%E7%9A%84%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 05 May 2014 20:58:54 +0000</pubDate><guid>https://mryqu.github.io/post/tomcat%E4%B8%AD%E4%BD%BF%E7%94%A8connectorj%E8%BF%9E%E6%8E%A5mysql%E7%9A%84%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98/</guid><description>最近玩的一个Web项目，上一个晚上做一些操作，第二天超时需要再登陆，却总是报密码不正确。需要重启tomcat才能解决。异常如下：
Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was 442,814,107 milliseconds ago. The last packet sent successfully to the server was 442,814,107 milliseconds ago. is longer than the server configured value of &amp;#39;wait_timeout&amp;#39;. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Co nnector/J connection property &amp;#39;autoReconnect=true&amp;#39; to avoid this problem.</description></item><item><title>网络资源(主力书籍)</title><link>https://mryqu.github.io/post/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E4%B8%BB%E5%8A%9B%E4%B9%A6%E7%B1%8D/</link><pubDate>Sun, 04 May 2014 22:03:49 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E4%B8%BB%E5%8A%9B%E4%B9%A6%E7%B1%8D/</guid><description>外文书籍 Library Genesis BookZZ 爱挖盘 manybooks 14个值得收藏可免费搜索/下载PDF电子图书（文档）的搜索引擎 图书馆 全球免费开放的电子图书馆 古籍 书格 专利 史上最完整的专利信息数据库网址大全 杂志 http://pdfmagazines.org/ http://www.gqzzw.com/ http://www.pdfzj.com/ http://pdf-giant.com/ http://www.magazine6.com/</description></item><item><title>[Gradle] 在build.gradle中添加本地包依赖</title><link>https://mryqu.github.io/post/gradle_%E5%9C%A8build.gradle%E4%B8%AD%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E5%8C%85%E4%BE%9D%E8%B5%96/</link><pubDate>Wed, 16 Apr 2014 22:17:45 +0000</pubDate><guid>https://mryqu.github.io/post/gradle_%E5%9C%A8build.gradle%E4%B8%AD%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E5%8C%85%E4%BE%9D%E8%B5%96/</guid><description>一直在Gradle中用的依赖包都是来自仓库，头一次添加本地包依赖。
buildscript { repositories { mavenCentral() } } apply plugin: &amp;#39;java&amp;#39; apply plugin: &amp;#39;eclipse&amp;#39; apply plugin: &amp;#39;idea&amp;#39; jar { baseName = &amp;#39;HelloAlgs&amp;#39; version = &amp;#39;0.1.0&amp;#39; } repositories { mavenCentral() } sourceCompatibility = 1.8 targetCompatibility = 1.8 dependencies { runtime files(&amp;#39;libs/algs4.jar&amp;#39;) } task wrapper(type: Wrapper) { gradleVersion = &amp;#39;2.3&amp;#39; }</description></item><item><title>[Hadoop] Failed to exec (compile-ms-winutils) on project hadoop-common</title><link>https://mryqu.github.io/post/hadoop_failed_to_exec_compile-ms-winutils_on_project_hadoop-common/</link><pubDate>Tue, 15 Apr 2014 22:16:23 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_failed_to_exec_compile-ms-winutils_on_project_hadoop-common/</guid><description>在Windows平台编译Hadoop时遇到了compile-ms-winutils执行失败的问题。Hadoop默认需要用VS2010编译，但是我的环境只有VS2013。
问题及解决方案如下：
Cannot run program &amp;ldquo;msbuild&amp;rdquo; 将C:\Windows\Microsoft.NET\Framework\v4.0.30319放入PATH环境变量 Command execution failed. Process exited with an error: 1(Exitvalue: 1) -&amp;gt; [Help 1] 打开hadoop-common\hadoop-hdfs-project\hadoop-hdfs\pom.xml，将&amp;rsquo;VisualStudio 10 Win64&amp;rsquo;改成&amp;rsquo;Visual Studio 12 Win64&amp;rsquo;。 将如下两个Visual Studio项目用VS2013打开，手动编译。 hadoop-common\hadoop-common-project\hadoop-common\src\main\winutils\winutils.sln hadoop-common\hadoop-common-project\hadoop-common\src\main\native\winutils.sln 重新执行：
C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\Tools\VsDevCmd.bat mvn install -DskipTests 上述问题不再出现。</description></item><item><title>在R作图系统中自定义坐标轴</title><link>https://mryqu.github.io/post/%E5%9C%A8r%E4%BD%9C%E5%9B%BE%E7%B3%BB%E7%BB%9F%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%90%E6%A0%87%E8%BD%B4/</link><pubDate>Tue, 15 Apr 2014 21:11:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8r%E4%BD%9C%E5%9B%BE%E7%B3%BB%E7%BB%9F%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%90%E6%A0%87%E8%BD%B4/</guid><description>在R作图系统中自定义坐标轴 R作图系统中坐标中的标签默认是等间隔，下列尝试是为了将少量数据的坐标显示在坐标轴上。
加载库并定义数据 library(lattice) library(ggplot2) library(grid) library(gridExtra) x &amp;lt;- c(1, 2, 3, 7, 8, 9) y &amp;lt;- c(1, 23, 12, 77, 14, 2) data &amp;lt;- data.frame(x = x, y = y) data ## x y ## 1 1 1 ## 2 2 23 ## 3 3 12 ## 4 7 77 ## 5 8 14 ## 6 9 2 Base作图系统 opar &amp;lt;- par(mfrow = c(1, 2), mar = c(4, 6, 4, 2)) with(data, plot(x, y, type = &amp;#34;b&amp;#34;, main = &amp;#34;Default Axis&amp;#34;)) par(las = 1) with(data, plot(x, y, type = &amp;#34;b&amp;#34;, main = &amp;#34;customised Axis&amp;#34;, xaxt = &amp;#34;n&amp;#34;, yaxt = &amp;#34;n&amp;#34;)) axis(1, data$x) axis(2, data$y) par(opar) Lattice作图系统 plot1 &amp;lt;- xyplot(y ~ x, data, type = &amp;#34;b&amp;#34;, main = &amp;#34;Default Axis&amp;#34;) plot2 &amp;lt;- xyplot(y ~ x, data, type = &amp;#34;b&amp;#34;, main = &amp;#34;customised Axis&amp;#34;, scales = list(x = list(at = unlist(data$x)), y = list(at = unlist(data$y))), las = 1) grid.</description></item><item><title>谷歌拼音输入法-笔划/组件输入</title><link>https://mryqu.github.io/post/%E8%B0%B7%E6%AD%8C%E6%8B%BC%E9%9F%B3%E8%BE%93%E5%85%A5%E6%B3%95-%E7%AC%94%E5%88%92%E7%BB%84%E4%BB%B6%E8%BE%93%E5%85%A5/</link><pubDate>Thu, 10 Apr 2014 22:14:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%B0%B7%E6%AD%8C%E6%8B%BC%E9%9F%B3%E8%BE%93%E5%85%A5%E6%B3%95-%E7%AC%94%E5%88%92%E7%BB%84%E4%BB%B6%E8%BE%93%E5%85%A5/</guid><description>有些工具用法总不使就记不住了，到处搜还不如搜自己的博客。 对于某些生僻字，您有可能并不清楚它的拼音。这时，您可以尝试使用谷歌拼音提供的笔划/组件输入功能。例如：先按&amp;quot;u&amp;quot;进入笔划输入模式，然后用使用代码h(横),s(竖),p(撇),n(捺),z(折),d(点)依次输入该字的各个笔划。其中，n和d是相同的。例如，您希望输入&amp;quot;谷&amp;quot;，则可以依次按下&amp;quot;upnpnszh&amp;quot;。 除了笔划以外，你也可以用拼音直接输入组成该汉字的可读部件，例如，输入&amp;quot;ucaowei&amp;quot;可以输入&amp;quot;莅&amp;quot;，输入&amp;quot;ujinxing&amp;quot;可以输入&amp;quot;鍟&amp;quot;。输入部件时，直接使用该部件的读音，或近似汉字的读音即可，例如，提手旁可以用&amp;quot;shou&amp;quot;来输入。</description></item><item><title>Outlook2013中日历的天气设置</title><link>https://mryqu.github.io/post/outlook2013%E4%B8%AD%E6%97%A5%E5%8E%86%E7%9A%84%E5%A4%A9%E6%B0%94%E8%AE%BE%E7%BD%AE/</link><pubDate>Wed, 09 Apr 2014 23:04:44 +0000</pubDate><guid>https://mryqu.github.io/post/outlook2013%E4%B8%AD%E6%97%A5%E5%8E%86%E7%9A%84%E5%A4%A9%E6%B0%94%E8%AE%BE%E7%BD%AE/</guid><description/></item><item><title>MongoDB副本集实践</title><link>https://mryqu.github.io/post/mongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E5%AE%9E%E8%B7%B5/</link><pubDate>Sat, 05 Apr 2014 08:18:56 +0000</pubDate><guid>https://mryqu.github.io/post/mongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E5%AE%9E%E8%B7%B5/</guid><description>副本集（ReplicaSet）就是有自动故障恢复功能的主从集群。副本集和主从集群最为明显的区别就是副本集没有固定的“主节点”：整个集群会选取出一个“主节点”，当其不能工作时则变更到其他节点。然而，两者看上去非常相似：副本集总会有一个活跃节点（primary）和一个或多个备份节点（secondary）。 副本集中可以有以下类型的节点：
常规节点（standard）：存储一份完整的数据副本，参与选举投票，有可能成为活跃节点。 被动节点（passive）：存储完整的数据副本，参与投票，不能成为活跃节点。 仲裁节点（arbiter）：仅参与投票，不接受复制的数据，也不能成为活跃节点。 副本集对数据库管理员和开发者都是非常友好的。副本集的管理是自动化的，无需数据库管理员频繁监控和干预，可以自动提升备份节点成为活跃节点，以确保运转正常。对于开发者而言，仅需为副本集指定一下服务器，驱动程序就会自动找到副本集的节点集群。 每个参与节点（非仲裁节点）都有一个权重，权重值取值范围0-1000，默认值为1。权重为0的节点不能成为活跃节点。活跃节点选举根据高优先级优先、优先级相同时数据较新优先的原则进行比较。应用仅能向活跃节点进行写操作。默认情况下，应用会向活跃节点进行读操作也获取最新数据。如果无需获得最新数据时，可以为了提高读操作吞吐量或减少应用延迟而向备份节点进行读操作。读操作偏好模式如下：
primary primaryPreferred secondary secondaryPreferred nearestMongoDB命令行提供了下列关于副本集的指令： &amp;gt; rs.help() rs.status() { replSetGetStatus : 1 } checks repl set status rs.initiate() { replSetInitiate : null } initiates set with default settings rs.initiate(cfg) { replSetInitiate : cfg } initiates set with configuration cfg rs.conf() get the current configuration object from local.system.replset rs.reconfig(cfg) updates the configuration of a running replica set with cfg (disconnects) rs.add(hostportstr) add a new member to the set with default attributes (disconnects) rs.</description></item><item><title>MongoDB主从复制实践</title><link>https://mryqu.github.io/post/mongodb%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 03 Apr 2014 21:53:44 +0000</pubDate><guid>https://mryqu.github.io/post/mongodb%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%AE%9E%E8%B7%B5/</guid><description>MongoDB主从复制（Master-slave replication）跟副本集（ReplicaSet）相比可以对主MongoDB节点设置多个从节点，并且可以将复制操作限制到特定数据库。但是MongoDB主从复制提供的冗余度更低而且无法自动故障切换，因此一般新的部署都倾向使用副本集而不是主从复制。
实验环境 两个节点中，MongoDB都安装在c:\mongodb目录下且MongoDB配置文件（c:\mongodb\etc\mongo.conf）均为：
systemLog: destination: file path: C:/mongodb/log/mongo.log logAppend: true storage: dbPath: C:/mongodb/data/db journal: enabled: false net: http: enabled: true RESTInterfaceEnabled: true 启动MongoDB 主节点启动命令：
c:\mongodb\bin\mongod.exe --config c:\mongodb\etc\mongo.conf --master --oplogSize=2048 从节点启动命令：
c:\mongodb\bin\mongod.exe --config c:\mongodb\etc\mongo.conf --slave --source 10.120.8.231 --slavedelay 10 --autoresync 主从复制测试 检查主节点 &amp;gt; show dbs; admin (empty) local 8.074GB test 0.078GB &amp;gt; db.isMaster() { &amp;#34;ismaster&amp;#34; : true, &amp;#34;maxBsonObjectSize&amp;#34; : 16777216, &amp;#34;maxMessageSizeBytes&amp;#34; : 48000000, &amp;#34;maxWriteBatchSize&amp;#34; : 1000, &amp;#34;localTime&amp;#34; : ISODate(&amp;#34;2014-04-03T01:47:49.780Z&amp;#34;), &amp;#34;maxWireVersion&amp;#34; : 2, &amp;#34;minWireVersion&amp;#34; : 0, &amp;#34;ok&amp;#34; : 1 } 检查从节点 &amp;gt; show dbs; admin (empty) local 0.</description></item><item><title>差一点搞混了Transactional注解</title><link>https://mryqu.github.io/post/%E5%B7%AE%E4%B8%80%E7%82%B9%E6%90%9E%E6%B7%B7%E4%BA%86transactional%E6%B3%A8%E8%A7%A3/</link><pubDate>Tue, 01 Apr 2014 20:03:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B7%AE%E4%B8%80%E7%82%B9%E6%90%9E%E6%B7%B7%E4%BA%86transactional%E6%B3%A8%E8%A7%A3/</guid><description>今天给我的Srping业务层加如下Service和Transactional注解：
@Service @Scope(BeanDefinition.SCOPE_SINGLETON) @Transactional(propagation=Propagation.REQUIRED, timeout=600, rollbackFor=Exception.class) 结果总是不认propagation、timeout和rollbackFor，后来才发现我引入类定义错了，本来应该用Spring的org.springframework.transaction.annotation.Transactional，可是引入了JavaEE用于CDI(Contextsand Dependency Injection for the Java EEplatform，上下文和依赖注入)bean的javax.transaction.Transactional,不注意还真容易混淆。</description></item><item><title>使用YCSB测试MongoDB</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8ycsb%E6%B5%8B%E8%AF%95mongodb/</link><pubDate>Mon, 31 Mar 2014 20:29:01 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8ycsb%E6%B5%8B%E8%AF%95mongodb/</guid><description>YCSB介绍 YCSB（Yahoo! Cloud Serving Benchmark）是雅虎开源的一款用于测试各类云服务/NoSQL/键值对存储的性能基准测试工具。覆盖的测试对象有：
PNUTS BigTable HBase Hypertable Azure Cassandra CouchDB Voldemort MongoDB OrientDB Infinispan Dynomite Redis GemFire GigaSpaces XAP DynamoDB YCSB项目的目标是提供一个标准的工具用来衡量不同键值对存储或云服务存储的性能。YCSB做了很多优化来提高客户端性能，例如在数据类型上用了最原始的比特数组以减少数据对象本身创建转换所需的时间等。YCSB的几大特性：
支持常见的数据存储读写操作，如插入，修改，删除及读取 多线程支持。YCSB用Java实现，有很好的多线程支持。 灵活定义场景文件。可以通过参数灵活的指定测试场景，如100%插入， 50%读50%写等等 数据请求分布方式：支持随机，zipfian(只有小部分的数据得到大部分的访问请求）以及最新数据几种请求分布方式 可扩展性：可以通过扩展Workload的方式来修改或者扩展YCSB的功能 使用YCSB测试MongoDB 初试YCSB 下载https://github.com/downloads/brianfrankcooper/YCSB/ycsb-0.1.4.tar.gz 并解压缩。执行如下命令查看帮助：接下来开始使用YCSB测试MongoDB2.6，不过这其中遇到一些问题。期望YCSB的下一版本能够解决这些问题。
解决java.lang.ClassNotFoundException:com.yahoo.ycsb.Client问题 执行测试失败：
C:\ycsb-0.1.4\>python bin/ycsb load mongodb -s -P workloads/workloada java -cp C:\ycsb-0.1.4\core\lib\core-0.1.4.jar:C:\ycsb-0.1.4\gemfire-binding\conf:C:\ycsb-0.1.4\hbase-binding\conf:C:\ycsb-0.1.4\infinispan-binding\conf:C:\ycsb-0.1.4\jdbc-binding\conf:C:\ycsb-0.1.4\mongodb-binding\lib\mongodb-binding-0.1.4.jar:C:\ycsb-0.1.4\nosqldb-binding\conf:C:\ycsb-0.1.4\voldemort-binding\conf com.yahoo.ycsb.Client -db com.yahoo.ycsb.db.MongoDbClient -s -P workloads/workloada -load Exception in thread "main" java.lang.NoClassDefFoundError: com/yahoo/ycsb/Client Caused by: java.lang.ClassNotFoundException: com.yahoo.ycsb.Client at java.net.URLClassLoader$1.run(URLClassLoader.java:202) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:190) at java.</description></item><item><title>Hello MongoDB Java Driver</title><link>https://mryqu.github.io/post/hello_mongodb_java_driver/</link><pubDate>Sun, 30 Mar 2014 13:50:33 +0000</pubDate><guid>https://mryqu.github.io/post/hello_mongodb_java_driver/</guid><description>首先需要下载MongoDB JavaDriver，我一开始以为mongo-java-driver-2.9.3.jar是最新版，后来才发现MongoDB JavaDriver下载页面版本排序是按照文件名而不是按照日期排序，其实mongo-java-driver-2.12.0.jar是最新版。因为从版本2.10.0开始提供新的类MongoClient而不是Mongo来连接数据库，所以需要注意所使用的MongoDB Java Driver版本。 Java代码如下：
package com.yqu.mongodb; import java.net.UnknownHostException; import java.util.List; import java.util.Set; import com.mongodb.BasicDBObject; import com.mongodb.DB; import com.mongodb.DBCollection; import com.mongodb.DBCursor; import com.mongodb.DBObject; import com.mongodb.MongoClient; import com.mongodb.MongoClientURI; import com.mongodb.MongoException; public class HelloMongoDB { public static void main(String[] args) { MongoClient mongoClient = null; try { // Since 2.10.0, uses MongoClient // mongoClient = new MongoClient(&amp;#34;localhost&amp;#34;, 27017); String host = &amp;#34;mongodb://localhost:27017&amp;#34;; mongoClient = new MongoClient(new MongoClientURI(host)); showdbs(mongoClient); // MongoDB will create it if database doesn&amp;#39;t exists DB db = mongoClient.</description></item><item><title>Windows下MongoDB安装与配置</title><link>https://mryqu.github.io/post/windows%E4%B8%8Bmongodb%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 30 Mar 2014 07:57:15 +0000</pubDate><guid>https://mryqu.github.io/post/windows%E4%B8%8Bmongodb%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</guid><description>到官网http://www.mongodb.org/downloads下载MongoDB并安装在c:\mongodb目录下，安装后需要进行配置才能启动MongoDB。首先创建如下目录：
md c:\mongodb\data md c:\mongodb\db md c:\mongodb\log md c:\mongodb\etc 接着创建MongoDB配置文件：c:\mongodb\etc\mongo.conf systemLog: destination: file path: C:/mongodb/log/mongo.log logAppend: true storage: dbPath: C:/mongodb/data/db journal: enabled: true net: http: enabled: true RESTInterfaceEnabled: true 通过如下命令启动MongoDB：
C:\mongodb\bin\mongod.exe --config C:\mongodb\etc\mongo.conf 可以通过以下三种方式验证MongoDB是否安装成功：
访问MongoDB监听端口 http://localhost:27017/ ，确认出现类似信息。 通过C:\mongodb\bin\mongo.exe登录Javascript shell并使用 访问HTTP接口 http://localhost:28017/ 并查看MongoDB服务器信息 在启动MongoDB的窗口通过Ctrl+ C停止MongoDB的运行。 最后通过如下命令将MongoDB配置成Windows服务：
C:\mongodb\bin\mongod.exe --config C:\mongodb\etc\mongo.conf--install 当然也可以通过如下命令手工配置Windows服务：
sc create MongoDB binPath= &amp;#34;C:\mongodb\bin\mongod.exe--config=C:\mongodb\etc\mongo.conf--service&amp;#34; start= demand DisplayName= &amp;#34;MongoDB&amp;#34; 参考 Install MongoDB on Windows MongoDB Configuration Options</description></item><item><title>重温MVC:一个很好的MVC图</title><link>https://mryqu.github.io/post/%E9%87%8D%E6%B8%A9mvc%E4%B8%80%E4%B8%AA%E5%BE%88%E5%A5%BD%E7%9A%84mvc%E5%9B%BE/</link><pubDate>Wed, 26 Mar 2014 22:28:35 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%87%8D%E6%B8%A9mvc%E4%B8%80%E4%B8%AA%E5%BE%88%E5%A5%BD%E7%9A%84mvc%E5%9B%BE/</guid><description>今天看了一个帖子A terrific Model View Controller (MVC) diagram，感觉文中说的很对：一个技术如果能简洁地表达出来，才容易被人记住并记的牢。该文中的Model/View/ControllerUML图共有两个，第一个图非常简单，仅展示作者用于控制器、视图和模型的符号。第二个图展示了MVC模式允许的操作和禁止的操作。
用户与视图对象交互。 视图对象和控制器对象可以相互访问调用。 不同的控制器对象之间可以相互访问调用。 控制器对象可以访问调用模型对象。 除了上面这四种访问方式，禁止对象之间的其他通信方法。</description></item><item><title>玩一下LineNumberReader</title><link>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Blinenumberreader/</link><pubDate>Wed, 26 Mar 2014 19:37:23 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E4%B8%80%E4%B8%8Blinenumberreader/</guid><description>找资料的副产品就是发现了LineNumberReader这个类，跟它的父类BufferedReader相比多了计算文件行数的功能。记不得以前是否用过了，这里记录一下备用。
import java.io.BufferedReader; import java.io.FileReader; import java.io.IOException; import java.io.LineNumberReader; public class TestFileLineNum { public static int countLinesV1(String flName) throws IOException { BufferedReader reader = new BufferedReader(new FileReader(flName)); int cnt = 0; while (reader.readLine() != null) { cnt++ ; } reader.close(); return cnt; } public static int countLinesV2(String flName) throws IOException { LineNumberReader reader = new LineNumberReader(new FileReader(flName)); while (reader.readLine() != null) { } int cnt = reader.getLineNumber(); reader.close(); return cnt; } public static void main(String[] args) throws IOException { for(int i=0;i&amp;lt;4;i ) { String flName = &amp;#34;test&amp;#34; + i + &amp;#34;.</description></item><item><title>[算法] 学习无向图</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E5%AD%A6%E4%B9%A0%E6%97%A0%E5%90%91%E5%9B%BE/</link><pubDate>Fri, 21 Mar 2014 21:40:18 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E5%AD%A6%E4%B9%A0%E6%97%A0%E5%90%91%E5%9B%BE/</guid><description>本文是学习http://algs4.cs.princeton.edu/41graph/的吐槽和体会。
一点吐槽 一开始对GraphClient.java中numberOfSelfLoops函数进行count/2不解，翻回Graph.java，看看addEdge函数才明白，合着对自循环连接，adj里面加两次。这么干有什么好处么？！！
再后来看Cycle.java，对hasParallelEdges函数又不解，仔细想想Graph.java不但接受addEdge(1,23)和addEdge(23, 1)，对执行多次addEdge(1,23)也不拒绝。一个无向图这么弄，对么？算不算检查不严格呀？！！
理解Cycle.java 示例代码：
public static void main(String[] args) { Graph G = new Graph(4); G.addEdge(0, 1); G.addEdge(1, 2); G.addEdge(1, 3); G.addEdge(2, 3); Cycle finder = new Cycle(G); if (finder.hasCycle()) { for (int v : finder.cycle()) { StdOut.print(v + &amp;#34; &amp;#34;); } StdOut.println(); } else { StdOut.println(&amp;#34;Graph is acyclic&amp;#34;); } } dfs搜索：
|上一节点u|当前节点v|下一节点w|注解 |&amp;mdash;&amp;ndash; |-1|0|1|节点1没有标注，嵌套dfs |0|1|3|节点3没有标注，嵌套dfs |1|3|2|节点2没有标注，嵌套dfs |3|2|1|节点1已标注，发现cycle，创建栈，依次：
(在for循环中)push 2 (在for循环中)push 3 push 1 push 2说白了就是当发现下一节点w已经标注，那就返回去找w到v的路径，然后凑上w和v，就是一个环路。 理解Bipartite.java 二分图又称作二部图、两偶图，是图论中的一种特殊模型。设G=(V,E）是一个无向图，如果顶点V可分割为两个互不相交的子集(A,B），并且图中的每条边（i，j）所关联的两个顶点i和j分别属于这两个不同的顶点集（iin A,j in B），则称图G为一个二分图。</description></item><item><title>GitHub fork操作</title><link>https://mryqu.github.io/post/github_fork%E6%93%8D%E4%BD%9C/</link><pubDate>Mon, 17 Mar 2014 22:37:40 +0000</pubDate><guid>https://mryqu.github.io/post/github_fork%E6%93%8D%E4%BD%9C/</guid><description>Fork（分支）操作不是Git实现的一部分，仅是GitHub独有的一个在服务器端克隆代码库的操作。假定我作为GitHub用户usr2，对用户usr1的github.com/usr1/demo代码库有兴趣。我可以通过clone命令将该代码库克隆到本机，并且可以通过pull命令获得该代码库的更新。但是除非用户usr1将我（用户usr2）设为该代码库的贡献者，否则我无法将我提交的修改通过push命令推送到该代码库。但是通过fork操作，我就可以将github.com/usr1/demo代码库完整复制到我的GitHub帐号下（包括代码库中的文件、提交历史、问题等等），例如下图的github.com/usr2/demo。我可通过clone命令将自己的github.com/usr2/demo代码库克隆到本机，我完全有权限将本机提交的修改通过push命令推送到上述自己的代码库。如果我希望我的修改被usr1采纳，我可以发送一个pullrequest通知usr1。至于usr1是否接收我的修改，决定权在usr1。克隆代码库的时候，所使用的远程代码库地址自动被Git命名为origin。其效果类似于：
git remote add origin git://github.com/usr2/demo.git github.com/usr2/demo代码库在fork操作之后就不再获得github.com/usr1/demo的后继更新了。可以手工添加github.com/usr1/demo为上游代码库地址：
git remote add upstream git://github.com/usr1/demo.git 我可通过fetch命令获取上游代码库的更新，在本机合并后，通过push命令推送到自己的远程代码库。
参考 GitHub help: Fork A Repo GitHub help: Syncing a fork GitHub help: Adding collaborators to a personal repository Simple guide to forks in GitHub and Git stackOverflow: Git fork is git clone? stackOverflow: What is the difference between origin and upstream in github</description></item><item><title>转战Octave</title><link>https://mryqu.github.io/post/%E8%BD%AC%E6%88%98octave/</link><pubDate>Sun, 16 Mar 2014 23:27:14 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%BD%AC%E6%88%98octave/</guid><description>可赶上机器学习的课了，原来学过《集体编程智慧》里面机器学习算法的Python实现，这次想着有个巩固提高。可是老师偏偏使用Octave，杂就杂吧，学学matlab风格的编程也不错。 Matlab是一款数值计算和分析的优秀软件，可是价格昂贵。其开源替代品就是Scilab和Octave。
Scilab是由INRIA（法国国立计算机及自动化研究院）和ENPC（法国国立桥梁学院）开发的开源科学计算自由软件。与Matlab类似，Scilab数据类型丰富，可以很方便地实现各种矩阵运算与图形显示，能应用于科学计算、数学建模、信号处理、决策优化、线性/非线性控制等各个方面。它还提供可以满足不同工程与科学需要的工具箱，例如Scicos，信号处理工具箱，图与网络工具箱等。可以说，就基本的功能如科学计算、矩阵处理及图形显示而言，Matlab能完成的工作Scilab都可以实现。由于Scilab的语法与Matlab非常接近，熟悉Matlab编程的人很快就会掌握Scilab的使用。有意思的是，Scilab提供的语言转换函数可以自动将用Matlab语言编写的程序翻译为Scilab语言。
GNU Octave是自由软件基金会支持的遵循GPL协议的一个自由再发布的软件，作者是以John W.Eaton为首的一些志愿者。它提供了一个环境，该环境支持叫做GNUOctave的高级语言，这种语言与Matlab兼容，主要用于数值计算。它提供了一个方便的命令行方式，可以数值求解线性和非线性问题，以及做一些数值模拟。 Octave也提供了一些工具包，可以解决一般的线性代数问题，非线性方程求根，常规函数积分，处理多项式，处理常微分方程和微分代数方程。它也很容易的使用Octave自带的接口方式扩展和定制功能。
Octave相对于Scilab，对Matlab的语法兼容性更好，几乎没有差别。比如，Octave也使用M文件的形式来扩展功能和定义函数。因此熟悉Matlab的用户更容易接受Octave环境。 它可编程的性能更好，Octave语言功能更为强大，几乎提供所有系统函数的支持，Octave在语法上也更接近C的语法，比如提供++和&amp;ndash;这样的预算符。这样，我们可以在Octave环境里面增加一些更为强大和易用的扩展。不象在Matlab和Scilab环境中限制比较多，有时无法充分的利用系统资源。它的计算库都是用C写，而Scilab则基本是Fortran的编写的。这也是一份有用的资源。和GNU下面的其他软件也可以较多协作。劣势就是Octave的功能比起Scilab要简单一些，这使得Octave对一些用户来说意义不如Scilab大。而且Octave目前没有图形界面，只能以命令行方式进行交互。
第一次编程作业的效果图：
将原来的一些编程思路转换成矩阵和矢量是一个挑战，对于复杂一些编程，还是逃不开纠结和调试。</description></item><item><title>[Hadoop] 压缩MapReduce的Mapper输出</title><link>https://mryqu.github.io/post/hadoop_%E5%8E%8B%E7%BC%A9mapreduce%E7%9A%84mapper%E8%BE%93%E5%87%BA/</link><pubDate>Mon, 03 Mar 2014 20:13:37 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%8E%8B%E7%BC%A9mapreduce%E7%9A%84mapper%E8%BE%93%E5%87%BA/</guid><description>介绍 压缩map输出是以压缩和解压缩的CPU消耗为代价来减少磁盘和网络IO开销。Hadoop中，mapper的输出数据是写到Mapper所在的本地磁盘的，并以网络传输的方式传送到Reducer所在的节点上。mapreduce.map.output.compress默认为false，即不对map输出进行压缩。如果中间数据不是二进制的，通常建议使用map输出压缩。
Hadoop支持的的内建压缩编码如下： 如果设置mapreduce.map.output.compress为true且没有设置mapreduce.map.output.compression.codec的话，默认使用org.apache.hadoop.io.compress.DefaultCodec。
|压缩格式|算法|工具|默认扩展名|说明 |&amp;mdash;&amp;ndash; |DEFLATE|DEFLATE|N/A|.deflate|DEFLATE是一种压缩算法，标准实现是zlib，尚没有命令行工具支持。文件扩展名.deflate是一个Hadoop的约定。所有的压缩算法都存在空间与时间的权衡：更快的压缩速率和解压速率是以牺牲压缩率为代价的。org.apache.hadoop.io.compress.zlib.ZlibCompressor.CompressionLevel中定义了0~9压缩级别，0为无压缩，9为最佳压缩。支持Java实现和原生库实现。 |GZip|DEFLATE|gzip|.gz|GZip与DEFLATE使用同样的压缩算法，不过相对于DEFLATE压缩格式增加了额外的头部和尾部。GZip是一种常规的压缩工具，空间与时间得到很好的权衡。支持Java实现和原生库实现。 |BZip2|BZip2|BZip2|.bz2|BZip2压缩率高于GZip，但压缩速度较慢；解析速度优于它的压缩速度，但还是较其它压缩算法偏慢。由上图可知，BZip2是Hadoop内嵌压缩算法中唯一可以被分割的，这样一个输入文件可分成多个InputSplit，便于本地数据加载并被Mapper处理。相关技术可见处理跨块边界的InputSplit一文。支持Java实现和原生库实现。 |LZ4|LZ4|N/A|.lz4|LZ4和Snappy相对于GZip压缩速度得到很大提升，但没有GZip的压缩率高。仅支持原生库实现。org.apache.hadoop.io.compress.Lz4Codec.isNativeCodeLoaded()用于检查是否加载原生库，其调用者在没有加载原生库时会抛异常。 |Snappy|Snappy|N/A|.snappy|LZ4和Snappy相对于GZip压缩速度得到很大提升，但没有GZip的压缩率高。仅支持原生库实现。org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded()在没有加载原生库时会抛异常。
如果使用原生库压缩编码，需配置LD_LIBRARY_PATH。默认情况下，Hadoop自动在本地库路径（java.library.path）下查询并加载合适的本地库实现。通过设置属性io.native.lib.available为false禁用原生库，此时内建的Java实现将被使用。
Hadoop源码分析 在org.apache.hadoop.mapred.MapTask.MapOutputBuffer.init(Context)和org.apache.hadoop.mapred.ReduceTask.initCodec()方法中检查mapreduce.map.output.compress属性，如果为true，则加载mapreduce.map.output.compression.codec属性所设的压缩编解码器。 MapTask当将数据spill到硬盘时使用压缩编码器进行数据压缩。 ReduceTask在使用Shuffle结果是使用压缩解码器进行数据解压缩。
使用map输出压缩的应用示例</description></item><item><title>[算法] Mergesort练习</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_mergesort%E7%BB%83%E4%B9%A0/</link><pubDate>Thu, 20 Feb 2014 23:39:55 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_mergesort%E7%BB%83%E4%B9%A0/</guid><description>本作业帖用于练习http://algs4.cs.princeton.edu/22mergesort/里面的作业。
Merge with atmost log N compares per item. Design a mergingalgorithm such that each item is compared at most a logarithmicnumber of times. (In the standard merging algorithm, an item can becompared N/2 times when merging two subarrays of size N/2.) reference Lower boundfor sorting a Youngtableaux. A Youngtableaux is an N-by-N matrix such that theentries are sorted both column wise and row wise. Prove thatTheta(N^2 log N) compares are necessary to sort the N^2 entries(where you can access the data only through the pairwisecomparisons).</description></item><item><title>[算法] 求数组中倒置个数</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E6%B1%82%E6%95%B0%E7%BB%84%E4%B8%AD%E5%80%92%E7%BD%AE%E4%B8%AA%E6%95%B0/</link><pubDate>Wed, 19 Feb 2014 23:32:27 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E6%B1%82%E6%95%B0%E7%BB%84%E4%B8%AD%E5%80%92%E7%BD%AE%E4%B8%AA%E6%95%B0/</guid><description>http://algs4.cs.princeton.edu/22mergesort/中有一道题是求数组中倒置个数的，原题如下：
Inversions. Develop and implement alinearithmic algorithm Inversions.java forcomputing the number of inversions in a given array (the number ofexchanges that would be performed by insertion sort for thatarray). This quantity is related tothe Kendall tau distance; 解决思路： Inversions.java在做MergeSort的过程中顺便求出了数组中倒置个数。假设上图中已经获得左右两个子部分中的倒置个数并进行了MergeSort。现在学习一下做整个数组的Merge时如何顺便计算这一层的倒置个数。
当aux[0]和aux[5]进行比较时，A小于E，则可知A比左半部分都小（少比较了4次），倒置+5 当aux[0]和aux[6]进行比较时，C小于E，则可知C比左半部分都小（少比较了4次），倒置+5 当aux[2]和aux[7]进行比较时，E小于G，则可知E比左半部分中G及其之后的数都小（少比较了2次），倒置=+(4-2+1)=+3 整个数组的倒置数为左边部分内部倒置数+右边部分内部倒置数+13。算法时间复杂度为NlogN。</description></item><item><title>Markdown介绍</title><link>https://mryqu.github.io/post/markdown%E4%BB%8B%E7%BB%8D/</link><pubDate>Wed, 19 Feb 2014 22:39:56 +0000</pubDate><guid>https://mryqu.github.io/post/markdown%E4%BB%8B%E7%BB%8D/</guid><description>Markdown是一种用于普通文本的便于读写的轻量级标记语言，可以转换成HTML、LaTeX或Docbook文档。很多网站都支持Markdown，如GitHub、Wikipedia和博客平台WordPress。RMarkdown将R代码和markdown进行有效集成以用于文学编程（LiterateProgramming），R代码会在RMarkdown转化markdown处理过程中被执行，并将R代码结果一同插入markdown文档。下面的示例是基于knitr工具完成RMarkDown转换的。
Markdown 文字样式：斜体和粗体、删除线 *斜体表述1* 和 _斜体表述2_ 示例。 **粗体表述1** 和 __粗体表述2__ 示例。 ___斜粗体表述1___ 和 ***斜粗体表述2*** 示例。 ~~删除线表述~~ 示例。 斜体表述1 和 斜体表述2 示例。粗体表述1 和 粗体表述2 示例。斜粗体表述1 和 **斜粗体表述2**示例。删除线表述 示例。
段落和换行 一个空行（两个回车）会被转换成分段，在行末加两个或多个空格会被转换成换行。
标题 在行首用一到六个井号 (#) 开始该行为标题行 # H1示例 ## H2示例 ### H3示例 #### H4示例 ##### H5示例 ###### H6示例 H1示例 H2示例 H3示例 H4示例 H5示例 H6示例 另一种方式用下一行的一到多个等号表示一级标题，一到多个短划线表示二级标题。
H1示例 ========= H2示例 --------- H1示例 H2示例 水平分割线 通过单行输入3个或3个以上中短划线、星号或下划线进行输入水平分隔线, 短划线、星号或下划线之间可以包含空格：
--- *** ___ - - - * * * _ _ _ 列表 HTML 列表分无序列表 (unordered list, ul) 和有序列表 (ordered list, ol) 两种。在Markdown 中用星号、加号、减号开始一行表示无序列表，用数字开始一行表示有序列表。例如：</description></item><item><title>[算法] Elementary Sorts练习</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_elementary_sorts%E7%BB%83%E4%B9%A0/</link><pubDate>Mon, 17 Feb 2014 22:27:59 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_elementary_sorts%E7%BB%83%E4%B9%A0/</guid><description>本作业帖用于练习http://algs4.cs.princeton.edu/21elementary/里面的作业。
Stoogesort. Analyze the running time andcorrectness of the following recursive sorting algorithm: if theleftmost item is larger than the rightmost item, swap them. Ifthere are 2 or more items in the current subarray, (i) sort theinitial two-thirds of the array recursively, (ii) sort the finaltwo-thirds of the array, (iii) sort the initial two-thirds of thearray again. StoogeSort时间复杂度为O(_n_log3 / log 1.5 )= O(_n_2.7095&amp;hellip;)，比合并排序慢，甚至比冒泡排序慢，仅用于低效简单排序示范。
Guess-sort. Pick two indices i and j atrandom; if a[i] &amp;gt; a[j], then swap them.</description></item><item><title>[算法] UNION-FIND练习</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_union-find%E7%BB%83%E4%B9%A0/</link><pubDate>Sat, 15 Feb 2014 21:36:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_union-find%E7%BB%83%E4%B9%A0/</guid><description>本作业帖用于练习http://algs4.cs.princeton.edu/15uf/里面的作业。
True or false. Inthe quick union implementation, suppose weset id[p] to id[root(q)] insteadof setting id[root(p)] Would the resultingalgorithm be correct? 答案： 否。使用id[root(p)]可以将p所在连接全部合并到q所在连接，而使用id[p]仅会将p及其子连接合并到q所在连接。
Which of thefollowing arrays could not possibly occur during the execution ofweighted quick union with path compression:
0 1 2 3 4 5 67 8 9
7 3 8 3 4 5 68 8 1
6 3 8 0 4 5 69 8 1
0 0 0 0 0 0 00 0 0</description></item><item><title>[Git] 裸代码仓库和镜像代码仓库</title><link>https://mryqu.github.io/post/git_%E8%A3%B8%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E5%92%8C%E9%95%9C%E5%83%8F%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93/</link><pubDate>Sat, 15 Feb 2014 00:38:47 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E8%A3%B8%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E5%92%8C%E9%95%9C%E5%83%8F%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93/</guid><description>注：本文中操作都没有设置$GIT_DIR环境变量。
Git init和clone命令对bare和mirror参数的支持 ||&amp;ndash;bare参数|&amp;ndash;mirror参数 |&amp;mdash;&amp;ndash; |git init命令|支持|/ |git clone命令|支持|支持
裸代码仓库与普通代码仓库的区别 普通代码仓库裸代码仓库git init命令git init命令会创建一个空的Git代码仓库，一个在当前目录下包含hooks、info、objects和refs子目录和config、description和HEAD文件的.git目录。当前目录下可以创建工作树（工作文件和目录）。
config文件内容如下：
[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true hideDotFiles = dotGitOnlygit init --bare命令会创建一个空的裸Git代码仓库，当前目录下直接创建hooks、info、objects和refs子目录和config、description和HEAD文件。裸Git代码仓库只包含版本控制信息而不包含工作树。
config文件内容如下：
[core] repositoryformatversion = 0 filemode = false bare = true symlinks = false ignorecase = true hideDotFiles = dotGitOnly git clone命令git clone命令会创建的一个包含.git子目录的目录，其中.git目录包含branches、hooks、info、logs、objects和refs子目录和config、description、HEAD、index和packed-refs文件。git clone命令所创建的目录中包含克隆的工作树（工作文件和目录）。
config文件内容如下：
[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true hideDotFiles = dotGitOnly [remote "</description></item><item><title>VirtualBox镜像资源</title><link>https://mryqu.github.io/post/virtualbox%E9%95%9C%E5%83%8F%E8%B5%84%E6%BA%90/</link><pubDate>Wed, 05 Feb 2014 09:25:28 +0000</pubDate><guid>https://mryqu.github.io/post/virtualbox%E9%95%9C%E5%83%8F%E8%B5%84%E6%BA%90/</guid><description>VirtualBox镜像资源: http://virtualboxes.org/images/</description></item><item><title>MinGW安装和使用</title><link>https://mryqu.github.io/post/mingw%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</link><pubDate>Tue, 04 Feb 2014 18:17:07 +0000</pubDate><guid>https://mryqu.github.io/post/mingw%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</guid><description>MinGW简介 MinGW全称Minimalist GNU For Windows，，是将GCC编译器和GNUBinutils移植到Win32平台下的产物，包括一系列头文件（Win32API）、库和可执行文件。MinGW是从Cygwin1.3基础上发展而来，相比Cygwin而言体积更小、使用更方便。MinGW分两个分支，MinGW（即MinGW32）和MinGW-w64。 MinGW包括：
GNU编译器套件，包括C/C++、ADA语言和Fortran语言编译器 用于生成Windows二进制文件的GNU工具（编译器、链接器和档案管理器） 用于Windows平台安装和部署MinGW和MSYS的命令行安装器（mingw-get） 用于命令行安装器的GUI打包器（mingw-get-inst） MinGW安装和使用 我只想使用C/C++，所以仅安装mingw32-base、mingw32-gcc-g++。msys-base其实也是可以不用安装的，因为我可以使用已有的GitBash。 我选择了默认的安装路径c:\MinGW，可以将c:\MinGW\bin加入环境变量以便使用。 参考 MinGW 官方网站 SourceForge.net：MinGW - Minimalist GNU for Windows SourceForge.net：MinGW-w64 - for 32 and 64 bit Windows</description></item><item><title>处理注解@RequestParam的"Required String parameter is not present"</title><link>https://mryqu.github.io/post/%E5%A4%84%E7%90%86%E6%B3%A8%E8%A7%A3requestparam%E7%9A%84required_string_parameter_is_not_present/</link><pubDate>Tue, 04 Feb 2014 10:04:20 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A4%84%E7%90%86%E6%B3%A8%E8%A7%A3requestparam%E7%9A%84required_string_parameter_is_not_present/</guid><description>最近玩一下SpringMVC，代码如下：
@Controller @RequestMapping(&amp;#34;/test.do&amp;#34;) public class TestController { @RequestMapping(method = RequestMethod.GET) public ModelAndView sync(Model m, @RequestParam(&amp;#34;fid&amp;#34;) String fid, @RequestParam(&amp;#34;sid&amp;#34;) String sid) throws Exception { if(fid==null || sid==null) { m.addAttribute(&amp;#34;file&amp;#34;, new FileMetaDAO()); return new ModelAndView(ViewProvider.UPLOAD); } else { m.addAttribute(&amp;#34;sync&amp;#34;, new SyncDAO()); return new ModelAndView(ViewProvider.HR_SYNC); } } } 访问http://localhost:8080/hellorest/test.do 时发生如下问题： 查了一下Annotation Type RequestParam的javadoc，加上可选参数required解决战斗。
@Controller @RequestMapping(&amp;#34;/test.do&amp;#34;) public class TestController { @RequestMapping(method = RequestMethod.GET) public ModelAndView sync(Model m, @RequestParam(value=&amp;#34;fid&amp;#34;, required = false) String fid, @RequestParam(value=&amp;#34;sid&amp;#34;, required = false) String sid) throws Exception { if(fid==null || sid==null) { m.</description></item><item><title>免费私有代码托管平台</title><link>https://mryqu.github.io/post/%E5%85%8D%E8%B4%B9%E7%A7%81%E6%9C%89%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0/</link><pubDate>Sat, 01 Feb 2014 17:35:11 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%85%8D%E8%B4%B9%E7%A7%81%E6%9C%89%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0/</guid><description>SourceForge、GitHub免费版、Gitorious免费版和GoogleCode等源代码仓库都要求项目必须开源。这里做一下免费私有代码托管平台资料汇总。
GitLab:支持Git库。首页说可以创建无限个私有或公开的库。使用时提示可以创建100000个级别为私有、GitLab内访问或公开的项目。 Atlassian公司的Bitbucket:支持Git库。公有和私有仓库都可以无限制创建，支持在线协作。免费版限制为5个用户。 Assembla:支持SVN/Git/Perforce库，支持在线协作。免费版限制为2个用户，一个私有库和500M存储。 beanstalk：支持SVN/Git库，支持在线协作。免费版限制为1个用户，一个私有库和100M存储。 unfuddle：有帖子说有免费帐户，但是没有找到。 开源中国的Git@OSC：支持Git库。最多可以创建 1000个项目，不限私有或者公开。 CSDN的CODE：支持Git库，支持在线协作。支持私有库和公开库。 京东的京东代码库：支持Git库。支持私有库和公开库。 参考 免费的Git私有代码托管服务 如何在“Google Code 代码托管”上建立私有代码版本库 Tortoisegit+BitBucket创造私有代码托管仓库</description></item><item><title>[算法] 算法课笔记-排序</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E7%AE%97%E6%B3%95%E8%AF%BE%E7%AC%94%E8%AE%B0-%E6%8E%92%E5%BA%8F/</link><pubDate>Fri, 31 Jan 2014 09:12:53 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_%E7%AE%97%E6%B3%95%E8%AF%BE%E7%AC%94%E8%AE%B0-%E6%8E%92%E5%BA%8F/</guid><description>排序算法分类 就地排序（inplace）：排序算法所需辅助空间不依赖于元素个数N 稳定排序（stable）：同键值的元素在排序后原相对顺序不变 排序算法对比 |排序算法|就地
排序|稳定
排序|最差时间
复杂度|平均时间
复杂度|最佳时间
复杂度|备注 |&amp;mdash;&amp;ndash; |选择排序（selection）|是||C=N²/2|C=N²/2
M=N|C=N²/2|C比较 M移动 |冒泡排序（Bubble）|是|是|C=N²/2|C=N²/2|C=N|当N较小或部分已排序时使用 |插入排序（insertion）|是|是|C=N²/2|C=N²/4
M=N²/4|C=N|当N较小或部分已排序时使用（部分已排序时，插入排序比选择排序要快） |希尔排序（shell）|是||?|?|C=N|严谨代码，次二次时间 |归并排序（merge）||是|C=NlgN|C=NlgN|C=NlgN|NlgN保证，稳定
Java中对对象排序
Perl, C++ stable sort, Python stable sort, Firefox JavaScript,&amp;hellip; |快速排序（quick）|是||C=N²/2|C=2NlnN|C=NlgN|NlgN概率保证，实践中最快
Java中对原始数据类型排序
C qsort, Unix, Visual C++, Python, Matlab, Chrome JavaScript,&amp;hellip; |三路基数快速排序
（3-way quick）|是||C=N²/2|C=2NlnN|C=N|当存在重复键值时改善快速排序 |堆排序（heap）|是||C=2NlgN|C=2NlgN|C=NlgN|NlgN保证，就地
选择排序 插入排序 希尔排序 Knuth Shuffle 合并排序 快速排序 快选 三路基数快速排序 堆排序</description></item><item><title>Hello Android!</title><link>https://mryqu.github.io/post/hello_android/</link><pubDate>Sat, 25 Jan 2014 12:31:21 +0000</pubDate><guid>https://mryqu.github.io/post/hello_android/</guid><description>第一次再简陋总比不做强！ ADT安装 不经常装ADT （Android development tool），第二次装又犯晕了。 ADT要跟JDK平台一致：
对应32位JDK的adt-bundle-windows-x86-20131030.zip 对应64位JDK的adt-bundle-windows-x86_64-20131030.zip JDK装好久了，不知道是32位还是64位的了，可以跑一下下面的代码：
public class JdkPlatformTest { public static voidmain(String[] args) { String arch =System.getProperty(&amp;#34;sun.arch.data.model&amp;#34;); System.out.println(arch+&amp;#34;-bit&amp;#34;); } } 此外Windows平台可以通过下列命令获取：wmic os get osarchitecture
Android虚拟设备仿真器操作命令 http://developer.android.com/tools/devices/emulator.html</description></item><item><title>使用Spring MVC下载Excel文件</title><link>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8spring_mvc%E4%B8%8B%E8%BD%BDexcel%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 20 Jan 2014 21:29:48 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BD%BF%E7%94%A8spring_mvc%E4%B8%8B%E8%BD%BDexcel%E6%96%87%E4%BB%B6/</guid><description>想使用Spring MVC下载Excel文件，照着下面的样例，很容易就实现了。 Spring MVC with Excel View Example (Apache POI and JExcelApi)
Spring MVC and Excel file via AbstractExcelView
问题一：数据仅能生成xls，不能生成xlsx 通过org.springframework.web.servlet.view.document.AbstractExcelView源代码可知，Spring的AbstractExcelView仅支持HSSFWorkbook，不支持XSSFWorkbook。这一问题可以通过Github上的hmkcode/Spring-Framework来解决。 com.hmkcode.view.abstractview.AbstractExcelView
com.hmkcode.view.ExcelView
问题二：下载的文件是我配置的视图路径export.do，而不是Excel后缀 通过在Rest Controller里添加如下代码解决：
SimpleDateFormat myFmt=new SimpleDateFormat(&amp;#34;yyyyMMdd_HHmmss&amp;#34;); response.setHeader(&amp;#34;Pragma&amp;#34;, &amp;#34;public&amp;#34;); response.setHeader(&amp;#34;Cache-Control&amp;#34;, &amp;#34;max-age=0&amp;#34;); if(excelVersion.equals(&amp;#34;xlsx&amp;#34;)){ response.setContentType(&amp;#34;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&amp;#34;); response.setHeader(&amp;#34;Content-Disposition&amp;#34;, &amp;#34;attachment; filename=test&amp;#34;+myFmt.format(new Date())+&amp;#34;.xlsx&amp;#34;); }else{ response.setContentType(&amp;#34;application/vnd.ms-excel&amp;#34;); response.setHeader(&amp;#34;Content-Disposition&amp;#34;, &amp;#34;attachment; filename=\&amp;#34;test&amp;#34;+myFmt.format(new Date())+&amp;#34;.xls\&amp;#34;&amp;#34;); }</description></item><item><title>遭遇Python*重复运算符陷阱</title><link>https://mryqu.github.io/post/%E9%81%AD%E9%81%87python%E9%87%8D%E5%A4%8D%E8%BF%90%E7%AE%97%E7%AC%A6%E9%99%B7%E9%98%B1/</link><pubDate>Sat, 18 Jan 2014 18:12:43 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%81%AD%E9%81%87python%E9%87%8D%E5%A4%8D%E8%BF%90%E7%AE%97%E7%AC%A6%E9%99%B7%E9%98%B1/</guid><description>在python中有个特殊的符号“*”，可以用做数值运算的乘法算子，也是用作对象的重复算子，但在作为重复算子使用时一定要注意* 重复出来的对象有可能是指向在内存中同一块地址的同一对象。
测试代码：
grid_width=2 grid_height=2 def modify_grid(cells, row, col, val): cells[row][col]=val print cells #testing 1 print &amp;#39;\ntesting 1&amp;#39; cells=[ [88 for col in range(grid_width)] for row in range(grid_height)] print cells modify_grid(cells,0,1,66) #testing 2: In the trap print &amp;#39;\ntesting 2&amp;#39; cells=[[88]*grid_width]*grid_height print cells modify_grid(cells,0,1,66) print &amp;#39;\n&amp;#39; cells=[[&amp;#34;88&amp;#34;]*grid_width]*grid_height print cells modify_grid(cells,0,1,&amp;#34;66&amp;#34;) #testing 3 print &amp;#39;\ntesting 3&amp;#39; cells=[] for idx in range(grid_height): cells.append([88]*grid_width) print cells modify_grid(cells,0,1,66) #testing 4 print &amp;#39;\ntesting 4&amp;#39; cells=[123]*(grid_height*grid_width) print cells cells[1]=321 print cells 结果</description></item><item><title>安装和卸载JRE或JDK时出现Error 1723的解决办法</title><link>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BDjre%E6%88%96jdk%E6%97%B6%E5%87%BA%E7%8E%B0error_1723%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link><pubDate>Wed, 15 Jan 2014 20:54:47 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BDjre%E6%88%96jdk%E6%97%B6%E5%87%BA%E7%8E%B0error_1723%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid><description>卸载JDK和JRE时失败，报错“Error 1723:java dll missing”。 网上的很多攻略都不管用，最后还是从微软网站找到fix程序。 Fix problems that programs cannot be installed or uninstalled</description></item><item><title>用JS处理粘贴而来的HTML表单</title><link>https://mryqu.github.io/post/%E7%94%A8js%E5%A4%84%E7%90%86%E7%B2%98%E8%B4%B4%E8%80%8C%E6%9D%A5%E7%9A%84html%E8%A1%A8%E5%8D%95/</link><pubDate>Sun, 12 Jan 2014 22:03:18 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%94%A8js%E5%A4%84%E7%90%86%E7%B2%98%E8%B4%B4%E8%80%8C%E6%9D%A5%E7%9A%84html%E8%A1%A8%E5%8D%95/</guid><description>今天用Javascript处理粘贴而来的HTML表单，代码如下：某日又写了一小段，代码如下：</description></item><item><title>[算法] O(0)的exch函数</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_o0%E7%9A%84exch%E5%87%BD%E6%95%B0/</link><pubDate>Fri, 10 Jan 2014 06:40:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_o0%E7%9A%84exch%E5%87%BD%E6%95%B0/</guid><description>常用的exch函数：
public static void exch(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } 不使用辅助空间的exch函数：
public static void exch(int[] nums, int i, int j) { nums[i] ^= nums[j]; nums[j] ^= nums[i]; nums[i] ^= nums[j]; } 控制流及nums[i]和nums[j]状态如下：
|nums[i]|nums[j] |&amp;mdash; |= nums[i] ^ nums[j]|/ |/|= nums[j] ^ (nums[i] ^ nums[j])
= nums[i] |= (nums[i] ^ nums[j]) ^ nums[i]
= nums[j]|/</description></item><item><title>ClusterShell实践</title><link>https://mryqu.github.io/post/clustershell%E5%AE%9E%E8%B7%B5/</link><pubDate>Tue, 07 Jan 2014 20:47:23 +0000</pubDate><guid>https://mryqu.github.io/post/clustershell%E5%AE%9E%E8%B7%B5/</guid><description>ClusterShell介绍 ClusterShell提供了一个轻量级、统一和健壮的命令执行Python框架，非常适于减轻Linux集群日常管理任务负担。ClusterShell的好处如下：
提供高效、并行和高可扩展的Python命令执行引擎。 提供统一节点组语法和对外部组的访问 当使用clush和nodeset等工具可有效提升集群创建和日常管理任务的效率 ClusterShell实践 安装 首先在集群内节点配置无密钥ssh访问。然后在主/工作节点上安装ClusterShell。
apt-get install clustershell 配置和实践 ClusterShell工具 ClusterShell包含如下工具：
clush帮助文档 clubak帮助文档 nodesetcluset帮助文档 ClusterShell在线文档为http://clustershell.readthedocs.io/。</description></item><item><title>CRAN任务视图使用</title><link>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E4%BD%BF%E7%94%A8/</link><pubDate>Tue, 07 Jan 2014 19:59:22 +0000</pubDate><guid>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E4%BD%BF%E7%94%A8/</guid><description>一般都是从CRAN（Comprehensive R ArchiveNetwork）安装R的各种包（package）来满足我们的编程需求。CRAN将包按照应用范畴归类，并公布在如下链接：http://cran.r-project.org/web/views/我们可以通过安装视图的命令把所有同一应用范畴的包都安装上。
为了自动安装视图，需要安装ctv包。
install.packages(&amp;#34;ctv&amp;#34;) library(&amp;#34;ctv&amp;#34;) 通过如下命令安装或更新视图。
install.views(&amp;#34;Econometrics&amp;#34;) update.views(&amp;#34;MachineLearning&amp;#34;) CRAN任务视图 |视图|说明 |&amp;mdash; |Bayesian|贝叶斯推断 |ChemPhys|化学计量学和计算物理学 |ClinicalTrials|临床试验设计、监控和分析 |Cluster|聚类分析和有限混合模型 |DifferentialEquations|微分方程 |Distributions|概率分布 |Econometrics|计量经济学 |Environmetrics|生态与环境数据分析 |ExperimentalDesign|实验设计和数据分析 |Finance|实证金融 |Genetics|统计遗传学 |Graphics|图形显示 &amp;amp; 动态图 &amp;amp; 图形设备 &amp;amp; 可视化 | HighPerformanceComputing|高性能计算和并行计算 |MachineLearning|机器学习与统计学习 |MedicalImaging|医学图像分析 |MetaAnalysis|元分析 |Multivariate|多元统计 | NaturalLanguageProcessing|自然语言处理 |NumericalMathematics|数值数学 |OfficialStatistics|官方统计和调查方法 |Optimization|优化和数学规划 |Pharmacokinetics|药物动力学数据分析 |Phylogenetics|系统发育、进化和遗传学分析 |Psychometrics|心理测量模型和方法 |ReproducibleResearch|可重复性研究 |Robust|稳健统计方法 |SocialSciences|社会科学统计 |Spatial|空间数据分析 |SpatioTemporal|时空数据处理和分析 |Survival|存活分析 |TimeSeries|时间序列分析 |WebC++nologies|Web技术与服务 |gR|图模型</description></item><item><title>[HBase] HBase Shell中的put操作解析</title><link>https://mryqu.github.io/post/hbase_hbase_shell%E4%B8%AD%E7%9A%84put%E6%93%8D%E4%BD%9C%E8%A7%A3%E6%9E%90/</link><pubDate>Fri, 03 Jan 2014 23:20:51 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_hbase_shell%E4%B8%AD%E7%9A%84put%E6%93%8D%E4%BD%9C%E8%A7%A3%E6%9E%90/</guid><description>阅读了HBase Shell datatype conversion一贴，感觉下列两个操作结果中的单元格数据值都像是文本类型的：
put &amp;#39;mytable&amp;#39;, &amp;#39;2342&amp;#39;, &amp;#39;cf:c1&amp;#39;, &amp;#39;67&amp;#39; put &amp;#39;mytable&amp;#39;, &amp;#39;2341&amp;#39;, &amp;#39;cf:c1&amp;#39;, 23 预知真相，看来只好看HBase Shell代码了。HBase Shell是Ruby代码，首先找到这些代码的位置：
cd $HBASE_HOME find . -name &amp;#39;*.rb&amp;#39; -print 找到了$HBASE_HOME/lib/ruby/shell/commands/put.rb，其GitHub代码库位置为https://github.com/apache/hbase/commits/master/hbase-shell/src/main/ruby/shell/commands/put.rb：
def command(table, row, column, value, timestamp=nil, args = {}) put table(table), row, column, value, timestamp, args end def put(table, row, column, value, timestamp = nil, args = {}) format_simple_command do table._put_internal(row, column, value, timestamp, args) end end 继而找到了$HBASE_HOME/lib/ruby/hbase/table.rb，其GitHub代码库位置为https://github.com/apache/hbase/blob/master/hbase-shell/src/main/ruby/hbase/table.rb：
def _put_internal(row, column, value, timestamp = nil, args = {}) p = org.</description></item><item><title>[HBase] Java客户端程序构建脚本</title><link>https://mryqu.github.io/post/hbase_java%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%A8%8B%E5%BA%8F%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC/</link><pubDate>Fri, 03 Jan 2014 00:05:34 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_java%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%A8%8B%E5%BA%8F%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC/</guid><description>上一博文[HBase] 原始数据类型存储中所用到的构建脚本build.sh如下：
#!/bin/bash HADOOP_HOME=/usr/local/hadoop HBASE_HOME=/usr/local/hbase CLASSPATH=.:$HBASE_HOME/conf:$(hbase classpath) javac -cp $CLASSPATH HBasePrimitiveDataTypeTest.java java -cp $CLASSPATH HBasePrimitiveDataTypeTest</description></item><item><title>[HBase] 原始数据类型存储</title><link>https://mryqu.github.io/post/hbase_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8/</link><pubDate>Thu, 02 Jan 2014 22:37:53 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8/</guid><description>对原始数据类型如何在HBase中存储，如何在HBaseShell中如何显示尚不了解，做一下小实验满足一下好奇心。使用下列代码存放和读取原始数据类型：
byte[] cf = Bytes.toBytes(CF_DEFAULT); Put put = new Put(Bytes.toBytes(&amp;#34;test&amp;#34;)); byte[] val = Bytes.toBytes(&amp;#34;123&amp;#34;); System.out.println(&amp;#34;Bytes for str: &amp;#34;+ bytesToHex(val)+&amp;#34;,len=&amp;#34;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;#34;str&amp;#34;), val); short shortVal = 123; val = Bytes.toBytes(shortVal); System.out.println(&amp;#34;Bytes for short:&amp;#34;+ bytesToHex(val)+&amp;#34;,len=&amp;#34;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;#34;short&amp;#34;), val); int intVal = 123; val = Bytes.toBytes(intVal); System.out.println(&amp;#34;Bytes for int:&amp;#34;+ bytesToHex(val)+&amp;#34;,len=&amp;#34;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;#34;int&amp;#34;), val); long longVal = 123L; val = Bytes.toBytes(longVal); System.out.println(&amp;#34;Bytes for long:&amp;#34;+ bytesToHex(val)+&amp;#34;,len=&amp;#34;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;#34;long&amp;#34;), val); float floatVal = 123; val = Bytes.</description></item><item><title>[Hadoop] 处理跨块边界的InputSplit</title><link>https://mryqu.github.io/post/hadoop_%E5%A4%84%E7%90%86%E8%B7%A8%E5%9D%97%E8%BE%B9%E7%95%8C%E7%9A%84inputsplit/</link><pubDate>Thu, 02 Jan 2014 07:50:10 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%A4%84%E7%90%86%E8%B7%A8%E5%9D%97%E8%BE%B9%E7%95%8C%E7%9A%84inputsplit/</guid><description>Mapper从HDFS中读取文件进行数据处理的。凭借InputFormat、InputSplit、RecordReader、LineReader等类，Mapper用户代码可以处理输入键值对进行数据处理。下面学习一下MapReduce是如何分割无压缩文本文件输入的。
涉及的类有：
InputFormat及其子类InputFormat类执行下列操作： 检验作业的输入文件和目录是否存在。 将输入文件分割策划功能InputSlit，基于文件的InputFormat根据文件大小将文件分割为逻辑上的Split。 实例化用于对每个文件分割块解析记录的RecordReaderInputFormat类包括下列两个主要的子类： TextInputFormat：用于解析文本文件。将文件按行生成记录；键为LongWritable，文件偏移量；值为Text，行的内容。 SequenceFileInputFormat：用于解析Hadoop压缩二进制文件。SequenceFile可为无压缩、记录压缩或块压缩。与TextInputFormat不同，SequenceFileInputFormat的键值对是泛型的。 InputSplit及其子类InputSplit是单个Mapper所要处理的数据子集逻辑表现形式。每个InputSplit很可能不会包含完整记录数，即在输入分割中首尾记录有可能是不完整的，处理全部记录由RecordReader负责。InputSplit的子类包括： FileSplit代表输入文件的GetLength()大小的一个片段。FileSplit由InputFormat.getSplits(JobContext)调用返回，并传给InputFormat类用于实例化RecordReader。 CombineFileSplit将多个文件并入一个分割内（默认每个文件小于分割大小） RecordReader及其子类RecordReader将输入分割片内的数据分析成Mapper所要处理的键值对。记录跟分割边界/块边界不一定匹配，RecordReader判断记录位置并处理日志边界。RecordReader包括下列子类： LineRecordReader：处理文本文件。 SequenceFileRecordReader：处理Sequence文件。 LineReader：用于对文件进行读取操作、分析行并获得键值对。 处理的具体流程如下：
FileInputFormat.getSplits(JobContext)方法主要完成计算InputSplit的工作。 首先判断输入文件是否可被分割的。如果文件流没有被压缩或者使用bzip2这种可分割的压缩算法，则文件可被分割；否则整个文件作为一个InputSplit。 如果文件可被分割的话，分割尺寸为max( max( 1,mapreduce.input.fileinputformat.split.minsize), min(mapreduce.input.fileinputformat.split.maxsize, blockSize))。如果没有对分割最小/大值进行设置的话，则分割尺寸即等于块大小，而块大小默认为64MB。 文件按照上述分割尺寸分割记录文件路径、每一分割的起始偏移量、分割块实际尺寸、输入文件所在机器。只要文件剩余数据量在1.1倍分割尺寸范围内，就会放到一个InputSplit中。 LineRecordReader主要完成从InputSplit获取键值对的工作。 LineRecordReader构造方法获知行分隔符是否为定制分割符； initialize(InputSplit,TaskAttemptContext)方法获知InputSplit的start和end(=start+splitLength)，如果start不为0的话，跳过第一行（不用管第一行是否完整）。即处理上一InputSplit的RecordReader处理本InputSplit的第一行，处理本InputSplit的RecordReader处理下一个InputSplit的第一行。 nextKeyValue()方法处理第一个InputSplit，需要跳过可能存在的UTF BOM。 LineReader主要完成从从文件输入流获取数据、如没有定制换行符则需判别CR/LF/CRLF换行符，并获得键值对。 以上类都不涉及对HDFS文件和块的实际读操作，本地和远程读取可学习org.apache.hadoop.hdfs.client.HdfsDataInputStream、org.apache.hadoop.hdfs.DFSInputStream等类的代码。
参考 How does Hadoop process records split across block boundaries?</description></item><item><title>[Hadoop] MapReduce输出SequenceFile实践</title><link>https://mryqu.github.io/post/hadoop_mapreduce%E8%BE%93%E5%87%BAsequencefile%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 01 Jan 2014 23:19:23 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_mapreduce%E8%BE%93%E5%87%BAsequencefile%E5%AE%9E%E8%B7%B5/</guid><description>Hadoop的Mapper输出默认格式为SequenceFile，而Reducer默认输出则为TextFile。在一个MapReduce工作流中，经常有多个MapReduce作业级联完成应用功能。如果中间MapReduce是输入输出都为SequenceFile，则性能很可能获得很大提升。 SequenceFile文件是Hadoop用来存储二进制形式的键值对而设计的一种平面文件(FlatFile)。SequenceFile可压缩可切分,非常适合Hadoop文件存储特性，SequenceFile的写入由org.apache.hadoop.io.SequenceFile.Writer来实现，根据压缩类型Writer又派生出两个子类BlockCompressWriter和RecordCompressWriter，压缩方式由SequenceFile类的内部枚举类CompressionType来表示：
NONE: 对记录不进行压缩; RECORD: 仅压缩每一个记录中的值; BLOCK: 将一个块中的所有记录压缩在一起; 输入SequenceFile示例 job.setInputFormatClass(SequenceFileInputFormat.class); 输出SequenceFile示例</description></item><item><title>*nux中的Here documents和Here strings</title><link>https://mryqu.github.io/post/linux%E4%B8%AD%E7%9A%84here_documents%E5%92%8Chere_strings/</link><pubDate>Wed, 01 Jan 2014 21:09:54 +0000</pubDate><guid>https://mryqu.github.io/post/linux%E4%B8%AD%E7%9A%84here_documents%E5%92%8Chere_strings/</guid><description>介绍 here document(又称之为here-document、here-text、heredoc、hereis、here-string或here-script)，是shell中的一种特殊重定向方式，用来将输入重定向到一个交互式的shell脚本或程序。格式如下：
command &amp;lt;&amp;lt; [-]delimiter here-document delimiter here documents始于Unixshell的最通用语法，在&amp;laquo;紧跟一个分割标识符（通常为EOF或END），跟随一堆多行字符，最后一行用分割标识符收尾。
注意：
结尾的分割标识符一定要顶格写，前后不能有任何字符，包括空格和tab缩进。 开始的分割标识符前后的空格会被省略掉。 开始的分割标识符前如果使用-的话，内容部分每行前面的 tab (制表符)将会被删除掉。这种用法是为了编写HereDocument的时候可以将内容部分进行缩进，方便代码阅读。 here strings语法跟here documents类似。格式如下：
command &amp;lt;&amp;lt;&amp;lt; word 实践及测试 Here documents简单测试 Here documents中变量替换和执行命令测试 通常，Heredocuments中内容会进行变量替换，反勾号中的命令也会执行。可以通过在开始的分割标识符上加单引号禁掉这种行为。 Here string简单测试 在shell文件中使用Here documents 参考 Here document Bash Reference Manual - Here Documents Bash Reference Manual - Here Strings Java 的多行字符串 Here Document 的实现</description></item><item><title>数据源/Hibernate配置明文密码加密思考</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E6%BA%90hibernate%E9%85%8D%E7%BD%AE%E6%98%8E%E6%96%87%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E6%80%9D%E8%80%83/</link><pubDate>Wed, 01 Jan 2014 17:48:44 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E6%BA%90hibernate%E9%85%8D%E7%BD%AE%E6%98%8E%E6%96%87%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%E6%80%9D%E8%80%83/</guid><description>无论是Web应用服务器数据源配置还是Hibernate配置，一般数据库用户和密码都是明文的，感觉很不安全。上网搜了一圈，博客帖子还不少，不过都跟Web应用服务器官方文档差不太多。 Tomcat坚持明文，理由是最终需要用原始用户名和密码去连接数据库，而Tomcat是开源的，攻击者很容易找到加密/解密方法，所以也得不到真正的保护。 另一方就是用AES/DES/3DES等密钥算法对明文密码进行加密，然后在程序某处进行解密，例如使用Tomcat连接池时用org.apache.tomcat.jdbc.pool.DataSourceFactory继承子类实现自己的数据源工厂时进行解密，使用Srping时用LocalSessionFactoryBean继承子类读取配置进行解密然后将其写回运行态的配置。这种方式说白了，如果程序不是很大，使用JAD等工具对程序进行反编译，找到如何加解密的算法还是不难的。 我个人认为，真正的Web应用实施肯定是要设置服务器访问权限及服务器内目录的访问权限的，一般人不应该能访问到Web服务器程序及配置，这样即使使用明文密码也能保证相同的安全等级。当然，如果开发一个不严肃的小项目，并且部署在一个公共访问机器上，做做障眼法瞒瞒那些不是码农的人也是可以的。
Web应用服务器文档：
Tomcat Wiki：FAQ/Password JBoss：Encrypting Data Source Passwords JBoss EAP：Encrypting Data Source Passwords TomEE：DataSource Password Encryption博客： Encrypting passwords in Tomcat Hibernate的配置文件中用户和密码的加密 hibernate配置文件中数据库密码加密,该如何解决 Hibernate的验证，而不存储在纯文本密码 如何给工程中的配置文件加密 解密 通过spring对hibernate/ibatis的配置文件加密 jndi 数据源配置密码加密 spring 属性文件加密码及解密 怎么实现数据库连接的密码加密 Jboss数据源密码加密 Tomcat数据源连接池加密 使用 Jasypt 保护数据库配置 spring datasource 密码加密后运行时解密的解决办法</description></item><item><title>swirl介绍</title><link>https://mryqu.github.io/post/swirl%E4%BB%8B%E7%BB%8D/</link><pubDate>Sat, 28 Dec 2013 14:22:46 +0000</pubDate><guid>https://mryqu.github.io/post/swirl%E4%BB%8B%E7%BB%8D/</guid><description>swirl是在R命令行使用、用于R统计编程语言交互式教学的软件包。 swirl需要R3.0.2或更新版本。如果使用老版本R，需要更新R之后才能使用swirl。如果不清楚当前R版本，可以在R命令行敲入R.version.string获得当前的版本信息。 swirl可以通过如下命令安装：
install.packages(&amp;#34;swirl&amp;#34;) 每次使用前，通过如下命令加载包并执行：
library(swirl) swirl()</description></item><item><title>Windows常用命令汇总</title><link>https://mryqu.github.io/post/windows%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</link><pubDate>Sun, 22 Dec 2013 13:12:02 +0000</pubDate><guid>https://mryqu.github.io/post/windows%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</guid><description>windows命令现在也就sysdm.cpl和mstsc用的比较多，很多还真不熟悉，搜了一篇备查。
appwiz.cpl：程序和功能 calc：启动计算器 certmgr.msc：证书管理实用程序 charmap：启动字符映射表 chkdsk.exe：Chkdsk磁盘检查（管理员身份运行命令提示符） cleanmgr: 打开磁盘清理工具 cliconfg：SQL SERVER 客户端网络实用工具 cmstp：连接管理器配置文件安装程序 cmd.exe：CMD命令提示符 自动关机命令 Shutdown -s -t600：表示600秒后自动关机 shutdown -a：可取消定时关机 Shutdown -r -t600：表示600秒后自动重启 rundll32user32.dll,LockWorkStation：表示锁定计算机 colorcpl：颜色管理，配置显示器和打印机等中的色彩 CompMgmtLauncher：计算机管理 compmgmt.msc：计算机管理 credwiz：备份或还原储存的用户名和密码 comexp.msc：打开系统组件服务 control：控制面版 dcomcnfg：打开系统组件服务 Dccw：显示颜色校准 devmgmt.msc：设备管理器 desk.cpl：屏幕分辨率 dfrgui：优化驱动器 Windows7→dfrg.msc：磁盘碎片整理程序 dialer：电话拨号程序 diskmgmt.msc：磁盘管理 dvdplay：DVD播放器 dxdiag：检查DirectX信息 eudcedit：造字程序 eventvwr：事件查看器 explorer：打开资源管理器 Firewall.cpl：Windows防火墙 FXSCOVER：传真封面编辑器 fsmgmt.msc：共享文件夹管理器 gpedit.msc：组策略 hdwwiz.cpl：设备管理器 inetcpl.cpl：Internet属性 intl.cpl：区域 iexpress：创建自解压/安装文件，系统自带 joy.cpl：游戏控制器 logoff：注销命令 lusrmgr.msc：本地用户和组 lpksetup：语言包安装/删除向导，安装向导会提示下载语言包 lusrmgr.msc：本机用户和组 main.cpl：鼠标属性 mmsys.cpl：声音 magnify：放大镜实用程序 MdSched:Windows内存诊断程序 mmc：打开控制台 mobsync：同步命令 mplayer2：简易widnows media player Msconfig.exe：系统配置实用程序 msdt：微软支持诊断工具 msinfo32：系统信息 mspaint：画图 Msra：Windows远程协助 mstsc：远程桌面连接 NAPCLCFG.</description></item><item><title>[JavaScript] 调试及console.log</title><link>https://mryqu.github.io/post/javascript_%E8%B0%83%E8%AF%95%E5%8F%8Aconsole.log/</link><pubDate>Sat, 21 Dec 2013 11:49:44 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E8%B0%83%E8%AF%95%E5%8F%8Aconsole.log/</guid><description>最近玩一下javascipt，在回调里碰到一个问题，需要调试。加入了console.log函数打印日志，在我的chrome浏览器按Ctrl+Shift+J快捷键调出DevTool并显示控制台来查找问题。 结合Wireshark，最后才发现对Json数据解析错误。
下面介绍一下console.log的使用。javascript的代码示例如下：
$(function () { $(&amp;#39;#fileupload&amp;#39;).fileupload({ url: url, dataType: &amp;#39;json&amp;#39;, done: function (e, data) { $.each(data.result.files, function (index, file) { $(&amp;#39;&amp;#39;).text(file.name).appendTo(&amp;#39;#files&amp;#39;); }); }, progressall: function (e, data) { var progress = parseInt(data.loaded / data.total * 100, 10); console.log(&amp;#34;complete:&amp;#34;+progress); $(&amp;#39;#progress .progress-bar&amp;#39;).css( &amp;#39;width&amp;#39;, progress + &amp;#39;%&amp;#39; ); } }).prop(&amp;#39;disabled&amp;#39;, !$.support.fileInput) .parent().addClass($.support.fileInput ? undefined : &amp;#39;disabled&amp;#39;); }); 浏览器控制台使用 Firefox http://getfirebug.com/ (可以使用Firefox内建的开发工具Ctrl+Shift+J (Tools &amp;gt; Web Developer &amp;gt;Error Console)，但是Firebug更出色；建议使用Firebug)
Safari和Chrome 使用方法基本相同。 https://developer.chrome.com/devtools/index https://developer.apple.com/technologies/safari/developer-tools.html
Internet Explorer 不要忘了在IE9或IE10中调试IE7和IE8时使用兼容模式。 http://msdn.</description></item><item><title>jQuery资料帖</title><link>https://mryqu.github.io/post/jquery%E8%B5%84%E6%96%99%E5%B8%96/</link><pubDate>Fri, 20 Dec 2013 19:21:43 +0000</pubDate><guid>https://mryqu.github.io/post/jquery%E8%B5%84%E6%96%99%E5%B8%96/</guid><description>学习网站 http://jqfundamentals.com/
http://try.jquery.com/
http://www./tracks/jquery
http://www.w3school.com.cn/jquery/
图书 jQuery基础教程：官方培训教材 jQuery实战：书不错，就是内容有点 老锋利的jQuery
代码组织 http://learn.jquery.com/code-organization/
其他 jQuery设计思想：http://www.ruanyifeng.com/blog/2011/07/jquery_fundamentals.html
jQuery最佳实践：http://www.ruanyifeng.com/blog/2011/08/jquery_best_practices.html
jQuery源码分析：http://www.cnblogs.com/chyingp/archive/2013/06/03/jquery-souce-code-study.html</description></item><item><title>[JavaScript] 逻辑操作符的特殊行为</title><link>https://mryqu.github.io/post/javascript_%E9%80%BB%E8%BE%91%E6%93%8D%E4%BD%9C%E7%AC%A6%E7%9A%84%E7%89%B9%E6%AE%8A%E8%A1%8C%E4%B8%BA/</link><pubDate>Sat, 07 Dec 2013 14:47:35 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E9%80%BB%E8%BE%91%E6%93%8D%E4%BD%9C%E7%AC%A6%E7%9A%84%E7%89%B9%E6%AE%8A%E8%A1%8C%E4%B8%BA/</guid><description>Javascript中并不要求逻辑运算的两个操作数为布尔类型，并且返回值也不一定为布尔类型。&amp;amp;&amp;amp;操作符，如果第一个操作表达式能被转换成false，返回第一个操作表达式；否则返回第二个操作表达式。当用于两个布尔类型值时，两个值都为true时返回ture，否则返回false。||操作符，如果第一个操作表达式能被转换成true，返回第一个操作表达式；否则返回第二个操作表达式。当用于两个布尔类型值时，任一个值为true时返回ture，否则返回false。示例：
参考 MDN：Logical operators</description></item><item><title>[JavaScript] 原始数据类型</title><link>https://mryqu.github.io/post/javascript_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Sat, 07 Dec 2013 10:09:54 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>原始数据类型 JavaScript共有5种原始数据类型：
|原始数据类型|包装对象|介绍 |&amp;mdash;&amp;ndash; |string|String|字符串遇到加号之外的计算操作符，会转换成数值。内容为不为数值的字符串转换成NaN。当用比较操作符比较两个字符串时，比较的是第一个字母的unicode。 |number|Number|十进制数：123八进制数：0123十六进制数：0x123指数：1e1、1E+1、2E-3无穷：Infinity、-Infinity非数字：NaN |Boolean|Boolean| |null||与undefined的区别在于，已定义但没有值 |undefined||
typeof操作符 typeof的返回值有六种可能：number、string、boolean、object、function、undefined。
条件判断或3元条件运算符(?:)判断 |值|Boolean结果 |&amp;mdash;&amp;ndash; |undefined|false |null|false |number|0和NaN为false，其他为true |string|空字符串&amp;quot;&amp;ldquo;为false，其他为true |对象|不为null的对象始终为true
参考 MDN：Primitive data type MDN：typeof operator</description></item><item><title>[Git] Git代理配置</title><link>https://mryqu.github.io/post/git_git%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 01 Dec 2013 22:00:58 +0000</pubDate><guid>https://mryqu.github.io/post/git_git%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid><description>设置Git的http和https代理 git config --global http.proxy http://proxyUser:proxyPwd@proxyServer:proxyPort git config --global https.proxy https://proxyUser:proxyPwd@proxyServer:proxyPort 查询Git的http和https代理 git config --global --get http.proxy git config --global --get https.proxy 移除Git的http和https代理 git config --global --unset http.proxy git config --global --unset https.proxy</description></item><item><title>Joda-Time笔记</title><link>https://mryqu.github.io/post/joda-time%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 01 Dec 2013 00:31:39 +0000</pubDate><guid>https://mryqu.github.io/post/joda-time%E7%AC%94%E8%AE%B0/</guid><description>Joda简介 Joda项目致力于为Java平台提供替代API的一些质量保证的基础库。包括如下子项目：
Joda-Time -日期和时间库 Joda-Money -货币库 Joda-Beans -下一代JavaBeans Joda-Convert -字符串与对象转换库 Joda-Collect - 提供JDK或Google Guava没有的集合数据类型 Joda-Primitives -提供原始数据类型集合 Joda-Time简介 其中Joda-Time由于JDK自身时间日期API的不给力而被广泛使用，已经成为事实上的标准时间日期库。Joda-Time在JavaSE8将融入JDK API内，使用者可以使用java.time (JSR-310)内的API了。Joda-Time在时区、时间差和时间解析等方面支持多种历法系统，但仍然提供很简单的API。默认的历法是ISO8601标准，此外也支持Gregorian(现行公历、格里历)、Julian(儒略历)、Buddhist(佛历)、Coptic(科普特历)、Ethiopic(埃塞俄比亚历)和Islamic(伊斯兰历)历法系统。 为什么要使用Joda-Time（以下简称Joda）？考虑创建一个用时间表示的某个随意的时刻，例如2000年1月1日0时0分。如何创建一个用时间表示这个瞬间的JDK对象？使用java.util.Date？事实上这是行不通的，因为自JDK1.1 之后的每个 Java 版本的 Javadoc 都声明应当使用java.util.Calendar。Date中Date(intyear, int month, int date) 、Date(int year, int month, int date, inthrs, int min)、Date(int year, int month, int date, int hrs, int min,int sec)已经废弃、不建议使用，严重限制了您创建此类对象的途径。然而，Date确实有一个构造函数Date(long date)，您可以用来创建用时间表示某个瞬间的对象（除“当前时间”以外）。该方法使用距离1970年1月1日子时格林威治标准时间（也称为_epoch_）以来的毫秒数作为一个参数，对时区进行校正。 那么Calendar又如何呢？可以使用下面的方式创建必需的实例：
Calendar calendar = Calendar.getInstance(); calendar.set(2000, Calendar.JANUARY, 1, 0, 0, 0); 使用Joda，代码应该类似如下所示：
DateTime dateTime = new DateTime(2000, 1, 1, 0, 0, 0, 0); 这一行简单代码没有太大的区别。但是如果使问题稍微复杂化，假设希望在这个日期上加上90天并输出结果。使用JDK，需要如下代码：</description></item><item><title>MySQL:清空具有外键约束的表</title><link>https://mryqu.github.io/post/mysql%E6%B8%85%E7%A9%BA%E5%85%B7%E6%9C%89%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E7%9A%84%E8%A1%A8/</link><pubDate>Wed, 20 Nov 2013 20:30:18 +0000</pubDate><guid>https://mryqu.github.io/post/mysql%E6%B8%85%E7%A9%BA%E5%85%B7%E6%9C%89%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E7%9A%84%E8%A1%A8/</guid><description>最近在MySQL Workbench上使用&amp;quot;TRUNCATE TABLE TABLE_E;&amp;ldquo;清空一个表时返回错误：Error Code: 1701. Cannot truncate a table referenced in a foreignkey constraint (yqutesting.table_f, CONSTRAINT table_f_ibfk_4FOREIGN KEY (old_id) REFERENCES yqutesting.table_e(ID))解决方法1:
删除约束 清空表 手工删除引用该表的记录 创建约束解决方法2: SET FOREIGN_KEY_CHECKS = 0; TRUNCATE TABLE TABLE_E; SET FOREIGN_KEY_CHECKS = 1; 参考: truncate foreign key constrained table</description></item><item><title>以管理员权限执行命令行</title><link>https://mryqu.github.io/post/%E4%BB%A5%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E8%A1%8C/</link><pubDate>Tue, 19 Nov 2013 13:20:02 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BB%A5%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E8%A1%8C/</guid><description>以管理员权限执行命令行，只需点击出Command Prompt的右键菜单，选择&amp;quot;Run asadministrator&amp;quot;即可。</description></item><item><title>[C++]不错的C++引用参数分析</title><link>https://mryqu.github.io/post/c++_%E4%B8%8D%E9%94%99%E7%9A%84c++%E5%BC%95%E7%94%A8%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90/</link><pubDate>Sat, 09 Nov 2013 07:29:24 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%B8%8D%E9%94%99%E7%9A%84c++%E5%BC%95%E7%94%A8%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90/</guid><description>阅读了一篇不错的C++ 引用参数 深入分析，摘要如下：
把参数声明成引用，实际上改变了缺省的按值传递参数的传递机制，在按值传递时，函数操纵的是实参的本地拷贝。
一、引用参数的三种常见用法： 需要改变实参的值，比如swap()。参数是引用时，函数接收的是实参的左值而不是值的拷贝。这意味着函数知道实参在内存中的位置，因而能够改变它的值或取它的地址。 向主调函数返回额外的结果。 向函数传递大型的类对象。 二、如果引用参数不希望在被调用的函数内部被修改，那么把参数声明为 const 型的引用是个不错的办法。 三、 我们可以声明任意内置数据类型的引用参数 四、引用参数还是指针参数 这两种参数都能够改变实参的值，也可以有效的传递大型类对象，怎么样决定参数该声明成哪种呢？ 根本区别是：引用必须被初始化为指向一个对象，一旦初始化了，它就不能再指向其他对象；指针可以指向一系列不同的对象也可以什么都不指向。因为指针可能指向一个对象或没有任何对象，所以函数在确定指针实际指向一个有效的对象之前不能安全地解引用（dereference）一个指针。另一方面，对于引用参数，函数不需要保证它指向一个对象。引用必须指向一个对象，甚至在我们不希望这样时也是如此。 如果一个参数可能在函数中指向不同的对象，或者这个参数可能不指向任何对象，则必须使用指针参数 。 引用参数的一个重要用法是：它允许我们在有效地实现重载操作符的同时，还能保证用法的直观性。</description></item><item><title>[Git] 查看某文件历史记录</title><link>https://mryqu.github.io/post/git_%E6%9F%A5%E7%9C%8B%E6%9F%90%E6%96%87%E4%BB%B6%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 09 Nov 2013 06:38:12 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E6%9F%A5%E7%9C%8B%E6%9F%90%E6%96%87%E4%BB%B6%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/</guid><description>在Git中查看某个文件历史记录，方式如下：
git log [filename]：显示对该文件的提交记录 git log -p [filename]：显示对该文件的提交记录及每次提交增量内容 gitk [filename]：图形显示对该文件的提交记录及每次提交增量内容</description></item><item><title>Tomcat的会话持久化</title><link>https://mryqu.github.io/post/tomcat%E7%9A%84%E4%BC%9A%E8%AF%9D%E6%8C%81%E4%B9%85%E5%8C%96/</link><pubDate>Fri, 08 Nov 2013 20:17:47 +0000</pubDate><guid>https://mryqu.github.io/post/tomcat%E7%9A%84%E4%BC%9A%E8%AF%9D%E6%8C%81%E4%B9%85%E5%8C%96/</guid><description>《玩玩HTTP servlet和session资源监控器》提到我hello的一个web项目，刚开始我只是用监视器清除了Tomcat容器外部的文件资源，以为会话失效后Tomcat会自己清除会话属性，但后来发现想的太简单了。不但会话失效，并且重启Tomcat服务器，服务器端原来的会话及其属性都在,如果客户端浏览器的会话没有丢的话，刷新页面仍然可以获得以前的信息。原来Tomcat（起码5.x之后的版本）在默认的情况下提供了会话持久化这项功能，见$TOMCAT_HOME$/conf/context.xml：Tomcat的默认会话管理器是标准会话管理器(StandardManager)，用于非集群环境中对单个处于运行状态的Tomcat实例会话进行管理。当Tomcat关闭时，这些会话相关的数据会被写入磁盘上的一个名叫SESSION.ser的文件，并在Tomcat下次启动时读取此文件。
默认只有在Tomcat正常关闭时才会保存完整的用户会话信息 默认保存于$CATALINA_HOME$/work/Catalina/[host]/[webapp]/下的SESSIONS.ser文件中 若是自定义的虚拟主机则保存在$CATALINA_HOME/work/Catalina/[host]/_/下的SESSIONS.ser文件中 如果不想再获得失效会话属性的话，解决办法为：
关闭Tomcat会话持久化功能。去掉context.xml中那句注释即可。 HttpSessionListener实现类的sessionDestroyed方法删除该会话所有属性。 参考 Apache Tomcat 5.5 Configuration ReferenceTomcat会话管理</description></item><item><title>[JavaScript] === 与 == 操作符的区别</title><link>https://mryqu.github.io/post/javascript_%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%AC%A6%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Fri, 08 Nov 2013 19:07:08 +0000</pubDate><guid>https://mryqu.github.io/post/javascript_%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%AC%A6%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>JavaScript中有两个等值比较操作符：严格相等===和宽松相等==。很多JavaScript指南都建议避免使用宽松相等，而是使用严格相等。
===：只有在两个操作数的数据类型和值都相等的情况下才为true ==：用于比较两个操作数是否相等，这两个操作数的数据类型不一定要相等，只要进行数据类型转换后相等即为true 严格相等=== （严格不相等!==） 规则如下：
如果类型不同，就[不相等] 如果两个都是数值原始类型，并且是同一个值，那么[相等]；(！例外)的是，如果其中至少一个是NaN，那么[不相等]。（判断一个值是否是NaN，只能用isNaN()来判断） 如果两个都是字符串原始类型，每个位置的字符都一样，那么[相等]；否则[不相等]。 如果两个都是布尔原始类型，两个值值都是true，或者都是false，那么[相等]。 如果两个原始类型值都是null，或者都是undefined，那么[相等]。 如果两个值都引用同一个对象（含数组和函数），那么[相等]；否则[不相等]。示例： 宽松相等== （宽松不相等!=） 规则如下：
如果两个值类型相同，进行 === 比较。 如果两个值类型不同，他们可能相等。根据下面规则进行类型转换再比较： null与undefined是[相等]的。 如果字符串原始类型和数值原始类型进行比较，把字符串转换成数值再进行比较。 如果Boolean对象与其他类型进行比较，Boolean对象会转换成数值(true:1,false:0)再进行比较。 如果一个是对象，另一个是数值或字符串原始类型，把对象转换成原始类型的值再比较。对象利用它的toString或者valueOf方法转换成原始类型。JavaScript内置核心对象(例如Array、Boolean、Function、Math、Number、RegExp和String)，会尝试valueOf先于toString；例外的是Date，Date利用的是toString转换。如果类型转换失败，则会产生一个runtime错误。 对象和原始类型比较，对象才会转换成原始类型。两个对象比较，如果两个值都引用同一个对象（含数组和函数），那么[相等]；否则[不相等]。示例： 参考 MDN：Comparison Operators</description></item><item><title>玩玩HTTP servlet和session资源监控器</title><link>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9http_servlet%E5%92%8Csession%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7%E5%99%A8/</link><pubDate>Thu, 07 Nov 2013 22:40:45 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9http_servlet%E5%92%8Csession%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7%E5%99%A8/</guid><description>WebListener是Servlet的监视器，它可以监听Http请求、会话生命周期事件等。其中包含如下接口：
ServletContextListener:监视servlet上下文的初始化(启动Web应用的初始化过程)、销毁（关闭Web应用）。 ServletContextAttributeListener:监视servlet上下文属性的添加、删除和替换。 ServletRequestListener:监视Http请求的初始化（进入第一个servlet或过滤器）、Web应用对请求处理结束（离开最后一个servlet或过滤器）。 ServletRequestAttributeListener:监视Http请求属性的添加、删除和替换。 HttpSessionListener:监视Http会话创建和失效操作。 HttpSessionAttributeListener:监视Http会话属性的添加、删除和替换。最近hello一个Web项目，其中有个向导上传文件进行处理，文件被保存在tomcat的临时目录，处理后再删除。过段时间发现临时目录里有一些未删除的临时文件，应该是上传文件后，在处理结束前有一段时间未进行操作，会话失效，临时文件没有被删除。后来添加了一个MyResourceMonitorListener完成这些未处理临时文件的删除操作，解决了这个问题。代码如下： MyResourceMonitorListener package com.yqu.http.session; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; import javax.servlet.http.HttpSession; import javax.servlet.http.HttpSessionEvent; import javax.servlet.http.HttpSessionListener; public class MyResourceMonitorListener implements ServletContextListener, HttpSessionListener { @Override public void sessionCreated(HttpSessionEvent event) { trace(&amp;#34;sessionCreated!&amp;#34;); } @Override public void sessionDestroyed(HttpSessionEvent event) { HttpSession session = event.getSession(); if (session != null) { String sessionId = session.getId(); trace(&amp;#34;sessionDestroyed with sessionId=&amp;#34; + sessionId + &amp;#34;!&amp;#34;); MyUtil.cleanSessionResources(session); } } @Override public void contextDestroyed(ServletContextEvent event) { MyUtil.</description></item><item><title>用python分析FM代码和日志</title><link>https://mryqu.github.io/post/%E7%94%A8python%E5%88%86%E6%9E%90fm%E4%BB%A3%E7%A0%81%E5%92%8C%E6%97%A5%E5%BF%97/</link><pubDate>Thu, 07 Nov 2013 21:53:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%94%A8python%E5%88%86%E6%9E%90fm%E4%BB%A3%E7%A0%81%E5%92%8C%E6%97%A5%E5%BF%97/</guid><description>学python有一段时间了，学完不用，结果就是很快遗忘。这周分析一些FM代码和日志，终于弃Java转python，自己乐一下！
filterDV t6Found=False with open(&amp;#39;SASFinancialManagement5.4f.log&amp;#39;, &amp;#39;w&amp;#39;) as fdst: with open(&amp;#39;SASFinancialManagement5.4.log&amp;#39;, &amp;#39;r&amp;#39;) as fsrc: for line in fsrc: if t6Found: if &amp;#34;DataValidation&amp;#34; in line: fdst.write(line) else: if &amp;#34;formSetId=436,formId=,tableCode=NewTable6&amp;#34; in line: t6Found=True if not fsrc.closed: fsrc.close() if not fdst.closed: fdst.close() calcDVDuration import re totalTime=0 with open(&amp;#39;SASFinancialManagement5.4f.log&amp;#39;, &amp;#39;r&amp;#39;) as fsrc: for line in fsrc: if &amp;#34;begin data validation at formSubScope for&amp;#34; in line: m = re.search(&amp;#39;formSetId=.* ]&amp;#39;, line) target = m.group(0) m = re.</description></item><item><title>Linux/Unix下显示二进制目标文件的符号表</title><link>https://mryqu.github.io/post/linux%E4%B8%8B%E6%98%BE%E7%A4%BA%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%A6%E5%8F%B7%E8%A1%A8/</link><pubDate>Thu, 31 Oct 2013 22:22:34 +0000</pubDate><guid>https://mryqu.github.io/post/linux%E4%B8%8B%E6%98%BE%E7%A4%BA%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E7%AC%A6%E5%8F%B7%E8%A1%A8/</guid><description>nm 查看二进制目标文件符号表的标准工具是nm，可以执行下列命令查看二进制目标文件（.o）/静态库（.a）/动态库（.so）的符号表：
nm -g yourObj.o nm -g yourLib.a nm -g yourLib.so C/C++语言在C++编译器编译以后，函数的名字会被编译器修改，改成编译器内部的名字，这个名字会在链接的时候用到。例如std::string::size()经过修饰后是_ZNKSs4sizeEv。通过添加&amp;quot;-C&amp;quot;选项，可以对底层符号表译成用户级名称（demangle），具有更好的可读性。
以test.cpp为例： 将其编译后，通过nm查看符号表，带&amp;quot;-C&amp;quot;选项与否的结果如下：
readelf 如果你的二进制目标文件（.o）/静态库（.a）/动态库（.so）是ELF（Executableand linkingformat）格式，则可以使用readelf命令提取符号表信息。
readelf -Ws usr/lib/yourLib.so 如果仅想输出函数名，可以通过awk命令进行解析：
readelf -Ws test.o | awk &amp;#39;$4==&amp;#34;FUNC&amp;#34; {print $8}&amp;#39;; 以上面的test.o为例：
显示test.o的elf文件头信息： 显示test.o的符号表：
参考 How do I list the symbols in a .so file nm - Linux man page readelf - Linux man page</description></item><item><title>事务管理器同步机制应用</title><link>https://mryqu.github.io/post/%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E5%BA%94%E7%94%A8/</link><pubDate>Sun, 27 Oct 2013 14:28:32 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E5%BA%94%E7%94%A8/</guid><description>在我目前的项目中，缓存管理器需要根据事务提交状态对应用缓存进行管理。这里对其机制应用做一个小总结。
事务管理器 javax.transaction.TransactionManager接口定义一些方法以便应用服务器管理事务边界，比如获取与当前线程绑定的事务、对事务执行resume和suspend方法。
事务 javax.transaction.Transaction接口允许对目标事务对象执行相关的事务操作。在每个全局事务创建时，Transaction对象也对应的创建出来。 事务对象可以被用来做资源获取(resource enlistment)、同步器注册(synchronizationregistration)、事务结束(transaction completion)和状态查询(statusquery)操作。
事务同步机制 事务管理器通过javax.transaction.Synchronization接口支持一种同步机制。通过对当前事务的目标Transaction对象调用registerSynchronization方法，应用服务器为该事务注册一个Synchronization对象。 事务管理器在启动2PC事务提交过程时,回调Synchronization对象的beforeCompletion方法通知有关部分事务将要被提交；事务管理器在事务已经提交或回滚后,回调Synchronization对象的afterCompletion方法通知有关部分事务的结束状态。 应用一般很少使用beforeCompletion方法，afterCompletion方法使用比较多。在我目前的项目中，就是使用afterCompletion方法来通知缓存管理器对缓存进行更新操作。
实例代码 package com.yqu.transaction; import java.lang.reflect.Method; import javax.naming.InitialContext; import javax.transaction.RollbackException; import javax.transaction.Synchronization; import javax.transaction.SystemException; import javax.transaction.Transaction; import javax.transaction.TransactionManager; public class SynchronizationSample implements Synchronization { private static int wepsphereVer; private static final String WEBSPHERE_TM_FACTORY51 = &amp;#34;com.ibm.ws.Transaction.TransactionManagerFactory&amp;#34;; private static final String WEBSPHERE_TM_FACTORY50 = &amp;#34;com.ibm.ejs.jts.jta.TransactionManagerFactory&amp;#34;; private static final String WEBSPHERE_TM_FACTORY4 = &amp;#34;com.ibm.ejs.jts.jta.JTSXA&amp;#34;; private static final String WEBLOGIC_TM_OBJNAME = &amp;#34;javax.transaction.TransactionManager&amp;#34;; private static final String JBOSS_TM_OBJNAME = &amp;#34;java:/TransactionManager&amp;#34;; private static final String TOMCAT_TM_OBJNAME = &amp;#34;java:comp/env/TransactionManager&amp;#34;; private static final String WEBSPHERE_RECOG_CLASS = &amp;#34;com.</description></item><item><title>[Eclipse] 确认Eclipse是32/64bit的方法</title><link>https://mryqu.github.io/post/eclipse_%E7%A1%AE%E8%AE%A4eclipse%E6%98%AF32%E6%88%9664bit%E7%9A%84%E6%96%B9%E6%B3%95/</link><pubDate>Sat, 26 Oct 2013 22:19:41 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse_%E7%A1%AE%E8%AE%A4eclipse%E6%98%AF32%E6%88%9664bit%E7%9A%84%E6%96%B9%E6%B3%95/</guid><description>两种方法：
打开Eclipse界面：Help -&amp;gt; About Eclipse -&amp;gt; Installation Details -&amp;gt; Configuration，若看到x86字样说明Eclipse是32bit的，若看到x86_64或x64字样则说明Eclipse是64bit的。 查看Eclipse安装目录下的eclipse.ini文件，如果launcher.library设置的值中写的是X86就说明Eclipse是32bit的，如果写的是x86_64或x64则说明Eclipse是64bit的。</description></item><item><title>[JPA] CascadeType.REMOVE与orphanRemoval的区别</title><link>https://mryqu.github.io/post/jpa_cascadetype.remove%E4%B8%8Eorphanremoval%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Sat, 26 Oct 2013 13:15:59 +0000</pubDate><guid>https://mryqu.github.io/post/jpa_cascadetype.remove%E4%B8%8Eorphanremoval%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>Cascading Remove 将引用字段标注为CascadeType.REMOVE（或包含REMOVE的CascadeType.ALL）表明删除操作将应该自动级联到由该字段引用的实体对象（多个实体对象可以由集合字段引用）:
@Entity class Employee { : @OneToOne(cascade=CascadeType.REMOVE) private Address address; : } Orphan Removal JPA2额外支持一种更积极的删除级联模式，可以通过@OneToOne和@OneToMany注释的orphanRemoval元素设置:
@Entity class Employee { : @OneToOne(orphanRemoval=true) private Address address; : } 区别 两个设置的区别在于关系断开的响应。 例如，将地址字段设置为null或另一个Address对象时，不同设置的结果是不同。
如果指定了 orphanRemoval = true，则断开关系的的Address实例将被自动删除。这对于清除没有所有者对象（例如Employee）引用的、不该存在的依赖对象（例如Address）很有用。 如果仅指定 cascade = CascadeType.REMOVE，则不会执行上述自动删除操作，因为断开关系不是删除操作。 参考 Deleting JPA Entity Objects</description></item><item><title>nohup命令笔记</title><link>https://mryqu.github.io/post/nohup%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 26 Oct 2013 11:24:28 +0000</pubDate><guid>https://mryqu.github.io/post/nohup%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</guid><description>Unix/Linux下一般比如想让某个程序在后台运行，很多都是使用 &amp;amp;在程序结尾来让程序自动运行。比如我们要运行mysql在后台：
/usr/local/mysql/bin/mysqld_safe --user=mysql &amp;amp; 但是很多程序并不象mysqld一样做成守护进程，一般普通程序使用 &amp;amp;结尾在后台运行，如果终端关闭了，普通程序还是会被关闭。如果想要在退出帐户/关闭终端之后继续运行相应的普通进程。我们就可以使用nohup这个命令，nohup就是不挂起的意思(nohang up)。
nohup COMMAND [ARG]... nohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加&amp;amp;到命令的尾部。
如果不将 nohup 命令的输出重定向，输出将附加到当前目录的 nohup.out 文件中。如果当前目录的 nohup.out文件不可写，输出重定向到 $HOME/nohup.out 文件中。如果没有文件能创建或打开以用于追加，那么 Command参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。
nohup command &amp;gt; myout.file 2&amp;gt;&amp;amp;1 该命令返回下列出口值：
126：可以查找但不能调用 Command 参数指定的命令。 127：nohup 命令发生错误或不能查找由 Command 参数指定的命令。 其他：Command 参数指定命令的退出状态。 使用jobs查看任务。使用fg %n关闭。</description></item><item><title>切记：Java中long字面量以L结尾</title><link>https://mryqu.github.io/post/%E5%88%87%E8%AE%B0java%E4%B8%ADlong%E5%AD%97%E9%9D%A2%E9%87%8F%E4%BB%A5l%E7%BB%93%E5%B0%BE/</link><pubDate>Sat, 26 Oct 2013 10:30:48 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%87%E8%AE%B0java%E4%B8%ADlong%E5%AD%97%E9%9D%A2%E9%87%8F%E4%BB%A5l%E7%BB%93%E5%B0%BE/</guid><description>最近碰到一个问题，输入是int，要求按无符号整数使用。为了实现要求，升级成long然后与上0xffffffff，结果不正常。问了几个基友，都有点茫然。 问题出在0xffffffff上了，现在就操练一下。
将0xffffffff赋给一个long变量，它的值是多少？
long n = 0xffffffff; System.out.println(Long.toHexString(n)); 结果是0xffffffffffffffff呦！
ffffffffffffffff 将0x000000008fffffff赋给一个long变量，它的值是多少？
long = 0x000000008fffffff; System.out.println(Long.toHexString(n)); 结果是0xffffffff8fffffff呦！！！
ffffffff8fffffff int转换成long的规则是，一个负的int数，会自动扩展符号位，升级成负的long数的。 正确的用法是0xffffffffL，字面量表明是long类型，所以头32位才会全是0。
long = 0xffffffffL; System.out.println(Long.toHexString(n)); 输出结果：
ffffffff</description></item><item><title>[C++] 重温函数隐藏和重写</title><link>https://mryqu.github.io/post/c++_%E9%87%8D%E6%B8%A9%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8F%E5%92%8C%E9%87%8D%E5%86%99/</link><pubDate>Sat, 26 Oct 2013 08:23:25 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E9%87%8D%E6%B8%A9%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8F%E5%92%8C%E9%87%8D%E5%86%99/</guid><description>首先回顾一下C++的重载、隐藏和重写概念：
在相同作用域中，同名不同参的函数称为重载，这是c++多态的一种表现。对相同名字的成员函数，编译器可以根据传递的参数类型调用相应的成员函数。同名不同参的全局函数和类成员函数由于作用域不同，不是重载。不能通过函数返回值进行重载。像int和float这样不同的参数类型，可能会由于隐式转换隐患而无法通过编译。 当派生类中的成员函数/变量和基类中的成员函数/变量同名时，会隐藏基类的成员函数/变量，也就是指在派生类调用这个同名的成员函数/变量，调用的是派生类的成员函数/变量，而不是基类的那个成员函数/变量。可以通过类名::成员函数/变量去访问基类中同名的成员函数/变量。 派生类中的成员函数与基类的成员函数同名同参，就称为重写。当直接访问成员函数调用的是在派生类中重写的函数而不是从基类继承下来的成员函数，如果要访问从基类继承下来的成员函数也是通过类名::成员函数这种方式去调用基类的成员函数。 下面的小示例testOverride.cpp用于测试添加virtual与否对重写的影响：
class BaseClass { public: BaseClass() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } BaseClass(const BaseClass&amp;amp;) { cout &amp;lt;&amp;lt; &amp;#34;BaseClass(BaseClass) on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } virtual void vfun1() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass:vfun1() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } virtual void vfun2() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass:vfun2() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } void fun1() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass:fun1() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } void fun2() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass:fun2() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } virtual ~BaseClass() { cout &amp;lt;&amp;lt; &amp;#34;~BaseClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } }; class DerivedClass : public BaseClass { public: DerivedClass():name(new string(&amp;#34;NULL&amp;#34;)) { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } DerivedClass(const string&amp;amp; n):name(new string(n)) { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass(string) on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } void vfun1() { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass:vfun1() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } void fun1() { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass:fun1() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } ~DerivedClass() { delete name; cout &amp;lt;&amp;lt; &amp;#34;~DerivedClass(): name has been deleted on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } private: void vfun2() { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass:vfun2() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } void fun2() { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass:fun2() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } private: string* name; }; int main() { cout &amp;lt;&amp;lt; &amp;#34;=== test bo1 ===&amp;#34; &amp;lt;&amp;lt; endl; BaseClass* bo1 = new BaseClass(); bo1-&amp;gt;vfun1(); bo1-&amp;gt;vfun2(); bo1-&amp;gt;fun1(); bo1-&amp;gt;fun2(); delete bo1; cout &amp;lt;&amp;lt; &amp;#34;=== test do1 ===&amp;#34; &amp;lt;&amp;lt; endl; DerivedClass* do1 = new DerivedClass(); do1-&amp;gt;vfun1(); // error: &amp;#39;virtual void DerivedClass::vfun2()&amp;#39; is private // within this context // do1-&amp;gt;vfun2(); do1-&amp;gt;fun1(); // error: &amp;#39;void DerivedClass::fun2()&amp;#39; is private // within this context // do1-&amp;gt;fun2(); delete do1; cout &amp;lt;&amp;lt; &amp;#34;=== test bo2 ===&amp;#34; &amp;lt;&amp;lt; endl; BaseClass* bo2 = new DerivedClass(&amp;#34;123&amp;#34;); bo2-&amp;gt;vfun1(); bo2-&amp;gt;vfun2(); bo2-&amp;gt;fun1(); bo2-&amp;gt;fun2(); delete bo2; return 0; } vfun2和fun2在BaseClass类中是public访问权限，而在DerivedClass类中是private访问权限。</description></item><item><title>[Eclipse] Find the override method implementation in subclasses</title><link>https://mryqu.github.io/post/eclipse_find_the_override_method_implementation_in_subclasses/</link><pubDate>Sat, 26 Oct 2013 00:00:39 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse_find_the_override_method_implementation_in_subclasses/</guid><description>已知当前对象为org.apache.hadoop.hdfs.client.HdfsDataInputStream实例，调用其祖宗抽象类java.io.InputStream的publicint read(byte b[], int off, int len) throwsIOException方法，究竟最后使用的是那个类的实现呢？ 由如上类继承图可知，应该从对象类往上依次查找方法实现：HdfsDataInputStream、FSDataInputStream、&amp;hellip;&amp;hellip;。工作很繁琐，挑战眼力！
一个快捷的方式就是进入java.io.InputStream类，选中read(byte b[], int off, intlen) 方法，按住CTRL键后点击鼠标左键，这样会出现一个菜单： 选择OpenImplementation菜单，输入HdfsDataInputStream、FSDataInputStream、&amp;hellip;&amp;hellip;，可以更轻松的找到重写该方法的子类。 最终可知使用的是java.io.DataInputStream类中的实现：
public final int read(byte b[], int off, int len) throws IOException { return in.read(b, off, len); }</description></item><item><title>学习十二要素应用宣言</title><link>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8%E5%AE%A3%E8%A8%80/</link><pubDate>Fri, 25 Oct 2013 22:02:43 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%A6%E4%B9%A0%E5%8D%81%E4%BA%8C%E8%A6%81%E7%B4%A0%E5%BA%94%E7%94%A8%E5%AE%A3%E8%A8%80/</guid><description>Heroku是业内知名的云应用平台，从对外提供服务以来，他们已经有上百万应用的托管和运营经验。大概在去年，创始人Adam Wiggins根据这些经验，发布了一个“十二要素应用宣言（The Twelve-Factor App）”。 简介 如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor为构建如下的SaaS应用提供了方法论：
使用标准化流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的划清界限，在各个系统中提供最大的可移植性。 适合部署在现代的云计算平台，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的差异降至最低，并使用持续交付实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现扩展。 这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。
背景 本文的贡献者者参与过数以百计的应用程序的开发和部署，并通过Heroku平台间接见证了数十万应用程序的开发，运作以及扩展的过程。 本文综合了我们关于 SaaS应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何避免软件污染。 我们的初衷是分享在现代软件开发过程中发现的一些系统性问题，并加深对这些问题的认识。我们提供了讨论这些问题时所需的共享词汇，同时使用相关术语给出一套针对这些问题的广义解决方案。本文格式的灵感来自于Martin Fowler 的书籍：Patterns of Enterprise Application Architecture，Refactoring。
读者应该是哪些人？ 任何SaaS应用的开发人员。部署和管理此类应用的运维工程师。
12-Factors I. 基准代码 一份基准代码，多份部署 12-Factor应用通常会使用版本控制系统加以管理，如Git、Mercurial、Subversion。一份用来跟踪代码所有修订版本的数据库被称作_代码库_（coderepository, code repo, repo）。 在类似 SVN这样的集中式版本控制系统中，_基准代码_就是指控制系统中的这一份代码库；而在Git那样的分布式版本控制系统中，_基准代码_则是指最上游的那份代码库。 基准代码和应用之间总是保持一一对应的关系：
一旦有多个基准代码，就不能称为一个应用，而是一个分布式系统。分布式系统中的每一个组件都是一个应用，每一个应用可以分别使用12-Factor进行开发。 多个应用共享一份基准代码是有悖于12-Factor原则的。解决方案是将共享的代码拆分为独立的类库，然后使用依赖管理策略去加载它们。 尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份_部署_相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署。 所有部署的基准代码相同，但每份部署可以使用其不同的版本。比如，开发人员可能有一些提交还没有同步至预发布环境；预发布环境也有一些提交没有同步至生产环境。但它们都共享一份基准代码，我们就认为它们只是相同应用的不同部署而已。
II. 依赖 显式声明依赖关系 大多数编程语言都会提供一个打包系统，用来为各个类库提供打包服务，就像Perl的CPAN或是Ruby的Rubygems。通过打包系统安装的类库可以是系统级的（称之为 &amp;ldquo;sitepackages&amp;rdquo;），或仅供某个应用程序使用，部署在相应的目录中（称之为 &amp;ldquo;vendoring&amp;rdquo; 或 &amp;ldquo;bunding&amp;rdquo;）。 **12-Factor规则下的应用程序不会隐式依赖系统级的类库。**它一定通过_依赖清单_，确切地声明所有依赖项。此外，在运行过程中通过_依赖隔离_工具来确保程序不会调用系统中存在但清单中未声明的依赖项。这一做法会统一应用到生产和开发环境。 例如，Ruby的Gem Bundler使用Gemfile 作为依赖项声明清单，使用bundle exec 来进行依赖隔离。Python中则可分别使用两种工具 &amp;ndash; Pip用作依赖声明，Virtualenv用作依赖隔离。甚至C语言也有类似工具，Autoconf用作依赖声明，静态链接库用作依赖隔离。无论用什么工具，依赖声明和依赖隔离必须一起使用，否则无法满足12-Factor规范。 显式声明依赖的优点之一是为新进开发者简化了环境配置流程。新进开发者可以检出应用程序的基准代码，安装编程语言环境和它对应的依赖管理工具，只需通过一个_构建命令_来安装所有的依赖项，即可开始工作。例如，Ruby/Bundler下使用bundle install ，而Clojure/Leiningen则是lein deps。 12-Factor应用同样不会隐式依赖某些系统工具，如ImageMagick或是curl 。即使这些工具存在于几乎所有系统，但终究无法保证所有未来的系统都能支持应用顺利运行，或是能够和应用兼容。如果应用必须使用到某些系统工具，那么这些工具应该被包含在应用之中。
III. 配置 在环境中存储配置 通常，应用的_配置_在不同部署(预发布、生产环境、开发环境等等)间会有很大差异。这其中包括：
数据库，Memcached，以及其他后端服务的配置 第三方服务的证书，如 Amazon S3、Twitter等 每份部署特有的配置，如域名等 有些应用在代码中使用常量保存配置，这与12-Factor所要求的代码和配置严格分离显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。 判断一个应用是否正确地将配置排除在代码之外，一个简单的方法是看该应用的基准代码是否可以立刻开源，而不用担心会暴露任何敏感的信息。 需要指出的是，这里定义的&amp;quot;配置&amp;quot;并不包括应用的内部配置，比如Rails的config/routes.</description></item><item><title>[C++] 重温析构函数</title><link>https://mryqu.github.io/post/c++_%E9%87%8D%E6%B8%A9%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0/</link><pubDate>Fri, 25 Oct 2013 21:11:16 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E9%87%8D%E6%B8%A9%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0/</guid><description>创建一个C++对象时，一般先调用父类构造函数，再调用自己的构造函数；而在销毁一个C++对象时，一般先调用自己的析构函数，再调用父类的析构函数。我用如下testDestructor.cpp进行测试。
class BaseClass { public: BaseClass() { cout &amp;lt;&amp;lt; &amp;#34;BaseClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } ~BaseClass() { cout &amp;lt;&amp;lt; &amp;#34;~BaseClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } }; class DerivedClass : public BaseClass { public: DerivedClass():name(new string(&amp;#34;NULL&amp;#34;)) { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass() on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } DerivedClass(const string&amp;amp; n):name(new string(n)) { cout &amp;lt;&amp;lt; &amp;#34;DerivedClass(string) on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } ~DerivedClass() { delete name; cout &amp;lt;&amp;lt; &amp;#34;~DerivedClass(): name has been deleted on &amp;#34; &amp;lt;&amp;lt; this &amp;lt;&amp;lt; endl; } private: string* name; }; int main() { cout &amp;lt;&amp;lt; &amp;#34;=== test bo1 ===&amp;#34; &amp;lt;&amp;lt; endl; BaseClass* bo1 = new BaseClass(); delete bo1; cout &amp;lt;&amp;lt; &amp;#34;=== test do1 ===&amp;#34; &amp;lt;&amp;lt; endl; DerivedClass* do1 = new DerivedClass(); delete do1; cout &amp;lt;&amp;lt; &amp;#34;=== test bo2 ===&amp;#34; &amp;lt;&amp;lt; endl; BaseClass* bo2 = new DerivedClass(&amp;#34;123&amp;#34;); delete bo2; cout &amp;lt;&amp;lt; &amp;#34;=== test bo3 ===&amp;#34; &amp;lt;&amp;lt; endl; BaseClass bo3 = DerivedClass(&amp;#34;321&amp;#34;); return 0; } 输出结果如下：</description></item><item><title>[HBase] HBase Shell交互实践</title><link>https://mryqu.github.io/post/hbase_hbase_shell%E4%BA%A4%E4%BA%92%E5%AE%9E%E8%B7%B5/</link><pubDate>Fri, 25 Oct 2013 20:12:48 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_hbase_shell%E4%BA%A4%E4%BA%92%E5%AE%9E%E8%B7%B5/</guid><description>HBase Shell是对HBase的脚本接口，是一个JRuby REPL(Read-Eval-PrintLoop，“读取-求值-输出”循环)，可以通过脚本访问所有HBase客户端API。
单列族练习 创建表friends $ hbase shell hbase(main):001:0&amp;gt; list TABLE customer 1 row(s) in 0.2050 seconds =&amp;gt; [&amp;#34;customer&amp;#34;, &amp;#34;student&amp;#34;] hbase(main):002:0&amp;gt; create &amp;#39;friends&amp;#39;, &amp;#39;d&amp;#39; 0 row(s) in 1.3350 seconds =&amp;gt; Hbase::Table - friends hbase(main):003:0&amp;gt; list TABLE customer friends 2 row(s) in 0.0060 seconds =&amp;gt; [&amp;#34;customer&amp;#34;, &amp;#34;friends&amp;#34;, &amp;#34;student&amp;#34;] 获得表friends的描述说明 hbase(main):004:0&amp;gt; describe &amp;#39;friends&amp;#39; Table friends is ENABLED friends COLUMN FAMILIES DESCRIPTION {NAME =&amp;gt; &amp;#39;d&amp;#39;, DATA_BLOCK_ENCODING =&amp;gt; &amp;#39;NONE&amp;#39;, BLOOMFILTER =&amp;gt; &amp;#39;ROW&amp;#39;, REPLICATION_SCO PE =&amp;gt; &amp;#39;0&amp;#39;, VERSIONS =&amp;gt; &amp;#39;1&amp;#39;, COMPRESSION =&amp;gt; &amp;#39;NONE&amp;#39;, MIN_VERSIONS =&amp;gt; &amp;#39;0&amp;#39;, TTL =&amp;gt; &amp;#39;FO REVER&amp;#39;, KEEP_DELETED_CELLS =&amp;gt; &amp;#39;FALSE&amp;#39;, BLOCKSIZE =&amp;gt; &amp;#39;65536&amp;#39;, IN_MEMORY =&amp;gt; &amp;#39;false&amp;#39;, BLOCKCACHE =&amp;gt; &amp;#39;true&amp;#39;} 1 row(s) in 0.</description></item><item><title>[Linux] 判断可执行文件或动态库是否包含符号表</title><link>https://mryqu.github.io/post/linux_%E5%88%A4%E6%96%AD%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E6%88%96%E5%8A%A8%E6%80%81%E5%BA%93%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E7%AC%A6%E5%8F%B7%E8%A1%A8/</link><pubDate>Thu, 24 Oct 2013 22:48:09 +0000</pubDate><guid>https://mryqu.github.io/post/linux_%E5%88%A4%E6%96%AD%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E6%88%96%E5%8A%A8%E6%80%81%E5%BA%93%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E7%AC%A6%E5%8F%B7%E8%A1%A8/</guid><description>在Linux下生成一个可执行文件或动态库，可以使用gcc/g++的&amp;quot;-g&amp;quot;选项使文件包含调试符号表。 要在Linux下判断一个第三方的可执行文件或动态库是否包含调试符号表，可以通过file命令实现：
srv01&amp;gt; file libcurl.so.6 libcurl.so.6: ELF 64-bit LSB shared object, x86-64, version 1 (FreeBSD), dynamically linked, not stripped srv01&amp;gt; file /usr/bin/X11/curl /usr/bin/X11/curl: ELF 64-bit LSB executable, x86-64, version 1 (FreeBSD), dynamically linked (uses shared libs), for FreeBSD 8.0 (800107), stripped 显示not stripped，表明文件带调试符号表；而显示stripped，表明文件已去除符号表。
如果文件包含调试符号表，可以通过objdump -t命令及选项打印文件的符号表：
srv01&amp;gt; objdump -t libcurl.so.6 libcurl.so.6: file format elf64-x86-64 SYMBOL TABLE: 0000000000000120 l d .hash 0000000000000000 00000000000012b0 l d .dynsym 0000000000000000 0000000000004b08 l d .dynstr 0000000000000000 0000000000006f36 l d .</description></item><item><title>[C] GCC对UTF8 BOM的支持</title><link>https://mryqu.github.io/post/c_gcc%E5%AF%B9utf8_bom%E7%9A%84%E6%94%AF%E6%8C%81/</link><pubDate>Thu, 24 Oct 2013 20:31:28 +0000</pubDate><guid>https://mryqu.github.io/post/c_gcc%E5%AF%B9utf8_bom%E7%9A%84%E6%94%AF%E6%8C%81/</guid><description>最近玩些特俗字符，结果对yqutest.cpp源码文件编译时先碰到error:converting to execution character set: Illegal bytesequence错误。GCC的源码字符集与执行字符集默认是UTF-8编码，为了避免源码文件乱码，最好也是采用UTF-8编码来存储源码文件。将源码编码转成UTF-8，问题得以解决。 但是否需要UTF-8 BOM(byte-order mark)呢？ 我一时兴起添加了BOM，十六进制为EF BB BF，即对应八进制的357 273 277，编译结果如下：
mryqu&amp;gt; g++ yqutest.cpp -o yqutst123 yqutest.cpp:1: error: stray &amp;#39;\357&amp;#39; in program yqutest.cpp:1: error: stray &amp;#39;\273&amp;#39; in program yqutest.cpp:1: error: stray &amp;#39;\277&amp;#39; in program yqutest.cpp:1: error: stray &amp;#39;#&amp;#39; in program yqutest.cpp:1: error: expected constructor, destructor, or type conversion before &amp;#39;&amp;lt;&amp;#39; token mryqu&amp;gt; g++ -v Using built-in specs. Target: amd64-undermydesk-freebsd Configured with: FreeBSD/amd64 system compiler Thread model: posix gcc version 4.</description></item><item><title>*nux下导出文件16进制内容的命令xxd</title><link>https://mryqu.github.io/post/linux%E4%B8%8B%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B616%E8%BF%9B%E5%88%B6%E5%86%85%E5%AE%B9%E7%9A%84%E5%91%BD%E4%BB%A4xxd/</link><pubDate>Thu, 24 Oct 2013 19:16:18 +0000</pubDate><guid>https://mryqu.github.io/post/linux%E4%B8%8B%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B616%E8%BF%9B%E5%88%B6%E5%86%85%E5%AE%B9%E7%9A%84%E5%91%BD%E4%BB%A4xxd/</guid><description>xxd命令可以导出文件的16进制内容，也能将16进制内容转换成2进制，还可以将内容导出成C语言变量，很不错的一个工具！ 参考 xxd(1) - Linux man page 5 Unix Commands I Wish I’d Discovered Years Earlier</description></item><item><title>[C++] 从静态库获取GCC版本和编译平台</title><link>https://mryqu.github.io/post/c++_%E4%BB%8E%E9%9D%99%E6%80%81%E5%BA%93%E8%8E%B7%E5%8F%96gcc%E7%89%88%E6%9C%AC%E5%92%8C%E7%BC%96%E8%AF%91%E5%B9%B3%E5%8F%B0/</link><pubDate>Thu, 24 Oct 2013 07:43:44 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E4%BB%8E%E9%9D%99%E6%80%81%E5%BA%93%E8%8E%B7%E5%8F%96gcc%E7%89%88%E6%9C%AC%E5%92%8C%E7%BC%96%E8%AF%91%E5%B9%B3%E5%8F%B0/</guid><description>获取GCC版本：strings -a {library} | grep &amp;ldquo;GCC: (&amp;rdquo;
mryqu&amp;gt; strings -a libcurl.a | grep &amp;#34;GCC: (&amp;#34; GCC: (GNU) 4.4.5 20110214 (Red Hat 4.4.5-6) 获取编译平台信息：ar -x {library}file *.o
mryqu&amp;gt; ar -x libcurl.a mryqu&amp;gt;file libcurl_la-url.o libcurl_la-url.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped 参考 How to retrieve the GCC version used to compile a given ELF executable? How to see the compilation platform of a static library file</description></item><item><title>用find和grep搜索特定目录下特定文件中的特定关键字</title><link>https://mryqu.github.io/post/%E7%94%A8find%E5%92%8Cgrep%E6%90%9C%E7%B4%A2%E7%89%B9%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E7%89%B9%E5%AE%9A%E5%85%B3%E9%94%AE%E5%AD%97/</link><pubDate>Wed, 23 Oct 2013 19:58:54 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%94%A8find%E5%92%8Cgrep%E6%90%9C%E7%B4%A2%E7%89%B9%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E7%89%B9%E5%AE%9A%E5%85%B3%E9%94%AE%E5%AD%97/</guid><description>下例为递归搜索当前目录下所有以yqu为后缀的文件中的关键字123：
find . -name &amp;#34;*.yqu&amp;#34; | xargs grep -H &amp;#34;123&amp;#34;</description></item><item><title>cut命令笔记</title><link>https://mryqu.github.io/post/cut%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 22 Oct 2013 23:22:24 +0000</pubDate><guid>https://mryqu.github.io/post/cut%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</guid><description>cut命令比较简单，但是也没测试过所有的选项，这里试一下没有细扣过的选项。
命令名 cut -- 对文件每一行的选定部分进行裁剪 概要 cut -b list [-n] [file ...] cut -c list [file ...] cut -f list [-d delim] [-s] [file ...] 描述 cut工具会从每个文件每一行裁剪出选定部分并写入标准输出。如果没有指定file参数，或file参数为单个破折号(&amp;#39;-&amp;#39;)，cut将从标准输入进行读取。list指定可以是列位置或特定字符分隔的字段序号，起始值为1。 list选项参数为逗号或空白字符分隔的数字或数字范围集合。数字范围可由数字+破折号（&amp;#39;-&amp;#39;）+第二个数字组成内包含范围。 数字和数字范围可以重复、重叠，但字段或列如果多次被选中，则仅显示一次。输入中没有选定的字段或列，不会报错。 N- 从第N个开始到所在行结束的所有字节、字符或列 N-M 从第N个开始到第M个之间(包括第M个)的所有字节、字符或列 -M 从第1个开始到第M个之间(包括第M个)的所有字节、字符或列 命令选项如下： -b list list指定字节位置。 -c list list指定字符位置。 -d delim 使用delim而不是制表符作为字段分隔符。 -f list list指定由字段分隔符(见-d选项)对输入分割后的字段。 输出字段由单个字段分隔符分开。 -n 不拆分多字节字符。 仅在多字节字符全部选中的情况下，字符才会被输出。 -s 抑制没有字段分隔符的行。如果没指定该选项的话，没有分隔符的行会原封不动地输出。 环境 环境变量LANG、LC_ALL和LC_CTYPE将影响cut的执行结果。 退出码 cut工具执行成功时返回0，执行出错时返回值大于0。 示例 从系统passwd文件抽取用户登录名和Shell(5)，显示成&amp;#39;&amp;#39;name:shell&amp;#39;&amp;#39;对: cut -d : -f 1,7 /etc/passwd 显示当前登录用户的名称和登录时间: who | cut -c 1-16,26-38 个人体会 cut命令在unix/mac和linux/MinGW上实现并不一样。 cut命令在linux/MinGW上的实现忽略-n选项，此外通过GNU CoreUtils中的cut源码可知-b和-c选项实现是一样的，operating_mode变量都是枚举byte_mode，走的是cut_bytes函数。而unix/mac上的实现通过-n选项可以同时是否输出多字节字符的部分字节码。 cut命令在linux/MinGW上的实现还有&amp;ndash;output-delimiter=STRING选项控制输出字符分隔符。</description></item><item><title>grep命令笔记</title><link>https://mryqu.github.io/post/grep%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 22 Oct 2013 22:52:04 +0000</pubDate><guid>https://mryqu.github.io/post/grep%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</guid><description>使用grep时一直没有使用什么命令选项，这里过一遍grep帮助，试一遍不明白的选项。
grep简介 grep是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。
grep命令帮助 示例: grep -i &amp;#39;hello world&amp;#39; menu.h main.c 正则选择和解释: -E, --extended-regexp PATTERN为扩展正则表达式（ERE） -F, --fixed-strings PATTERN是一套新行分割字符串 -G, --basic-regexp PATTERN为基本正则表达式（BRE） -P, --perl-regexp PATTERN为Perl正则表达式 -e, --regexp=PATTERN 使用PATTERN作为正则表达式 -f, --file=FILE 从文件中获得PATTERN -i, --ignore-case 忽略大小写 -w, --word-regexp 强制PATTERN仅匹配整个单词 -x, --line-regexp 强制PATTERN仅匹配整行 -z, --null-data 数据行以0字节而不是新行截至（打印整个文件了） 杂项: -s, --no-messages 抑制错误消息 -v, --invert-match 选择非匹配行 -V, --version 显示版本信息并退出 --help 显示该帮助并退出 -J, --bz2decompress 在进行搜索前解压缩bzip压缩输入 -Z, --decompress 在进行搜索前解压缩输入(HAVE_LIBZ=1) --mmap 如可能使用内存映射输入 输出控制: -m, --max-count=NUM 在NUM个匹配后停止工作 -b, --byte-offset 在输出行显示字节偏移 -n, --line-number 显示行号 --line-buffered 对每行都清除缓存强制输出 -H, --with-filename 对每个匹配结果显示文件名 -h, --no-filename 抑制输出中前缀的文件名 --label=LABEL 将LABEL作为标准输入的文件名显示（输入为管道有用） -o, --only-matching 仅显示行匹配PATTERN部分 -q, --quiet, --silent 抑制所有正常输出。通常用于脚本条件语句中，判断匹配结果是1还是0 --binary-files=TYPE 将二进制文件假定为类型，分别为&amp;#39;binary&amp;#39;、&amp;#39;text&amp;#39;或 &amp;#39;without-match&amp;#39;。默认为&amp;#39;binary&amp;#39;，对二进制文件进行搜索 而不显示；&amp;#39;text&amp;#39;，一概视为文本文件，搜索并显示； &amp;#39;without-match&amp;#39;，对二进制文件直接忽略，不搜索不显示。 -a, --text 等同于--binary-files=text -I 等同于--binary-files=without-match -d, --directories=ACTION 如何处理目录的操作项，分别为&amp;#39;read&amp;#39;、&amp;#39;recurse&amp;#39;或&amp;#39;skip&amp;#39;。 -D, --devices=ACTION 如何处理设备、FIFO和socket的操作项，分别为&amp;#39;read&amp;#39;或&amp;#39;skip&amp;#39;。 -R, -r, --recursive 等同于--directories=recurse --include=PATTERN 匹配PATTERN的文件将被检查 --exclude=PATTERN 匹配PATTERN的文件将被忽略 --exclude-from=FILE 匹配模式文件中PATTERN的文件将被忽略 -L, --files-without-match 仅显示不包含匹配的文件名 -l, --files-with-matches 仅显示包含匹配的文件名 -c, --count 仅显示每个文件匹配行数 --null 在文件名后显示0字节（跟不带这个选项就少一个冒号？） 上下文控制: -B, --before-context=NUM 输出匹配结果及其前NUM行 -A, --after-context=NUM 输出匹配结果及其后NUM行 -C, --context=NUM 输出匹配结果及其前后各NUM行 -NUM 等同--context=NUM --color[=WHEN], --colour[=WHEN] 使用标记突显匹配字符串，WHEN可为&amp;#39;always&amp;#39;、&amp;#39;never&amp;#39;或&amp;#39;auto&amp;#39; 默认项为&amp;#39;never&amp;#39;，&amp;#39;always&amp;#39;总是使用标记，而&amp;#39;auto&amp;#39;仅输出 在没有被管道到其他命令或重定向到文件时才使用标记。 -U, --binary 在行结尾EOL不除去回车换行CR字符(MSDOS) -u, --unix-byte-offsets 如果没有回车换行则报告字节偏移(MSDOS)</description></item><item><title>Xterm DISPLAY变量</title><link>https://mryqu.github.io/post/xterm_display%E5%8F%98%E9%87%8F/</link><pubDate>Mon, 21 Oct 2013 20:49:10 +0000</pubDate><guid>https://mryqu.github.io/post/xterm_display%E5%8F%98%E9%87%8F/</guid><description>DISPLAY变量的格式为[host]:&amp;lt;display&amp;gt;[.screen] host 指网络主机名，空缺则指本机。 每个主机可以有多个显示，每个显示可以有多个屏幕。因此，DISPLAY=:0通常指本机内的所有GPU，DISPLAY=:0.0指本机内的第一个配置屏幕/GPU，DISPLAY=:0.1指本机内的第二个配置屏幕/GPU。</description></item><item><title>Xming使用笔记</title><link>https://mryqu.github.io/post/xming%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 21 Oct 2013 20:20:36 +0000</pubDate><guid>https://mryqu.github.io/post/xming%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid><description>XWindow系统里有一个统一的Server来负责各个程序与显示器、键盘和鼠标等输入输出设备的交互，每个有GUI的应用程序都通过网络协议与Server进行交互。所以对于任何一个应用程序，本地运行和远程运行的差别仅仅是XServer的地址不同，别的没有差别。所以在Windows运行一个XServer，就可以很方便的远程运行有GUI的Linux应用了。 Xming是一个在Microsoft Windows操作系统上运行XWindow系统的服务器。它非常简单易用，搭配强大。一般搭配putty的下列配置，就可以在Windows平台上远程运行有GUI的Linux应用了：
Connection-SSH-X11-Enable X11 forwarding Xming操作笔记如下：
选择单词：双击鼠标左键 选择一行：三击鼠标左键 选择特定文本：鼠标左键点击文本起点，然后按住鼠标右键选择。 复制文本：Alt + Shift + C</description></item><item><title>[Hadoop] hadoop job -list已废弃</title><link>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</link><pubDate>Sun, 20 Oct 2013 22:04:34 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</guid><description>执行hadoop job -list，显示该命令已废弃，不过还能执行成功。
~$ hadoop job -list DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it. 看一下Hadoop 2.2.0的代码hadoop-common-project/hadoop-common/src/main/bin/hadoop：
#hdfs commands namenode|secondarynamenode|datanode|dfs|dfsadmin|fsck|balancer|fetchdt|oiv|dfsgroups|portmap|nfs3) echo &amp;#34;DEPRECATED: Use of this script to execute hdfs command is deprecated.&amp;#34; 1&amp;gt;&amp;amp;2 echo &amp;#34;Instead use the hdfs command for it.&amp;#34; 1&amp;gt;&amp;amp;2 echo &amp;#34;&amp;#34; 1&amp;gt;&amp;amp;2 #try to locate hdfs and if present, delegate to it. shift if [ -f &amp;#34;${HADOOP_HDFS_HOME}&amp;#34;/bin/hdfs ]; then exec &amp;#34;${HADOOP_HDFS_HOME}&amp;#34;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;#34;$@&amp;#34; elif [ -f &amp;#34;${HADOOP_PREFIX}&amp;#34;/bin/hdfs ]; then exec &amp;#34;${HADOOP_PREFIX}&amp;#34;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;#34;$@&amp;#34; else echo &amp;#34;HADOOP_HDFS_HOME not found!</description></item><item><title>[C] Exec format error</title><link>https://mryqu.github.io/post/c_exec_format_error/</link><pubDate>Sun, 20 Oct 2013 17:28:57 +0000</pubDate><guid>https://mryqu.github.io/post/c_exec_format_error/</guid><description>很久没用g++了，结果编个小程序还出错。
mryqu:~/ctest$ g++ -g -c wvc.cpp -o wvc mryqu:~/ctest$ chmod a+x wvc mryqu:~/ctest$ ./wvc -bash: ./wvc: cannot execute binary file: Exec format error mryqu:~/ctest$ file wvc wvc: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped 查了查gcc的帮助，才发现用了-c选项后其实是只编译不链接的：
-c Compile or assemble the source files, but do not link. The linking stage simply is not done. The ultimate output is in the form of an object file for each source file.</description></item><item><title>批处理：搜索Jar包中的类文件</title><link>https://mryqu.github.io/post/%E6%89%B9%E5%A4%84%E7%90%86%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 20 Oct 2013 15:55:59 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%89%B9%E5%A4%84%E7%90%86%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%96%87%E4%BB%B6/</guid><description>网上转载的很多，原文出处不详。
批处理文件利用7z和findstr两个命令搜索当前目录下所有Jar包，分析是否有所要查找的类文件：
@echo off SETLOCAL set WHICH_CLASS=%1 echo WHICH_CLASS=%WHICH_CLASS% for /F %%i in (&amp;#39;dir /A:-D /S /B *.jar&amp;#39;) do 7z l %%i | findstr %WHICH_CLASS% &amp;amp;&amp;amp; echo %WHICH_CLASS% found in: &amp;#34;%%i&amp;#34; echo &amp;#34;Finished class finding...&amp;#34; echo &amp;#34;======================================&amp;#34; ENDLOCAL 命令运行格式：
findclass com\\yqu\\kxmt\\TestFindClass.class</description></item><item><title>[C] #和##宏操作符</title><link>https://mryqu.github.io/post/c_%E5%AE%8F%E6%93%8D%E4%BD%9C%E7%AC%A6/</link><pubDate>Sun, 20 Oct 2013 10:45:24 +0000</pubDate><guid>https://mryqu.github.io/post/c_%E5%AE%8F%E6%93%8D%E4%BD%9C%E7%AC%A6/</guid><description>在看# and ## in macros之前觉得对#和##宏操作符挺明白的，看了之后才感觉需要重新学习一下。
#define f(a,b) a##b #define g(a) #a #define h(a) g(a) int main() { printf(&amp;#34;%s\n&amp;#34;,h(f(1,2))); printf(&amp;#34;%s\n&amp;#34;,g(f(1,2))); return 0; } 如果你能确保自己能写出正确答案的话，那么你可以略过这篇帖子。 C/C++语言中对宏的处理属于编译器预处理的范畴，属于编译期概念而非运行期概念。其中#操作符用于对指定的宏参数进行字符串化，而##操作符用来将两个符号连接为一个符号。
struct command { char *name; void (*function) (void); }; ``` #define COMMAND(NAME) \ { #NAME, NAME ## _command } struct command commands[] = { COMMAND (quit), COMMAND (help), … };
&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;等同&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt; struct command commands[] = { { &amp;ldquo;quit&amp;rdquo;, quit_command }, { &amp;ldquo;help&amp;rdquo;, help_command }, … };</description></item><item><title>在Vi中搜索多字节unicode字符</title><link>https://mryqu.github.io/post/%E5%9C%A8vi%E4%B8%AD%E6%90%9C%E7%B4%A2%E5%A4%9A%E5%AD%97%E8%8A%82unicode%E5%AD%97%E7%AC%A6/</link><pubDate>Sun, 20 Oct 2013 09:00:49 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%9C%A8vi%E4%B8%AD%E6%90%9C%E7%B4%A2%E5%A4%9A%E5%AD%97%E8%8A%82unicode%E5%AD%97%E7%AC%A6/</guid><description>使用Vi编辑unicode字符文本文件时，可以通过下列方式搜索和替换字符：
\%d 匹配特定十进制字符 (例如 \%d 123) \%x 匹配特定十六进制字符 (例如 \%x2a) \%o 匹配特定八进制字符 (例如 \%o040) \%u 匹配特定多字节字符 (例如 \%u20ac) \%U 匹配特定大的多字节字符(例如 \%U12345678) 为了在文本中查看任何字符的unicode或十六机制格式内容，将光标置于该字符上之后输入ga 命令。这会以十进制、十六机制和八进制显示显示字符值：</description></item><item><title>Chrome使用笔记</title><link>https://mryqu.github.io/post/chrome-notes/</link><pubDate>Sat, 19 Oct 2013 21:15:28 +0000</pubDate><guid>https://mryqu.github.io/post/chrome-notes/</guid><description>清除Chrome中特定网站的所有历史记录 （2013-10-19） 想要Chrome中特定网站的所有历史记录，可是搜出特定网站的所有历史记录后必须对每一项进行选择，然后才能删除。终于在网上搜出一个妙招来：
进入Chrome历史记录页面； 搜索想要删除的URL； 为了删除所搜结果的所有记录，将第一个待删项的checkbox勾选上，接着滚动页面到最后一个待删项，按住SHIFT键将最后一个待删项的checkbox勾选上，这样所有待删项都会被勾选上； 点击&amp;quot;Remove selected items&amp;quot;按钮即可。 Chrome浏览器离线安装包下载地址 （2013-12-12） http://www.google.com/chrome/eula.html?standalone=1&amp;amp;hl=zh-CN
一键保存当前打开的所有标签页 （2014-01-22） 经常是用Chrome打开一堆网页，但是由于某种原因必须重启机器，不想将这些页面存入书签，但是又想保存下来开机后继续浏览。
在网上搜了一下，下列Chrome插件可以满足这个需求：
OneTab Session Buddy PanicButton Stash Read Later VIEW LATER Save For Later 其中OneTab 和Session Buddy 都是五星插件，并且用户众多，最终我选择了 OneTab 。
在chrome控制台中加载Javascript文件 （2014-02-02） Include javascript file in chrome console 里面介绍了几种在Chrome控制台加载Javascript文件的方法，对我来说使用JQuery是最方便的做法。
$.getScript(&amp;#39;script.js&amp;#39;); 手工修改Chrome配置文件 （2014-03-02） 当初装Chrome，g.cn上死活下载不了，随便装了一个澳洲版的。结果访问taobao、weibo被认成了澳洲用户，都被推到了海外入口。
一开始折腾Chrome的配置菜单，没找到。后来直接修改C:\Users\AppData\Local\Google\Chrome\UserData\Default\Preferences搞定了。
原始值：
&amp;#34;last_known_google_url&amp;#34;: &amp;#34;https://www.google.com.au/&amp;#34;, &amp;#34;last_prompted_google_url&amp;#34;: &amp;#34;https://www.google.com.au/&amp;#34;, 修改后：
&amp;#34;last_known_google_url&amp;#34;: &amp;#34;https://www.google.com.hk/&amp;#34;, &amp;#34;last_prompted_google_url&amp;#34;: &amp;#34;https://www.google.com.hk/&amp;#34;, Chrome Extension记录 （2019-01-23） 重装机器后发现Chrome扩展工具需要重装，现搜了事。为了便于以后重装，特此记录。
LinkedIn Extension
OneTab
网页截图 - Screenshot Extension
Postman</description></item><item><title>Cscope笔记</title><link>https://mryqu.github.io/post/cscope%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 19 Oct 2013 20:20:11 +0000</pubDate><guid>https://mryqu.github.io/post/cscope%E7%AC%94%E8%AE%B0/</guid><description>Cscope简介 Cscope是一个类似Ctags的工具，但功能比ctags强大很多。Cscope是一款自带一个基于文本的用户界面的源代码浏览工具，尽管它最初是为C代码的搜索（包括lex、yacc文件）设计的，但是也可以用于对C++和Java代码的搜索。用Cscope你可以轻易地搜索到你的标识符是在哪里被定义和使用的，它可以轻而易举地解决以下问题：
这个变量在哪里被使用？ 这个预处理符号的值是什么？ 这个函数都在哪些源代码文件中出现过？ 都有哪些函数调用了这个函数？ &amp;ldquo;out of space&amp;quot;的消息是从哪里来的？ 这个源文件在在目录结构中的位置？ 都有哪些源文件包含了这个头文件？ Cscope是由Santa Cruz Operation, Inc发布的，它遵循BSD开源协议。
安装 Cscope项目仅提供源代码，不提供二进制文件。cscope-win32项目提供了使用MinGW、MSYS和Cygwin编译Windows平台Cscope的方法，此外也提供编译好好的csope.exe文件。下载cscope-15.8a-win64rev1-static.zip，将其中的cscope.exe解压缩到系统环境变量path包含的路径即可。 使用 创建符号数据库 Cscope在第一次被使用在指定的源文件时会建立一个符号的数据库。接下来调用时，Cscope仅仅重建那些被改动或者和新文件相关的数据库。那些没有被改动的文件相关的数据库会被直接复制使用。这使得重建数据库要比第一次运行快许多。 Cscope命令的参数如下：
-R: 在生成索引文件时，搜索子目录树中的代码 -b: 只生成索引文件，不进入cscope的界面 -q:生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度 -k: 在生成索引文件时，不搜索/usr/include目录 -i:如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪儿去找源文件列表。可以使用”-“，表示由标准输入获得文件列表。 -Idir:在**-I**选项指出的目录中查找头文件 -u: 扫描所有文件，重新生成交叉索引文件 -C: 在搜索时忽略大小写 -Ppath:在以相对路径表示的文件前加上的path，这样，你不用切换到你数据库文件所在的目录也可以使用它了。 我针对curl项目执行cscope -Rkq ，这样会启动Cscope的文本用户界面，之后我搜索set_binmode函数： 搜索符号 在Cscope的文本界面里可以在命令模式执行:cs find或:cs f命令搜索符号，其参数为：
s: 查找C语言符号，即查找函数名、宏、枚举值等出现的地方 g: 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能 d: 查找本函数调用的函数 c: 查找调用本函数的函数 t: 查找指定的字符串 e: 查找egrep模式，相当于egrep功能，但查找速度快多了 f: 查找并打开文件，类似vim的find功能 i: 查找包含本文件的文件 下面示例为用
:cs f c set_binmode 命令搜索set_binmode函数的调用者：
E567: no cscope connections错误处理 有个帖子vim cannot connect to cscope database讲过解决方案，但是在我的Windows平台cscope文本界面不起作用。通过:cs add {prj path}/cscope.</description></item><item><title>Exuberant Ctags笔记</title><link>https://mryqu.github.io/post/exuberant_ctags%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 19 Oct 2013 14:46:08 +0000</pubDate><guid>https://mryqu.github.io/post/exuberant_ctags%E7%AC%94%E8%AE%B0/</guid><description>Ctags简介 Ctags（Generate tag files for sourcecode）产生标记(/索引)文件以帮助在源文件中定位对象。Ctags最初支持C语言，现在已经支持C/C++/Java/JS/Python等41种语言。Vim/Emacs/SublimeText/UltraEdit等编辑器或工具都支持Ctags生成的标记文件。 对于C/C++语言来说，其生成的标记文件tags中包括这些对象的列表：
用#define定义的宏 枚举型变量的值 函数的定义、原型和声明 名字空间（namespace） 类型定义（typedefs） 变量（包括定义和声明） 类（class）、结构（struct）、枚举类型（enum）和联合（union） 类、结构和联合中成员变量或函数 安装 下载ctags58.zip，将其中的ctags.exe解压缩到系统环境变量path包含的路径即可。 使用选项 如果没有指定−−language−force选项，每个源文件的语言基于文件名和语言的映射进行自动选择。该映射可用−−list−maps选项显示，它可能会被−−langmap选项改变。对于操作系统所支持的文件，如果文件名无法映射到某种语言且该文件可被执行，则会对文件第一行检查是为&amp;quot;#!&amp;ldquo;公认的语言脚本。默认情况下，所有其他文件名都会被忽略。由于仅文件名可匹配某种语言的文件会被扫描，这使得在单个目录对所有文件(例如&amp;quot;ctags*&amp;quot;)或对目录树的所有文件(例如&amp;quot;ctags −R&amp;rdquo;)执行ctags成为可能。.h扩展名即用于C++也用于C，所以Ctags将.h映射为C++，这样做不会有不良后果。
-R：等同于&amp;ndash;recurse，递归子目录遍历 -L：从文件读取Ctags待处理文件列表并对其执行ctags find . -name &amp;#34;*.h&amp;#34; -o -name &amp;#34;*.c&amp;#34; -o -name &amp;#34;*.cpp&amp;#34; -o -name &amp;#34;*.bld&amp;#34; -o -name &amp;#34;*.blt&amp;#34; &amp;gt; prj.files ctags -L prj.files --list−maps：显示文件名和语言的映射 --list−languanges：显示所有支持的语言 --langmap：设置文件名和语言的映射 如果程序中有的.c文件其实是C++程序，这该怎么办？答案是使用ctags &amp;ndash;langmap=c++:+.c。 −−language−force：强制使用特定语言，而不是通过文件名和语言的映射进行自动选择 像C++标准库stl中文件名没有后缀，怎么办？ 使用ctags−−language−force=C++这样就把所有文件当成C++来处理了。 −−fields：指定标记文件中条目的可用扩展字段（没有指明的默认关闭） a
类成员的访问属性
f
文件限制范围 [enabled]
i
继承信息
k
单字符形式的标记类型 [enabled]
K
全名称形式的标记类型
l
包含该标记的源文件语言
m
实现信息
n
标记定义行号</description></item><item><title>REST的Richardson成熟度模型</title><link>https://mryqu.github.io/post/rest%E7%9A%84richardson%E6%88%90%E7%86%9F%E5%BA%A6%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 19 Oct 2013 10:59:05 +0000</pubDate><guid>https://mryqu.github.io/post/rest%E7%9A%84richardson%E6%88%90%E7%86%9F%E5%BA%A6%E6%A8%A1%E5%9E%8B/</guid><description>一个web服务有多么的&amp;quot;restful&amp;quot;，最有名的就是《RESTful Web Services》的合著者Leonard Richardson提出的REST 成熟度模型，简称Richardson成熟度模型。
第0级：使用HTTP作为传输方式；一个URI，一个HTTP方法。SOAP、XML-RPM都属于这一级别，仅是来回传送&amp;quot;Plain OldXML&amp;quot;(POX)。即使没有显式调用RPC接口（SOAP、XML-RPM），通常会调用服务器端的一个处理过程。一个接口会有一个端点，文档的内容会被解析用还判断所要调用的处理过程及其参数。这种做法相当于把HTTP 这个应用层协议降级为传输层协议用。HTTP 头和有效载荷是完全隔离的，HTTP头只用于保证传输，不涉及业务逻辑；有效载荷包含全部业务逻辑，因此 API 可以无视 HTTP 头中的任何信息。 第1级：引入了资源的概念，每个资源有对应的标识符和表达；多个URI，一个HTTP方法。这些资源仍是被&amp;quot;GETful&amp;quot;接口操作而不是HTTP动词，但服务基本上提供和操作资源。例如： GET http://example.com/app/createUser GET http://example.com/app/getUser?id=123 GEThttp://example.com/app/changeUser?id=123&amp;amp;field=value GET http://example.com/app/deleteUser?id=123 第2级：根据语义使用HTTP动词，适当处理HTTP响应状态码；多个URI，多个HTTP方法。 GET用于查询资源； HEAD用于查询资源是否存在； POST创建新资源； PUT更新已存在的资源； PATCH部分更新已存在的资源； DELETE删除已存在的资源。在这一级别，资源名称为基URI的一部分，而不是查询参数。 第3级：使用超媒体作为应用状态引擎（HATEOAS）；多个URI，多个HTTP方法。在资源的表达中包含了链接信息。客户端可以根据链接来发现可以执行的动作。链接推荐使用ATOM (RFC4287)中的显式语义。 当然围绕这一模型，争论很多，Martin Fowler、Rest之父Roy Fielding、《RESTful WebServices Cookbook》作者Subbu Allamaraju都有不同的见解。
参考 Leonard Richardson：REST 成熟度模型 Martin Fowler：Richardson Maturity Model Roy Fielding：REST APIs must be hypertext-driven Subbu Allamaraju：Measuring REST 如何度量应用的RESTful成熟度？</description></item><item><title>RESTful Web Services Cookbook笔记（一）</title><link>https://mryqu.github.io/post/restful_web_services_cookbook-note/</link><pubDate>Sat, 19 Oct 2013 08:10:45 +0000</pubDate><guid>https://mryqu.github.io/post/restful_web_services_cookbook-note/</guid><description>使用统一接口 HTTP是一种应用层协议，它定义了客户端与服务器之间的转移操作的表述形式。在此协议中，诸如GET，POST和DELETE之类的方法是对资源的操作。有了它，无须创造createOrder,getOrder,updateOrder等应用程序特定的操作了。 作为应用协议，HTTP的设计目标是在客户端和服务器之间保持对库、服务器、代理、缓存和其他工具的可见性。可见性是HTTP的一个核心特征。 一旦识别并设计资源，就可以使用GET方法获取资源的表述，使用PUT方法更新资源，使用DELETE方法删除资源，以及使用POST方法执行各种不安全和非幂等的操作。可以添加适当的HTTP标头来描述请求和相应。 以下特性完全取决于保持请求和相应的可见性：
缓存：缓存响应内容，并在资源修改时使缓存自动失效。 乐观并发控制：检测并发写入，并在操作过期的表述时防止资源发生变更。 内容协商：在给定资源的多个可用表述中，选择合适的表述。 安全性和幂等性：确保客户端可以重复或重试特定的HTTP请求。 HTTP通过以下途径来实现可见性：
HTTP的交互是无状态的，任何HTTP中介都可以推断出给定请求和响应的意义，而无须关联过去和将来的请求和响应。 HTTP使用一个统一接口，包括有OPTIONS，GET，HEAD，POST，DELETE和TRACE方法。接口中的每一个方法操作一个且仅一个资源。每个方法的语法和含义不会因应用程序和资源的不同而发生改变。 HTTP使用一种与MIME类似的信封格式进行表述编码。这种格式明确区分标头和内容。标头是可见的，除了创建、处理消息的部分，软件的其他部分都可以不用关心消息的内容。 保持可见性的另一方面是使用适当的状态码和状态消息，以便代理、缓冲和客户端可以决定请求的结果。 在某些情况下，可能需要权衡其他特性，如网络效率、客户端的便利性以及分离关注点，为此放弃可见性。当进行这种权衡时，应仔细分析对缓存、幂等性、安全性等特性的影响。 当有多个共享数据的资源，或一个操作修改多个资源时，需要权衡是否降低可见性（例如是否禁止缓存）以便获得更好的信息抽象、更松散的耦合程度、更好地网络效率、更好地资源粒度，或纯粹为了方便客户端使用。 可以通过带有应用程序状态的URI链接来保持应用程序状态而无需依赖服务器中内存中的会话。 安全性和幂等性是服务器要实现的HTTP方法的特征。当客户端发送GET、HEAD、OPTIONS、PUT或DELETE请求时，如果没有使用并发条件限制时，确保服务器提供相同响应。
|方法|是否安全?|是否幂等? |&amp;mdash;&amp;ndash; |GET|是|是 |HEAD|是|是 |OPTIONS|是|是 |PUT|否|是 |DELETE|否|是 |POST|否|否
客户端通过下列方法实现幂等的/安全的HTTP请求：
将GET、OPTIONS和HEAD视为只读操作，可按需随时可发送请求。 在网络或软件异常的情况下，通过If-Unmodified-Since/If-Match条件标头重发GET、PUT和DELETE请求。 不要重发POST请求，除非客户端（通过服务器文档）知道对特定资源的POST实现是幂等的。 Web基础设施严重依赖于GET方法的幂等性和安全性。客户端期望能够重复发起GET请求，而不必担心造成副作用。缓存依赖于不需访问源服务器就能提供已缓存表述的能力。 不要把GET方法用于不安全和非幂等操作。因为这样做可能造成永久性的、意想不到的、不符合需要的资源改变。 可以使用POST方法或PUT方法创建新资源。只有在客户端可以决定资源的URI时才使用PUT方法创建新资源；否则使用POST，由服务器决定新创建资源的URI（客户端请求可以使用Slug头建议新资源的URI）。 在以下场合中使用POST方法：
创建新的资源，把资源作为一个工厂 通过一个控制器资源来修改一个或多个资源 执行需要大数据输入的查询 在其他HTTP方法看上去不合适时，执行不安全或非幂等的操作。（缓存不会缓存这一方法的响应） 使用POST方式实现异步任务：服务器在接受到POST请求时，返回状态码202（Accepted），并包含一个让客户端可以跟踪异步任务状态的资源表述和客户端稍后检查状态的建议时间（ping-after）。 客户端使用GET请求查询异步任务状态，如服务器还在执行中，返回响应码200（OK）及包含当前状态的任务资源表述；如服务器成功完成，返回响应码303（SeeOther）以及包含新资源URL的Location头；如服务器任务失败，返回响应码200（OK）及任务失败的表述。 使用DELETE方法实现异步请求：服务器在收到DELETE请求，返回状态码202（Accepted），并包含一个让客户端可以跟踪异步任务状态的资源表述和客户端稍后检查状态的建议时间（ping-after）。 客户端使用GET请求查询异步任务状态，服务器返回响应码200（OK）及包含当前状态的任务资源表述。 避免使用非标准的自定义HTTP方法。当前比较有名的自定义方法包括WebDAV定义的方法、PATCH和MERGE。 HTTP服务器可能会使用自定义HTTP标头，比较有名的自定义HTTP包括X-Powered-By、X-Cache、X-Pingback、X-Forwarded-For及X-HTTP-Method-Override。实现客户端和服务器时，要让他们在没有发现需要的自定义标头时也不会失败。避免使用自定义HTTP标头改变HTTP方法的行为。
识别资源 从领域名词中识别资源。 直接将领域实体映射为资源可能导致资源效率低下且难以使用，可以通过网络效率、表述的多少以及客户端的应用程度来帮助确定资源的粒度。 粗粒度设计便于富客户端应用程序，更精细的资源颗粒可以更好地忙族缓存的要求。因此，应从客户端和网络的角度确定资源的粒度。下列原书可能会进一步影响资源粒度：
可缓存性 修改频率 可变性 仔细设计资源粒度，以确保使用更多缓存，减少修改频率，或将不可变数据从使用缓存较少、修改频率更高或可变数据分离出来，这样可以改善客户端和服务器端的效率。 基于应用程序特有的条件来识别相似的资源（例如共享同一数据库schema的资源，有相同特性或属性的资源），可以将这些有共性的资源组织成为集合。 基于客户端的使用模式、性能和延时要求，确定一些新的聚合其他资源的复合资源，来减少客户端与服务器的交互。 符合资源降低了统一接口的可见性，应为它们的表述中包含了和其他资源相重叠的资源。因此，在提供复合资源前,需要考虑一下几点：
如果在应用程序的请求很少，那么它可能不是一个好的选择。依赖缓存代理，从缓存中获取这些资源，也许能让客户端收益匪浅。 另一个因素是网络开销&amp;ndash;客户端与服务器之间的网络开销，服务区和后端服务或他所依赖的数据存储之间的网络开销。如果后者开销很大，那获取大量数据并在服务器上将他们组合成复合资源可能会增加客户端的延时，降低服务器的吞吐量。 想要改善延时，可以在客户端和服务器之间增加一个缓存层，并避免复合资源，进行一些负载测试来验证复合资源是否能起到改善作用。 最后，为每个客户端创建特定目标的复合资源并非是注重实效的做法。选择对Web服务最重要的客户端，设计复合资源来满足它们的需要。 像计算两地距离、行车路线、信用卡验证之类的计算或处理函数可被当作资源处理，并使用带有查询参数的HTTP GET获取函数输出表述。 当需要原子性修改多个资源时，可以为每个不同的操作指派一个控制器。客户端通过HTTP POST方法提交请求触发操作。如果操作结果是创建一个新资源，返回响应码201（Created）并在Location头里包含新资源的URL。如果操作结果是对一个或多个已有资源的修改，返回响应码303（See Other）并在Location头里包含客户端可用户获取修改表述的URL。如果服务器无法提供所有修改资源的单个URI，返回状态码200（OK）并在消息体内包含客户选可以用于了解操作结果的表述。 在RESTful Web服务中，控制器有助于对服务器和客户端之间进行关注分离，增进网络效率，让服务器端原子性地实现复杂操作。
设计表述 在HTTP设计中，发送发可以用一些名为实体头的标头来描述表述正文（也成为实体正文或消息正文）。有了这些标头，接收方可能在无须查看正文的情况下决定如何处理正文，还可以将解析正文所需要提前了解及猜测的内容尖刀最小程度。 使用以下标头来注解包含消息正文的表述：
标头用途解析处理Content-Type用于描述表述类型，即通常所说的media-type或MIME类型，包含charset参数或其他针对该媒体类型而定义的参数。</description></item><item><title>[Hadoop] Ubuntu 13.10下构建Mahout项目</title><link>https://mryqu.github.io/post/hadoop_ubuntu_13.10%E4%B8%8B%E6%9E%84%E5%BB%BAmahout%E9%A1%B9%E7%9B%AE/</link><pubDate>Fri, 18 Oct 2013 20:58:18 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_ubuntu_13.10%E4%B8%8B%E6%9E%84%E5%BB%BAmahout%E9%A1%B9%E7%9B%AE/</guid><description>JDK 在Oracle网站下载jdk-6u45-linux-i586.bin到/opt目录 进入/opt目录安装JDK: chmod +x jdk-6u45-linux-i586.bin sudo ./jdk-6u45-linux-i586.bin 进入/etc目录配置profile文件: sudo vi profile 在文件末尾添加： JAVA_HOME=/opt/jdk1.6.0_45 export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 运行source /etc/profile 使其生效。 运行java -version 检验: java version &amp;#34;1.6.0_45&amp;#34; Eclipse 在Eclipse网站下载eclipse-jee-juno-SR2-linux-gtk.tar.gz到/opt目录 进入/opt目录解压缩Eclipse: $ sudo tar -zxvf eclipse-jee-juno-SR2-linux-gtk.tar.gz$ sudo rm ./eclipse-jee-juno-SR2-linux-gtk.tar.gz 创建Eclipse启动快捷方式： $ sudo gedit /usr/share/applications/eclipse.desktop [Desktop Entry] Type=Application Name=Eclipse Comment=Eclipse IDE Icon=/opt/eclipse/icon.xpm Exec=/opt/eclipse/eclipse Terminal=false StartupNotify=true Type=Application Categories=Development;IDE;Java; Exec=env UBUNTU_MENUPROXY= /opt/eclipse/eclipse m2eclipse 通过下列update site安装:http://download.eclipse.org/technology/m2e/releases Mahout 在Mahout网站下载mahout-distribution-0.8-src.tar.gz到自己的Eclipseworkspace中 进入worksapce解压缩mahout: $ tar -zxvf mahout-distribution-0.8-src.tar.gz $ rm .</description></item><item><title>Linux包管理速查表</title><link>https://mryqu.github.io/post/linux%E5%8C%85%E7%AE%A1%E7%90%86%E9%80%9F%E6%9F%A5%E8%A1%A8/</link><pubDate>Fri, 18 Oct 2013 20:14:05 +0000</pubDate><guid>https://mryqu.github.io/post/linux%E5%8C%85%E7%AE%A1%E7%90%86%E9%80%9F%E6%9F%A5%E8%A1%A8/</guid><description>管理软件包 |任务|apt (deb)|yum (rpm)|zypper (rpm) |&amp;mdash;&amp;ndash; |通过仓库安装软件包|apt-get install {pkg}|yum install {pkg}|zypper install {pkg} |更新软件包|apt-get install {pkg}|yum update {pkg}|zypper update -t package {pkg} |移除软件包|apt-get remove {pkg}|yum erase {pkg}|zypper remove {pkg} |通过文件安装软件包|dpkg -i {pkg}|yum localinstall {pkg}|zypper install {pkg}
搜索软件包 |任务|apt (deb)|yum (rpm)|zypper (rpm) |&amp;mdash;&amp;ndash; |通过包名搜索|apt-cache search {pkg}|yum list {pkg}|zypper search {pkg} |通过模式搜索|apt-cache search pattern|yum search pattern|zypper search -t pattern pattern |通过文件名搜索|apt-file search path|yum provides file|zypper wp file |列举已安装软件包|dpkg -l|rpm -qa|zypper search -is |显示软件包信息|apt-cache show pgk-name|yum info {pkg}|zypper info {pkg}</description></item><item><title>Debian软件包管理速查表：dpkg、apt-get、apt-cache</title><link>https://mryqu.github.io/post/debian%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%E9%80%9F%E6%9F%A5%E8%A1%A8dpkgapt-getapt-cache/</link><pubDate>Fri, 18 Oct 2013 19:54:39 +0000</pubDate><guid>https://mryqu.github.io/post/debian%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%E9%80%9F%E6%9F%A5%E8%A1%A8dpkgapt-getapt-cache/</guid><description>dpkg是Debian系统底层包管理器，apt-get是高层包管理工具，apt-cache是高层包查询工具。
dpkg速查表 dpkg是Debian Linux用于安装/管理单个软件包的命令行工具：
语法描述示例dpkg -i {.deb package}安装软件包dpkg -i zip_2.31-3_i386.debdpkg -i {.deb package}安装新的软件包。如果软件包已安装则尝试更新到最新版本dpkg -i zip_2.31-3_i386.debdpkg -R {Directory-name}递归地安装目录下所有软件包dpkg -R /tmp/downloadsdpkg -r {package}移除一个已安装的软件包，保留配置文件dpkg -r zipdpkg -P {package}移除一个已安装的软件包及配置dpkg -P apache-perl dpkg -l列举所有安装的软件包、及包版本和简短描述dpkg -l dokg -l | less dpkg -l '*apache*' dpkg -l | grep -i 'sudo'dpkg -l {package}列举单个安装的软件包、及包版本和简短描述dpkg -l apache-perldpkg -L {package}找出安装的软件包所提供的文件，例如列出安装的文件dpkg -L apache-perl dpkg -L perldpkg -c {.Deb package}列出软件包所提供的文件，例如deb包文件内的所有文件，这对找出将要安装什么文件非常有帮助dpkg -c dc_1.06-19_i386.debdpkg -S {/path/to/file}找出拥有该文件的包，例如找出该文件归属的包dpkg -S /bin/netstat
dpkg -S /sbin/ippooldpkg -p {package}显示包的详细信息，包组、版本、维护者、架构、依赖包、描述等dpkg -p lsofdpkg -s {package} | grep Status找出Debian包是否安装(状态)dpkg -s lsof | grep Status apt-get速查表 apt-get是Debian Linux用于管理软件包的命令行工具：</description></item><item><title>FilenameFilter和FileFilter介绍</title><link>https://mryqu.github.io/post/filenamefilter%E5%92%8Cfilefilter%E4%BB%8B%E7%BB%8D/</link><pubDate>Fri, 18 Oct 2013 19:26:35 +0000</pubDate><guid>https://mryqu.github.io/post/filenamefilter%E5%92%8Cfilefilter%E4%BB%8B%E7%BB%8D/</guid><description>FilenameFilter和FileFilter说明 java.io.File类提供了四个方法用于列举某个路径下的文件和目录，但不会递归列举子目录下的内容。其中两个是列举路径下的所有文件和目录。
String[] list() File[] listFiles()另外两个是列举路径满足指定过滤器的文件和目录。 String[] list(FilenameFilter filter) File[] listFiles(FileFilter filter) 示例 要求：返回当前目录下所有以yqu开头且以.tmp结尾的文件和目录。
代码 package com.yqu.file; import java.io.File; import java.io.FileFilter; import java.io.FilenameFilter; public class HelloFileListing { public static void main(String[] args) { File f = new File(&amp;#34;c:/test&amp;#34;); System.out.println(&amp;#34;\n====Method listFiles() example====&amp;#34;); File[] files = f.listFiles(); for (File fl : files) { String type = fl.isFile() ? &amp;#34;File: &amp;#34; : &amp;#34;Directory: &amp;#34;; try { System.out.println(type + fl.getCanonicalPath()); } catch (Exception e) { e.</description></item><item><title>玩玩无序列表ul和有序列表ol</title><link>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9%E6%97%A0%E5%BA%8F%E5%88%97%E8%A1%A8ul%E5%92%8C%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8ol/</link><pubDate>Fri, 18 Oct 2013 19:19:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%8E%A9%E7%8E%A9%E6%97%A0%E5%BA%8F%E5%88%97%E8%A1%A8ul%E5%92%8C%E6%9C%89%E5%BA%8F%E5%88%97%E8%A1%A8ol/</guid><description>写博客有时候用到列表，这里好好玩一玩。
CSS list-style-type 属性 属性介绍 |值|描述 |&amp;mdash;&amp;ndash; |none|无标记。 |disc|默认。标记是实心圆。 |circle|标记是空心圆。 |square|标记是实心方块。 |decimal|标记是数字。 |decimal-leading-zero|0开头的数字标记。(01, 02, 03, 等。) |lower-roman|小写罗马数字(i, ii, iii, iv, v, 等。) |upper-roman|大写罗马数字(I, II, III, IV, V, 等。) |lower-alpha|小写英文字母The marker is lower-alpha (a, b, c, d, e, 等。) |upper-alpha|大写英文字母The marker is upper-alpha (A, B, C, D, E, 等。) |lower-greek|小写希腊字母(alpha, beta, gamma, 等。) |lower-latin|小写拉丁字母(a, b, c, d, e, 等。) |upper-latin|大写拉丁字母(A, B, C, D, E, 等。) |hebrew|传统的希伯来编号方式 |armenian|传统的亚美尼亚编号方式 |georgian|传统的乔治亚编号方式(an, ban, gan, 等。) |cjk-ideographic|简单的表意数字 |hiragana|标记是：a, i, u, e, o, ka, ki, 等。（日文片假名） |katakana|标记是：A, I, U, E, O, KA, KI, 等。（日文片假名） |hiragana-iroha|标记是：i, ro, ha, ni, ho, he, to, 等。（日文片假名） |katakana-iroha|标记是：I, RO, HA, NI, HO, HE, TO, 等。（日文片假名） |inherit|规定应该从父元素继承 list-style-type 属性的值。</description></item><item><title>数据库非XA驱动和XA驱动列表</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%9Exa%E9%A9%B1%E5%8A%A8%E5%92%8Cxa%E9%A9%B1%E5%8A%A8%E5%88%97%E8%A1%A8/</link><pubDate>Thu, 17 Oct 2013 19:44:55 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%9Exa%E9%A9%B1%E5%8A%A8%E5%92%8Cxa%E9%A9%B1%E5%8A%A8%E5%88%97%E8%A1%A8/</guid><description>数据库非XA驱动XA驱动Postgresorg.postgresql.Driverorg.postgresql.xa.PGXADataSourceMySQLcom.mysql.jdbc.Drivercom.mysql.jdbc.jdbc2.optional.MysqlXADataSourceOracleoracle.jdbc.OracleDriveroracle.jdbc.xa.client.OracleXADataSourceDB2com.ibm.db2.jcc.DB2Drivercom.ibm.db2.jcc.DB2XADataSourceSQL Servercom.microsoft.sqlserver.jdbc.SQLServerDrivercom.microsoft.sqlserver.jdbc.SQLServerXADataSourceTeradatacom.teradata.jdbc.TeraDriver</description></item><item><title>vFabric Web Server配置：多tc Server负载均衡</title><link>https://mryqu.github.io/post/vfabric_web_server%E9%85%8D%E7%BD%AE%E5%A4%9Atc_server%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</link><pubDate>Wed, 16 Oct 2013 22:03:02 +0000</pubDate><guid>https://mryqu.github.io/post/vfabric_web_server%E9%85%8D%E7%BD%AE%E5%A4%9Atc_server%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</guid><description>HTTP请求需要分发到tc Server集群成员。为了实现这一目的，可以采用硬件负载均衡硬件或软件(Apache HTTP Server、vFabric Web Server和Microsoft IIS)。本文介绍用vFabric Web Server的mod_proxy模块实现tcServer负载均衡。
vFabric Web Server:加载mod_proxy动态共享对象 在httpsd.conf文件对下列行进行添加或去除注释: LoadModule proxy_module &amp;#34;VFWS-INSTALL/httpd-2.2/modules/mod_proxy.so&amp;#34; LoadModule proxy_http_module &amp;#34;VFWS-INSTALL/httpd-2.2/modules/mod_proxy_http.so&amp;#34; LoadModule proxy_balancer_module &amp;#34;VFWS-INSTALL/httpd-2.2/modules/mod_proxy_balancer.so&amp;#34; vFabric Web Server:创建额外的配置文件 在vFabric Web Server实例的conf目录创建mod_proxy.conf: # Enable capturing of proxy statistics ProxyStatus on SetHandler balancer-manager Order Deny,Allow Deny from all Allow from 127.0.0.1 # These apps aren&amp;#39;t clustered -- requests go to dedicated server ProxyPass /my-app1 balancer://my-standalone/my-app1 ProxyPass /my-app2 balancer://my-standalone/my-app2 # Clustered apps get directed to loadbalanced worker ProxyPass /my-app3 balancer://my-balancer/my-app3 ProxyPass /my-app4 balancer://my-balancer/my-app4 # Standalone &amp;#34;balancer&amp;#34; for standalone apps that aren&amp;#39;t clustered BalancerMember http://MYSERVER1:8080 # Load balanced &amp;#34;balancer&amp;#34; for clustered apps BalancerMember http://MYSERVER1:8080 route=aGVsbG8gcWUh_MyServer1_1 loadfactor=1 BalancerMember http://MYSERVER1:8180 route=aGVsbG8gcWUh_MyServer1_2 loadfactor=2 ProxySet lbmethod=byrequests stickysession=aGVsbG8gcWUh_Cluster1|aGVsbG8gcWUh_cluster1 # Configure cache timeouts for static content AddType text/javascript .</description></item><item><title>vFabric Web Server 5.2模块和库</title><link>https://mryqu.github.io/post/vfabric_web_server_5.2%E6%A8%A1%E5%9D%97%E5%92%8C%E5%BA%93/</link><pubDate>Wed, 16 Oct 2013 20:55:44 +0000</pubDate><guid>https://mryqu.github.io/post/vfabric_web_server_5.2%E6%A8%A1%E5%9D%97%E5%92%8C%E5%BA%93/</guid><description>vFabric Web Server 是VMware的vFabric套件中的Web服务器和负载均衡组件。vFabric WebServer 5.2基于Apache HTTP Server 2.2版本。 其大部分模块可见链接
核心功能和多处理模块 |模块|介绍 |&amp;mdash;&amp;ndash; |core|Apache HTTP服务器核心提供的功能，始终有效。 |mpm_common|收集了被多个多路处理模块(MPM)实现的公共指令。 |beos|专门针对BeOS优化过的多路处理模块(MPM) |event|一个标准workerMPM的实验性变种。 |mpm_netware|专门为Novell NetWare优化的线程化的多路处理模块(MPM) |mpmt_os2|专门针对OS/2优化过的混合多进程多线程多路处理模块(MPM) |prefork|一个非线程型的、预派生的MPM |mpm_winnt|用于Windows NT/2000/XP/2003 系列的MPM |worker|线程型的MPM，实现了一个混合的多线程多处理MPM，允许一个子进程中包含多个线程。
其它普通模块 |模块|介绍 |&amp;mdash;&amp;ndash; |mod_actions|根据特定的媒体类型或请求方法，激活特定的CGI脚本 |mod_alias|提供从文件系统的不同部分到文档树的映射和URL重定向 |mod_asis|发送自己包含HTTP头内容的文件 |mod_auth_basic|使用基本认证 |mod_auth_digest|使用MD5摘要认证(更安全，但是只有最新的浏览器才支持) |mod_authn_alias|基于实际认证支持者创建扩展的认证支持者，并为它起一个别名以便于引用 |mod_authn_anon|提供匿名用户认证支持 |mod_authn_dbd|使用SQL数据库为认证提供支持 |mod_authn_dbm|使用DBM数据库为认证提供支持 |mod_authn_default|在未正确配置认证模块的情况下简单拒绝一切认证信息 |mod_authn_file|使用纯文本文件为认证提供支持 |mod_authnz_ldap|允许使用一个LDAP目录存储用户名和密码数据库来执行基本认证和授权 |mod_authz_dbm|使用DBM数据库文件为组提供授权支持 |mod_authz_default|在未正确配置授权支持模块的情况下简单拒绝一切授权请求 |mod_authz_groupfile|使用纯文本文件为组提供授权支持 |mod_authz_host|供基于主机名、IP地址、请求特征的访问控制 |mod_authz_owner|基于文件的所有者进行授权 |mod_authz_user|基于每个用户提供授权支持 |mod_autoindex|自动对目录中的内容生成列表，类似于&amp;quot;ls&amp;quot;或&amp;quot;dir&amp;quot;命令 |mod_cache|基于URI键的内容动态缓冲(内存或磁盘) |mod_cern_meta|允许Apache使用CERN httpd元文件，从而可以在发送文件时对头进行修改 |mod_cgi|在非线程型MPM(prefork)上提供对CGI脚本执行的支持 |mod_cgid|在线程型MPM(worker)上用一个外部CGI守护进程执行CGI脚本 |mod_charset_lite|允许对页面进行字符集转换 |mod_dav|允许Apache提供DAV协议支持 |mod_dav_fs|为mod_dav访问服务器上的文件系统提供支持 |mod_dav_lock|为mod_dav锁定服务器上的文件提供支持 |mod_dbd|管理SQL数据库连接，为需要数据库功能的模块提供支持 |mod_deflate|压缩发送给客户端的内容 |mod_dir|指定目录索引文件以及为目录提供&amp;quot;尾斜杠&amp;quot;重定向 |mod_disk_cache|基于磁盘的缓冲管理器 |mod_dumpio|将所有I/O操作转储到错误日志中 |mod_echo|一个很简单的协议演示模块 |mod_env|允许Apache修改或清除传送到CGI脚本和SSI页面的环境变量 |mod_example|一个很简单的Apache模块API演示模块 |mod_expires|允许通过配置文件控制HTTP的&amp;quot;Expires:&amp;ldquo;和&amp;quot;Cache-Control:&amp;ldquo;头内容 |mod_ext_filter|使用外部程序作为过滤器 |mod_file_cache|提供文件描述符缓存支持，从而提高Apache性能 |mod_filter|根据上下文实际情况对输出过滤器进行动态配置 |mod_headers|允许通过配置文件控制任意的HTTP请求和应答头信息 |mod_ident|实现RFC1413规定的ident查找 |mod_imagemap|处理服务器端图像映射 |mod_include|实现服务端包含文档(SSI)处理 |mod_info|生成Apache配置情况的Web页面 |mod_isapi|仅限于在Windows平台上实现ISAPI扩展 |mod_ldap|为其它LDAP模块提供LDAP连接池和结果缓冲服务 |mod_log_config|允许记录日志和定制日志文件格式 |mod_log_forensic|实现&amp;quot;对比日志&amp;rdquo;，即在请求被处理之前和处理完成之后进行两次记录 |mod_logio|对每个请求的输入/输出字节数以及HTTP头进行日志记录 |mod_mem_cache|基于内存的缓冲管理器 |mod_mime|根据文件扩展名决定应答的行为(处理器/过滤器)和内容(MIME类型/语言/字符集/编码) |mod_mime_magic|通过读取部分文件内容自动猜测文件的MIME类型 |mod_negotiation|提供内容协商支持 |mod_nw_ssl|仅限于在NetWare平台上实现SSL加密支持 |mod_proxy|提供HTTP/1.</description></item><item><title>vFabric Web Server控制台命令</title><link>https://mryqu.github.io/post/vfabric_web_server%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%91%BD%E4%BB%A4/</link><pubDate>Wed, 16 Oct 2013 19:28:36 +0000</pubDate><guid>https://mryqu.github.io/post/vfabric_web_server%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%91%BD%E4%BB%A4/</guid><description>检查并设置PowerShell 在Windows中，vFabric WebServer控制台命令需要在PowerShell下执行。默认状态下，PowerShell的脚本处理是被禁止的。 通过如下命令检查当前的PowerShell设置:
PS prompt&amp;gt; Get-ExecutionPolicy 如果命令返回Restricted,这意味着PowerShell还没有使能。通过执行如下命令使它允许最低限度执行本地脚本：
PS prompt&amp;gt; Set-ExecutionPolicy RemoteSigned 按照需要设置不同的执行策略并使用组和用户策略使能PowerShell。通常，仅有管理员使用vFabric WebServer脚本，因此RemoteSigned执行策略在大多情况下是足够的。
通过执行如下命令设置编码为UTF-8，以便更好地显示httpctl输出、更容易检查日志文件。
PS prompt&amp;gt; chcp 65001 使用vFabric Web Server控制台 可以使用httpdctl 脚本控制vFabric Web Server实例，其命令如下:
|命令|描述 |&amp;mdash;&amp;ndash; |start|启动vFabric Web Server实例。如果实例已启动，该命令返回错误。 |stop|强制停止vFabric Web Server实例。当前所有打开的连接将中断。 |gracefulstop|优雅停止vFabric Web Server实例，脚本会等到所有打开的连接关闭后才停止vFabric Web Server实例。 |restart|重启实例。如果实例之前没有启动，脚本会启动实例，此外也会在启动实例前运行configtest。 |graceful|优雅重启实例。与restart命令的区别在于当前打开的连接不会中断，副作用就是老的日志文件不会立即关闭。 |status|显示实例状态信息，例如是否运行中、运行中的进程标识符 (PID)。 |install|安装实例成Windows或UNIX服务。服务可以用Windows服务控制台、sc命令手动启动或停止，或随Windows自动启动或停止。
install命令可用参数：
服务名: vFabrichttpd_实例名_ 例子: vFabrichttpdmyserver显示名: vFabric httpd 实例名
例子: vFabric httpd myserverUnix下，实例安装成/etc/init.d目录下名为vFabric-httpd-&amp;lt;实例名&amp;gt;的脚本文件。服务随Unix自动启动或停止。 |uninstall|卸载作为Windows或UNIX服务的实例。Windows下，实例会从服务注册表中删除。Unix下，命令会删除/etc/init.d/vFabric-httpd-_instance-name_脚本文件。 |configtest|对例如conf/httpd.conf之类的配置文件运行语法检查。脚本解析配置文件，如果语法正确返回OK，否则返回特定语法错误的详细信息。
示例如下：
PS C:\sas\Config\Lev1\Web\WebServer\bin&amp;gt; .\httpdctl.ps1 status httpdctl.ps1 - manage the SAS [Config-Lev1] httpd - WebServer server instance Copyright c 2012 VMware, Inc.</description></item><item><title>开源事务管理器列表</title><link>https://mryqu.github.io/post/%E5%BC%80%E6%BA%90%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%E5%88%97%E8%A1%A8/</link><pubDate>Tue, 15 Oct 2013 20:04:34 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%BC%80%E6%BA%90%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%E5%88%97%E8%A1%A8/</guid><description>WebLogic、WebSphere和JBoss这些Web应用服务器都自带事务管理器，而Tomcat和tcServer需要额外使用第三方事务管理器。公司选择了AtomikosTransactionEssentials作为JTA/XA提供者，这里列一下当前使用较多的开源事务管理器。
|事务管理器|开源许可证|当前版本|介绍 |&amp;mdash;&amp;ndash; |JOTM|BSD样式|2.1.9 (2010-1-14)|JOTM(Java Open TransactionManager)是由ObjectWeb协会开发的功能完整的且资源开放的独立的事务管理器。 它提供了JAVA 应用程序的事务支持，而且与JTA（JAVA事务API）兼容。
JOTM内嵌了一些开源项目。例如CAROL用于事务上下文传播；XAPool是一个XA兼容的JDBC连接池；HOWL是用于事务恢复的日志。 |Bitronix JTA Transaction Manager|LGPL|2.1.4 (2013-9-15)|Bitronix Transaction Manager (BTM)是JTA 1.1 API的一个简单但完整的实现。 |SimpleJTA|Apache 2.0|2.02 (2007-4-10)|SimpleJTA实现了一个单独的JTA兼容事务处理器，仅支持Oracle 9i和ApacheDerby数据库，不支持JTS。 |Atomikos TransactionsEssentials|Apache 2.0|3.9.0.M1 (2013-6-8)|Atomikos分两个：一个是开源的TransactionEssentials，一个是商业的ExtremeTransactions。（功能对比）
Atomikos TransactionsEssentials是对JDBC/XA池,JMS/XA池和JTA/XA提供基本支持的开源事务处理系统。 |Narayana(JBossTS)|LGPL v2.1|5.0.0.M6 (2013-10-11)|Narayana（JBossTS）前身是最初纽卡斯尔大学在1986到1995开发的Arjuna系统，后由JBoss从Arjuna和HP手中收购并开源的。
它支持下列事务处理协议标准:JTA、JTS、Web服务事务、REST事务、STM、XATMI/TX
Stack Overflow有一篇文章对上面的一些事务管理器进行了对比：
JOTM 用户抱怨的比较多 GeronimoTM/Jencks(Jencks是Apache Geronimo中使用的JCA容器，并使用ApacheGeronimo的事务管理器) 缺乏文档。 SimpleJTA 没有实现JTS (Java Transaction Service)而且不是活跃的。 Bitronix 有不错的文档但是不提供技术支持。 Atomikos 是一个另人钦佩的产品。有丰富的文档，而且提供技术支持。 JBossTS 从收购通告可见肯定是一个成熟的产品，而且提供技术支持。</description></item><item><title>[Hadoop] 源码分析mapred.mapper.new-api/mapred.reducer.new-api设置与区别</title><link>https://mryqu.github.io/post/hadoop_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90mapred.mapper.new-api%E5%92%8Cmapred.reducer.new-api%E8%AE%BE%E7%BD%AE%E4%B8%8E%E5%8C%BA%E5%88%AB/</link><pubDate>Mon, 14 Oct 2013 20:06:53 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90mapred.mapper.new-api%E5%92%8Cmapred.reducer.new-api%E8%AE%BE%E7%BD%AE%E4%B8%8E%E5%8C%BA%E5%88%AB/</guid><description>即mapred和mapreduce包的区别后，本文再次从源码角度分析新老API（mapred.mapper.new-api/ mapred.reducer.new-api）的设置与区别。 mapred.mapper.new-api /mapred.reducer.new-api这两个参数很少显式去设置，默认为false，即使用mapred包下的老API。 不过MapReduce框架也会去自动识别应该使用老API还是新API。作业提交有两种方式，异步方式用submit，同步方式用waitForCompletion。不过org.apache.hadoop.mapreduce.Job.waitForCompletion(boolean)里调用了org.apache.hadoop.mapreduce.Job.submit()方法，submit方法又调用了org.apache.hadoop.mapreduce.Job.setUseNewAPI()方法。setUseNewAPI方法里面对新老API做了判断：
是否设置了mapred.mapper.class属性，则mapred.mapper.new-api为true，否则为false。说白了就是用org.apache.hadoop.mapreduce.Job.setMapperClass(Class)还是org.apache.hadoop.mapred.JobConf.setMapperClass(Class)设置的Mapper，前者设置的是mapreduce.job.map.class属性，后者设置的是mapred.mapper.class属性。 如果mapreduce.job.reduces属性值不为0，则看是否设置了mapred.reducer.class属性，则mapred.reducer.new-api为true，否则为false。说白了就是用org.apache.hadoop.mapreduce.Job.setReducerClass(Class)还是org.apache.hadoop.mapred.JobConf.setReducerClass(Class)设置的Mapper，前者设置的是mapreduce.job.reducer.class属性，后者设置的是mapred.reducer.class属性。 new-api相关区别 使用new-api不使用new-api不允许设置下列属性：
mapred.input.format.classmapred.mapper.classmapred.partitioner.classmapred.reducer.classmapred.output.format.class不允许设置下列属性：
mapreduce.job.inputformat.classmapreduce.job.map.classmapreduce.job.partitioner.classmapreduce.job.reducer.classmapreduce.job.outputformat.class使用下列类或接口的实现：
o.a.h.conf.Configurationo.a.h.mapreduce.Mapper抽象类o.a.h.mapreduce.Reducer抽象类o.a.h.mapreduce.OutputFormat抽象类o.a.h.mapreduce.OutputCommitter抽象类o.a.h.mapreduce.TaskIDo.a.h.mapreduce.TaskAttemptIDo.a.h.mapreduce.TaskAttemptContext接口o.a.h.mapreduce.InputFormat抽象类o.a.h.mapreduce.InputSplit抽象类使用下列类或接口的实现：
o.a.h.mapred.JobConfo.a.h.mapred.Mapper接口o.a.h.mapred.Reducer接口o.a.h.mapred.OutputFormat接口o.a.h.mapred.OutputCommitter抽象类o.a.h.mapred.TaskIDo.a.h.mapred.TaskAttemptIDo.a.h.mapred.TaskAttemptContext接口o.a.h.mapred.InputFormat接口o.a.h.mapred.InputSplit接口使用方法：
o.a.h.mapred.MapTask.runNewMappero.a.h.mapreduce.JobSubmitter.writeNewSplitso.a.h.mapred.ReduceTask.runNewReducer使用方法：
o.a.h.mapred.MapTask.runOldMappero.a.h.mapreduce.JobSubmitter.writeOldSplitso.a.h.mapred.ReduceTask.runOldReducer</description></item><item><title>Servlet URL映射模式</title><link>https://mryqu.github.io/post/servlet_url%E6%98%A0%E5%B0%84%E6%A8%A1%E5%BC%8F/</link><pubDate>Sun, 13 Oct 2013 20:56:47 +0000</pubDate><guid>https://mryqu.github.io/post/servlet_url%E6%98%A0%E5%B0%84%E6%A8%A1%E5%BC%8F/</guid><description>Servlet 2.5规范中的映射规则: 完全匹配URL 匹配通配符路径 匹配扩展名 匹配默认servlet 特殊URL模式: url-pattern:/* servlet上的/* 会压制所有其他servlet。无论什么请求都会被该servlet处理。这是一种不好的URL模式。通常，仅将/* 用于过滤器。它能通过调用FilterChain#doFilter()让请求继续由监听另外一个特定URL模式的任何servlet处理。
url-pattern:/ / 不会压制其他servlet。它仅会替换servlet容器内建的默认servlet，用于无法匹配任何已注册servlet的所有请求。一般仅调用在静态资源(CSS/JS/image/etc)和列举目录上。servlet容器内建默认servlet也能处理HTTP缓存请求、媒体（音视频）流和文件重新下载。由于必须负责默认servlet的所有任务，工作量不小，通常不会想要替换默认servlet。这也是一种不好的URL模式。关于为什么JSP页面不会调用这个servlet，是因为servlet容器的内建JSPservlet默认映射到*.jsp并被调用。
url-pattern: 这也有一个空字符串URL模式 。当上下文根被请求时会被调用。这不同于welcome-file方法，因为它对任何子目录请求不会被调用，而welcome-file方法对任何局部有效但没有匹配上servlet的请求都会被调用。这更像需要“主页servlet”所要用到的URL模式。.</description></item><item><title>tc Server与Atomikos集成</title><link>https://mryqu.github.io/post/tc_server%E4%B8%8Eatomikos%E9%9B%86%E6%88%90/</link><pubDate>Sun, 13 Oct 2013 17:15:41 +0000</pubDate><guid>https://mryqu.github.io/post/tc_server%E4%B8%8Eatomikos%E9%9B%86%E6%88%90/</guid><description>tc Server是基于Apache的Tomcat的，Atomikos有篇文档介绍Tomcat与Atomikos集成，同样适用于tcServer。
Atomikos安装配置 复制JAR文件 复制下列JAR文件到TCS_HOME/lib目录：
atomikos-util.jar transactions.jar transactions-api.jar transactions-jdbc.jar transactions-jdbc-deprecated.jar transactions-jms.jar transactions-jms-deprecated.jar transactions-jta.jar transactions-osgi.jar geronimo-jms_1.1_spec.jar geronimo-jta_1.0.1B_spec.jar JDBC驱动 如果使用Hibernate：transactions-hibernate3.jar和/或transactions-hibernate2.jar 复制Atomikos配置文件 将jta.properties复制到TCS_HOME/lib目录并做适当修改。
com.atomikos.icatch.service=com.atomikos.icatch.standalone.UserTransactionServiceFactory com.atomikos.icatch.console_file_limit=10240000 com.atomikos.icatch.output_dir=${catalina.base}/logs com.atomikos.icatch.log_base_dir=${catalina.base}/logs com.atomikos.icatch.max_actives=-1 com.atomikos.icatch.default_jta_timeout=3600000 com.atomikos.icatch.max_timeout=3600000 com.atomikos.icatch.tm_unique_name=tm com.atomikos.icatch.console_log_level=WARN com.atomikos.icatch.force_shutdown_on_vm_exit=false 复制类文件 创建AtomikosLifecycleListener和BeanFactory两个类并放置在TCS_HOME/lib目录： 创建用于Atomikos的tc Server生命期监视器：当tcServer实例启动时，创建UserTransactionManager并初始化；当tcServer关闭时，关闭UserTransactionManager。
package com.atomikos.tomcat; import org.apache.catalina.Lifecycle; import org.apache.catalina.LifecycleEvent; import org.apache.catalina.LifecycleListener; import com.atomikos.icatch.jta.UserTransactionManager; public class AtomikosLifecycleListener implements LifecycleListener { private UserTransactionManager utm; public void lifecycleEvent(LifecycleEvent event) { try { if (Lifecycle.START_EVENT.equals(event.getType())) { if (utm == null) { utm = new UserTransactionManager(); } utm.</description></item><item><title>Ubuntu下安装部署MySQL数据库</title><link>https://mryqu.github.io/post/ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2mysql%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Fri, 11 Oct 2013 21:52:52 +0000</pubDate><guid>https://mryqu.github.io/post/ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2mysql%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>安装MySQL mysql-server是MySQL数据库服务器，必选安装。mysql-client是MySQL数据库客户端，提供对MySQL服务器的查询工具及备份/恢复数据工具；libmysqlclient-dev是MySQL的C语言开发接口，libmysql-java是MySQL的JDBC驱动，按需安装。
sudo apt-get update sudo apt-get install mysql-server sudo apt-get isntall mysql-client sudo apt-get install libmysqlclient-dev sudo apt-get install libmysql-java 查看是否安装成功:
sudo netstat -tap | grep mysql 查看上述软件包所提供的文件:
dpkg -L mysql-server dpkg -L mysql-client dpkg -L libmysqlclient-dev 通过上述命令检查之后，如果看到有MySQL的socket处于LISTEN状态则表示安装成功。
MySQL服务操作 查看状态
使用service查看状态：sudo service mysql status 使用mysql脚本查看状态：/etc/inint.d/mysql status 使用mysqladmin查看状态：mysqladmin -u root -p status 启动
使用service启动：sudo service mysql start 使用mysql脚本启动：/etc/inint.d/mysql start 使用mysqld_safe启动：mysqld_safe&amp;amp; 停止
使用service停止：sudo service mysql stop 使用mysql脚本停止：/etc/inint.d/mysql stop 使用mysqladmin停止：mysqladmin -u root -p shutdown 重启</description></item><item><title>正则表达式风格与语法对比</title><link>https://mryqu.github.io/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%A3%8E%E6%A0%BC%E4%B8%8E%E8%AF%AD%E6%B3%95%E5%AF%B9%E6%AF%94/</link><pubDate>Fri, 11 Oct 2013 06:26:12 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%A3%8E%E6%A0%BC%E4%B8%8E%E8%AF%AD%E6%B3%95%E5%AF%B9%E6%AF%94/</guid><description>现在很多编程语言都支持正则表达式，一般都会提到是Perl风格（PCRE，Perl兼容正则表达式）还是POSIX风格（IEEE制定的POSIXExtended 1003.2标准）。解析POSIX与Perl标准的正则表达式区别详细介绍了这两种风格正则表达式的区别。我对正则表达式的使用主要是Java语言中，其次在R、Python和Javascript中有不同程度的涉猎。不同软件的正则表达式语法汇总介绍了不同语言/软件之间的区别。
参考 https://developer.mozilla.org/en/docs/web/javascript/guide/regular_expressions https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html https://docs.python.org/2/library/re.html</description></item><item><title>Shell中的source和.命令</title><link>https://mryqu.github.io/post/shell%E4%B8%AD%E7%9A%84source%E5%92%8C.%E5%91%BD%E4%BB%A4/</link><pubDate>Thu, 10 Oct 2013 23:11:05 +0000</pubDate><guid>https://mryqu.github.io/post/shell%E4%B8%AD%E7%9A%84source%E5%92%8C.%E5%91%BD%E4%BB%A4/</guid><description>source是csh(C Shell)的内置命令: 标识读入并执行文件中的命令。 这与执行shell脚本是不一样的./script.sh会启动一个新的shell并执行script.sh中的命令。
source [-h] filename [arguments] The shell reads and executes commands from name. The commands are not placed on the history list. If any args are given, they are placed in argv. (+) source commands may be nested; if they are nested too deeply the shell may run out of file descriptors. An error in a source at any level terminates all nested source commands. With -h, commands are placed on the history list instead of being executed, much like `history -L&amp;#39;.</description></item><item><title>获取Tomcat版本的简单办法</title><link>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96tomcat%E7%89%88%E6%9C%AC%E7%9A%84%E7%AE%80%E5%8D%95%E5%8A%9E%E6%B3%95/</link><pubDate>Sun, 29 Sep 2013 21:28:50 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%8E%B7%E5%8F%96tomcat%E7%89%88%E6%9C%AC%E7%9A%84%E7%AE%80%E5%8D%95%E5%8A%9E%E6%B3%95/</guid><description>[Tomcat]\bin\version.bat可以用来查看Tomcat版本。
C:\tomcat6\bin&amp;gt;version.bat Using CATALINA_BASE: &amp;#34;C:\tomcat6&amp;#34; Using CATALINA_HOME: &amp;#34;C:\tomcat6&amp;#34; Using CATALINA_TMPDIR: &amp;#34;C:\tomcat6\temp&amp;#34; Using JRE_HOME: &amp;#34;C:\Program Files\Java\jdk1.6.0_45&amp;#34; Using CLASSPATH: &amp;#34;C:\tomcat6\bin\bootstrap.jar&amp;#34; Server version: Apache Tomcat/6.0.37 Server built: Apr 29 2013 11:34:47 Server number: 6.0.0.37 OS Name: Windows Server 2008 R2 OS Version: 6.1 Architecture: x86 JVM Version: 1.6.0_45-b06 JVM Vendor: Sun Microsystems Inc.</description></item><item><title>非概率抽样</title><link>https://mryqu.github.io/post/%E9%9D%9E%E6%A6%82%E7%8E%87%E6%8A%BD%E6%A0%B7/</link><pubDate>Sun, 29 Sep 2013 20:41:15 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%9D%9E%E6%A6%82%E7%8E%87%E6%8A%BD%E6%A0%B7/</guid><description>非概率抽样：调查者根据自己的方便或主观判断抽取样本的方法。它不是严格按随机抽样原则来抽取样本，所以失去了大数定律的存在基础，也就无法确定抽样误差,无法正确地说明样本的统计值在多大程度上适合于总体。虽然根据样本调查的结果也可在一定程度上说明总体的性质，特征，但不能从数量上推断总体。非概率抽样主要有偶遇抽样，主观抽样，定额抽样，滚雪球抽样等类型。
定义 非概率抽样就是调查者根据自己的方便或主观判断抽取样本的方法。 它不是严格按随机抽样原则来抽取样本，所以失去了大数定律的存在基础，也就无法确定抽样误差，无法正确地说明样本的统计值在多大程度上适合于总体。虽然根据样本调查的结果也可在一定程度上说明总体的性质、特征，但不能从数量上推断总体。
分类 非概率抽样依抽样特点可分为方便抽样、定额抽样、立意抽样、滚雪球抽样和空间抽样。
方便抽样 样本限于总体中易于抽到的一部分。最常见的方便抽样是偶遇抽样，即研究者将在某一时间和环境中所遇到的每一总体单位均作为样本成员。“街头拦人法”就是一种偶遇抽样。某些调查对被调查者来说是不愉快的、麻烦的，这时为方便起见就采用以自愿被调查者为调查样本的方法。方便抽样是非随机抽样中最简单的方法，省时省钱，但样本代表性因受偶然因素的影响太大而得不到保证。
定额抽样 定额抽样也称配额抽样，是将总体依某种标准分层（群）；然后按照各层样本数与该层总体数成比例的原则主观抽取样本。定额抽样与分层概率抽样很接近，最大的不同是分层概率抽样的各层样本是随机抽取的，而定额抽样的各层样本是非随机的。总体也可按照多种标准的组合分层(群)，例如，在研究自杀问题时，考虑到婚姻与性别都可能对自杀有影响，可将研究对象分为未婚男性、已婚男性、未婚女性和已婚女性四个组，然后从各群非随机地抽样。定额抽样是通常使用的非概率抽样方法，样本除所选标识外无法保证代表性。
立意抽样 立意抽样又称判断抽样，研究人员从总体中选择那些被判断为最能代表总体的单位作样本的抽样方法。当研究者对自己的研究领域十分熟悉，对研究总体比较了解时采用这种抽样方法，可获代表性较高的样本。这种抽样方法多应用于总体小而内部差异大的情况，以及在总体边界无法确定或因研究者的时间与人力、物力有限时采用。
滚雪球抽样 以若干个具有所需特征的人为最初的调查对象，然后依靠他们提供认识的合格的调查对象，再由这些人提供第三批调查对象，……依次类推，样本如同滚雪球般由小变大。滚雪球抽样多用于总体单位的信息不足或观察性研究的情况。这种抽样中有些分子最后仍无法找到，有些分子被提供者漏而不提，两者都可能造成误差。
空间抽样 对非静止的、暂时性的空间相邻的群体的抽样方法。例如，游行与集会没有确定的总体，参加者从一地到另一地，一些人离去又有一些人进来，但这些事件是在一定范围内进行的。对这样的总体在同一时间内抽样十分重要，以便样本组成不会经历时间上的太大变化。具体作法是:若干调查员间隔均匀的距离,从某一方向开始，访问离他最近的人，然后每隔一定步数抽取一人为调查对象。
抽样列举 常用的非概率抽样有方便抽样、定额抽样、立意抽样、雪球抽样等。
方便抽样 方便抽样又称偶遇抽样。在这种抽样中，研究者选择那些最容易接近的人作为研究对象。此法常用于干预试验或预调查时，也可用于调查收尾时补缺。
立意抽样 立意抽样又称目的抽样和判断抽样。根据研究目的的需要和研究者的主观判断，选择研究对象。
雪球抽样 雪球抽样是指选择并调查几个具有研究目的所需要的特征的人，再依靠他们选择合乎研究需要的人，后者又可选择更多合乎研究需要的人，以此类推下去，样本就像滚雪球一样越来越大。
定额抽样 定额抽样是先将要研究的人群按某种特征划分成几个组别，然后，按照一定的比例，从每组人群中任意选择一定量的样本作为研究对象。由于抽样前先进行了分层处理，抽得的样本代表性比单纯的方便抽样要好。
优点 简单易行、成本低、省时间,在统计上也比概率抽样简单。但由于无法排除抽样者的主观性，无法控制和客观地测量样本代表性，因此样本不具有推论总体的性质。非概率抽样多用于探索性研究和预备性研究，以及总体边界不清难于实施概率抽样的研究。在实际应用中，非概率抽样往往与概率抽样结合使用。
方法 PPS抽样调查法;Q分类法;SEM模型;不重复抽样;专项调查;主观概率法;二手资料调研;二路焦点小组;产品留置测试;任意抽样;会议调查;典型调查法;分层抽样;分层最佳抽样;分层比例抽样;判断抽样;双重抽样;可行性研究;因果性调研;垃圾调研法;多维尺度法;多阶段抽样;威廉·戈塞;定性研究方法;定量研究方法;实地调研;家庭日记法;市场实验调查法;市场容量测定法;平衡量表法;投射研究;投影技法;抽样;抽样调查;抽签法;拐点调研;探索性调研;推销人员估计法;描述性调研;数值分配量表;整群抽样;文案调查法;文献调查法;无准备访问;案例研究法;案头调研;概率抽样;深层访谈法;滚雪球抽样;焦点访谈法;独立控制配额抽样;电话调查;留置调查;盲测;相互控制配额抽样;等比量表;等距抽样;等距量表;简单随机抽样;类别量表;经销商访谈;经验判断法;网上间接调查;网络调研;联合分析法;营销学术语英汉对照表;行踪分析;观察法;评价量表;询问法;辅助变量;辛迪加调研;逐户寻找法;邮寄调查;配对比较量表;配额抽样;重点调查;重置抽样;问卷调查法;随机号码表法;面谈访问法;顺序量表;&amp;hellip;</description></item><item><title>[HBase] Shell命令</title><link>https://mryqu.github.io/post/hbase_shell%E5%91%BD%E4%BB%A4/</link><pubDate>Fri, 27 Sep 2013 19:58:03 +0000</pubDate><guid>https://mryqu.github.io/post/hbase_shell%E5%91%BD%E4%BB%A4/</guid><description>HBase提供可扩展的基于jruby(JIRB)命令行已用于执行一些命令。HBase命令行主要归为六类。
1) 通用HBase命令 status 显示集群状态。可以为‘summary’、‘simple’或‘detailed’。默认为‘summary’。 用法:
hbase&amp;gt; status hbase&amp;gt; status ‘simple’ hbase&amp;gt; status ‘summary’ hbase&amp;gt; status ‘detailed’ version 输出HBase版本 用法:
hbase&amp;gt; version whoami 显示当前HBase用户。 用法:
hbase&amp;gt; whoami 2) 表管理命令 alter 修改列族schema；提供表名和指定新列族schema的字典。字典必须包含所要修改的列族名。例如，
对表‘t1’修改或添加列族‘f1’从当前值到最大版本5：
hbase&amp;gt; alter ‘t1’, NAME =&amp;gt; ‘f1’, VERSIONS =&amp;gt; 5 对多个列族进行操作:
hbase&amp;gt; alter ‘t1’, ‘f1’, {NAME =&amp;gt; ‘f2’, IN_MEMORY =&amp;gt; true}, {NAME =&amp;gt; ‘f3’, VERSIONS =&amp;gt; 5} 删除表‘t1’中的列族‘f1’，使用下列方法之一：
hbase&amp;gt; alter ‘t1’, NAME =&amp;gt; ‘f1’, METHOD =&amp;gt; ‘delete’ hbase&amp;gt; alter ‘t1’, ‘delete’ =&amp;gt; ‘f1’ 也可以修改诸如MAX_FILESIZE、READONLY、MEMSTORE_FLUSHSIZE、DEFERRED_LOG_FLUSH等表属性，例如将region最大容量设为128MB：</description></item><item><title>安装Python的simplejson库</title><link>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85python%E7%9A%84simplejson%E5%BA%93/</link><pubDate>Tue, 24 Sep 2013 22:51:08 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%89%E8%A3%85python%E7%9A%84simplejson%E5%BA%93/</guid><description>在Ubuntu下运行一个Python程序，遇到如下问题：ImportError: No module named simplejson。
首先查看一下Python和pip的版本：
python -V pip -V 竟然没有装pip，解决方案如下：
sudo apt-get install python-pip pip2 install simplejson</description></item><item><title>[Git] 预览远程仓库与本地仓库的差异</title><link>https://mryqu.github.io/post/git_%E9%A2%84%E8%A7%88%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E4%B8%8E%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E7%9A%84%E5%B7%AE%E5%BC%82/</link><pubDate>Mon, 23 Sep 2013 20:19:12 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E9%A2%84%E8%A7%88%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E4%B8%8E%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E7%9A%84%E5%B7%AE%E5%BC%82/</guid><description>首先使用git fetch更新远程分支的本地副本，这不会对任何本地分支造成影响。
使用git log HEAD..origin可以显示本地分支与origin远程分支之间的提交日志。
使用git log -p HEAD..origin除了显示上述提交日志外，还会显示每个提交的补丁。
使用git diff HEAD...origin显示整个补丁。此外如果有本地未提交的修改，可以使用git diff origin/master显示整个补丁。
如果不想使用git pull来合并所有远程提交，可以使用git cherry-pick接受所需要的指定远程提交。最后当准备好接受所有远程提交再使用git pull合并剩余远程提交。</description></item><item><title>尝试Protocol Buffers支持的各种数据类型</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95protocol_buffers%E6%94%AF%E6%8C%81%E7%9A%84%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Sun, 22 Sep 2013 22:45:14 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95protocol_buffers%E6%94%AF%E6%8C%81%E7%9A%84%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>Protocol Buffers(即protobuf)是Google开源的序列化库，是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化/反序列化。它很适合做数据存储或RPC的数据交换格式，常用作通信协议、数据存储等领域。 相比于常见的XML格式，ProtocolBuffers官方网站这样描述它的优点：
平台无关、语言无关； 高性能； 体积小； 使用简单； 兼容性好。 现在尝试一下Protocol Buffers支持的各种数据类型。
test.proto package com.yqu.proto; option java_package = &amp;#34;com.yqu.proto&amp;#34;; option java_outer_classname=&amp;#34;TestProtos&amp;#34;; message Test { required double doubleVar = 1; required float floatVar = 2; required int32 int32Var = 3; required int64 int64Var = 4; required uint32 uint32Var = 5; required uint64 uint64Var = 6; required sint32 sint32Var = 7; required sint64 sint64Var = 8; required fixed32 fixed32Var = 9; required fixed64 fixed64Var = 10; required sfixed32 sfixed32Var = 11; required sfixed64 sfixed64Var = 12; required bool booleanVar = 13; required string stringVar = 14; required bytes bytesVar = 15; enum Suit { SPADES = 0; HEARTS = 1; DIAMONDS = 2; CLUBS = 3; } required Suit enumVar = 16 [default = HEARTS]; repeated int32 int32ArrayVar = 17; repeated uint32 uint32ArrayVar = 18 [packed=true]; repeated string stringArrayVar = 19; message MsgVar { required string url = 1; optional string title = 2; } repeated MsgVar msgVar = 20; } 使用Google提供的Protocol Buffers编译器生成Java语言：</description></item><item><title>[Git] 获取两个版本间所有变更的文件列表</title><link>https://mryqu.github.io/post/git_%E8%8E%B7%E5%8F%96%E4%B8%A4%E4%B8%AA%E7%89%88%E6%9C%AC%E9%97%B4%E6%89%80%E6%9C%89%E5%8F%98%E6%9B%B4%E7%9A%84%E6%96%87%E4%BB%B6%E5%88%97%E8%A1%A8/</link><pubDate>Sun, 22 Sep 2013 07:25:11 +0000</pubDate><guid>https://mryqu.github.io/post/git_%E8%8E%B7%E5%8F%96%E4%B8%A4%E4%B8%AA%E7%89%88%E6%9C%AC%E9%97%B4%E6%89%80%E6%9C%89%E5%8F%98%E6%9B%B4%E7%9A%84%E6%96%87%E4%BB%B6%E5%88%97%E8%A1%A8/</guid><description>git diff commit-SHA1 commit-SHA2 &amp;ndash;name-status返回变更的文件列表，每个文件前带有变更状态：
&amp;rsquo; &amp;rsquo; = unmodified M = modified A = added D = deleted R = renamed C = copied U = updated but unmergedgit diff commit-SHA1 commit-SHA2 &amp;ndash;stat返回变更的文件列表，每个文件后面带有变更统计信息。</description></item><item><title>[Hadoop] 安装protobuf</title><link>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85protobuf/</link><pubDate>Sat, 21 Sep 2013 16:23:17 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85protobuf/</guid><description>Protocol Buffers (即protobuf)是Google的语言无关、平台无关、结构数据序列化的可扩展机制。 在Window平台编译Hadoop需要protobuf，下载所需的protoc-2.5.0-win32.zip，将protoc.exe复制到某目录，加入PATH变量即可。
参考 Hadoop WIKI: How to Contribute to Hadoop Hadoop WIKI: ProtocolBuffers protobuf releases GitHub: google/protobuf protobuf documents</description></item><item><title>Python安装oauth2库</title><link>https://mryqu.github.io/post/python%E5%AE%89%E8%A3%85oauth2%E5%BA%93/</link><pubDate>Sat, 21 Sep 2013 13:50:50 +0000</pubDate><guid>https://mryqu.github.io/post/python%E5%AE%89%E8%A3%85oauth2%E5%BA%93/</guid><description>玩一下用python和twitterAPI访问Twitter数据，首先需要安装oauth2库以获得身份验证。pip是PythonPackaging Authority(PyPA)推荐用于安装Python包的工具。首先下载get-pip.py，然后通过下面的命令安装python get-pip.py pip.exe会被安装到\script\目录下。之后就可以用pip安装oauth2包了.</description></item><item><title>SSH keys for Git System</title><link>https://mryqu.github.io/post/ssh_keys_for_git_system/</link><pubDate>Wed, 18 Sep 2013 22:58:33 +0000</pubDate><guid>https://mryqu.github.io/post/ssh_keys_for_git_system/</guid><description>SSH keys An SSH key allows you to establish a secure connection betweenyour computer and Git system such as GitHub, GitLab. Before generating an SSH key, check if your system already hasone by running cat ~/.ssh/id_rsa.pub . If you see a long string startingwith ssh-rsa or ssh-dsa ,you can skip the ssh-keygen step. To generate a new SSH key, just open your terminal and use codebelow. The ssh-keygen command prompts you for a location andfilename to store the key pair and for a password.</description></item><item><title>尝试Apache Avro支持的各种数据类型</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95apache_avro%E6%94%AF%E6%8C%81%E7%9A%84%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Wed, 18 Sep 2013 22:16:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95apache_avro%E6%94%AF%E6%8C%81%E7%9A%84%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>Apache Avro是一个独立与编程语言的数据序列化系统，该项目由Doug Cutting（Hadoop之父）牵头创建的。它可以提供：
丰富的数据结构类型 快速可压缩的二进制数据形式 存储持久数据的文件容器 远程过程调用（RPC） 同动态语言的简单集成。读写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只值得在静态类型语言中实现。 今天尝试一下Apache Avro支持的各种数据类型。
test.avsc {&amp;#34;namespace&amp;#34;: &amp;#34;com.yqu.avro&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;record&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Test&amp;#34;, &amp;#34;fields&amp;#34;: [ {&amp;#34;name&amp;#34;: &amp;#34;stringVar&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;string&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;bytesVar&amp;#34;, &amp;#34;type&amp;#34;: [&amp;#34;bytes&amp;#34;, &amp;#34;null&amp;#34;]}, {&amp;#34;name&amp;#34;: &amp;#34;booleanVar&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;boolean&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;intVar&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;int&amp;#34;, &amp;#34;order&amp;#34;:&amp;#34;descending&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;longVar&amp;#34;, &amp;#34;type&amp;#34;: [&amp;#34;long&amp;#34;, &amp;#34;null&amp;#34;], &amp;#34;order&amp;#34;:&amp;#34;ascending&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;floatVar&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;float&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;doubleVar&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;double&amp;#34;}, {&amp;#34;name&amp;#34;: &amp;#34;enumVar&amp;#34;, &amp;#34;type&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;enum&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suit&amp;#34;, &amp;#34;symbols&amp;#34; : [&amp;#34;SPADES&amp;#34;, &amp;#34;HEARTS&amp;#34;, &amp;#34;DIAMONDS&amp;#34;, &amp;#34;CLUBS&amp;#34;]}}, {&amp;#34;name&amp;#34;: &amp;#34;strArrayVar&amp;#34;, &amp;#34;type&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;array&amp;#34;, &amp;#34;items&amp;#34;: &amp;#34;string&amp;#34;}}, {&amp;#34;name&amp;#34;: &amp;#34;intArrayVar&amp;#34;, &amp;#34;type&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;array&amp;#34;, &amp;#34;items&amp;#34;: &amp;#34;int&amp;#34;}}, {&amp;#34;name&amp;#34;: &amp;#34;mapVar&amp;#34;, &amp;#34;type&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;map&amp;#34;, &amp;#34;values&amp;#34;: &amp;#34;long&amp;#34;}}, {&amp;#34;name&amp;#34;: &amp;#34;fixedVar&amp;#34;, &amp;#34;type&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;fixed&amp;#34;, &amp;#34;size&amp;#34;: 16, &amp;#34;name&amp;#34;: &amp;#34;md5&amp;#34;}} ] } 使用下列命令将schema编译成代码</description></item><item><title>[算法] Trie（数字树、字典树、前缀树）</title><link>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_trie%E6%95%B0%E5%AD%97%E6%A0%91%E5%AD%97%E5%85%B8%E6%A0%91%E5%89%8D%E7%BC%80%E6%A0%91/</link><pubDate>Wed, 18 Sep 2013 21:06:56 +0000</pubDate><guid>https://mryqu.github.io/post/%E7%AE%97%E6%B3%95_trie%E6%95%B0%E5%AD%97%E6%A0%91%E5%AD%97%E5%85%B8%E6%A0%91%E5%89%8D%E7%BC%80%E6%A0%91/</guid><description>术语trie取自retrieval，也被称为数字树、字典树或前缀树，是一种有序树数据结构，哈希树的变种。 与二叉查找树不同，树中节点不存储与节点关联的键，而是通过树中的位置定义键。一个节点的所有子孙节点拥有与该节点相同的字符串前缀，根节点与空字符串相关联。并不是每个节点都与值关联，仅叶节点和部分内部节点与值关联。 含有键为&amp;quot;A&amp;quot;、&amp;ldquo;to&amp;rdquo;、&amp;ldquo;tea&amp;rdquo;、&amp;ldquo;ted&amp;rdquo;、&amp;ldquo;ten&amp;rdquo;、&amp;ldquo;i&amp;rdquo;、&amp;ldquo;in&amp;quot;和&amp;quot;inn&amp;quot;的trie示例。 trie 中的键通常是字符串，但也可以是其它的结构。trie的算法可以很容易地修改为处理其它结构的有序序列，比如一串数字或者形状的排列。比如，bitwise trie中的键是一串位元，可以用于表示整数或者内存地址。
性质 根节点不包含字符，除根节点外每一个节点都只包含一个字符； 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串； 每个节点的所有子节点包含的字符都不相同。 应用 替代其他数据结构 trie较二叉查找树有很多优点，trie可用于替代哈希表，优点如下：
trie数据查找与不完美哈希表（链表实现，完美哈希表为数组实现）在最差情况下更快：对于trie，最差情况为O(m)，m为查找字符串的长度；对于不完美哈希表，会有键冲突（不同键哈希相同），最差情况为O(N)，N为全部字符产集合个数。典型情况下是O(m)用于哈希计算、O(1)用于数据查找。 trie中不同键没有冲突 trie的桶与哈希表用于存储键冲突的桶类似，仅在单个键与多个值关联时需要 当更多的键加入trie，无需提供哈希方法或改变哈希方法 tire通过键为条目提供了字母顺序Trie也有一些缺点： trie数据查找在某些情况下（尤其当数据直接从磁盘或随机访问时间远远高于主内存的辅助存储设备时）比哈希表慢 当键为某些类型时（例如浮点数）之类的键，前缀链很长且前缀不是特别有意义。然而bitwisetrie能够处理标注IEEE单精度和双精度浮点数。 一些trie会比哈希表消耗更多空间：对于trie，每个字符串的每个字符都可能需要分配内存；对于大多数哈希表，为整个条目分配一块内存。 字典表示 典型应用是预测文本排序（常被搜索引擎系统用于文本词频统计）、字典自动完成、字符串近似匹配（拼写检查、断字）。
实现 trie基本操作有：查找、插入和删除。 trie数据查找的方法为
从根结点开始一次搜索； 取得要查找关键词的第一个字母，并根据该字母选择对应的子树并转到该子树继续进行检索； 在相应的子树上，取得要查找关键词的第二个字母,并进一步选择对应的子树进行检索。 迭代过程…… 在某个结点处，关键词的所有字母已被取出，则读取附在该结点上的信息，即完成查找。 public class Trie { private Node root = new Node(&amp;#34;&amp;#34;); public Trie() {} public Trie(List argInitialWords) { for (String word:argInitialWords) { addWord(word); } } public void addWord(String argWord) { char argChars[] = argWord.toCharArray(); Node currentNode = root; for (int i = 0; i &amp;lt; argChars.</description></item><item><title>JDK7中的双端队列Deque实现</title><link>https://mryqu.github.io/post/jdk7%E4%B8%AD%E7%9A%84%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97deque%E5%AE%9E%E7%8E%B0/</link><pubDate>Thu, 08 Aug 2013 20:12:21 +0000</pubDate><guid>https://mryqu.github.io/post/jdk7%E4%B8%AD%E7%9A%84%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97deque%E5%AE%9E%E7%8E%B0/</guid><description>双端队列Deque（全名double-endedqueue）是一种数据结构，可在双端队列的两端插入、获取或删除元素。队列和栈可以认为是双端队列的特列。 Deque常用的方法：
First Element (Head)Last Element (Tail)Throws exceptionSpecial valueThrows exceptionSpecial valueInsertaddFirst(e)offerFirst(e)addLast(e)offerLast(e)RemoveremoveFirst()pollFirst()removeLast()pollLast()ExaminegetFirst()peekFirst()getLast()peekLast() Deque扩展了Queue接口，当Deque用作FIFO队列时，元素从双端队列队尾加入，从队首移出。从Queue接口继承的方法等同于Deque如下方法：
Queue&amp;nbsp;MethodEquivalent&amp;nbsp;Deque&amp;nbsp;Methodadd(e)addLast(e)offer(e)offerLast(e)remove()removeFirst()poll()pollFirst()element()getFirst()peek()peekFirst() Deques也可作为LIFO栈。该接口应该优先于遗留的Stack类使用。当双端队列用作栈时，元素从队首入栈和出栈。Stack方法等同与Deque如下方法：
Stack MethodEquivalent&amp;nbsp;Deque&amp;nbsp;Methodpush(e)addFirst(e)pop()removeFirst()peek()peekFirst() 注意：当deque用作队列或堆栈时，peek方法也可正常工作，都从deque起始位置移除元素。 JDK6加入的Deque实现 LinkedList: 一个基于链接节点实现的无界双端队列。允许null元素。 ArrayDeque: 一个基于可变长度数组实现的无界双端队列。不允许null元素。
就效率而言，ArrayDeque在两端添加或删除元素时比LinkedList更高效。ArrayDeque用作栈时比Stack更快，用作队列时比LinkedList更快。 LinkedList实现比ArrayDeque实现更复杂，耗费更多的内存。当遍历双端列表时删除当前元素，LinkedList比ArrayDeque更高效。 继承BlockingQueue的BlockingDeque接口及其实现LinkedBlockingDeque：一个基于链接节点实现的可选有界双端队列。如果LinkedBlockingDeque在构造时没有设定容量大小，添加元素永远不会有阻塞队列的等待（至少在其中有Integer.MAX_VALUE元素之前不会）。 LinkedBlockingDeque实现采用一个独占锁，所有对队列的操作都进行了锁保护，因而很好的支持双向阻塞的特性。缺点是由于独占锁，所以不能同时进行两个操作，这样性能上就大打折扣。 LinkedBlockingDeque实现具有显对低的开销及相对低的可扩展性。如果仅需要FIFO队列功能，最好使用LinkedBlockingQueue，LinkedBlockingQueue具有相同的开销但是有更好的伸缩性(例如很多线程竞争时保持更好的性能)。 深入浅出 Java Concurrency (24): 并发容器 part 9 双向队列集合 Deque
深入浅出 Java Concurrency (25): 并发容器 part 10 双向并发阻塞队列 BlockingDeque
JDK7加入的Deque实现 ConcurrentLinkedDeque：一个基于链接节点实现的无界无阻塞双端队列。收集关于队列大小的信息会很慢，需要遍历队列。 ConcurrentLinkedDeque具有跟LinkedBlockingDeque相反的表现：相对高的开销及很好的可伸缩性（使用CAS操作进行非堵塞操作，减少了锁的开销，避免序列化瓶颈）。 [concurrency-interest] BlockingDeque and revised Deque
Deque应用：回文（Palindrome）检查 Deque的应用不是很多，很容易使用双端队列解决的一个有趣问题是经典的回文问题。回文是正着读和倒着读都一样的字符串，例如radar、toot和madam。 回文检查方案是采用Deque存储字符串的字符，将字符串中的字符从左到右插入Deque尾部，则deque头部将持有字符串的首字符，deque尾部将持有字符串的末字符。然后从Deque两端移出字符进行比较，直到Deque内字符数为0或1为止。 public class PalindromeChecker { public static boolean palchecker(String str) { if(str==null || str.isEmpty()) return false; ArrayDeque aDeque = new ArrayDeque (str.</description></item><item><title>序列化压缩实现及对比测试</title><link>https://mryqu.github.io/post/%E5%BA%8F%E5%88%97%E5%8C%96%E5%8E%8B%E7%BC%A9%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%AF%B9%E6%AF%94%E6%B5%8B%E8%AF%95/</link><pubDate>Thu, 08 Aug 2013 07:13:16 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%BA%8F%E5%88%97%E5%8C%96%E5%8E%8B%E7%BC%A9%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%AF%B9%E6%AF%94%E6%B5%8B%E8%AF%95/</guid><description>网上介绍序列化压缩的用gzip比较多。写个测试代码，测试一下四种序列化方式：
无压缩 zlib压缩 gzip压缩 zip压缩 测例结果显示压缩效果：gzip压缩 &amp;gt; zlib压缩 &amp;gt; zip压缩&amp;gt; 无压缩 测例结果显示压缩速度：zlib压缩&amp;gt; gzip压缩&amp;gt; zip压缩 = 无压缩 确实用gzip性价比比较高！
### zlib介绍
zlib是一个开源库，提供了在内存中压缩和解压的函数。zlib它的设计目标是处理单纯的数据（而不管数据的来源是什么）。
### gzip介绍
gzip是UNIX下的一种数据格式(.tar.gz)。gzip是在zlib之上，包了一层，在头和尾添加了一些额外的信息。 gzip是一种文件压缩工具（或该压缩工具产生的压缩文件格式），它的设计目标是处理单个的文件。gzip在压缩文件中的数据时使用的就是zlib。为了保存与文件属性有关的信息，gzip需要在压缩文件（.gz）中保存更多的头信息内容，而zlib不用考虑这一点。但gzip只适用于单个文件，所以我们在UNIX/Linux上经常看到的压缩包后缀都是.tar.gz或*.tgz，也就是先用tar把多个文件打包成单个文件，再用gzip压缩的结果。
### zip介绍
zip只是一种数据结构，跟rar同级别的。zip是适用于压缩多个文件的格式（相应的工具有PkZip和WinZip等），因此，zip文件还要进一步包含文件目录结构的信息，比gzip的头信息更多。但需要注意，zip格式可采用多种压缩算法，我们常见的zip文件大多不是用zlib的算法压缩的，其压缩数据的格式与gzip大不一样。 Java SDK提供了对上述三种压缩技术的支持：Inflater类和Deflater类直接用zlib库对数据压缩/解压缩，GZIPInputStream类和GZIPOutputStream类提供了对gzip格式的支持，ZipFile、ZipInputStream、ZipOutputStream则用于处理zip格式的文件。 所以，你应当根据你的具体需求，选择不同的压缩技术：如果只需要压缩/解压缩数据，你可以直接用zlib实现，如果需要生成gzip格式的文件或解压其他工具的压缩结果，你就必须用gzip或zip等相关的类来处理了。
测试代码 import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.File; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.io.Serializable; import java.util.Arrays; import java.util.zip.DataFormatException; import java.util.zip.Deflater; import java.util.zip.GZIPInputStream; import java.util.zip.GZIPOutputStream; import java.util.zip.Inflater; import java.util.zip.ZipEntry; import java.util.zip.ZipInputStream; import java.util.zip.ZipOutputStream; public class TestCompressedSerializaion { public static BigObject createBigObject() { final int SIZE = 1 &amp;lt;&amp;lt; 12; int[] bigArray = new int[SIZE]; for (int i = 0; i &amp;lt; SIZE; ++i) { bigArray[i] = (int) (Math.</description></item><item><title>JDK7中的队列实现</title><link>https://mryqu.github.io/post/jdk7%E4%B8%AD%E7%9A%84%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0/</link><pubDate>Wed, 07 Aug 2013 20:02:21 +0000</pubDate><guid>https://mryqu.github.io/post/jdk7%E4%B8%AD%E7%9A%84%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0/</guid><description>JDK7之前已有的队列实现 JDK7之前已有的队列实现分为两类：用于一般用途的实现和用于并发的实现。
用于一般用途的队列实现 LinkedList实现了Queue接口，为offer、poll等方法提供了先入先出队列操作。 PriorityQueue类是基于堆（数据结构）的优先队列。如果PriorityQueue在构造时指定比较器Comparator，则用比较器对元素排序，否则使用元素的自然排序（通过其java.util.Comparable实现）。队列的取操作（poll、remove、peek和element）访问队列头部的元素。队列头部是顺序上最小的元素或具有相同最小值的元素之一。PriorityQueue的iterator方法提供的爹抬起不保证按特定顺序遍历PriorityQueue中的元素。
并发队列实现 java.util.concurrent包下包含一系列同步的Queue接口和类。 ConcurrentLinkedQueue基于链接节点的、线程安全的队列。并发访问不需要同步。因为它在队列的尾部添加元素并从头部删除它们，所以只要不需要知道队列的大小。ConcurrentLinkedQueue对公共集合的共享访问就可以工作得很好。收集关于队列大小的信息会很慢，需要遍历队列。 http://www.cs.rochester.edu/research/synchronization/pseudocode/queues.html JDK5加入了BlockingQueue接口和五个阻塞队列类。阻塞队列BlockingQueue扩展了Queue的操作，元素添加操作会在没有空间可用时阻塞，而元素获取操作会在队列中没有任何东西时阻塞。 五个队列所提供的各有不同：
ArrayBlockingQueue：一个基于数组实现的有界（大小有限）队列。 LinkedBlockingQueue：一个基于链接节点实现的可选有界队列。如果LinkedBlockingQueue在构造时没有设定容量大小，添加元素永远不会有阻塞队列的等待（至少在其中有Integer.MAX_VALUE元素之前不会）。 PriorityBlockingQueue：一个基于堆实现的无界优先级队列。 DelayQueue：一个基于堆实现的、基于时间的调度队列。 SynchronousQueue：一个利用BlockingQueue接口的会合（rendezvous）机制。它没有内部容量。它就像线程之间的手递手机制，类似于生活中一手交钱一手交货这种情况。在队列中加入一个元素的生产者会等待另一个线程的消费者。当这个消费者出现时，这个元素就直接在消费者和生产者之间传递，永远不会加入到阻塞队列中。公平模式下等待线程按照FIFO顺序访问队列，非公平模式下等待线程访问顺序不定。 JDK7的TransferQueue JDK7加入了继承自BlockingQueue的TransferQueue接口和及其实现LinkedTransferQueue：一个基于链接节点实现的无界TransferQueue。 TransferQueue可以让使用者决定使用正常的BlockingQueue语义还是有保障的手递手机制，因而比SynchronousQueue更通用和有效。当队列内已经存在元素时，调用transfer会确保所有已有元素在此传递元素之前被处理。DougLea称之为容量智能化，LinkedTransferQueue实际上是ConcurrentLinkedQueue,(在公平模式下)SynchronousQueue, 无界的LinkedBlockingQueues等的超集。 TransferQueue混合了若干高级特性的同时，也提供了更高的性能。LinkedTransferQueue相比不公平模式SynchronousQueue，性能超过3倍；相比公平模式SynchronousQueue，性能超过14倍。SynchronousQueueJDK5实现是使用两个队列（用于等待生产者和等待消费者）,用一个锁保护这两个队列。而LinkedTransferQueue实现使用CAS操作进行非堵塞操作，减少了锁的开销，避免序列化瓶颈。 获得TransferQueue队列大小会很慢，需要遍历队列。 http://tech.puredanger.com/2009/02/28/java-7-transferqueue/
http://www.blogjava.net/yongboy/archive/2012/02/04/369575.html</description></item><item><title>JDK7的Fork/Join并发框架</title><link>https://mryqu.github.io/post/jdk7%E7%9A%84forkjoin%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6/</link><pubDate>Tue, 06 Aug 2013 20:02:21 +0000</pubDate><guid>https://mryqu.github.io/post/jdk7%E7%9A%84forkjoin%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6/</guid><description>硬件的发展趋势非常清晰；Moore定律表明不会出现更高的时钟频率，但是每个芯片上会集成更多的内核。很容易想象让十几个处理器繁忙地处理一个粗粒度的任务边界（比如一个用户请求），但是这项技术不会扩大到数千个处理器——在这种环境下短时间内流量可能会呈指数级增长，但最终硬件趋势将会占上风。当跨入多内核时代时，我们需要找到更细粒度的并行性，否则将面临即便有许多工作需要去做而处理器却仍处于空闲的风险。如果希望跟上技术发展的脚步，软件平台也必须配合主流硬件平台的转变。最终，Java7包含的一种框架，用于表示某种更细粒度级别的并行算法：Fork/Join框架。 Fork/Join融合了分而治之（divide-and-conquer）编程技术；获取问题后，递归地将它分成多个子问题，直到每个子问题都足够小，以至于可以高效地串行地解决它们。递归的过程将会把问题分成两个或者多个子问题，然后把这些问题放入队列中等待处理（fork步骤），接下来等待所有子问题的结果（join步骤），把多个结果合并到一起。 假如充分分解任务的大小，那么创建一个线程的开销有可能超出执行该任务的开销。因此，fork/join框架使用与可用核数相匹配的适当大小的线程池，以减少这种频繁交换的开销。为避免线程空闲，框架包含了一个工作窃取方法，该方法可以使空闲线程从一个执行较慢的线程中窃取等待其处理的工作。 Java教程 - Fork/Join
分解和合并：Java 也擅长轻松的并行编程！
JDK 7 中的 Fork/Join 模式
Doug Lea： &amp;ldquo;A Java Fork/Join Framework&amp;quot;：了解 Fork/Join 模式的实现机制和执行性能。 InfoQ: Doug Lea谈Fork/Join框架</description></item><item><title>Java NaN小结</title><link>https://mryqu.github.io/post/java_nan%E5%B0%8F%E7%BB%93/</link><pubDate>Mon, 05 Aug 2013 23:14:48 +0000</pubDate><guid>https://mryqu.github.io/post/java_nan%E5%B0%8F%E7%BB%93/</guid><description>Double.NAN介绍 Double类有个NaN常量，是Not a Number的缩写，其值等于Double.longBitsToDouble(0x7ff8000000000000L) ，用于表示非数值。NaN必须使用isNaN(double)方法来判断，NaN与任何double数值进行加减乘除等数学运算后的结果仍然是NaN，且NaN使用==运算符与自身进行判断返回结果为false。测试代码如下： 测试结果如下：
Double.NaN==Double.NaN :false Double.isNaN(Double.NaN*0) :true Double.NaN*0==0 :false Double.isNaN(Double.NaN/0) :true Double.NaN/0==0 :false Double.isNaN(0/Double.NaN) :true 0/Double.NaN==0 :false Double.isNaN(Double.NaN+0) :true Double.NaN+0==0 :false Double.isNaN(Double.NaN-0) :true Double.NaN-0==0 :false Double.isNaN(Double.NaN*Double.NaN) :true Double.NaN*Double.NaN==0 :false 自定义NAN介绍 Double.NaN可以用来表示计算结果发生异常，但是无法获知异常原因。我们可以通过自定义NAN来解决这一问题。使用Double类的isNaN(double)方法判断自定义NAN，其返回结果为true，我们可以通过自己的方法判决到底是那种NaN。测试代码如下： 测试结果如下：
Double.isNaN(Double.NaN) :true MyNaN.isMyNaN(Double.NaN) :false Double.isNaN(MyNaN.INVALID_PARAMETER_NAN) :true MyNaN.isMyNaN(MyNaN.INVALID_PARAMETER_NAN) :true Double.isNaN(Double.longBitsToDouble(0xffff000000000123L)) :true MyNaN.isMyNaN(Double.longBitsToDouble(0xffff000000000123L)) :false</description></item><item><title>Ubuntu操作笔记</title><link>https://mryqu.github.io/post/ubuntu-notes/</link><pubDate>Mon, 05 Aug 2013 22:49:19 +0000</pubDate><guid>https://mryqu.github.io/post/ubuntu-notes/</guid><description>在Ubuntu上修改主机名 (2013-08-05) 显示主机名 hostname -s 更多细节见hostname帮助文档。
修改主机名 sudo hostname your-new-name # Ubuntu专有 hostnamectl set-hostname new-hostname 更多细节见hostnamectl帮助文档。 上述命令重启服务器后失效。
修改主机名配置 sudo -H vi /etc/hostname sudo -H vi /etc/hosts Ubuntu下显示本机IP (2013-10-20) 命令为：ip addr show 感觉比ifconfig eth0更通用些！
在Ubuntu Linux上安装netstat (2014-01-01) 在UbuntuLinux上安装netstat，apt-get其实是找不到netstat包的，需要用apt-get安装net-tools 。net-tools 是Linux平台NET-3网络分发包，包括arp、hostname、ifconfig、netstat、rarp、route、plipconfig、slattach、mii-tool、iptunnel和ipmaddr工具。
apt-get install net-tools 在Ubuntu中禁掉IPv6 (2015-03-20) 为了禁止掉IPv6，需要在/etc/sysctl.conf做如下修改：
net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 如果IPv6仍没有禁掉，是由于sysctl.conf没有激活造成的。为了解决上述问题，执行下面的命令：
sudo sysctl -p 之后，运行:
$ cat /proc/sys/net/ipv6/conf/all/disable_ipv6 它将返回1，这表示IPv6被成功禁止掉。 在Ubuntu中强制Apt-get使用IPv4或IPv6 (2015-05-18) 快速命令行选项 如果只想一次使apt-get使用IPv4或IPv6，使用下列步骤。该功能尽在apt-get的0.9.7.9~exp1版本后可用。首先，通过如下命令确认apt-get版本高于0.9.7.9~exp1：
apt-get --version 结果近似于:</description></item><item><title>Java线程是否会被垃圾回收？</title><link>https://mryqu.github.io/post/java%E7%BA%BF%E7%A8%8B%E6%98%AF%E5%90%A6%E4%BC%9A%E8%A2%AB%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Tue, 30 Jul 2013 20:33:07 +0000</pubDate><guid>https://mryqu.github.io/post/java%E7%BA%BF%E7%A8%8B%E6%98%AF%E5%90%A6%E4%BC%9A%E8%A2%AB%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>如果将线程启动后，然后线程变量置空，线程会怎么样？
import java.lang.ref.WeakReference; public class TestThread { public static void testUnreferencedThread() { // anonymous class extends Thread Thread t = new Thread() { public void run() { // infinite loop while (true) { try { Thread.sleep(1000); } catch (InterruptedException e) {} // as long as this line printed out, you know it is alive. System.out.println(&amp;#34;thread is running...&amp;#34;); } } }; t.start(); WeakReference&amp;lt;Thread&amp;gt; wr = new WeakReference&amp;lt;Thread&amp;gt;(t); t = null; // no more references for Thread t // another infinite loop while (true) { try { Thread.</description></item><item><title>显示jar文件中某个类的公开方法</title><link>https://mryqu.github.io/post/%E6%98%BE%E7%A4%BAjar%E6%96%87%E4%BB%B6%E4%B8%AD%E6%9F%90%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%85%AC%E5%BC%80%E6%96%B9%E6%B3%95/</link><pubDate>Fri, 26 Jul 2013 20:58:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%98%BE%E7%A4%BAjar%E6%96%87%E4%BB%B6%E4%B8%AD%E6%9F%90%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%85%AC%E5%BC%80%E6%96%B9%E6%B3%95/</guid><description>使用jar命令显示jar文件的内容 C:\&amp;gt;jar tvf log4j.jar 0 SatAug 25 00:29:46 GMT+08:00 2007 META-INF/ 262 Sat Aug 25 00:29:44GMT+08:00 2007 META-INF/MANIFEST.MF 0 SatAug 25 00:10:04 GMT+08:00 2007 org/ 0 SatAug 25 00:10:04 GMT+08:00 2007 org/apache/ 0 SatAug 25 00:10:06 GMT+08:00 2007 org/apache/log4j/ ................. 676 Sat Aug 25 00:10:04GMT+08:00 2007 org/apache/log4j/Appender.class 2567 Sat Aug 25 00:10:04 GMT+08:00 2007org/apache/log4j/Logger.class 1038 Sat Aug 25 00:10:04 GMT+08:00 2007org/apache/log4j/Layout.class ................. 0 SatAug 25 00:29:46 GMT+08:00 2007 META-INF/maven/ 0 SatAug 25 00:29:46 GMT+08:00 2007 META-INF/maven/log4j/ 0 SatAug 25 00:29:46 GMT+08:00 2007 META-INF/maven/log4j/log4j/ 17780 Sat Aug 25 00:09:44 GMT+08:00 2007META-INF/maven/log4j/log4j/pom.</description></item><item><title>Java RMI 客户端回调（callback）</title><link>https://mryqu.github.io/post/java_rmi_%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9B%9E%E8%B0%83callback/</link><pubDate>Fri, 26 Jul 2013 19:40:26 +0000</pubDate><guid>https://mryqu.github.io/post/java_rmi_%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9B%9E%E8%B0%83callback/</guid><description>项目的代码用到了Java RMI 客户端回调，了解一下这方面资料。 http://docs.oracle.com/cd/E13211_01/wle/rmi/callbak.htm
http://blog.sina.com.cn/s/blog_6a1928130100mmk5.html</description></item><item><title>Python dictionary practice</title><link>https://mryqu.github.io/post/python_dictionary_practice/</link><pubDate>Thu, 25 Jul 2013 19:55:43 +0000</pubDate><guid>https://mryqu.github.io/post/python_dictionary_practice/</guid><description>reverse Dict (Swap Key and Value) &amp;gt;&amp;gt;&amp;gt; a={&amp;#34;a&amp;#34;:123,&amp;#34;b&amp;#34;:222,&amp;#34;c&amp;#34;:30,&amp;#34;d&amp;#34;:6,&amp;#34;e&amp;#34;:1} &amp;gt;&amp;gt;&amp;gt; print a {&amp;#39;a&amp;#39;: 123, &amp;#39;c&amp;#39;: 30, &amp;#39;b&amp;#39;: 222, &amp;#39;e&amp;#39;: 1, &amp;#39;d&amp;#39;: 6} &amp;gt;&amp;gt;&amp;gt; res = dict((v,k) for k,v in a.iteritems()) &amp;gt;&amp;gt;&amp;gt; print res {1: &amp;#39;e&amp;#39;, 6: &amp;#39;d&amp;#39;, 123: &amp;#39;a&amp;#39;, 222: &amp;#39;b&amp;#39;, 30: &amp;#39;c&amp;#39;} &amp;gt;&amp;gt;&amp;gt; a={&amp;#34;a&amp;#34;:123,&amp;#34;b&amp;#34;:222,&amp;#34;c&amp;#34;:30,&amp;#34;d&amp;#34;:6,&amp;#34;e&amp;#34;:1} &amp;gt;&amp;gt;&amp;gt; print a {&amp;#39;a&amp;#39;: 123, &amp;#39;c&amp;#39;: 30, &amp;#39;b&amp;#39;: 222, &amp;#39;e&amp;#39;: 1, &amp;#39;d&amp;#39;: 6} &amp;gt;&amp;gt;&amp;gt; res = dict(zip(a.values(), a.keys())) &amp;gt;&amp;gt;&amp;gt; print res {1: &amp;#39;e&amp;#39;, 6: &amp;#39;d&amp;#39;, 123: &amp;#39;a&amp;#39;, 222: &amp;#39;b&amp;#39;, 30: &amp;#39;c&amp;#39;} Top N by Dict Value &amp;gt;&amp;gt;&amp;gt; from collections import Counter &amp;gt;&amp;gt;&amp;gt; a={&amp;#34;a&amp;#34;:123,&amp;#34;b&amp;#34;:222,&amp;#34;c&amp;#34;:30,&amp;#34;d&amp;#34;:6,&amp;#34;e&amp;#34;:1} &amp;gt;&amp;gt;&amp;gt; top_three = Counter(a).</description></item><item><title>[Hadoop] 在RACE虚拟机上安装单节点Hadoop</title><link>https://mryqu.github.io/post/hadoop_%E5%9C%A8race%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%8A%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9hadoop/</link><pubDate>Wed, 24 Jul 2013 21:58:09 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%9C%A8race%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%8A%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9hadoop/</guid><description>RACE（Remote Access ComputerEnvironment）是SAS公司内使用的虚拟机集成系统。通过RACE系统申请虚拟机，使用自己或别的项目组、同事创建的RACEimage安装操作系统和应用程序，省心省力。
RACE安装及配置 申请一台RACE虚拟机，使用RACE Image（Id：579290，STG_LAX_RHEL6_SAS94_16G_Ora112 ）安装了RHEL linux操作系统。 启动后，使用下列脚本替换主机信息
/nfs/cardio/vol/vol1/sasinside/setup/changehost94.sh 安装Java JDK 如果RACE Image没有安装Java JDK的话，需要自己安装：
yum install java-1.6.0-openjdk java-1.6.0-openjdk-devel 幸好在/sasjdk/jdk发现很多版本的Java JDK，最后决定使用下列位置的openjdk:
/usr/lib/jvm/java-openjdk/ 创建帐号 原系统中没有安装hadoop，但是有hadoop帐号。我没有找到密码，只好重做一把：
userdel hadoop useradd hadoop passwd hadoop 下载并解压缩Hadoop 因为Hadoop 2.0采用YARN，hive、mahout等需要MapReduce V1的可能无法使用，这里安装的是Hadoop 1.2.1。
# mkdir /opt/hadoop # cd /opt/hadoop/ # wget http://download.nextag.com/apache/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz # tar -xzf hadoop-1.2.1.tar.gz # chown -R hadoop /opt/hadoop # cd /opt/hadoop/hadoop-1.2.1/ 配置Hadoop 下列为Hadoop的单节点伪分布模式配置。 conf/core-site.xml:
fs.default.name hdfs://localhost:9000/ conf/hdfs-site.xml:
dfs.replication 1 conf/mapred-site.xml:
mapred.job.tracker localhost:9001 conf/hadoop-env.sh:
export JAVA_HOME=/usr/lib/jvm/java-openjdk/ export HADOOP_OPTS=-Djava.</description></item><item><title>ActiveMQ集群</title><link>https://mryqu.github.io/post/activemq%E9%9B%86%E7%BE%A4/</link><pubDate>Wed, 24 Jul 2013 21:24:19 +0000</pubDate><guid>https://mryqu.github.io/post/activemq%E9%9B%86%E7%BE%A4/</guid><description>ActiveMQ Introduction ActiveMQ is an open source (Apache 2.0 licensed) message brokerwhich fully implements the Java Message Service 1.1. It providesadvanced features like clustering, multiple message stores, andability to use file systems, and databases as a JMS persistenceprovider.
ActiveMQ HA ActiveMQ support reliable high performance load balancing ofmessages on a queue across consumers. If a consumer dies, anyunacknowledged messages are redelivered to other consumers on thequeue. If one consumer is faster than the others it gets moremessages etc.</description></item><item><title>PostgreSQL数据库分区的update操作</title><link>https://mryqu.github.io/post/postgresql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%8C%BA%E7%9A%84update%E6%93%8D%E4%BD%9C/</link><pubDate>Fri, 19 Jul 2013 23:23:36 +0000</pubDate><guid>https://mryqu.github.io/post/postgresql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%8C%BA%E7%9A%84update%E6%93%8D%E4%BD%9C/</guid><description>CREATE TABLE measurement ( city_id int not null, unitsales int ); CREATE TABLE measurement_1 ( CHECK (unitsales &amp;lt; 100 ) ) INHERITS (measurement); CREATE TABLE measurement_2 ( CHECK (unitsales &amp;gt;= 100 ) ) INHERITS (measurement); CREATE OR REPLACE FUNCTIONmeasurement_insert_trigger() RETURNS TRIGGER AS $$ BEGIN IF (NEW.unitsales &amp;lt; 100) THEN INSERT INTO measurement_1 VALUES (NEW.*); ELSE INSERT INTO measurement_2 VALUES (NEW.*); END IF; RETURNNULL; END; $$ LANGUAGE plpgsql; CREATE TRIGGER insert_measurement_trigger BEFOREINSERT ON measurement FOR EACH ROWEXECUTE PROCEDURE measurement_insert_trigger(); INSERT INTO measurement VALUES (1, 1); INSERT INTO measurement VALUES (2, 2); INSERT INTO measurement VALUES (3, 300); INSERT INTO measurement VALUES (4, 400); mysdm=# select * from measurement_1; city_id | unitsales ---------+----------- 1| 1 2| 2 (2 rows) mysdm=# select * from measurement_2; city_id | unitsales ---------+----------- 3| 300 4| 400 (2 rows) Postgres没有智能到在update时根据记录的新值变动分区，而是报错！</description></item><item><title>Hibernate shards数据库分片</title><link>https://mryqu.github.io/post/hibernate_shards%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%89%87/</link><pubDate>Fri, 19 Jul 2013 07:01:23 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate_shards%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%89%87/</guid><description>简介 Hibernate Shards是Hibernate的一个子项目，由Google工程师Max Ross创建并捐献给Hibernate社区。 http://www.hibernate.org/subprojects/shards.html https://github.com/hibernate/hibernate-shards
Hibernate Shards是对Hibernate Core提供水平分区支持的一个框架。
标准Hibernate编程模型 灵活的分片策略 支持虚拟分片 免费/开源 实现Hibernate Shards Hibernate Shards几乎可以与现有Hibernate项目无缝结合使用。 Hibernate Shards的首要目标是让程序员使用标准Hibernate Core API查询和处理已分片的数据库,因此Hibernate Shards主要由大家已经熟知的Hibernate Core接口的实现（分片感知）组成，大多数Hibernate应用程序使用Hibernate Core提供的接口，因此无需对已有代码做过多重构。
|Hibernate Core接口|Hibernate Shards实现 |&amp;mdash;&amp;ndash; |org.hibernate.Session|org.hibernate.shards.session.ShardedSession |org.hibernate.SessionFactory|org.hibernate.shards.ShardedSessionFactory |org.hibernate.Criteria|org.hibernate.shards.criteria.ShardedCriteria |org.hibernate.Query|org.hibernate.shards.query.ShardedQuery
唯一问题是 Hibernate Shards 需要一些特定信息和行为。比如，需要一个分片访问策略、一个分片选择策略和一个分片解析策略。这些是您必须实现的接口，虽然部分情况下，您可以使用默认策略。我们将在后面的部分逐个了解各个接口。 首先让我们看一下《HibernateShard 参考指南》中所用的数据库模式、对象模型及映射。
气象报告数据库模式 CREATE TABLE WEATHER_REPORT ( REPORT_ID INT NOT NULL AUTO_INCREMENT PRIMARY KEY, CONTINENT ENUM(&amp;#39;AFRICA&amp;#39;, &amp;#39;ANTARCTICA&amp;#39;, &amp;#39;ASIA&amp;#39;, &amp;#39;AUSTRALIA&amp;#39;, &amp;#39;EUROPE&amp;#39;, &amp;#39;NORTH AMERICA&amp;#39;, &amp;#39;SOUTH AMERICA&amp;#39;), LATITUDE FLOAT, LONGITUDE FLOAT, TEMPERATURE INT, REPORT_TIME TIMESTAMP ); 气象报告对象模型 @Entity @Table(name=&amp;#34;WEATHER_REPORT&amp;#34;) public class WeatherReport { @Id @GeneratedValue(generator=&amp;#34;WeatherReportIdGenerator&amp;#34;) @GenericGenerator(name=&amp;#34;WeatherReportIdGenerator&amp;#34;, strategy=&amp;#34;org.</description></item><item><title>PostgreSQL与MySQL数据库分区</title><link>https://mryqu.github.io/post/postgresql%E4%B8%8Emysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%8C%BA/</link><pubDate>Tue, 16 Jul 2013 21:10:39 +0000</pubDate><guid>https://mryqu.github.io/post/postgresql%E4%B8%8Emysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%8C%BA/</guid><description>数据库分区是逻辑数据库的分割。分区可以通过创建独立的较小数据库（每个有自己的表、索引和事物日志）或分割所选的元素（例如一个表）来实现。数据库分区通常是为了易管理性、性能和数据有效性。
分类 分区主要有两种形式：
水平分区 水平分区是将不同的行放入不同的表中。比如将邮编小于50000的客户放入“东部客户”表中，将邮编等于或大于50000的客户放入“西部客户”表中。该例中有两个分区表“东部客户”和“西部客户”，其合集视图就是所有客户的完整视图。 通过这样的方式不同分区里面的物理列分割的数据集得以组合，从而进行个体分割（单分区）或集体分割（1个或多个分区）。所有在表中定义的列在每个数据集中都能找到，所以表的特性依然得以保持。
垂直分区 垂直分区创建含有（主键加上）较少列的表并使用额外的表存储（主键加上）剩余的列，每个分区表中都含有其中列所对应的行。范式化是内在包含垂直分区的过程。 垂直分区被称为“行分割”，通常用于分割表中（查找很慢的）动态数据和（查找很快的、使用较动态数据更频繁的）静态数据。这样在保证数据相关性的同时，在诸如统计分析之类的查询中访问静态数据还能提高性能。 不同的物理存储也可以用于垂直分区，例如不频繁使用的列或者宽列被存入不同的设备。 其缺点是需要管理冗余列，查询所有数据需要join操作。
分区标准 当前高端关系数据库管理系统提供分割数据库的不同标准。这些标准使用分区键基于一定标准分配分区。常用的标准为：
基于范围的分区 通过判断分区键是否在一定范围内选择分区。例如所有邮编列在70000和79999之间的行可以是一个分区。
基于列表的分区 一个分区分配给一列数值。如果分区键为这些值之一，该分区被选中。例如所有国家列为冰岛、挪威、瑞典、芬兰或丹麦的行可以是一个北欧国家分区。
基于哈希的分区 哈希函数的返回值决定分区归属。假设有四个分区，哈希函数返回值为0到3。 组合分区允许上述分区方案的一定组合。例如先使用基于范围的分区，然后使用基于哈希的分区。
PostgreSQL数据库分区 PostgreSQL支持基本的数据库分区，本文以PostgreSQL 9.1为例介绍一下PostgreSQL数据库分区。
优点 分区具有下列优点：
在某些情况下查询性能能显著提升，特别是表中频繁访问的行在一个单独分区或者少数量分区中。分区替代索引起始列会减少索引大小，使频繁使用的索引更有可能放入内存。 当查询或更新访问单个分区的大部分记录时，通过对分区的顺序扫描取代对全表的索引读或随机读，也会提升性能。 如果批量加载和删除需求付诸于分区设计，这些需求可以通过添加或删除分区来完成。ALTER TABLE NOINHERIT和DROP TABLE都比批量操作更快，而且完全可以避免批量删除导致的VACUUM负担。 很少使用的数据可被移往更便宜更慢的存储媒体。 这些优点仅在表非常大时是真正有价值的。对表采用分区的收益取决于应用程序，一般经验法则是表超过了数据库服务器的物理内存时使用分区。
表继承 PostgreSQL通过表继承支持分区，每个分区作为单个父表的子表创建。父表本身通常为空，仅用于代表整个数据集。
CREATE TABLE cities ( name text, population float, altitude int -- in feet ); CREATE TABLE capitals ( state char(2) ) INHERITS (cities); 父表的所有check约束和not-null约束自动被子表继承，其他类型的约束（unique、主键和外键约束）不会被继承。
SELECT name, altitude FROM cities WHERE altitude &amp;gt; 500; SELECT name, altitude FROM ONLY cities WHERE altitude &amp;gt; 500; -- 通过ONLY关键词，第二个查询仅作用于表cities而不会用于cities的子表。 支持的分区标准 PostgreSQL数据库支持基于范围的分区和基于列表的分区。</description></item><item><title>R语言字符处理</title><link>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E5%A4%84%E7%90%86/</link><pubDate>Sat, 13 Jul 2013 22:36:49 +0000</pubDate><guid>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E5%A4%84%E7%90%86/</guid><description>字符处理Encoding(x)
Encoding(x) &lt;- value
enc2native(x)
enc2utf8(x)
读取或设置字符向量的编码> ## x is intended to be in latin1 > x &lt;- "fa\xE7ile" > Encoding(x) [1] "latin1" > Encoding(x) &lt;- "latin1" > xx &lt;- iconv(x, "latin1", "UTF-8") > Encoding(c(x, xx)) [1] "latin1" "UTF-8" > Encoding(xx) &lt;- "bytes" # will be encoded in hex > cat("xx = ", xx, "\n", sep = "") xx = fa\xc3\xa7ilenchar(x, type = "chars", allowNA = FALSE)
返回字符长度，在我的测试中allowNA参数没有作用？
nzchar(x) 判断是否空字符</description></item><item><title>R语言数值计算</title><link>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</link><pubDate>Sat, 13 Jul 2013 21:14:49 +0000</pubDate><guid>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</guid><description>R中数值计算的对象一般是向量或列表，不同长度的对象进行计算时，短的对象元素将被循环使用。
运算操作符+ - * /
&amp; | ！
== != > >= &lt; &lt;=
^ 幂运算
%% 取模
%/% 整除> a&lt;-c(2,49,25,8) > b&lt;-c(2,7,6) > a/b [1] 1.000000 7.000000 4.166667 4.000000 Warning message: In a/b : longer object length is not a multiple of shorter object length > 2^5 [1] 32 > 25%%6 [1] 1 > 13%/%5 [1] 2 > 7&amp;8 [1] TRUE无归类的函数sign 取符号> sign(-2:2) [1] -1 -1 0 1 1abs 取绝对值sqrt 取平方根> sqrt(-2:2) [1] NaN NaN 0.</description></item><item><title>git资料</title><link>https://mryqu.github.io/post/git%E8%B5%84%E6%96%99/</link><pubDate>Sat, 13 Jul 2013 18:52:24 +0000</pubDate><guid>https://mryqu.github.io/post/git%E8%B5%84%E6%96%99/</guid><description>综合 Pro Git 英文版 中文版
Git Community Book 英文版 中文版
GotGitHub
Git使用详解
项目主页 Creating Project Pages manually
Setup GitHub Pages &amp;ldquo;gh-pages&amp;rdquo; branch and &amp;ldquo;master&amp;rdquo; branch as subfolders of a parent project folder (&amp;ldquo;grandmaster&amp;rdquo;).
Setup GitHub Pages &amp;ldquo;gh-pages&amp;rdquo; branch as a subfolder within the &amp;ldquo;master&amp;rdquo; project on your local checkout - a step-by-step guide.
其他 Collaborative Github Workflow
如何理解git reset 取消提交的操作？
Git Document
Atlassian Git Tutorial
版本管理svn,git,cvs比较
learnGitBranching
a successful git branching model</description></item><item><title>[Hadoop] mapred和mapreduce包的区别</title><link>https://mryqu.github.io/post/hadoop_mapred%E5%92%8Cmapreduce%E5%8C%85%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Fri, 12 Jul 2013 16:55:48 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_mapred%E5%92%8Cmapreduce%E5%8C%85%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>背景介绍 在Hadoop的代码中，存在org.apache.hadoop.mapred和org.apache.hadoop.mapreduce两个包。mapred包下是老的API，在Hadoop0.20时被废弃了，引入了新包mapreduce，但是由于新的API迟迟没有完成，所以在Hadoop0.21中取消了mapred包的废弃状态。原来的设想中老包mapred在Hadoop0.22和1.0中将再次设成废弃状态，但时至今日也没有被废弃。
区别 本文将通过WordCount示例代码，介绍一下二者的区别。WordCount示例代码分别取自0.19和0.23.9版本的Hadoop源码。
0.19版WordCount示例 0.23.9版WordCount示例 区别新API老API包新API位于org.apache.hadoop.mapreduce包内老API位于org.apache.hadoop.mapred.包内Mapper和Reducer类型新API使用Mapper和Reducer抽象类
抽象类更容易扩展，Hadoop实现可以轻松向其抽象类中添加方法(用默认的实现)而不会对已有Hadoop应用造成影响老API使用Mapper和Reduceer接口使用对象新API使用Configuration和一些Helper类完成作业配置；
新API使用Job完成作业控制；
新API使用Context完成用户代码与MapReduce系统的通信。老API使用JobConf
完成作业配置，它是Configuration子类；
![[Hadoop]?mapred和mapreduce包的区别](/images/2013/7/0026uWfMzy78EeY1A9Ge0.png)
老API使用JobClient完成作业控制；
老API使用OutputCollector和Reporter完成用户代码与MapReduce系统的通信。
方法map() reduce() clearup() setup() run()；
所有方法可抛IOException或InterruptedException；
Reduce()输入值为java.lang.Iterable；键值对输出通过Context对象的write方法实现；
map() reduce()；
所有方法可抛IOException；
Reduce()输入值为java.lang.Iterator；
键值对输出通过OutputCollector对象的collect方法实现；输出文件part-m-nnnnn和part-r-nnnnn
(nnnnn为从0开始的整数)part-nnnnn 注意事项 尽量使用新API。在mapred和mapreduce两个包下存在FileInputFormat、FileOutputFormat等名字一样的类，如果引入错误的话，程序会无法通过编译。
参考 Upgrading To The New Map Reduce API
Difference between Hadoop OLD API and NEW API</description></item><item><title>Eclipse RCP资料</title><link>https://mryqu.github.io/post/eclipse_rcp%E8%B5%84%E6%96%99/</link><pubDate>Thu, 11 Jul 2013 23:14:43 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse_rcp%E8%B5%84%E6%96%99/</guid><description>Lubos: Eclipse plugin and RCP development notes</description></item><item><title>分布式事务处理</title><link>https://mryqu.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/</link><pubDate>Thu, 11 Jul 2013 22:49:43 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86/</guid><description>事务 概念 企业级应用程序经常需要访问多个组件共享的分布式数据并执行操作。这些程序应该在下列情况下保持（由应用程序商业规则所定义的）数据完整性：
分布式访问单个数据资源 从单个应用组件访问分布式资源 在这种情况下，对（分布式）资源上的一组操作可能需要被作为一个工作单元来对待。在一个工作单元中的所有操作必须全部成功或在失败时一起回滚到之前的状态。
下列情况下情况会更加复杂，需要应用程序维护工作单元的成功或失败信息：
在一组分布式组件上实现的工作单元对多个资源上的数据进行操作 串行或在并行线程中执行的操作需要协调或同步 事务(Transaction)以及事务管理器（或事务处理服务）降低了企业级分布式应用程序构建难度，维护了数据的完整性。
特性 事务是恢复和并发控制的基本单位。 事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。
原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。当任一操作失败，事务中的所有操作需要撤销，数据恢复到之前的状态。 一致性（consistency）。事务必须保持定义在数据上的不变属性（例如完整性约束）。在事务成功结束后，数据必须处于一致状态。换句话说，事务必须是使资源从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。这需要：在事务执行期间，数据的（可能不一致的）中间状态不会暴露给其他事务；两个并发事务不能对同一数据进行操作。数据库管理系统通常使用锁机制实现这一功能。 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对资源中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 嵌套事务 事务处理组件 应用程序组件 应用程序组件是事务型资源的客户端，包含商业事务程序。在事务管理器的帮助下，这些组件创建全局事务并划分事务界限，在必要时传播事务上下文，在事务范围内通过资源管理器对事务型资源进行操作。这些组件不负责实现事务语义。然而，作为应用逻辑的一部分，这些组件通常决定是否提交还是回滚事务。
资源管理器 资源管理器是管理持久化和稳定数据存储系统的组件，并同事务管理器一起参与两阶段提交和恢复协议。 资源管理器通常是稳定数据存储系统的驱动或者包装器，提供两套接口接口：一套接口用于应用程序组件获得连接并操作数据、另一套接口用于事务管理器参与两阶段提交和恢复协议。该组件可能也直接或间接向事务管理器注册资源，以便事务管理器能够跟踪所有参与事务的资源。该过程称之为资源征集（enlistment）。为了实现两阶段提交和恢复协议，资源管理器应该实现辅助机制用于事务恢复。
事务管理器 事务管理器是事务处理环境中的核心组件。主要职责是应应用程序组件请求创建事务、允许资源征集（enlistment）和遣散（delistment）、同资源管理器一起实施两阶段提交和恢复协议。 一个典型事务型应用程序发起事务，向事务管理器发出请求初始化一个事务。作为应答，事务管理器启动一个事务并与当前线程关联。事务管理器也会创建一个事务上下文。所有参与事务的应用程序组件/线程共享事务上下文。发起事务的线程或其他线程在事务管理器允许的情况下通过发出提交或回滚请求来终止事务。 在事务终止之前，任意数量的组件或线程可在事务管理器已知的任意数量事务型资源上执行事务型操作。在资源管理器允许的情况下，事务在最终终止之前可以被挂起或恢复。 一旦应用程序发出提交请求，事务管理器（通过投票）准备用于提交操作的所有资源，并基于是否所有资源准备好提交向所有资源发出提交或回滚请求。在两阶段提交和恢复协议处理过程前后调用应用程序组件synchronization回调。
两阶段提交（2PC） 两阶段提交分为两个阶段：投票阶段和决策阶段。
在投票（或准备）阶段，事务管理器会询问每个资源管理器是否同意成功执行。资源管理器有可能返回否定应答，例如当超时导致数据库回滚。如果资源管理器做肯定应答的话，它应该确信它始终可以将工作持久化（这暗示它不会应为内部超时取消工作）， 事务管理器接收到所有应答（也称之为选票），会对事务结果作出全局决策。该决策取决于收集的应答: 如果所有应答都是肯定的（意味着每个稳定数据存储系统都可以将工作持久化），事务管理器会指示每个资源管理器进行提交。 如果有一个应答是否定的（或丢失），则回滚决策会发给剩余的资源，剩余资源取消该事务中的工作。 有两件事需要注意:
每个资源必须有能力理解两阶段提交：它需要回复来自事务管理器的准备请求，并能在事务管理器决定回滚时取消工作。 如果资源在准备阶段投肯定票之后跟事务管理器联系中断（例如事务管理器崩溃），它将不知道如何去做。由于两阶段提交协议规则它不能自己取消，因此它需要无期限地记着这个事务。此外，这限制了其他事务的并发访问。在这种情况下，该资源被称为不确定的。 资源处于不确定状态并限制并发访问令很多厂商烦恼。为了减少限制，两阶段提交协议的实践变种包含一种叫做试探性决策：太长时间处于不确定状态的资源会决定单方面回滚（或提交）事务，有可能导致违背全部接受或全部不接受的特性。 事务处理标准和技术 X/Open 分布式事务处理(DTP)模型是厂商协会OpenGroup提出的一个分布式处理模型，在事务处理和数据库领域中多数商业厂商间的一个标准。 对象事务服务(OTS)是由对象管理组织(OMG)规定的分布式事务处理服务。这个规范扩展了 CORBA 模型并定义了一系列跨越多个CORBA 对象完成事务处理的接口。 JTA和JTS是Sun提出的事务处理和事务服务的Java规范。 微软事务服务器（MTS）是一个基于构件的事务服务器，它的构件基于微软的构件对象模型(COM)。MTS编程模型为建造事务性COM构件提供接口，而MTS运行环境提供一个部署和管理这些构件和管理事务的方法。使用了MTS，由多个COM构件做的工作可被组合在一个单一的事务中。 企业级Java Beans (EJB)是Sun提出的一个技术规范。它规定了一个建造基于构件的分布式应用的框架。
JTA 概念 JTA是Java事务API的缩写，定义了在事务管理器与分布式事务系统的资源管理器、应用服务器、事务型应用程序之间的标准Java接口，包括javax.transaction和javax.transaction.xa包。在实际系统中还需要厂商专有的JTA实现。JTA是JavaEE平台的标准部分和每个EJB应用服务器都包含了JTA实现。
JTA组件 JTA的主要组件为：
TransactionManager TransactionManager可用于创建事务，获取、挂起和恢复当前事务,设置事务超时值属性。其方法为线程安全的，多个并发线程可以创建自己的事务，获取仅自己创建的事务。
|begin|创建一个新事务并与当前线程关联 |commit|提交当前线程关联的事务 |getStatus|获取当前线程关联的事务状态 |getTransaction|获取当前线程关联的事务 |resume|使用挂起的事务对象代表的事务恢复调用线程的事务上下文 |rollback|回滚当前线程关联的事务 |setRollbackOnly|修改当前线程关联的事务以致事务的唯一可能结果是回滚 |setTransactionTimeout|修改当前线程使用begin方法启动的事务的超时值 |suspend|挂起调用线程当前关联的事务并返回代表正在挂起事务上下文的事务对象
Transaction Transaction允许对有效的事务进行操作。一个事务对象对应着一个全局事务，它可用于资源征集/遣散、synchronization注册、结束事务和状态查询操作。
|commit|提交事务对象代表的事务 |delistResource|接触资源与目标事务对象代表的事务之间的关联 |enlistResource|关联资源与目标事务对象代表的事务 |getStatus|获得目标事务对象代表的事务 |registerSynchronization|向目标事务对象代表的事务注册Synchronization |rollback|回滚事务对象代表的事务 |setRollbackOnly|修改目标事务对象代表的事务以致事务的唯一可能结果是回滚</description></item><item><title>小玩Java序列化</title><link>https://mryqu.github.io/post/%E5%B0%8F%E7%8E%A9java%E5%BA%8F%E5%88%97%E5%8C%96/</link><pubDate>Mon, 08 Jul 2013 21:17:41 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%8F%E7%8E%A9java%E5%BA%8F%E5%88%97%E5%8C%96/</guid><description>折腾GemFire，免不了要折腾序列化和发序列化。GemFire支持Java的序列化，同时也有自己的DataSerializable接口实现自己的序列化，此外还有Delta接口支持数据同步时仅传送上一次数据同步后的更新。 今天测试的实现先用Java的序列化，一开始玩java.io.Serializable接口，后来玩writeObject()和readObject()方法。顺便看看有writeObject方法后ObjectOutputStream调用堆栈与原有分支的不同。
private void writeSerialData(Object obj, ObjectStreamClass desc) throws IOException { ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout(); for (int i = 0; i &amp;lt; slots.length; i++) { ObjectStreamClass slotDesc = slots[i].desc; if (slotDesc.hasWriteObjectMethod()) { PutFieldImpl oldPut = curPut; curPut = null; if (extendedDebugInfo) { debugInfoStack.push(&amp;#34;custom writeObject data (class \&amp;#34;&amp;#34; + slotDesc.getName() + &amp;#34;\&amp;#34;)&amp;#34;); } SerialCallbackContext oldContext = curContext; try { curContext = new SerialCallbackContext(obj, slotDesc); bout.setBlockDataMode(true); slotDesc.invokeWriteObject(obj, this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); } finally { curContext.</description></item><item><title>动态GemFire Region使用局限</title><link>https://mryqu.github.io/post/gemfire_usage-limit-of-dynamci-region/</link><pubDate>Fri, 05 Jul 2013 21:23:00 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_usage-limit-of-dynamci-region/</guid><description>介绍 当前项目原有设计使用了嵌套的Map作为缓存。我在使用GemFire产品时使用普通region替代外层map，使用动态region替代内层map。
对于&amp;quot;/outer_region/Dimension&amp;quot;region中的条目，键是维ID（例如5），值是动态region&amp;quot;/inter_region/Dimension/5&amp;quot;. &amp;ldquo;/outer_region/Dimension&amp;rdquo; region的容量是256个条目，动态region&amp;quot;/inter_region/Dimension/5&amp;quot;的容量是10个条目。 当维#5被删除，&amp;quot;/outer_region/Dimension&amp;quot;相应条目应该删除，而动态region&amp;quot;/inter/Dimension/5&amp;quot;应该被销毁。
测试发现，当GemFire节点通过API创建了动态region后，它会将动态region列表发送给其他节点，此后的GemFire节点在创建Cache会失败。通过异常日志可知动态region会在Cache创建过程中被创建，但后继GemFire节点无法找到父region (在该节点创建Cache之前根本没机会创建****region!),这是导致失败的原因。
如果对cache使用cache-xml-file， GemFire会先创建普通region之后创建动态region。这需要将一个cache下所有region定义都放到cache-xml-file里，上述问题可能会被避免。但是一个cache被多个项目共享，所有项目的region定义放在一起的话，配置耦合度很高，对于产品的灵活性和扩展性很不利。
日志 Caused by: com.gemstone.gemfire.cache.RegionDestroyedException: Error -- Could not find a region named: &amp;#39;/inter_region/Dimension&amp;#39; at com.gemstone.gemfire.cache.DynamicRegionFactory.createDynamicRegionImpl(DynamicRegionFactory.java) at com.gemstone.gemfire.cache.DynamicRegionFactory.createDefinedDynamicRegions(DynamicRegionFactory.java) at com.gemstone.gemfire.cache.DynamicRegionFactory._internalInit(DynamicRegionFactory.java) at com.gemstone.gemfire.internal.cache.DynamicRegionFactoryImpl.internalInit(DynamicRegionFactoryImpl.java) at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.readyDynamicRegionFactory(GemFireCacheImpl.java) at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.initializeDeclarativeCache(GemFireCacheImpl.java) at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.init(GemFireCacheImpl.java) at com.gemstone.gemfire.internal.cache.GemFireCacheImpl.create(GemFireCacheImpl.java) at com.gemstone.gemfire.cache.CacheFactory.create(CacheFactory.java) at com.gemstone.gemfire.cache.CacheFactory.create(CacheFactory.java) at org.springframework.data.gemfire.CacheFactoryBean.createCache(CacheFactoryBean.java) at org.springframework.data.gemfire.CacheFactoryBean.init(CacheFactoryBean.java) at org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java) at org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java) ... 34 more</description></item><item><title>初探ANTLR</title><link>https://mryqu.github.io/post/%E5%88%9D%E6%8E%A2antlr/</link><pubDate>Wed, 03 Jul 2013 20:25:21 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%88%9D%E6%8E%A2antlr/</guid><description>当前的项目是基于多维数据集市的RTOLAP财务系统，其中的公式使用ANTLR 3进行语法解析和编译。 此外看Hibernate源码的时候也接触到ANTLR，Hibernate使用ANTLR产生查询分析器。
ANTLR简介 ANTLR的全称是ANother Tool for LanguageRecognition，其前身是PCCTS，和YACC、LEX、JavaCC、Coco/R等工具一样，都是编译器的编译程序。 ANTLR对语法树构造、遍历和转换、错误修复和报告提供出色的支持，它为包括Java，C++，C#和Python在内的语言提供了一个通过语法描述来自动构造自定义语言的识别器、解析器、编译器和转换器的框架。 ANTLR可以通过断言（Predicate）解决识别冲突；支持动作（Action）和返回值（ReturnValue）来；更棒的是，它可以根据输入自动生成语法树并可视化的显示出来。由此，计算机语言的翻译变成了一项普通的任务。 ANTLR是由旧金山大学的Terence Parr博士领导下完成的，最新版本为4.1。
编译器工作主要分有词法分析，语法分析，代码生成三个步骤。ANTLR分别提供了三个东西:
词法分析器（Lexer） 词法分析器又称为Scanner，Lexicalanalyser和Tokenizer。程序设计语言通常由关键字和严格定义的语法结构组成。编译的最终目的是将程序设计语言的高层指令翻译成物理机器或虚拟机可以执行的指令。词法分析器的工作是分析量化那些本来毫无意义的字符流，将他们翻译成离散的字符组（也就是一个一个的Token），包括关键字、标识符、符号和操作符供语法分析器使用。 语法分析器（Parser） 编译器又称为Syntacticalanalyser。在分析字符流的时候，Lexer不关心所生成的单个Token的语法意义及其与上下文之间的关系，而这就是Parser的工作。语法分析器将收到的Tokens组织起来，并转换成为目标语言语法定义所允许的序列。 无论是Lexer还是Parser都是一种识别器，Lexer是字符序列识别器而Parser是Token序列识别器。他们在本质上是类似的东西，而只是在分工上有所不同而已。 抽象语法树遍历器 (Tree walker) 树分析器可以用于对语法分析生成的抽象语法树进行遍历，并能执行一些相关的操作，可以进行语义匹配生成代码。 ANTLR 3的Eclipse插件 ANTLR IDE用于ANTLR3的一个Eclipse插件。
支持ANTLR 3.0、3.1、3.2、3.3和3.4。 ANTLR启动器和调试器(仅限Java) ANTLR内建解析器。 代码格式化工具(Ctrl+Shift+F) 语法图（铁路图） 定制目标 自动生成资源 对语法文件中错误和告警自动标注 高级文本编辑器、代码选择(F3)和代码补全(Ctrl+Space) 对（Java、C#、Python和C等）目标语言自动语法高亮 标注生成的资源 高级字符串模板(StringTemplate)编辑器(*.st and *.stg) 高级语法单元测试(gUnit)编辑器(*.gunit and *.testsuite) 使用ANTLR生成代码的ANT设置 &amp;lt;property name=&amp;#34;lib.dir&amp;#34; value=&amp;#34;lib&amp;#34; /&amp;gt; &amp;lt;property name=&amp;#34;gensrc.dir&amp;#34; value=&amp;#34;gen-source/Java&amp;#34; /&amp;gt; &amp;lt;property name=&amp;#34;parser.dir&amp;#34; value=&amp;#34;/com/sas/yourgramarpackage&amp;#34;/&amp;gt; &amp;lt;target name=&amp;#34;gen-source&amp;#34;&amp;gt; &amp;lt;mkdir dir=&amp;#34;${gensrc.dir}/${parser.dir}&amp;#34; /&amp;gt; &amp;lt;antlr:antlr3 xmlns:antlr=&amp;#34;antlib:org/apache/tools/ant/antlr&amp;#34; target=&amp;#34;${src.dir}/${parser.dir}/YourGrammar.g&amp;#34; outputdirectory=&amp;#34;${gensrc.dir}/${parser.dir}&amp;#34;&amp;gt; &amp;lt;classpath&amp;gt; &amp;lt;fileset dir=&amp;#34;${lib.dir}&amp;#34;&amp;gt; &amp;lt;include name=&amp;#34;*.jar&amp;#34; /&amp;gt; &amp;lt;/fileset&amp;gt; &amp;lt;/classpath&amp;gt; &amp;lt;/antlr:antlr3&amp;gt; &amp;lt;/target&amp;gt; 使用ANTLR生成代码的Maven设置 &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>博客链接（搜索、统计、数据挖掘）</title><link>https://mryqu.github.io/post/%E5%8D%9A%E5%AE%A2%E9%93%BE%E6%8E%A5%E6%90%9C%E7%B4%A2%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</link><pubDate>Wed, 03 Jul 2013 10:37:49 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8D%9A%E5%AE%A2%E9%93%BE%E6%8E%A5%E6%90%9C%E7%B4%A2%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</guid><description>统计（侧重R） |Name|Blog|Weibo |&amp;mdash;- |R-bloggers|http://www.r-bloggers.com/| |statMethods blog|http://statmethods.wordpress.com/| |谢益辉|http://yihui.name/|Weibo：@谢益辉 |刘思喆|http://www.bjt.name/|Weibo：@刘思喆 |邓一硕|http://yishuo.org/|Weibo：@邓一硕 |陈堰平|http://yanping.me/|Weibo：@平沙落雁 |邱怡轩|http://yixuan.cos.name/|Weibo：@解名缰 |魏太云|http://blog.cos.name/taiyun/|Weibo：@cloud_wei |陈丽云|http://www.loyhome.com/|Weibo：@cloudly |肖楠|http://www.road2stat.com/|Weibo：@road2stat |肖凯|http://xccds.github.io/|Weibo：@xccds |高涛|http://joegaotao.github.io/cn|Weibo： @三水成海 |陈刚|http://gossipcoder.com/| |李舰|http://jliblog.com/|Weibo：@lijian001 |熊熹|http://blog.cos.name/tracy/|Weibo：@熊熹91 |范建|http://blog.cos.name/fan/|Weibo：@thinkfan
搜索 百度搜索研发部官方博客
淘宝搜索技术
量子恒道官方博客</description></item><item><title>[Hadoop] 分布式缓存</title><link>https://mryqu.github.io/post/hadoop_%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</link><pubDate>Fri, 28 Jun 2013 21:30:09 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</guid><description>一直在看分布式缓存，最近涉猎到Hadoop的分布式缓存，做个汇总以备后用。
adoop分布式缓存是Map-Reduce框架提供的用于缓存应用程序所需文件（文本文件、存档文件、Jar文件等）的工具。 应用程序通过URL（hdfs://或http://）指定通过JobConf进行缓存的文件。分布式缓存假定URL所指定的文件已经存在于Hadoop分布式文件系统或本地文件系统中并可被集群中所有机器访问到。Hadoop框架会在任何作业在节点执行之前将必须的缓存文件复制到任务节点以供使用。为了节省网络带宽，这些文件只会为每个作业复制一次，且归档类型的缓存文件会在任务节点中解压缩。分布式缓存能用于分发简单只读数据或文本文件及复杂文件（存档文件、Jar文件等）。归档文件（zip、tar和tgz/tar.gz文件）在任务节点中解压缩。Jar文件可选择加入任务的类路径，这是基本的软件分发机制。 分布式缓存跟踪缓存文件的修改时戳。很明显当作业执行时这些缓存文件不应被应用程序或外部修改。
下面的示例介绍了如何使用DistributedCache：
将所需文件复制到FileSystem: $ bin/hadoop fs -copyFromLocal lookup.dat /myapp/lookup.dat $ bin/hadoop fs -copyFromLocal map.zip /myapp/map.zip $ bin/hadoop fs -copyFromLocal mylib.jar /myapp/mylib.jar $ bin/hadoop fs -copyFromLocal mytar.tar /myapp/mytar.tar $ bin/hadoop fs -copyFromLocal mytgz.tgz /myapp/mytgz.tgz $ bin/hadoop fs -copyFromLocal mytargz.tar.gz /myapp/mytargz.tar.gz 设置应用程序的JobConf: JobConf job = new JobConf(); DistributedCache.addCacheFile(new URI(&amp;#34;/myapp/lookup.dat&amp;#34;), job); DistributedCache.addCacheArchive(new URI(&amp;#34;/myapp/map.zip&amp;#34;, job); DistributedCache.addFileToClassPath(new Path(&amp;#34;/myapp/mylib.jar&amp;#34;), job); DistributedCache.addCacheArchive(new URI(&amp;#34;/myapp/mytar.tar&amp;#34;, job); DistributedCache.addCacheArchive(new URI(&amp;#34;/myapp/mytgz.tgz&amp;#34;, job); DistributedCache.addCacheArchive(new URI(&amp;#34;/myapp/mytargz.tar.gz&amp;#34;, job); 在Mapper或Reducer中使用缓存的文件: public static class MapClass extends MapReduceBase implements Mapper{ private Path[] localArchives; private Path[] localFiles; public void configure(JobConf job) { // Get the cached archives/files File f = new File(&amp;#34;.</description></item><item><title>嵌套的动态GemFire region研究</title><link>https://mryqu.github.io/post/gemfire_nesting-dynamic-region/</link><pubDate>Fri, 28 Jun 2013 16:16:14 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_nesting-dynamic-region/</guid><description>研究目的和结论 研究多级动态region是否可行，结论可行 研究嵌套region(一个region是另一个region的值)是否可行，结论可行 Java代码 import java.util.Set; import com.gemstone.gemfire.cache.Cache; import com.gemstone.gemfire.cache.CacheFactory; import com.gemstone.gemfire.cache.DynamicRegionFactory; import com.gemstone.gemfire.cache.Region; public class EmbededDynamicRegion { public static void main(String[] args) { System.out.println(&amp;#34;\nConnecting to the distributed system and creating the cache.&amp;#34;); Cache cache = null; try { // Create the cache which causes the cache-xml-file to be parsed cache = new CacheFactory().set(&amp;#34;name&amp;#34;, &amp;#34;yqu_test_cache&amp;#34;) .set(&amp;#34;cache-xml-file&amp;#34;, &amp;#34;xml/YquTest.xml&amp;#34;).create(); // Get the exampleRegion Region yquRegion = cache.getRegion(&amp;#34;yqu_region&amp;#34;); printRegionFullPath(yquRegion); DynamicRegionFactory dynRegFactory = DynamicRegionFactory.get(); for(int i=0;i&amp;lt;3;i++) { Region keyRegion = dynRegFactory.</description></item><item><title>网络工具笔记</title><link>https://mryqu.github.io/post/network-tool-notes/</link><pubDate>Fri, 28 Jun 2013 10:02:55 +0000</pubDate><guid>https://mryqu.github.io/post/network-tool-notes/</guid><description>nslookup nslookup命令是用来查询因特网域名服务器的。该命令在Unix、Linux和Windows平台都有提供。如果在Linux平台上找不到nslookup命令，检查是否安装bind-utils。
nslookup的使用模式 nslookup有两种模式：交互式和非交互式。
交互式模式允许向域名服务器查询各种主机、域名或打印域内主机列表。 非交互式模式用于查询一个主机或域的信息。 C:\&amp;gt;nslookup /? Usage: nslookup [-opt ...] # interactive mode using default server nslookup [-opt ...] - server # interactive mode using &amp;#39;server&amp;#39; nslookup [-opt ...] host # just look up &amp;#39;host&amp;#39; using default server nslookup [-opt ...] host server # just look up &amp;#39;host&amp;#39; using &amp;#39;server&amp;#39; 制定了查询对象就进入非交互式模式，否则进入交互模式。示例如下： 这两次查询百度的命令区别在于：第一次使用了默认DNS，第二次指定了Google的DNS。返回结果是非权威答案，即从上连DNS服务器的本地缓存中读取出的值，而非实际去查询到的值。
nslookup选项 set all：列出nslookup工具的常用选项的当前设置值。 set class=[value]：可以更改查询类 IN：Internet类（默认） CH：Chaos类 HS：Hesiod类 ANY：通配 Chaos和Hesiod现在几乎无人使用。 set [no]debug：可以用来设置是否进入调试模式。如果setdebug，则会进入到调试模式，查询过程中会显示完整的响应包以及其中的交互包。 set[no]d2：开启了高级调试模式，会输出很多nslookup内部工作的信息，包括了许多函数调用信息。 set domain=[name]：用于设置默认的域。 set [no]search：使用域搜索列表。 setport=[value]：众所周知，DNS默认的服务端口是53。当某些特殊情况，此端口改变时，可以通过本命令来设置。 set type=[value]：也可以写成setquerytype=[value]，用于更改信息查询类型。默认情况下，nslookup是查询域名所对应的A记录，而如果你想查询其对应的MX记录等信息时，就需要专门设置type值了。目前常用的type值如下： A：查看主机的IPv4地址 AAAA：查看主机的IPv6地址 ANY：查看关于主机域的所有信息 CNAME：查找与别名对应的正式名字 ISDN：域名对应的ISDN号码 HINFO：查找主机的CPU与操作系统类型 MB：存放指定邮箱的服务器 MG：邮件组记录 MINFO：查找邮箱信息 MR：改名的邮箱记录 MX：查找邮件交换信息 NS：查找主机域的域名服务器 PTR：查找与给定IP地址匹配的主机名 RP：查找域负责人记录 RT：路由穿透记录 SOA：查找域内的SOA地址 SRV：TCP服务器信息记录 TXT：域名对应的文本信息 UINFO：查找用户信息 X25：域名对应的X.</description></item><item><title>常用HTML转义字符</title><link>https://mryqu.github.io/post/%E5%B8%B8%E7%94%A8html%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6/</link><pubDate>Tue, 25 Jun 2013 10:23:39 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B8%B8%E7%94%A8html%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6/</guid><description>最常用的字符实体 |显示|说明|实体名称|实体编号 |&amp;mdash;&amp;ndash; | |半方大的空白|&amp;amp; ensp;|&amp;amp; #8194; | |全方大的空白|&amp;amp; emsp;|&amp;amp; #8195; | |不断行的空白格|&amp;amp; nbsp;|&amp;amp; #160; |&amp;lt; |小于|&amp;amp; lt;|&amp;amp; #60; |&amp;gt;|大于|&amp;amp; gt;|&amp;amp; #62; |&amp;amp;|&amp;amp; 符号|&amp;amp; amp;|&amp;amp; #38; |&amp;quot;|双引号|&amp;amp; quot;|&amp;amp; #34; |©|版权|&amp;amp; copy;|&amp;amp; #169; |®|已注册商标|&amp;amp; reg;|&amp;amp; #174; |™|商标（美国）|&amp;amp; trade;|&amp;amp; #8482; |×|乘号|&amp;amp; times;|&amp;amp; #215; |÷|除号|&amp;amp; divide;|&amp;amp; #247;
ISO 8859-1 (Latin-1)字符集 HTML 4.01 支持 ISO 8859-1 (Latin-1) 字符集。
备注：为了方便起见，以下表格中，“实体名称”简称为“名称”，“实体编号”简称为“编号”
|显示|名称|编号|显示|名称|编号|显示|名称|编号 |&amp;mdash;&amp;ndash; | |&amp;amp; nbsp;|&amp;amp; #160;|¡|&amp;amp; iexcl;|&amp;amp; #161;|¢|&amp;amp; cent;|&amp;amp; #162; |£|&amp;amp; pound;|&amp;amp; #163;|¤|&amp;amp; curren;|&amp;amp; #164;|¥|&amp;amp; yen;|&amp;amp; #165; |¦|&amp;amp; brvbar;|&amp;amp; #166;|§|&amp;amp; sect;|&amp;amp; #167;|¨|&amp;amp; uml;|&amp;amp; #168; |©|&amp;amp; copy;|&amp;amp; #169;|ª|&amp;amp; ordf;|&amp;amp; #170;|«|&amp;amp; laquo;|&amp;amp; #171; |¬|&amp;amp; not;|&amp;amp; #172;|­|&amp;amp; shy;|&amp;amp; #173;|®|&amp;amp; reg;|&amp;amp; #174; |¯|&amp;amp; macr;|&amp;amp; #175;|°|&amp;amp; deg;|&amp;amp; #176;|±|&amp;amp; plusmn;|&amp;amp; #177; |²|&amp;amp; sup2;|&amp;amp; #178;|³|&amp;amp; sup3;|&amp;amp; #179;|´|&amp;amp; acute;|&amp;amp; #180; |µ|&amp;amp; micro;|&amp;amp; #181;|¶|&amp;amp; para;|&amp;amp; #182;|·|&amp;amp; middot;|&amp;amp; #183; |¸|&amp;amp; cedil;|&amp;amp; #184;|¹|&amp;amp; sup1;|&amp;amp; #185;|º|&amp;amp; ordm;|&amp;amp; #186; |»|&amp;amp; raquo;|&amp;amp; #187;|¼|&amp;amp; frac14;|&amp;amp; #188;|½|&amp;amp; frac12;|&amp;amp; #189; |¾|&amp;amp; frac34;|&amp;amp; #190;|¿|&amp;amp; iquest;|&amp;amp; #191;|À|&amp;amp; Agrave;|&amp;amp; #192; |Á|&amp;amp; Aacute;|&amp;amp; #193;|Â|&amp;amp; Acirc;|&amp;amp; #194;|Ã|&amp;amp; Atilde;|&amp;amp; #195; |Ä|&amp;amp; Auml;|&amp;amp; #196;|Å|&amp;amp; Aring;|&amp;amp; #197;|Æ|&amp;amp; AElig;|&amp;amp; #198; |Ç|&amp;amp; Ccedil;|&amp;amp; #199;|È|&amp;amp; Egrave;|&amp;amp; #200;|É|&amp;amp; Eacute;|&amp;amp; #201; |Ê|&amp;amp; Ecirc;|&amp;amp; #202;|Ë|&amp;amp; Euml;|&amp;amp; #203;|Ì|&amp;amp; Igrave;|&amp;amp; #204; |Í|&amp;amp; Iacute;|&amp;amp; #205;|Î|&amp;amp; Icirc;|&amp;amp; #206;|Ï|&amp;amp; Iuml;|&amp;amp; #207; |Ð|&amp;amp; ETH;|&amp;amp; #208;|Ñ|&amp;amp; Ntilde;|&amp;amp; #209;|Ò|&amp;amp; Ograve;|&amp;amp; #210; |Ó|&amp;amp; Oacute;|&amp;amp; #211;|Ô|&amp;amp; Ocirc;|&amp;amp; #212;|Õ|&amp;amp; Otilde;|&amp;amp; #213; |Ö|&amp;amp; Ouml;|&amp;amp; #214;|×|&amp;amp; times;|&amp;amp; #215;|Ø|&amp;amp; Oslash;|&amp;amp; #216; |Ù|&amp;amp; Ugrave;|&amp;amp; #217;|Ú|&amp;amp; Uacute;|&amp;amp; #218;|Û|&amp;amp; Ucirc;|&amp;amp; #219; |Ü|&amp;amp; Uuml;|&amp;amp; #220;|Ý|&amp;amp; Yacute;|&amp;amp; #221;|Þ|&amp;amp; THORN;|&amp;amp; #222; |ß|&amp;amp; szlig;|&amp;amp; #223;|à|&amp;amp; agrave;|&amp;amp; #224;|á|&amp;amp; aacute;|&amp;amp; #225; |â|&amp;amp; acirc;|&amp;amp; #226;|ã|&amp;amp; atilde;|&amp;amp; #227;|ä|&amp;amp; auml;|&amp;amp; #228; |å|&amp;amp; aring;|&amp;amp; #229;|æ|&amp;amp; aelig;|&amp;amp; #230;|ç|&amp;amp; ccedil;|&amp;amp; #231; |è|&amp;amp; egrave;|&amp;amp; #232;|é|&amp;amp; eacute;|&amp;amp; #233;|ê|&amp;amp; ecirc;|&amp;amp; #234; |ë|&amp;amp; euml;|&amp;amp; #235;|ì|&amp;amp; igrave;|&amp;amp; #236;|í|&amp;amp; iacute;|&amp;amp; #237; |î|&amp;amp; icirc;|&amp;amp; #238;|ï|&amp;amp; iuml;|&amp;amp; #239;|ð|&amp;amp; eth;|&amp;amp; #240; |ñ|&amp;amp; ntilde;|&amp;amp; #241;|ò|&amp;amp; ograve;|&amp;amp; #242;|ó|&amp;amp; oacute;|&amp;amp; #243; |ô|&amp;amp; ocirc;|&amp;amp; #244;|õ|&amp;amp; otilde;|&amp;amp; #245;|ö|&amp;amp; ouml;|&amp;amp; #246; |÷|&amp;amp; divide;|&amp;amp; #247;|ø|&amp;amp; oslash;|&amp;amp; #248;|ù|&amp;amp; ugrave;|&amp;amp; #249; |ú|&amp;amp; uacute;|&amp;amp; #250;|û|&amp;amp; ucirc;|&amp;amp; #251;|ü|&amp;amp; uuml;|&amp;amp; #252; |ý|&amp;amp; yacute;|&amp;amp; #253;|þ|&amp;amp; thorn;|&amp;amp; #254;|ÿ|&amp;amp; yuml;|&amp;amp; #255;</description></item><item><title>MySQL、Postgres、Oracle、SQL server、DB2、Teradata、Netezza数据类型比较</title><link>https://mryqu.github.io/post/mysqlpostgresoraclesql_serverdb2teradatanetezza%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%AF%94%E8%BE%83/</link><pubDate>Mon, 24 Jun 2013 20:49:03 +0000</pubDate><guid>https://mryqu.github.io/post/mysqlpostgresoraclesql_serverdb2teradatanetezza%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%AF%94%E8%BE%83/</guid><description>mysqlpostgresoraclemssqldb2teredatanetezzabigint8bytes
-9223372036854775808~9223372036854775807
0~184467440737095516158bytes
-9223372036854775808~9223372036854775807Not support8bytes
-9223372036854775808~92233720368547758078bytes (precision of 19digits)
-9223372036854775808~92233720368547758078bytes
-9223372036854775808~92233720368547758078bytes
-9223372036854775808~9223372036854775807decimal(m,n)65digits
64: MySQL 5.0.3~5.0.5
8?: MySQL 5.0.3 beforeno limit?
1000digits?m:1 ~38
n:-84~127.m:1 ~38
n:0~m1~31digitsm:1~18m:1 ~38
n:0~mnumeric=decimalnumeric=decimalnumeric=decimalnumeric=decimalnumeric=decimalinteger4bytes
-2147483648~2147483647
0~42949672954bytes
-2147483648~2147483647INTEGER=NUMBER(38)
int
4bytes
-2147483648~21474836474bytes (precision of 10digits)
-2147483648~21474836474bytes
-2147483648~21474836474bytes
-2147483648~2147483647varchar(n)0~255characters : MySQLbefore
0~65,535characters : MySQL 5.0.3 and above
unlimited lengthvarchar2(n)
4000 bytes800032672bytes64000 bytes64000 characterschar(n)0~255characters?&amp;nbsp;unlimited length2000 bytes80001~25464000 bytes64000 characterstextTINYTEXT:255(2^8)bytes
TEXT:65535(2^16)bytes
MEDIUMTEXT:16777215 (2^24)bytes
LONGTEXT:4294967295 (2^32)bytesunlimited lengthCLOB: (4 gigabytes - 1) * (database block size).</description></item><item><title>Shell参数扩展</title><link>https://mryqu.github.io/post/shell%E5%8F%82%E6%95%B0%E6%89%A9%E5%B1%95/</link><pubDate>Sun, 23 Jun 2013 18:55:00 +0000</pubDate><guid>https://mryqu.github.io/post/shell%E5%8F%82%E6%95%B0%E6%89%A9%E5%B1%95/</guid><description>在hadoop-env.sh中，有如下语句：
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-&amp;#34;/etc/hadoop&amp;#34;} 这种用法在Shell Parameter Expansion中进行了详尽的介绍，系统学习一下。 Bash中的$符号的作用是参数替换，将参数名替换为参数所代表的值。对于$来说，大括号是可选的，即$ABC和${ABC}代表同一个参数。但是它可以防止变量被错误解析，比如：${hello}world、${arr[1]}。 参数扩展 下列Bash对参数的测试项为未设置和null。如果略掉冒号，则仅测试未设置。
|表达式|含义 |&amp;mdash;&amp;ndash; |${parameter:-word}|如果parameter没有被声明或者其值为空的话，则表达式替换成word；否则替换成parameter的值。 |${parameter:=word}|如果parameter没有被声明或者其值为空的话，则parameter设为word之后表达式返回parameter的值；否则替换成parameter的值。 |${parameter?word}|如果parameter没有被声明或者其值为空的话，则word被写往标准错误输出和Shell，非可交互的情况下退出；否则替换成parameter的值。 |${parameter:+word}|如果parameter没有被声明或者其值为空的话，则不进行替换；否则替换成parameter的值。 |${!varprefix*}
${!varprefix@}|匹配之前所有以varprefix开头进行声明的变量 |${!name[@]}
${!name[*]}|如果name是数组对象，返回数组下标列表；如果name以设置但不为数组对象，返回0；否则返回null。
字符串操作 |表达式|含义 |&amp;mdash;&amp;ndash; |${% raw %}{#{% endraw %}parameter}|parameter的长度。 |${parameter:offset}|在parameter中，从位置offset开始提取子串。 |${parameter:offset:length}|在parameter中，从位置offset开始提取长度为length的子串。 |${parameter#word}
${parameter##word}|从头开始扫描parameter对应值，将匹配word正则表达式的字符删除掉#为最短匹配，##为最长匹配。 |${parameter%word}
${parameter%%word}|从尾开始扫描parameter对应值，将匹配word正则表达式的字符删除掉%为最短匹配，%%为最长匹配。 |${parameter/pattern/string}
${parameter//pattern/string}|将parameter对应值的pattern代替为string。/表示只替换一次，//表示全部替换。 |${parameter^pattern}
${parameter^^pattern}|如果pattern是单个字符，将parameter对应值中匹配pattern的字符转换为大写。^表示只转换匹配的首字母，^^表示全部转换。 |${parameter,pattern}
${parameter,,pattern}|如果pattern是单个字符，将parameter对应值中匹配pattern的字符转换为小写。,表示只转换匹配的首字母，,,表示全部转换。</description></item><item><title>Java对象的内存使用量分析</title><link>https://mryqu.github.io/post/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E9%87%8F%E5%88%86%E6%9E%90/</link><pubDate>Wed, 19 Jun 2013 09:17:09 +0000</pubDate><guid>https://mryqu.github.io/post/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E9%87%8F%E5%88%86%E6%9E%90/</guid><description>前段时间做GemFire中对象的内存使用量分析时，学习了一下Java对象的内存使用量分析。 如果不知道一个没有变量的空对象占8字节，空数组占12字节，空字符串对象占40字节的话，有必要看一下下面的链接进行学习。 Memory usage of Java Strings and string-related objects
Determining Memory Usage in Java
Java对象内存结构
主题：如何获取一个对象的在内存中的大小？
JAVA Objects Memory Size Reference</description></item><item><title>发现Hibernate 3.2.6统计中一个bug</title><link>https://mryqu.github.io/post/%E5%8F%91%E7%8E%B0hibernate_3.2.6%E7%BB%9F%E8%AE%A1%E4%B8%AD%E4%B8%80%E4%B8%AAbug/</link><pubDate>Tue, 18 Jun 2013 17:13:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%8F%91%E7%8E%B0hibernate_3.2.6%E7%BB%9F%E8%AE%A1%E4%B8%AD%E4%B8%80%E4%B8%AAbug/</guid><description>今天使用Hibernate的统计类，分析一下结果。结果发现了一个bug，不能获得查询缓存中的查询语句。 这个bug倒在3.6.8已经修改了，不过还是影响我的工作。
Statistics stat = sessionFactory.getStatistics(); logger.info(&amp;#34;isStatisticsEnabled:&amp;#34;+stat.isStatisticsEnabled()); logger.info(&amp;#34;stat=&amp;#34;+stat.toString()); logger.info(&amp;#34;queries=&amp;#34;+Arrays.toString(stat.getQueries())); org.hibernate.stat.StatisticsImpl.java
public String[] getQueries() { return ArrayHelper.toStringArray( queryStatistics.keySet()); } org.hibernate.util.ArrayHelper.java (Hibernate 3.2.6)
public static String[] toStringArray(Collection coll) { return (String[]) coll.toArray(EMPTY_STRING_ARRAY); } org.hibernate.util.ArrayHelper.java (Hibernate3.6.8)
public static String[] toStringArray(Collection coll) { return (String[]) coll.toArray( new String[coll.size()]); }</description></item><item><title>模型评估笔记</title><link>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 16 Jun 2013 22:44:54 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</guid><description>模型评估简介 模型评估是模型开发过程的不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。在数据挖掘中，使用训练集中的数据评估模型性能是不可接受的，因为这易于生成过于乐观和过拟合的模型。数据挖掘中有两种方法评估模型，验证（Hold-Out）和交叉验证（Cross-Validation）。为了避免过拟合，这两种方法都使用（模型没有遇到过的）测试集来评估模型性能。
验证（Hold-Out） 使用这种方法时，通常大的数据集会被_随机_分成三个子集：
训练集：用于构建预测模型。 验证集：用于评估训练阶段所得模型的性能。它为模型参数优化和选择最优模型提供了测试平台。不是所有模型算法都需要验证机。 测试集或之前未遇到的样本用于评估模型未来可能的性能。如果模型与训练集拟合的好于测试集，有可能是过拟合所致。 交叉验证（Cross-Validation） 当仅有有限数量的数据时，为了对模型性能进行无偏估计，我们可以使用_k_折交叉验证（k-foldcross-validation）。使用这种方法时，数据被分成_k_份数目相等的子集。我们构建_k_次模型，每次留一个子集做测试集，其他用作训练集。如果_k_等于样本大小，这也被称之为留一验证（leave-one-out）。
分类模型评估 混淆矩阵（Confusion Matrix） 混淆矩阵显示了分类模型相对数据的真实输出（目标值）的正确预测和不正确预测数目。矩阵为_N_x_N_，其中_N_为目标值（类）数目。这类模型的性能通常使用矩阵中的数据评估。下表为两个类别（阳性和阴性）的2x2混淆矩阵。
混淆矩阵目标&amp;nbsp;阳性阴性模型阳性TPFP阳性预测值
TP/(TP+FP)阴性FNTN阴性预测值
TN/(FN+TN)&amp;nbsp;灵敏度特异度准确度&amp;nbsp;=(TP+TN)/(TP+FP+FN+TN)
TP/(TP+FN)TN/(FP+TN) 术语：
阳性 (P, positive) 阴性 (N, Negative) 真阳性 (TP, true positive)：正确的肯定。又称：命中 (hit) 真阴性 (TN, true negative)：正确的否定。又称：正确拒绝 (correctrejection) 伪阳性 (FP, false positive)：错误的肯定，又称：假警报 (falsealarm)、第二型错误 伪阴性 (FN, false negative)：错误的否定，又称：未命中(miss)、第一型错误 灵敏度(sensitivity)或真阳性率(TPR, true positive rate)：又称：召回率（recall）、命中率 (hit rate)在阳性值中实际被预测正确所占的比例。TPR = TP / P = TP / (TP+FN) 伪阳性率(FPR, false positive rate)：又称：错误命中率，假警报率 (false alarm rate)FPR = FP / N = FP / (FP + TN) = 1-SPC 特异度 (SPC, Specificity)或真阴性率(TNR, true negativerate)：在阴性值中实现被预测正确所占的比例。SPC = TN / N = TN / (FP+TN) = 1-FPR 假发现率 (FDR, false discovery rate)：FDR = FP / (FP + TP) = 1-TPR 准确度 (ACC, accuracy）：预测正确的数占样本数的比例。ACC = (TP + TN) / (P + N) 阳性预测值 (PPV, positive predictive value)或精度(precision)：阳性预测值被预测正确的比例。PPV = TP / (TP + FP) 阴性预测值 (NPV, negative predictive value)：阴性预测值被预测正确的比例。NPV = TN / (TN + FN) F1评分：精度和灵敏度的调和平均数。F1 = 2 precision * recall / (precision+recall) =2TP/(2TP+FP+FN) Matthews相关系数 (MCC)，即 Phi相关系数：(TPTN - FPFN)/ sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)} 示例:</description></item><item><title>PostgreSQL JDBC setFetchSize</title><link>https://mryqu.github.io/post/postgresql_jdbc_setfetchsize/</link><pubDate>Fri, 14 Jun 2013 17:56:08 +0000</pubDate><guid>https://mryqu.github.io/post/postgresql_jdbc_setfetchsize/</guid><description>今天看到我们的Hiberante配置没有设hibernate.jdbc.fetch_size。 Fetch Size是设定JDBC的Statement读取数据的时候每次从数据库中取出的记录条数。例如一次查询1万条记录，对于Oracle的JDBC驱动来说，是不会1次性把1万条取出来的，而只会取出FetchSize条数，当纪录集遍历完了这些记录以后，再去数据库取Fetch Size条数据。因此大大节省了无谓的内存消耗。当然FetchSize设的越大，读数据库的次数越少，速度越快；FetchSize越小，读数据库的次数越多，速度越慢。这有点像平时我们写程序写硬盘文件一样，设立一个缓冲，每次写入缓冲，等缓冲满了以后，一次写入硬盘，道理相同。 看了一下Postgres，它的JDBC驱动却是一次将查询的所有结果都返回。相反使用游标、设置fetchsize倒是麻烦不少。 http://jdbc.postgresql.org/documentation/head/query.html</description></item><item><title>Hibernate3 HQL: ClassCastException解决办法</title><link>https://mryqu.github.io/post/hibernate3_hql_classcastexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link><pubDate>Tue, 11 Jun 2013 18:06:03 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate3_hql_classcastexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid><description>下面的示例代码跑在Hibernate 3.6.8，会抛出异常java.lang.ClassCastException:[Ljava.lang.Object 无法转换成实体对象。通过调试可知返回的仍然是标量字段对象数组，而不是实体对象。
public class DemoEntity { public static final String DEMO_ENTITY_ID = &amp;#34;demoEntityID&amp;#34;; public static final String USER_ID = &amp;#34;userID&amp;#34;; public static final String OFFICE_ID = &amp;#34;officeID&amp;#34;; private Integer demoEntityID; private String userID; private Integer officeID; private String subjectTxt; public List findDemoEntitys(int startID, int limit, boolean includeStartIdInResults) { try { StringBuilder querySb = new StringBuilder(); querySb.append(&amp;#34;select demo.&amp;#34;).append(DemoEntity.DEMO_ENTITY_ID); querySb.append(&amp;#34;, demo.&amp;#34;).append(DemoEntity.USER_ID); querySb.append(&amp;#34;, demo.&amp;#34;).append(DemoEntity.OFFICE_ID); querySb.append(&amp;#34; from DemoEntity demo where demo.&amp;#34;).append(DemoEntity.DEMO_ENTITY_ID); if (includeStartIdInResults) { querySb.</description></item><item><title>Hibernate3.X升级到4.X实践</title><link>https://mryqu.github.io/post/hibernate3.x%E5%8D%87%E7%BA%A7%E5%88%B04.x%E5%AE%9E%E8%B7%B5/</link><pubDate>Fri, 07 Jun 2013 22:49:33 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate3.x%E5%8D%87%E7%BA%A7%E5%88%B04.x%E5%AE%9E%E8%B7%B5/</guid><description>Jar调查 |jar文件|Hibernate 4.2.2|当前的Hibernate|操作 |&amp;mdash; |antlr.jar|required, 2.7.7|3.2.0|无需改变。 |dom4j.jar|required, 1.6.1|1.6.1|无需改变。 |hibernate-commons-annotations.jar|required, 4.0.2|3.3.1|替换。 |hibernate-corel.jar|required, 4.2.2|3.2.6|替换。 |hibernate-jpa-2.0-api.jar|required, 1.0.1||增加。 |javassist.jar|required, 3.15.0|3.15.0|无需改变。 |jboss-logging.jar|required, 3.1.0||增加。 |jboss-transaction-api_1.1_specl.jar|required, 1.0.1||一开始增加，后来去掉了。 |hibernate-annotations.jar|null|3.3.1|去掉。从Hibernate3.6.0开始hibernate-annotations被合并到hibernate-core。 |hibernate-entitymanager.jar|jpa, 4.2.2|3.2.2|替换。
修改HibernateUtil 将AnnotationConfiguration替换成Configuration； 在使用ServiceRegistry;
Configuration config = new Configuration().configure(); ServiceRegistry serviceRegistry = newServiceRegistryBuilder() .applySettings(config.getProperties()).buildServiceRegistry(); sessionFactory = config.buildSessionFactory(serviceRegistry); Hibernate4不支持Ant HibernateToolTask。 使用Hibernate3和HibernateToolTask创建hibernate.cfg.xml 使用Hibernate4编译。 https://community.jboss.org/thread/177200
修改Web容器下的jar文件 替换hibernate3.jar为hibernate-core.jar 替换hibernate-commons-annotations.jar 删除ejb3-persistence.jar 删除hibernate-annotations.jar 复制hibernate-entitymanager.jar 复制hibernate-jpa-2.0-api.jar 复制jboss-logging.jar 复制jboss-transaction-api_1.1_spec.jar （最终没有复制） 通过删除jboss-transaction-api_1.1_spec.jar解决TransactionManager冲突 org.springframework.jndi.TypeMismatchNamingException: Objectof type [class com.atomikos.icatch.jta.J2eeTransactionManager]available at JNDI location [java:comp/env/TransactionManager] isnot assignable to [javax.transaction.TransactionManager] 通过删除ejb3-persistence.jar解决javax.persistence冲突 java.lang.NoSuchMethodError:javax.persistence.OneToMany.orphanRemoval() ejb3-persistence.</description></item><item><title>多维数据遍历</title><link>https://mryqu.github.io/post/%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E9%81%8D%E5%8E%86/</link><pubDate>Fri, 31 May 2013 12:21:17 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E9%81%8D%E5%8E%86/</guid><description>在联机分析处理（OLAP）系统中，需要对存储在数据库或数据仓库中的数据提供分析。由于数据维数不定，无法采用多重for循环进行数据遍历。我在开发过程中一般使用扁平化下标对多维数据进行遍历，今天尝试了一下递归方式，效率更高一些，但是对栈的消耗也更多一些。下面的代码示例使用两种不同的方式对多维数据进行遍历：
递归 采用扁平化下标 示例代码 package com.yqu.collection; import java.util.ArrayList; import java.util.List; public class MultipleDimensionTraveling &amp;lt;T&amp;gt;{ private List&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; mdList; public MultipleDimensionTraveling(){ mdList = new ArrayList&amp;lt;List&amp;lt;T&amp;gt;&amp;gt;(); } public MultipleDimensionTraveling(List&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; mdList){ this.mdList = mdList; } public void addDimension(List&amp;lt;T&amp;gt; dim){ mdList.add(dim); } public void travelByRecursion(){ if(!mdList.isEmpty()) travelByRecursion(0, new ArrayList&amp;lt;T&amp;gt;(mdList.size())); } private void travelByRecursion(int dimIdx, List&amp;lt;T&amp;gt; crossing){ for(int i=0;i&amp;lt;mdList.get(dimIdx).size();i++){ if(crossing.size()&amp;lt;mdList.size()) crossing.add(dimIdx, mdList.get(dimIdx).get(i)); else crossing.set(dimIdx, mdList.get(dimIdx).get(i)); if(dimIdx==mdList.size()-1){ System.out.println(crossing.toString()); } else { travelByRecursion(dimIdx+1, crossing); } } } public void travelByFlatIndice(){ if(!</description></item><item><title>Servlet</title><link>https://mryqu.github.io/post/servlet/</link><pubDate>Wed, 29 May 2013 09:58:56 +0000</pubDate><guid>https://mryqu.github.io/post/servlet/</guid><description>现在用的VFabric tc Server 2.8.0基于Apache的Tomcat7.0.3版本，支持Servlet3.0和JSP 2.2规范。 Java Servlet3.1规范这周可以下载了，目前正在学习当中。将Servlet的不同版本的资料汇总一下，利人利己。 JSR 340：Java Servlet 3.1 Specification
JSR 315：Java Servlet 3.0 Specification
JSR 154：Java Servlet 2.4 Specification
JSR 53：Java Servlet 2.3 and JavaServer Pages 1.2 Specification
Servlet API 2.2 的新特性
Servlet 3.0 新特性详解</description></item><item><title>Hibernate缓存</title><link>https://mryqu.github.io/post/hibernate%E7%BC%93%E5%AD%98/</link><pubDate>Sat, 25 May 2013 09:40:06 +0000</pubDate><guid>https://mryqu.github.io/post/hibernate%E7%BC%93%E5%AD%98/</guid><description>Hibernate缓存 Hibernate带有三种不同缓存机制：一级缓存、二级缓存和查询缓存。
SessionFactory和Session SessionFactory(在JEE中叫做EntityManager)的用途是创建会话，初始化JDBC链接并（使用例如C3P0之类的可插拔provider）进行池化。SessionFactory是非可变的，通过hibernate.cfg.cml文件或Springbean配置中提供的匹配信息、缓存信息等配置进行创建。会话是最低级的工作单元，对应一个数据库事物。当会话创建后并对Hibernate实体机型一些操作，比如设置实体的一个属性，Hibernate不会立即更新底层数据库表。相反Hibernate记录实体的状态（是否为脏数据），并在会话最终刷新更新到数据库。这就是Hibernate所谓的一级缓存。
一级缓存 一级缓存是Hibernate记录正在进行的会话加载和接触的实体有可能的脏数据状态。正在进行的会话代表工作单元，始终使用，无法关闭。一级缓存的用途是隐藏对数据库许多SQL查询或更新，并在会话最终批量一起执行。当想起一级缓存的时候就应该想到会话。
二级缓存 二级缓存是进程范围内的缓存，与一个SessionFactory绑定。二级缓存可被相同（通常一个应用程序仅一个）SessionFactory的所有会话共享。默认二级缓存没有使能。二级缓存不存储任何实体实例，而是存储“脱水”状态，即字符串或整形数组代表实体的属性，一个实体id指向“脱水”的实体。概念上可以认为它是一个映射，id作为键，数组作为值。或像下面用于缓存region的这些东西：
public class Person { private Person parent; private Set&amp;lt;Person&amp;gt; children; public void setParent(Person p) { parent = p; } public void setChildren(Set&amp;lt;Person&amp;gt; set) { children = set; } public Set&amp;lt;Person&amp;gt; getChildren() { return children; } public Person getParent() { return parent; } } Hibernate映射配置如下:
&amp;lt;class name=&amp;#34;org.javalobby.tnt.hibernate.Person&amp;#34;&amp;gt; &amp;lt;cache usage=&amp;#34;read-write&amp;#34;/&amp;gt; &amp;lt;id name=&amp;#34;id&amp;#34; column=&amp;#34;id&amp;#34; type=&amp;#34;long&amp;#34;&amp;gt; &amp;lt;generator class=&amp;#34;identity&amp;#34;/&amp;gt; &amp;lt;/id&amp;gt; &amp;lt;property name=&amp;#34;firstName&amp;#34; type=&amp;#34;string&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;middleInitial&amp;#34; type=&amp;#34;string&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;lastName&amp;#34; type=&amp;#34;string&amp;#34;/&amp;gt; &amp;lt;many-to-one name=&amp;#34;parent&amp;#34; column=&amp;#34;parent_id&amp;#34; class=&amp;#34;Person&amp;#34;/&amp;gt; &amp;lt;set name=&amp;#34;children&amp;#34;&amp;gt; &amp;lt;key column=&amp;#34;parent_id&amp;#34;/&amp;gt; &amp;lt;one-to-many class=&amp;#34;Person&amp;#34;/&amp;gt; &amp;lt;/set&amp;gt; &amp;lt;/class&amp;gt; Hibernate概念上为此类持有如下记录:</description></item><item><title>JavaSE 新增特性</title><link>https://mryqu.github.io/post/javase_%E6%96%B0%E5%A2%9E%E7%89%B9%E6%80%A7/</link><pubDate>Wed, 22 May 2013 22:09:39 +0000</pubDate><guid>https://mryqu.github.io/post/javase_%E6%96%B0%E5%A2%9E%E7%89%B9%E6%80%A7/</guid><description>参考 Wiki：Java version history JDK各版本很cool的特性 JDK6中httpserver实例 IBM developerWorks：JDK 7 新特性 - 总览 Try-with-resources in Java 7 Java 7 的新特性一览表 编程没有银弹：探讨 Java 8 新增特性的优缺点 IBM developerWorks：Java 8 新特性概述 Java 8 的新特性和改进总览 Java 8 正式发布，新特性全搜罗</description></item><item><title>使用GemFire做Mybatis/Hibernate二级缓存</title><link>https://mryqu.github.io/post/gemfire_as-l2-cache-of-mybatis-and-hibernate/</link><pubDate>Wed, 22 May 2013 09:12:27 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_as-l2-cache-of-mybatis-and-hibernate/</guid><description>使用GemFire做Mybatis二级缓存 MyBatis支持第三方二级缓存实现，目前支持Ehcache、Hazelcast和OSCache。 GemFire不在支持的范围，但是可以通过实现org.apache.ibatis.cache.Cache接口来使用。
MyBatis的Cache配置及实现 设置MyBatis的Cache全局使用开关：默认是true，如果它配成false，其余各个MapperXML文件配成支持cache也没用。
&amp;lt;settings&amp;gt; &amp;lt;setting name=&amp;#34;cacheEnabled&amp;#34; value=&amp;#34;true&amp;#34;/&amp;gt; &amp;lt;/settings&amp;gt; 各个Mapper XML文件，默认是不采用cache。在配置文件加一行就可以支持cache：
&amp;lt;cache /&amp;gt; 实现GemfireCache
package com.yqu.mybatis.caches.gemfire; import com.gemstone.gemfire.cache.AttributesFactory; import com.gemstone.gemfire.cache.CacheFactory; import com.gemstone.gemfire.cache.Region; import java.util.concurrent.locks.ReadWriteLock; import java.util.concurrent.locks.ReentrantReadWriteLock; import org.apache.ibatis.cache.Cache; import org.apache.ibatis.cache.CacheException; public final class GemfireCache implements Cache { private static Region&amp;lt;object&amp;gt; mybatis_region = null; private Region&amp;lt;object&amp;gt; region = null; private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private String id; public void setId(String id) { this.id = id; } public void setRegion(Region&amp;lt;object&amp;gt; region) { this.</description></item><item><title>Java缓存规范JCache API(JSR107)</title><link>https://mryqu.github.io/post/java%E7%BC%93%E5%AD%98%E8%A7%84%E8%8C%83jcache_apijsr107/</link><pubDate>Wed, 22 May 2013 07:13:07 +0000</pubDate><guid>https://mryqu.github.io/post/java%E7%BC%93%E5%AD%98%E8%A7%84%E8%8C%83jcache_apijsr107/</guid><description>今天看了一下Java缓存规范JCacheAPI（JSR107），它对Java对象缓存进行标准化，方便高效开发，让程序员摆脱实现缓存有效期、互斥、假脱机（spooling）和缓存一致性等负担。该规范提供了API、RI（参考实现）和TCK（技术兼容性套件）。 从设计的角度看，基本组成部分有一个CacheManager，用来持有、控制缓存集合。缓存里存放键值对条目。 整个规范包括了如下内容：
支持原子操作的缓存读写 缓存事件监听器 统计 事务 注解 JSR107从2001年开始，中间搁置了一段时间，后来Terracotta（产品：EhCache）和Oracle（产品：Coherence）在2010年加强了对JSR-107的投入，原本有望放入JAVAEE7(JSR342)中，可惜在期限内完不成，直到2012年底才推出了草案。 我更关注数据网格（JSR347），那个是JSR107的超集，关注缓存的逐出、复制和分布化，以及事务。可惜连草案也还没影呢。 http://jcp.org/en/jsr/detail?id=107
http://jcp.org/en/jsr/detail?id=347</description></item><item><title>GemFire 数据逐出和持久化</title><link>https://mryqu.github.io/post/gemfire_data-eviction-and-persistence/</link><pubDate>Fri, 17 May 2013 15:48:33 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_data-eviction-and-persistence/</guid><description>为什么逐出数据? 如果有多于JVM内存的数据想放入Region，数据逐出是可能使用的一种解决方案。 一种备选方案是对数据进行分区。然而分区Region也可能无法将所有数据放入内存，所以有可能需要对分区Region采用数据逐出。 另一种备选方案是让数据过一定期限后从内存删除，这是基于时间而不是空间的一种方案。
数据逐出如何工作？ 当使用数据逐出时需要决定所采用的算法和动作。 算法规定了需要检查的所耗费资源的最大值，可为基于条目数量、内存消耗字节数和可用堆消耗百分比的LRU（最近最少使用）算法。
条目数量和绝对内存消耗量完全由GemFire逐出控制器基于Region级别进行管理。EntryLRU是最简单的算法，适用于每个条目消耗相同大小的内存。Memory LRU则适用于每个条目消耗不同大小的内存。 Heap消耗百分比由GemFire逐出控制器基于缓存级别进行管理。最大值设置在管理器配置的缓存下配置。当管理器断定需要进行数据逐出时，它命令逐出控制器对所有逐出算法设为lru-heap-percentage的region采取数据逐出，直到管理器停止这一命令。注意的是，当其他非LRU资源甚至非GemFire缓存消耗内存时，这一算法也会导致HeapLRUregion的数据逐出。 对于一个region，数据逐出操作会逐出最近最少使用到的条目。几乎所有操作（包括读写）都认为是对条目的使用，除了以下的操作：
Region.containsKey Region.containsValue Region.getEntry 当使用MemoryLRU或HeapLRU算法时需要实现ObjectSizer接口。这让GemFire可以调用自己的代码来计算条目的字节大小。让条目大小估算精确很重要，但同时需要注意的是复杂ObjectSize实现会花费较长时间并导致性能下降。如果条目的所有值都是String或byte[]类型，GemFire会自动计算内存大小，无须实现ObjectSizer。
分区Region在数据逐出的不同之处 对于分区region，基于条目数量和内存消耗量的逐出行为当节点数据超过本地缓存主副本和冗余副本组合的限制后发生。对于基于堆消耗百分比的逐出行为由管理器驱动。 因为维护整个分区region或者同一节点所有桶（bucket）的LRU条目信息代价太大，GemFire是基于桶来维护LRU条目信息的。此外，对分区region的所有桶施行数据组出会导致数据分布失衡。 因此，对分区region进行的数据逐出可能会保留相对本地节点其他桶或其他分布系统节点相对更老的条目。它可能在主副本中保留条目而在第二副本中逐出条目，或者相反。 LRU逐出对每个桶单独进行:
对基于内存和条目数的数据逐出，LRU逐出在操作新条目时有可能执行，直到Region的桶组合整体内存下降到门限下结束。对于内存逐出，分区region最大内存门限会忽略lru-memory-size设置，始终是local-max-memory。 对于基于堆的数据逐出，每个分区region桶被当作单独region来处理，每个逐出动作仅考虑桶内的LRU，而不是整体分区region。 动作为本地删除条目的数据逐出无法用于复制region，因为不允许对复制分区进行本地写操作，这会违反所有数据在复制分区都可见的契约。如果需要使用本地删除条目的数据逐出，可以考虑使用预加载数据策略，其行为在初始化时与复制分区相同并允许动作为本地删除条目的数据逐出。
数据无持久化 数据持久化 EvictionAction.NONE 条目将在内存中一直保存。 条目将在内存和磁盘中一直保存。 EvictionAction.LOCAL_DESTROY 条目（键和值两部分）将从内存中释放。仅当被逐出数据可从外部数据源加载时可用。 EvictionAction.OVERFLOW_TO_DISK 条目将被逐出到磁盘但是不会持久化 (当缓存关闭时磁盘文件将被删除)，条目的键部分始终在内存中保存。 条目(键和值两部分)一直在磁盘中保存。条目的值部分将被逐出，键部分始终在内存中保存。 磁盘存储文件名和扩展名 磁盘存储文件包括存储管理、访问控制文件和操作日志（oplog，记录了删除和其他所有操作）。下面的表描述了文件名和扩展名及示例。
文件名 文件名包括三部分:
第一部分: 使用标识 值 用途 示例 OVERFLOW 仅为溢出region和队列的操作日志数据。 OVERFLOWoverflowDS1_1.crf BACKUP 持久化、持久化+溢出rgion和队列操作日志数据。 BACKUPoverflowDS1.if, BACKUPDEFAULT.if DRLK_IF 访问控制 - 对磁盘存储上锁。 DRLK_IFoverflowDS1.lk, DRLK_IFDEFAULT.lk 第二部分: 磁盘存储名 值 用途 示例 &amp;lt;磁盘存储名&amp;gt; 非默认磁盘存储。 name=&amp;ldquo;overflowDS1&amp;rdquo; DRLK_IFoverflowDS1.lk,
name=&amp;ldquo;persistDS1&amp;rdquo; BACKUPpersistDS1_1.crf DEFAULT 默认磁盘存储名，当对region或队列指定持久化或溢出但没有命名磁盘存储时使用。 DRLK_IFDEFAULT.lk, BACKUPDEFAULT_1.</description></item><item><title>GemFire查询</title><link>https://mryqu.github.io/post/gemfire_query/</link><pubDate>Wed, 15 May 2013 07:30:01 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_query/</guid><description>GemFire在region中存储的数据为键值对，其中值可以为任何对象，例如简单的字节数组或者复杂的嵌套对象。GemFire提供了一种查询机制可以获得满足特定条件的键、值或条目集合。GemFire支持的查询语义和语法是OQL（对象查询语言）的一个子集。OQL是由对象数据管理组制定的ODMG3.0对象模型的重要组件之一，与SQL很相似，可以查询复杂对象、对象属性和方法，支持完整的ASCII和Unicode字符集。 为了提高查询执行效率，GemFire像数据库一样支持索引。在查询执行时，查询引擎使用数据存储上的索引可以减少查询处理时间。查询是GemFire很强大的功能，但它也需要大量性能优化和容量规划也确保不拖垮系统。
Region存储示例 本文的查询示例基于类Porfolio和Positon的对象。
Portfolio.java package query; import java.io.DataInput; import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import java.util.HashMap; import java.util.Iterator; import java.util.Map; import com.gemstone.gemfire.DataSerializable; import com.gemstone.gemfire.DataSerializer; public class Portfolio implements Serializable, DataSerializable { private int ID; public String pkid; public Position position1; public Position position2; public String description; public HashMap positions = new HashMap(); String type; public String status; public String [] names={&amp;#34;aaa&amp;#34;,&amp;#34;bbb&amp;#34;,&amp;#34;ccc&amp;#34;,&amp;#34;ddd&amp;#34;}; public int getID() { return ID; } public String getPk() { return pkid; } public HashMap getPositions() { return positions; } public Position getP1() { return position1; } public Position getP2() { return position2; } public boolean isActive() { return status.</description></item><item><title>GemFire Region分类</title><link>https://mryqu.github.io/post/gemfire_region-type/</link><pubDate>Wed, 15 May 2013 07:28:53 +0000</pubDate><guid>https://mryqu.github.io/post/gemfire_region-type/</guid><description>GemFire开发指南6.5的第4.2节仅列举了分区、复制（分布式）、分布式（非复制）和本地四种Region类型，但RegionShortcut类却定义了23个快捷预定义属性Region。Region的主要行为取决于数据策略、关注策略、范围、本地最大内存和冗余拷贝数（仅用于分区Region）、逐出算法和动作。
Region快捷预定义属性 数据策略 范围 本地最大内存注1 冗余拷贝数注1 逐出算法 逐出动作 LOCAL NORMAL LOCAL LOCAL_HEAP_LRU NORMAL LOCAL LRU_HEAP LOCAL_DESTROY LOCAL_OVERFLOW NORMAL LOCAL LRU_HEAP OVERFLOW_TO_DISK LOCAL_PERSISTENT PERSISTENT_REPLICATE LOCAL LOCAL_PERSISTENT_OVERFLOW PERSISTENT_REPLICATE LOCAL LRU_HEAP OVERFLOW_TO_DISK PARTITION PARTITION PARTITION_HEAP_LRU PARTITION LRU_HEAP LOCAL_DESTROY PARTITION_OVERFLOW PARTITION LRU_HEAP OVERFLOW_TO_DISK PARTITION_PERSISTENT PERSISTENT_PARTITION PARTITION_PERSISTENT_OVERFLOW PERSISTENT_PARTITION LRU_HEAP OVERFLOW_TO_DISK PARTITION_PROXY PARTITION 0 PARTITION_PROXY_REDUNDANT PARTITION 0 1 PARTITION_REDUNDANT PARTITION 1 PARTITION_REDUNDANT_HEAP_LRU PARTITION 1 LRU_HEAP LOCAL_DESTROY PARTITION_REDUNDANT_OVERFLOW PARTITION 1 LRU_HEAP OVERFLOW_TO_DISK PARTITION_REDUNDANT_PERSISTENT PERSISTENT_PARTITION 1 PARTITION_REDUNDANT_
PERSISTENT_OVERFLOW PERSISTENT_PARTITION 1 LRU_HEAP OVERFLOW_TO_DISK REPLICATE REPLICATE DISTRIBUTED_ACK REPLICATE_HEAP_LRU PRELOAD DISTRIBUTED_ACK LRU_HEAP LOCAL_DESTROY REPLICATE_OVERFLOW REPLICATE DISTRIBUTED_ACK LRU_HEAP OVERFLOW_TO_DISK REPLICATE_PERSISTENT PERSISTENT_REPLICATE DISTRIBUTED_ACK REPLICATE_PERSISTENT_OVERFLOW PERSISTENT_REPLICATE DISTRIBUTED_ACK LRU_HEAP OVERFLOW_TO_DISK REPLICATE_PROXY EMPTY DISTRIBUTED_ACK 注1：仅用于分区region</description></item><item><title>为Unix终端或Windows命令行设置UTF-8编码</title><link>https://mryqu.github.io/post/%E4%B8%BAunix%E7%BB%88%E7%AB%AF%E6%88%96windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%AE%BE%E7%BD%AEutf-8%E7%BC%96%E7%A0%81/</link><pubDate>Tue, 14 May 2013 21:20:30 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%B8%BAunix%E7%BB%88%E7%AB%AF%E6%88%96windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%AE%BE%E7%BD%AEutf-8%E7%BC%96%E7%A0%81/</guid><description>Unix终端## 使用“locale –a” 命令检查支持的编码 servermt&amp;gt; locale -a C POSIX ……… en_US.ISO8859-1 en_US.ISO8859-15 en_US.US-ASCII en_US.UTF-8 ……… 设置环境变量 LANG=en_US.UTF-8 Windows命令行 通过chcp命令设置 Displays or sets the active code page number: CHCP [nnn] C:\&amp;gt;chcp Active code page: 437 C:\&amp;gt;chcp 65001 Active code page: 65001 通过mode con命令设置 Select code page: MODE CON[:] CP SELECT=yyy Code page status: MODE CON[:] CP [/STATUS] C:\&amp;gt;mode con cp /status Status for device CON: ---------------------- Code page: 437 C:\&amp;gt;mode con cp select=65001 Status for device CON: ---------------------- Lines: 300 Columns: 160 Keyboard rate: 31 Keyboard delay: 1 Code page: 65001 代码页代号 Identifier .</description></item><item><title>Windows服务的创建、查询及删除操作</title><link>https://mryqu.github.io/post/windows%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E8%AF%A2%E5%8F%8A%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/</link><pubDate>Tue, 14 May 2013 21:04:27 +0000</pubDate><guid>https://mryqu.github.io/post/windows%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E6%9F%A5%E8%AF%A2%E5%8F%8A%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C/</guid><description>SC是与Windows服务管理器和服务通信的命令行程序。
查询SC帮助 创建Windows服务 示例：sc create akxService binPath= C:\Test\akxService.exe
查询Windows服务 删除Windows服务 示例：sc delete akxService 如果服务名含有空格，可在服务名上加双引号。</description></item><item><title>技术博文链接</title><link>https://mryqu.github.io/post/%E6%8A%80%E6%9C%AF%E5%8D%9A%E6%96%87%E9%93%BE%E6%8E%A5/</link><pubDate>Wed, 06 Mar 2013 20:32:37 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%8A%80%E6%9C%AF%E5%8D%9A%E6%96%87%E9%93%BE%E6%8E%A5/</guid><description>Webkit Webkit内核探究【1】——Webkit简介
Webkit内核探究【2】——Webkit CSS实现
WebKit内核源代码分析（一）
WebKit内核源代码分析（二）
WebKit内核源代码分析（三）
WebKit内核源代码分析（四）
WebKit内核源代码分析（五）
安全存储密码 如何安全的存储密码 - hash、salt 以及更多
MD5+Salt加密机制
ActiveMQ ActiveMQ in Action (1) 关于Session.DUPS_OK_ACKNOWLEDGE的注解： 当使用DUPS_OK_ACKNOWLEDGE会话应答模式，会话延迟应答消息的传递情况。 当JMS出现问题，这可能导致一些消息的重复传递，所以仅用于消费者能容忍重复消息的情况下。 其优点是通过减少会话防止重复消息的工作来减少会话的负载。 ActiveMQ in Action (2) ActiveMQ in Action (3) ActiveMQ in Action (4) ActiveMQ in Action (5) ActiveMQ in Action (6) ActiveMQ in Action (7) 飞鸟Blog:优化ActiveMQ性能
Tomcat集群 负载均衡技术 Apache + Tomcat集群配置详解 （1） Apache + Tomcat集群配置详解 （2） IP组播与组播协议 Tomcat集群Cluster实现原理剖析 利用JMX监控Tomcat集群
负载均衡 http://en.wikipedia.org/wiki/Load_balancing_(computing) http://zh.wikipedia.org/wiki/负载均衡_(计算机)
Web Application Server架构 Tomcat 系统原理分析 Tomcat 设计模式分析 Jetty 的工作原理以及与 Tomcat 的比较</description></item><item><title>尝试了一下jacob</title><link>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95%E4%BA%86%E4%B8%80%E4%B8%8Bjacob/</link><pubDate>Mon, 18 Feb 2013 12:49:30 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%B0%9D%E8%AF%95%E4%BA%86%E4%B8%80%E4%B8%8Bjacob/</guid><description>JACOB开源项目 Jacob是Java与COM组件桥接的缩写，即JAVA-COMBridge。通过使用Jacob类库，我们可以很方便地在Java程序中使用JNI来进行本地调用COM库。它可运行在x86和（支持32位和64位Java虚拟机的）X64环境。Jacob最初是由美国人DanAlder在Inventure公司担任CTO时编写的，目的是为了方便众多的程序员在Java2虚拟机上，调用Win32平台上COM自动化服务器中的组件。当Jacob项目以开源的方式在网络上公布以后，越来越多的人开始参与项目的研发与改进中去。
JACOB 相关博文： Jacob的简单介绍
Jacob使用入门及问题解析</description></item><item><title>孔多塞投票悖论</title><link>https://mryqu.github.io/post/%E5%AD%94%E5%A4%9A%E5%A1%9E%E6%8A%95%E7%A5%A8%E6%82%96%E8%AE%BA/</link><pubDate>Sun, 20 Jan 2013 15:20:34 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%94%E5%A4%9A%E5%A1%9E%E6%8A%95%E7%A5%A8%E6%82%96%E8%AE%BA/</guid><description>简介 投票悖论指的是在通过“多数原则”实现个人选择到集体选择的转换过程中所遇到的障碍或非传递性，这是阿罗的不可能定理衍生出的难题。公共选择理论对投票行为的研究假设投票是那些其福利受到投票结果影响的人们进行的，投票行为的作用是将个人偏好转化为社会偏好。在多数投票原则下，可能没有稳定一致的结果。 投票悖论是公共选择理论中的概念，又称为循环的大多数，是指在集体投票时容易出现投票结果随投票次序的不同变化，大部分甚至全部备选方案在比较过程中都有机会轮流当选的循环现象。 18世纪时，法国著名思想家提出了所谓的“投票悖论”，后人称其为“孔多塞投票悖论”。其描述为：设有A、B、C三个人，他们对X、Y、Z的偏好如下： A： X&amp;gt;Y&amp;gt;Z B： Y&amp;gt;Z&amp;gt;X C： Z&amp;gt;X&amp;gt;Y
如果按照社会少数服从多数的原则，对X与Y进行民主表决，那么结果如下： A： X&amp;gt;Y B： Y&amp;gt;X C： X&amp;gt;Y 社会偏好：X&amp;gt;Y
因为A、C两个人都偏好X，只有一个人B偏好Y，所以根据少数服从多数原则，我们最后得到X&amp;gt;Y的社会偏好。 同理，我们如果再按照少数服从多数的原则，对Y与Z以及X与Z进行民主表决。通过三次选择，于是我们得到一个矛盾的社会偏好： X&amp;gt;Y；Y&amp;gt;Z；Z&amp;gt;X
从上面的论述中，孔多塞认为，大众投票并不会真正传递社会偏好，投票制度并不能真正保证社会合意的结果。因为，根据常理推断，社会偏好应该具有某种传递特征。因此，大众投票并不能保证出最优的，投票从本质上不具有传递性，甚至会有某种非理性。
同时，孔多塞悖论还给我们另一层的其实：认为设计的投票顺序和规则，可以对投票的结果产生非常重大的影响。
例如三个女孩A、B、C一块出去吃午饭，可以选择肯德基、麦当劳、必胜客其中之一。她们的喜好如下： A： 麦当劳&amp;gt;肯德基&amp;gt;必胜客 B： 肯德基&amp;gt;麦当劳&amp;gt;必胜客 C： 必胜客&amp;gt;麦当劳&amp;gt;肯德基
由于偏好难以达成一致，于是三人决定投票，并定投票规则为：先在麦当劳和必胜客之间选一个，然后再在胜者和肯德基之间选一个。
假如三人都毫无心机，那么第一轮麦当劳胜出；第二轮又将胜出。这实际上是最佳选择，也就是说麦当劳在三人中的综合评论是最高的。
但是如果B为了达到自己的目的而动用一些策略，投票的结果将完全改变。B可以在第一轮故意投票给必胜客，淘汰掉麦当劳，必胜客胜出，第二轮肯德基铁定胜出，因此B通过策略实现了自己的最爱，但是这一结果却不符合总体的最大利益。
发展 1972年诺贝尔经济学奖的获得者肯尼思·阿罗，在他的《社会选择与个人价值》（1951）中，证明了著名的阿罗不可能性定理，把这个投票悖论形式化了。在该书中，他运用数学工具把孔多塞的观念严格化和一般化了。那么，能不能设计出一个消除循环投票，做出合理决策的投票方案呢？
阿罗的结论 根本不存在一种能保证效率、尊重个人偏好、并且不依赖程序 (agenda)的多数规则的投票方案。
阿罗证明 不存在同时满足如下四个基本公理的社会选择函数： 1）个人偏好的无限制性，即对一个社会可能存在的所有状态，逻辑上可能的个人偏好都不应当先验地被排除； 2）弱帕累托原则， 3）非相关目标独立性，即关于一对社会目标的社会偏好序不受其它目标偏好序变化的影响； 4）社会偏好的非独裁性。
简单地说，阿罗的不可能定理意味着，在通常情况下，当社会所有成员的偏好为已知时，不可能通过一定的方法从个人偏好次序得出社会偏好次序，不可能通过一定的程序准确地表达社会全体成员的个人偏好或者达到合意的公共决策。投票悖论表明：根本不存在一种能满足阿罗五个假设条件的社会选择原理。解决投票悖论的方法是限制投票偏好，即将多峰偏好改为单峰偏好。
解决 1998年诺贝尔经济学奖获得者阿马蒂亚·森在20世纪70年代提出对“投票悖论”的解决方法。阿马蒂亚·森所提出的解决投票悖论、绕过“阿罗不可能定理”的方法就是改变甲、乙、丙其中一个人的偏好次序，以解决投票悖论的问题。
举例 比如将A的偏好次序从（X&amp;gt;Y&amp;gt;Z）改变为（X&amp;gt;Z&amp;gt;Y），新的偏好次序排列如下： A：X&amp;gt;Z&amp;gt;Y B：Y&amp;gt;Z&amp;gt;X C：Z&amp;gt;X&amp;gt;Y
于是得到三个社会偏好次序——（X&amp;gt;Y）（Z&amp;gt;Y）（Z&amp;gt;X），这样就能避开投票悖论，当然它却改变了A的偏好次序。
阿马蒂亚·森选择模式 阿马蒂亚·森把这个发现加以延伸和拓展，得出了解决投票悖论的三种选择模式： 一、所有人都同意其中一项选择方案并非是最佳； 二、所有人都同意其中一项选择方案并非是次佳； 三、所有人都同意其中一项选择方案并非是最差。
阿马蒂亚·森表示在上述三种选择模式下，投票悖论不会再出现，取而代之的结果是得大多数票者获胜的规则总是能达到唯一的决定。但是有一个问题是为了追求一致性，改变、忽略、牺牲了个人偏好次序。</description></item><item><title>t分布的由来</title><link>https://mryqu.github.io/post/t%E5%88%86%E5%B8%83%E7%9A%84%E7%94%B1%E6%9D%A5/</link><pubDate>Sun, 16 Dec 2012 09:11:46 +0000</pubDate><guid>https://mryqu.github.io/post/t%E5%88%86%E5%B8%83%E7%9A%84%E7%94%B1%E6%9D%A5/</guid><description>一直对student分布的名字莫名其妙，搜了一下，原来t分布是由统计学家哥威廉·戈塞在都柏林的A.吉尼斯父子酿酒厂对小样本中平均数比例对其标准误差的分布所做的研究，由于吉尼斯酿酒厂的规定禁止戈塞发表关于酿酒过程变化性的研究成果，因此戈塞不得不于1908年，首次以“学生”(Student)为笔名，发表自己的研究成果。因此t分布又称为学生分布。 http://baike.baidu.com/view/1419652.htm
http://baike.baidu.com/view/1332600.htm</description></item><item><title>学会了用excel制作甘特图</title><link>https://mryqu.github.io/post/%E5%AD%A6%E4%BC%9A%E4%BA%86%E7%94%A8excel%E5%88%B6%E4%BD%9C%E7%94%98%E7%89%B9%E5%9B%BE/</link><pubDate>Sun, 23 Sep 2012 17:00:51 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AD%A6%E4%BC%9A%E4%BA%86%E7%94%A8excel%E5%88%B6%E4%BD%9C%E7%94%98%E7%89%B9%E5%9B%BE/</guid><description>参考文档 http://dreamtails.pixnet.net/blog/post/22059710-用excel畫甘特圖! http://www.excel123.cn/Article/tuxinghetubiao/201201/917.html</description></item><item><title>[Flex] Explicitly mapping ActionScript and Java objects</title><link>https://mryqu.github.io/post/flex_explicitly_mapping_actionscript_and_java_objects/</link><pubDate>Sun, 16 Sep 2012 10:30:48 +0000</pubDate><guid>https://mryqu.github.io/post/flex_explicitly_mapping_actionscript_and_java_objects/</guid><description>Flex和Java对象的映射 http://livedocs.adobe.com/blazeds/1/blazeds_devguide/help.html?content=serialize_data_3.html</description></item><item><title>Eclipse中解决远程调试超时的设置</title><link>https://mryqu.github.io/post/eclipse%E4%B8%AD%E8%A7%A3%E5%86%B3%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E8%B6%85%E6%97%B6%E7%9A%84%E8%AE%BE%E7%BD%AE/</link><pubDate>Fri, 07 Sep 2012 20:55:16 +0000</pubDate><guid>https://mryqu.github.io/post/eclipse%E4%B8%AD%E8%A7%A3%E5%86%B3%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E8%B6%85%E6%97%B6%E7%9A%84%E8%AE%BE%E7%BD%AE/</guid><description>主要是加大调试器超时和启动超时设置 Tomcat设置 catalina.bat中添加如下：
:doStart shift if &amp;#34;%TITLE%&amp;#34; == &amp;#34;&amp;#34; set TITLE=Tomcat set _EXECJAVA=start &amp;#34;%TITLE%&amp;#34; %_RUNJAVA% set CATALINA_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,address=5558,server=y,suspend=n if not &amp;#34;&amp;#34;%1&amp;#34;&amp;#34; == &amp;#34;&amp;#34;-security&amp;#34;&amp;#34; goto execCmd shift echo Using Security Manager set &amp;#34;SECURITY_POLICY_FILE=%CTALINA_BASE%\conf\catalina.policy&amp;#34; goto execCmd Eclipse设置</description></item><item><title>[Flex] 显式使用public namespace</title><link>https://mryqu.github.io/post/flex_%E6%98%BE%E5%BC%8F%E4%BD%BF%E7%94%A8public_namespace/</link><pubDate>Sat, 01 Sep 2012 17:24:28 +0000</pubDate><guid>https://mryqu.github.io/post/flex_%E6%98%BE%E5%BC%8F%E4%BD%BF%E7%94%A8public_namespace/</guid><description>今天看代码时，发现public namespace的使用，搜了一下flex4 in action，貌似没有。 放狗搜了一下，学习学习。 myspace.as
package { public namespace myspace =&amp;#34;http://myspace&amp;#34;; } TestClass.as
package { import myspace; public class TestClass { public function foo():void { trace(&amp;#34;Public foo is called&amp;#34;); } myspace function foo():void { trace(&amp;#34;MySpace foo is called&amp;#34;); } private function fooPrivate():void { trace(&amp;#34;Called private function&amp;#34;); } protected function fooProtected():void { trace(&amp;#34;Called protected function&amp;#34;); } public function callFoo(t:TestClass):void { // call the private/protected members on the object. t.fooPrivate(); t.fooProtected(); } } } testApp.</description></item><item><title>表驱动法</title><link>https://mryqu.github.io/post/%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%B3%95/</link><pubDate>Fri, 24 Aug 2012 09:11:39 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%B3%95/</guid><description>表提供了一种复杂逻辑和继承结构的替换方案。如果发现自己对某个应用程序的逻辑或者继承树关系感到困惑，可以问问自己它是否可以通过一个查询表来加以简化。 使用表的一项关键决策是决定如何访问表。可以通过直接访问、索引访问或者阶梯访问。 使用表的另一项关键决策是决定应该把什么内容放入表中。</description></item><item><title>Tomcat JNDI 数据源配置</title><link>https://mryqu.github.io/post/tomcat_jndi_%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</link><pubDate>Wed, 22 Aug 2012 09:19:36 +0000</pubDate><guid>https://mryqu.github.io/post/tomcat_jndi_%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</guid><description>学写一下Tomcat:JNDI Datasource HOW-TO，JNDI数据源可以配置到两个位置。Tomcat详细介绍了第二种方式，我目前的项目使用的是第一种方式。第一种方式的好处是，多个Web应用程序可以共享Tomcat全局命名空间里的资源。
Tomcat全局命名空间 $CATALINA_HOME$/conf/server.xml $CATALINA_HOME$/conf/localhost/javatest.xml Web应用程序环境(Context)</description></item><item><title>数据库常用操作笔记</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 18 Aug 2012 07:10:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/</guid><description>GreenPlum/PostGreSQL操作 Create a new database: createdb medb Drop database: dropdb medb Access database: psql -h gpserver -d gpdatabase -U gpuser -W Get help: medb=# \h Quit: medb=# \q Read command from file: medb=# \i input.sql To dump a database: pg_dump medb &amp;gt; db.out To reload the database: psql -d database -f db.out Dump all database: pg_dumpall &amp;gt; /var/lib/pgsql/backups/dumpall.sql Restore database: psql -f /var/lib/pgsql/backups/dumpall.sql medb Show databases: psql -l medb=# \l; Show users: medb=# select * from &amp;quot;pg_user&amp;quot;; Show tables: medb=# select * from &amp;quot;pg_tables&amp;quot;; Set password: medb=# upadte pg_shadow set passwd = 'new_password' where usename = 'username'; Clean all databases (Should be done via a daily cron): vacuumdb --quiet --all check column of table medb=# select * from INFORMATION_SCHEMA.</description></item><item><title>数据库catalog的定义</title><link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93catalog%E7%9A%84%E5%AE%9A%E4%B9%89/</link><pubDate>Mon, 13 Aug 2012 22:16:37 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93catalog%E7%9A%84%E5%AE%9A%E4%B9%89/</guid><description>The database catalog of a database instance consists ofmetadata in which definitions of database objects such as basetables, views (virtual tables), synonyms, value ranges, indexes,users, and user groups are stored.
The SQL standard specifies a uniform means to access thecatalog, called the INFORMATION_SCHEMA, but not all databasesfollow this, even if they implement other aspects of the SQLstandard. For an example of database-specific metadata accessmethods, see Oracle metadata.</description></item><item><title>Flex启动次序</title><link>https://mryqu.github.io/post/flex%E5%90%AF%E5%8A%A8%E6%AC%A1%E5%BA%8F/</link><pubDate>Wed, 18 Jul 2012 13:28:23 +0000</pubDate><guid>https://mryqu.github.io/post/flex%E5%90%AF%E5%8A%A8%E6%AC%A1%E5%BA%8F/</guid><description>所有Flex组件在启动过程都会触发一些事件。这些事件指示何时组件首次被创建、在内部进行描绘、在屏幕上进行绘制。这些事件也指示何时组件结束创建，当组件为容器时指示何时子组件被创建。 组件被实例化、加入或链接父组件，之后在容器内确定大小并布局。组件创建顺序如下： 下例展示了组件创建生命期内分发的一些重要事件： 容器和组件的创建顺序是不同的，因为容器可为其他组件的父组件。容器内的组件也必须经历创建顺序。如果一个容器是另一个容器的父组件，内部容器的子组件也必须经历创建顺序。 下例展示了容器创建生命期内分发的一些重要事件： 当所有组件被创建并在屏幕绘制，Application对象会分发一个applicationComplete事件。这是程序启动的最后一个被分发的事件。 multiview容器(navigators)的启动顺序与标准容器不同。默认情况下，导航器(navigator)的所有顶级视图会被实例化。然而，Flex仅创建初始可见视图的子组件。当用户切到导航器的其他视图，Flex才会为此视图创建子组件。</description></item><item><title>FLEX组件的生命周期</title><link>https://mryqu.github.io/post/flex%E7%BB%84%E4%BB%B6%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</link><pubDate>Mon, 16 Jul 2012 13:19:52 +0000</pubDate><guid>https://mryqu.github.io/post/flex%E7%BB%84%E4%BB%B6%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</guid><description>组件实例化生命周期描述了用组件类创建组件对象时所发生的一系列步骤,作为生命周期的一部分,flex自动调用组件的的方法,发出事件,并使组件可见。 下面例子用as创建一个btn控件,并将其加入容器中
var boxContainer:Box = new Box(); //设置Box容器 ... //创建btn var b:Button = new Button(); b.label = &amp;#34;Submit&amp;#34;; ... //将btn添加到Box容器中 boxContainer.addChild(b); 下面的步骤显示了用代码创建一个Button控件，并将这个控件添加到Box容器中时所发生的一切：
调用了组件的构造函数; var b:Button = new Button(); 通过设置组件的属性对组件进行设置: //Configure the button control. b.label = &amp;ldquo;Submit&amp;rdquo;; 组件的setter方法将会调用invalidateProperties()、invalidateSize()、invalidateDisplayList()方法。 调用addChild()方法将该组件添加到父组件。 //Add the Button control to the Box container. boxContainer.addChild(b); 将component的parent的属性设置为对父容器的引用. 计算组件样式(style)设置。 在组件上发布priininialize事件。 调用组件的createChildren()方法。 调用invalidateProperties(),invalidateSize(),invalidateDisplayList()方法以触发后续到来的,下一个&amp;quot;渲染事件&amp;quot;(render event)期间对commitProperties(),measure(),updateDisplayList()方法的调用.这个规则唯一一个例外就是当用户设置组件的height和width属性时,Flex不会调用measure()方法。 在组件上分发initialize事件。此时，组件所有的子组件都被初始化，但是组件没有改更size和处理布局。可以利用这个事件在组件布局之前执行一些附加的处理。 在父容器上分发childAdd事件。 在父容器上分发initialize事件。 在下一个&amp;quot;渲染事件&amp;quot;(render event)中,Flex执行以下动作: 调用组件的commitProperties()方法。 调用组件的measure()方法。 调用组件的layoutChrome方法。 调用组件的updateDisplayList()方法。 在组件上发布updateComplete事件。 如果commitProperties(),measure,updateDisplayList方法调用了invalidateProperties(),invalidateSize(),或invalidateDisplayList()方法,则Flex会分发另外一个render事件。 在最后的render事件发生后,Flex执行以下动作: 通过设置组件的visible属性使组件变为可视. 在组件上分发creationComplete事件.组件的大小(size)和布局被确定. 这个事件只在组件创建时分发一次. 在组件上分发updateComplete事件.无论什么时候,只要组件的布局(layout),位置,大小或其它可视的属性发生变化就会分发这事件,然后组件被更新，以使组件能够被正确地显示. 原文：http://blog.csdn.net/stonywang/article/details/2667551</description></item><item><title>解：failed to create task or type cobertura-instrument</title><link>https://mryqu.github.io/post/%E8%A7%A3failed_to_create_task_or_type_cobertura-instrument/</link><pubDate>Mon, 07 Nov 2011 19:50:31 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%A7%A3failed_to_create_task_or_type_cobertura-instrument/</guid><description>由于项目需要，学习使用cobertura检查junit测试覆盖率。 结果ant总是报错：
BUILD FAILEDbuild.xml:54: Problem: failed to create task or typecobertura-instrumentCause: The name is undefined.Action: Check the spelling.Action: Check that any custom tasks/types have been declared.Action: Check that any&amp;lt;presetdef&amp;gt;/&amp;lt;macrodef&amp;gt;declarations have taken place. 搜了一些文章，都无解，最后看cobertura的example，找到病根。 解决方法： 将&amp;lt;taskdef classpath=&amp;ldquo;cobertura.classpath&amp;quot;resource=&amp;ldquo;tasks.properties&amp;rdquo; /&amp;gt;改成&amp;lt;taskdef classpathref=&amp;ldquo;cobertura.classpath&amp;quot;resource=&amp;ldquo;tasks.properties&amp;rdquo; /&amp;gt;就好了。</description></item><item><title>实践记录：将MDF MSSQL数据库内容导入MySQL</title><link>https://mryqu.github.io/post/%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95%E5%B0%86mdf_mssql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E5%AE%B9%E5%AF%BC%E5%85%A5mysql/</link><pubDate>Thu, 24 Sep 2009 10:37:58 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95%E5%B0%86mdf_mssql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E5%AE%B9%E5%AF%BC%E5%85%A5mysql/</guid><description>玩一个例程源码，它使用的是SQL server数据库，虽然我机子装了VS2005带的SQL server2005，我还是想用MySQL。 把自己的转换过程草草记录下来，也不算太无聊吧。
【环境】VS2005附带的SQL server 2005 &amp;amp; MySQL 5.1
1、下载并安装Microsoft SQL Server Management StudioExpress（SSMSE） http://www.microsoft.com/downloadS/details.aspx?familyid=C243A5AE-4BD1-4E3D-94B8-5A0F62BF7796&amp;amp;displaylang=en
2、 配置SQL2005
==SQL server configuration manager== SQL server service -&amp;gt; 选择SQL serverbrower属性，修改模式为手动，然后启动SQL server brower
==SQL Server Surface Area Configuration -&amp;gt;Surface Area Configuration for Services and Connections== SQLEXPRESS -&amp;gt; Database Engine -&amp;gt;Remote connection -&amp;gt; Local and remote connection&amp;amp; using both tcp/ip and named pipes
==SQL server configuration manager== SQL server 2005 network configuration -&amp;gt; protocolsfor SQLEXPRESS -&amp;gt; 选择TCP/TP属性中IPAddresses，删掉动态端口，设定端口为1433</description></item><item><title>读《剑出偏锋 JBoss的过去现在和未来》</title><link>https://mryqu.github.io/post/%E8%AF%BB%E5%89%91%E5%87%BA%E5%81%8F%E9%94%8B_jboss%E7%9A%84%E8%BF%87%E5%8E%BB%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/</link><pubDate>Mon, 30 Mar 2009 23:08:28 +0000</pubDate><guid>https://mryqu.github.io/post/%E8%AF%BB%E5%89%91%E5%87%BA%E5%81%8F%E9%94%8B_jboss%E7%9A%84%E8%BF%87%E5%8E%BB%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/</guid><description>剑出偏锋 JBoss的过去现在和未来 JBoss的确很好用，全是拜Marc老兄带人稳扎稳打做出来的。学习，实践，平常心!</description></item><item><title>UML笔记（JUDE）</title><link>https://mryqu.github.io/post/uml%E7%AC%94%E8%AE%B0jude/</link><pubDate>Thu, 05 Feb 2009 20:55:54 +0000</pubDate><guid>https://mryqu.github.io/post/uml%E7%AC%94%E8%AE%B0jude/</guid><description>UML介绍 统一建模语言（UML是 Unified ModelingLanguage的缩写）是用来对软件密集系统进行可视化建模的一种语言。UML为面向对象开发系统的产品进行说明、可视化、和编制文档的一种标准语言。 UML的主要创始人是Jim Rumbaugh、Ivar Jacobson和GradyBooch，他们最初都有自己的建模方法（OMT、OOSE和Booch），彼此之间存在着竞争。最终，他们联合起来创造了一种开放的标准。1997年，OMG组织（ObjectManagementGroup对象管理组织）发布了统一建模语言UML。UML的目标之一就是为开发团队提供标准通用的设计语言来开发和构建计算机应用。UML提出了一套IT专业人员期待多年的统一的标准建模符号。通过使用UML，这些人员能够阅读和交流系统架构和设计规划&amp;ndash;就像建筑工人多年来所使用的建筑设计图一样。 最常用的UML图包括：用例图、类图、序列图、状态图、活动图、组件图和部署图。 类图 类图中的元素 类和接口是类图中的基本元素，其UML表示是一个长方形，垂直地分为三个区：最上层显示类名或接口名，中间的区域列出类的属性，底部的区域列出类的操作。 对于抽象类/方法，类/方法名是斜体的。 对于静态属性/方法，属性/方法下面有下划线。 根据属性/方法的访问权限不同，其图示也不同。
|属性/方法访问权限|图示 |&amp;mdash;&amp;ndash; |公开|+ |包内访问|~ |保护|# |私有|-
在关联建模中，存在一些情况下，你需要包括其它类，因为它包含了关于关联的有价值的信息。对于这种情况，你会使用关联类来绑定你的基本关联。关联类和一般类一样表示。不同的是，主类和关联类之间用一条相交的点线连接。关联类类似查询表，可以凭借关联信息从一个类查找到另一个类。 UML中的软件包类似于Java中的包，使建模者能够组织模型分类器到不同的名字空间中，便于管理。 类图中的六大关系 |关系名|介绍|体现|图示 |&amp;mdash;&amp;ndash; |泛化关系generalization|表示一般与特殊的关系|类与类之间的继承，接口与接口之间的继承|用一条实线加空三角来表示 |实现关系realization|表示类与接口的关系|类对接口的实现|用一条虚线加空三角来表示 |依赖关系dependency|类与类之间的连接，表示一个类依赖于另外一个类的定义；依赖关系仅仅描述了类与类之间的一种使用与被使用的关系|局部变量、方法/函数的参数或者是对静态方法的调用|用一条虚线加箭头来表示 |关联关系association|类与类之间的连结，关联关系使一个类知道另外一个类的属性和方法；通常含有“知道”，“了解”的含义依赖关系是具有偶然性的、临时性的、非常弱的，方向是单向的；关联关系是固定的、长期的对应关系，方向可以是单向或者双向的。对类而言依赖存在的理由有：B作为一个参数被传递给A内所定义的一个方法(参数可见性)；B在A的一个方法内被声明为局部对象(局部声明可见性)；B对A全局可见(全局可见性)。而关联一般应来描述普通的属性可见性(B是A的一个属性，是一种相对长久的可见性, 是普遍存在的)。|成员变量|用一条实线来表示关联关系的一段带箭头的是可访问的（Navigableassociation）；带叉号的是不可访问或禁止访问的（Non-navigableassociation）；什么都不带的是未特别指出的关系（Unspecifiedassociation），例如无法直接访问但是可以间接访问。 |聚合关系aggregation|关联关系的一种，是一种强关联关系；聚合关系是整体和个体/部分之间的关系；关联关系的两个类处于同一个层次上，而聚合关系的两个类处于不同的层次上，一个是整体，一个是个体/部分；在聚合关系中，代表个体/部分的对象有可能会被多个代表整体的对象所共享|成员变量|用一条实线加空心菱形来表示 |组合关系composition|也是关联关系的一种，但它是比聚合关系更强的关系。组合关系要求聚合关系中代表整体的对象要负责代表个体/部分的对象的整个生命周期；组合关系不能共享；在组合关系中，如果代表整体的对象被销毁或破坏，那么代表个体/部分的对象也一定会被销毁或破坏；而聚在合关系中，代表个体/部分的对象则有可能被多个代表整体的对象所共享，而不一定会随着某个代表整体的对象被销毁或破坏而被销毁或破坏。|成员变量|用一条实线加实心菱形来表示
继承和实现体现的是类与类、或者类与接口间的纵向关系；依赖、关联、聚合和组合关系则体现的是类与类、或者类与接口间的引用、横向关系，是比较难区分的，这几种关系都是语义级别的，所以从代码层面并不能完全区分各种关系。 但总的来说，后几种关系所表现的强弱程度依次为：组合&amp;gt;聚合&amp;gt;关联&amp;gt;依赖。
序列图 同步消息的图示为一条实线加实三角，异步消息的图示为一条实线加箭头。 交互框常见操作符 |操作符|含义 |&amp;mdash;&amp;ndash; |alt|多选一的片段；只有条件为真者会执行 |opt|可选的；该片段只在所给条件为真时执行，等同于只有一个片断的alt |par|并行；每一个片断并行运行 |loop|循环；片断可以执行多次；警戒条件表示循环的条件 |region|关键区域；片断一次只有一个线程执行 |neg|否定；片断展示无效的交互 |ref|引用；引用到另一张图中定义的交互。画一个框盖住交互设计的生命线。你可以定义参数和返回值 |sd|序列图；圈出一张完整的序列图，如果你愿意的话
参考 《UML精粹：标准对象建模语言简明指南》 JUDE文档
IBM的“UML 基础”系列文章。</description></item><item><title>关于JavaScript框架</title><link>https://mryqu.github.io/post/%E5%85%B3%E4%BA%8Ejavascript%E6%A1%86%E6%9E%B6/</link><pubDate>Wed, 04 Feb 2009 00:11:44 +0000</pubDate><guid>https://mryqu.github.io/post/%E5%85%B3%E4%BA%8Ejavascript%E6%A1%86%E6%9E%B6/</guid><description>JS库一览 http://www.slideshare.net/jeresig/javascript-library-overview
http://www.webjx.com/javascript/jsajax-8545.html
JS库评估 http://wiki.freaks-unidos.net/javascript-libraries
为什么选择DOJO？ 原文版 http://dojotoolkit.org/book/dojo-book-0-9/introduction/why-dojo
中文版 http://bigqiangbigqiang.spaces.live.com/blog/cns!64A5E0FB4DFCD63F!606.entry
http://bigqiangbigqiang.spaces.live.com/blog/cns!64A5E0FB4DFCD63F!607.entry
为什么选择mootools,抛弃了prototype http://www.javaeye.com/topic/122425
不要使用ExtJS http://pablotron.org/?cid=1556
ExtJS源自YUI，功能更强，许可更苛刻。</description></item><item><title>Adobe Flash、Flex、AIR和ColdFusion</title><link>https://mryqu.github.io/post/adobe_flashflexair%E5%92%8Ccoldfusion/</link><pubDate>Sun, 07 Dec 2008 01:58:53 +0000</pubDate><guid>https://mryqu.github.io/post/adobe_flashflexair%E5%92%8Ccoldfusion/</guid><description>Adobe Flash Adobe Flash，前称ShockwaveFlash并流行地简称Flash，前身FutureSplash，既指Adobe FlashProfessional 多媒体创作程序，也指Adobe Flash Player。Adobe公司于2005年12月3日收购Macromedia公司，因此Flash成了Adobe公司的软件。
特性 被大量应用于因特网网页的矢量动画文件格式。 使用向量运算（VectorGraphics）的方式，产生出来的影片占用存储空间较小。 使用Flash创作出的影片有自己的特殊文件格式（swf） 该公司声称全世界97%的网络浏览器都内置Flash播放器（FlashPlayer） 是Adobe提出的“富因特网应用”（RIA）概念的实现平台 Flash6之后版本纳入面向对象程序概念。与其他语言比较，不论是在数据库、XML、PHP等各种平台上，都能更进一步的相互结合应用。 主要文件格式 **swf**这是一个完整的影片档，无法被编辑。有时会被念作“swiff”或“swaif”[1]。Swf在发布时可以选择保护功能，如果没有选择，很容易被别人输入到他的源文件中使用。然而保护功能依然阻挡不了为数众多的破解软件，有不少闪客专门以此来学习别人的代码和设计方式。 **fla**Flash的源文件，只能用AdobeFlash打开编辑。 as（ActionScript的缩写）是一种编程语言的简单文本文件.FLA文件能够直接包含 ActionScript, 但是也可以把它存成AS档做为外部链接文件(如定义ActionScript类则必须在写在as文件里,再通过import加入类)，以方便共同工作和更高级的程序修改。 swc，是一种供Flash使用的库格式，可以粗略地理解为Flash用的dll。无法被编辑。 FLV，FLV是FlashVideo的简称，是一种网络视频格式，FLV是 FLASH VIDEO的简称，FLV流式媒体格式是一种视频格式，它的出现有效地解决了视频文件导入Flash后，使导出的SWF文件体积庞大，不能在网络上有效使用等缺点。 版本历史 FutureSplash Animator (1996-4-10) - Flash前身，由简单的工具和时间线组成。
Flash 1 (1996-11) - Macromedia给FutureSplashAnimator更名后为Flash的第一个版本。 Flash 2 (1997-6) - 引入库的概念。 Flash 3 (1998-5-31) - 影片剪辑、Javascript插件、透明度和独立播放器。 Flash 4 (1999-6-15) - 变量、文本输入框、增强的ActionScript、流媒体MP3。 Flash 5 (2000-8-24) - Javascript、智能剪辑、HTML文本格式。 Flash MX (2002-3-15) - Unicode、组件、XML、流媒体视频编码。 Flash MX 2004 (2003-9-10) - 文本抗锯齿、Actionscript2.0、增强的流媒体视频、行为。 Flash MX 2004 Pro (2003-9-10) - 包括所有Flash MX 2004的特性，加上Web Services、 ActionScript 2.</description></item><item><title>JDK、Ant和Maven开发环境配置</title><link>https://mryqu.github.io/post/jdkant%E5%92%8Cmaven%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 07 Dec 2008 00:00:04 +0000</pubDate><guid>https://mryqu.github.io/post/jdkant%E5%92%8Cmaven%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</guid><description>JDK 下载JDK并安装到c:\tools下 设置Java环境变量：JAVA_HOME = c:\tools\Java\jdk1.x.0_xxCLASSPATH =.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;path变量 %JAVA_HOME%\bin 运行&amp;quot;java -version&amp;quot;进行验证 Ant 下载Ant并解压缩到c:\tools下 设置Ant环境变量：ANT_HOME = c:\tools\apache-ant-1.x.xpath变量 %ANT_HOME%\bin 运行&amp;quot;ant -version&amp;quot;进行验证 maven 下载Maven并解压缩到c:\tools下 设置Maven环境变量：M2_HOME = c:\tools\apache-maven-x.x.xpath变量 %M2_HOME%\bin 运行&amp;quot;mvn &amp;ndash;version&amp;quot;进行验证 m2eclipse 通过下列update site安装:http://download.eclipse.org/technology/m2e/releases 在Window - Preferences - Maven - Installations添加上一步安装的Maven</description></item><item><title>org.gjt.mm.mysql.Driver和com.mysql.jdbc.Driver的区别</title><link>https://mryqu.github.io/post/org.gjt.mm.mysql.driver_%E5%92%8Ccom.mysql.jdbc.driver%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Sun, 05 Oct 2008 11:43:53 +0000</pubDate><guid>https://mryqu.github.io/post/org.gjt.mm.mysql.driver_%E5%92%8Ccom.mysql.jdbc.driver%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>org.gjt.mm.mysql.Driver是早期的驱动名称，后来就改名为com.mysql.jdbc.Driver，现在一般都推荐使用com.mysql.jdbc.Driver。在最新版本的mysqljdbc驱动中，为了保持对老版本的兼容，仍然保留了org.gjt.mm.mysql.Driver，但是实际上org.gjt.mm.mysql.Driver中调用了com.mysql.jdbc.Driver，因此现在这两个驱动没有什么区别。
//org.gjt.mm.mysql.Driver的源代码 package org.gjt.mm.mysql; import java.sql.SQLException; public class Driver extends com.mysql.jdbc.Driver { // ~Constructors//----------------------------------------------------------- public Driver() throws SQLException {super();} } 由源代码可以看出，仅仅是为了兼容，才保留了该名字，所以建议直接使用com.mysql.jdbc.Driver</description></item><item><title>Meta的http-equiv属性详解</title><link>https://mryqu.github.io/post/%E4%BB%8A%E5%A4%A9%E7%9C%8B%E7%9A%84%E4%B8%9C%E4%B8%9Cmeta%E7%9A%84http-equiv%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3/</link><pubDate>Fri, 03 Oct 2008 19:25:51 +0000</pubDate><guid>https://mryqu.github.io/post/%E4%BB%8A%E5%A4%A9%E7%9C%8B%E7%9A%84%E4%B8%9C%E4%B8%9Cmeta%E7%9A%84http-equiv%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3/</guid><description>http-equiv顾名思义，相当于http的文件头作用，它可以向浏览器传回一些有用的信息，以帮助正确和精确地显示网页内容，与之对应的属性值为content，content中的内容其实就是各个参数的变量值。 meta标签的http-equiv属性语法格式是：＜meta http-equiv=&amp;ldquo;参数&amp;rdquo; content=&amp;ldquo;参数变量值&amp;quot;＞；其中http-equiv属性主要有以下几种参数：
Expires(期限) 说明：可以用于设定网页的到期时间。一旦网页过期，必须到服务器上重新传输。 用法：＜meta http-equiv=&amp;ldquo;expires&amp;rdquo; content=&amp;ldquo;Wed, 20 Jun 2007 22:33:00 GMT&amp;quot;＞ 注意：必须使用GMT的时间格式。 Pragma(cache模式) 说明：禁止浏览器从本地计算机的缓存中访问页面内容。 用法：＜meta http-equiv=&amp;ldquo;Pragma&amp;rdquo; content=&amp;ldquo;no-cache&amp;quot;＞ 注意：这样设定，访问者将无法脱机浏览。 Refresh(刷新) 说明：自动刷新并指向新页面。 用法：＜meta http-equiv=&amp;ldquo;Refresh&amp;rdquo; content=&amp;ldquo;2；URL=http://www.net.cn/&amp;ldquo;＞ 注意：其中的2是指停留2秒钟后自动刷新到URL网址。 Set-Cookie(cookie设定) 说明：如果网页过期，那么存盘的cookie将被删除。 用法：＜meta http-equiv=&amp;ldquo;Set-Cookie&amp;rdquo; content=&amp;ldquo;cookievalue=xxx; expires=Wednesday, 20-Jun-2007 22:33:00 GMT； path=/&amp;ldquo;＞ 注意：必须使用GMT的时间格式。 Window-target(显示窗口的设定) 说明：强制页面在当前窗口以独立页面显示。 用法：＜meta http-equiv=&amp;ldquo;Window-target&amp;rdquo; content=&amp;quot;_top&amp;quot;＞ 注意：用来防止别人在框架里调用自己的页面。 content-Type(显示字符集的设定) 说明：设定页面使用的字符集。 用法：＜meta http-equiv=&amp;ldquo;content-Type&amp;rdquo; content=&amp;ldquo;text/html; charset=gb2312&amp;quot;＞ Pics-label(网页等级评定) 用法：网页等级评定 说明：在IE的internet选项中有一项内容设置，可以防止浏览一些受限制的网站，而网站的限制级别就是通过meta属性来设置的。 还有Page_Enter、Page_Exit…… 补充： 设定进入页面时的特殊效果
设定离开页面时的特殊效果
Duration的值为网页动态过渡的时间，单位为秒。
Transition是过渡方式，它的值为0到23，分别对应24种过渡方式。如下表： 0 盒状收缩 1 盒状放射
2 圆形收缩 3 圆形放射
4 由下往上 5 由上往下</description></item><item><title>JavaScript编辑器</title><link>https://mryqu.github.io/post/javascript%E7%BC%96%E8%BE%91%E5%99%A8/</link><pubDate>Mon, 24 Dec 2007 23:59:25 +0000</pubDate><guid>https://mryqu.github.io/post/javascript%E7%BC%96%E8%BE%91%E5%99%A8/</guid><description>Antechnus公司的javascript editor http://www.c-point.com/index.html InterAKTonline公司的JSEclipse http://www.interaktonline.com/Products/Eclipse/JSEclipse/Overview/ Teniga 据说这个最强，下次有空试试 https://sourceforge.net/projects/teniga 放弃自己搜索了，这个强帖太厉害http://blog.csdn.net/holym/archive/2007/09/29/1805887.aspx</description></item><item><title>[C++] 类型转换</title><link>https://mryqu.github.io/post/c++_%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</link><pubDate>Sat, 15 Dec 2007 21:20:37 +0000</pubDate><guid>https://mryqu.github.io/post/c++_%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</guid><description>C++中的强制转换函数共有以下几种：
C 风格（C-style）强制转型: (Type) expr 函数风格（Function-style）强制转型: Type( expr )要注意的是Type(expr)语法上等同(Type)expr，但是要避免使用。Type(expr,expr_else)是安全的。 static_cast &amp;lt;type-id&amp;gt; ( expr )：用于非多态类型转换。static_cast是第一个应该尝试的类型转换。它完成类似隐性类型转换（例如int转float，指针转void*）这样的工作，也能调用显式（或隐式）类型转换函数。在很多情况下，显式使用static_cast没有必要。static_cast也能在继承层次上进行类型转换。在进行上行转换（子类转父类）是没有必要的，下行转换只要没有虚拟继承的情况下也可用，但是它不会做任何检查，下行转换为非该对象真正的类型时行为不明确。type-id和expr必须是指针、引用、算术类型或枚举类型。 dynamic_cast &amp;lt;type-id&amp;gt; ( expr )：用于多态类型转换。dynamic_cast是几乎唯一用于处理多态类型转换的。你可以将一个指针或引用转换成其他类的多态类型（一个多态类型至少有一个虚函数，不管是声明的还是继承的）。它不仅经可用于下行转换，还可以横向转换或上行转换到另一个继承链。dynamic_cast会检查转换是否可行，如果可行则返回期望的对象，否则原表达式是指针的话返回空指针、原表达式是引用的话抛出std::bad_cast异常。dynamic_cast有一些限制。当继承层次上有相同类型的多个对象（DiamondDerivationproblem，菱形派生问题）而又没有使用虚拟继承时，无法工作。它仅能遍历公开继承，在遍历保护继承或私有继承时总是失败。非公开的继承很少使用，所以这种问题也很少见。Type-id必须是类的指针、类的引用或者void*；如果type-id是类指针类型，那么expr也必须是一个指针，如果type-id是一个引用，那么exp也必须是一个引用。 const_cast &amp;lt;type-id&amp;gt; ( expr)：用来修改类型的const、volatile和__unaligned属性。const_cast可用于对一个变量添加或删除const属性，其他C++类型转换（甚至reinterpret_cast）没有删除const的能力。需要注意的是原有变量是const的，如果修改之前的常量值会造成不确定的行为。如果一个const引用指向非常量，对引用去掉const是安全的。当重载的成员函数是const的时候非常有用，例如你可以对一个对象添加const以调用重载的成员函数。const_cast也能对volatile属性进行修改，只是会更少被用到。除了const 或volatile修饰之外， type_id和expr的类型是一样的。 reinterpret_cast &amp;lt;type-id&amp;gt; ( expr )：对类型简单重新解释reinterpret_cast是最危险的类型转换，应该尽可能少地使用。它直接将一个类型转换成另外一个，例如将一个指针获得的值转换成另一种类型、将指针存储成整型值、或其他一些丑陋的转换。基本上，reinterpret_cast仅能保障转换回原类型是正常的，你能在中间类型不小于原有类型的情况下获得相同的值。有很多reinterpret_cast不能做的转换。主要用于转义转换和二进制处理，例如将原始数据流转成实际数据、或将数据存储在对齐指针的低bit位中。type-id必须是一个指针、引用、算术类型、函数指针或者成员指针。 其中前两种称为旧风格（old-style）的强制转型，后四种为标准C++的类型转换符。
旧风格的强制转型可以看成按下列顺序排列的第一个成功的类型转换组合：
const_cast static_cast (忽略访问限制) static_cast接着const_cast reinterpret_cast reinterpret_cast接着const_cast 旧风格的强制转型比较危险，因为可能被解析成reinterpret_cast，而且解析成static_cast时会忽略访问权限控制（能做其他类型转换无法实现的功能）。此外，使用旧风格的强制转型也不如C++类型转换容易查找，所以一般不推荐使用。
参考 Type conversions
MSDN：Casting Operators
When should static_cast, dynamic_cast, const_cast and reinterpret_cast be used?
总结C++中的所有强制转换函数(const_cast，reinterpret_cast，static_cast，dynamic_cast)
In C++, why use static_cast(x) instead of (int)x?</description></item><item><title>敏捷开发</title><link>https://mryqu.github.io/post/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</link><pubDate>Thu, 06 Dec 2007 22:59:25 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</guid><description>什么是敏捷开发？ 九十年代末，几种方法学开始不断获得公众的注意。每种方法学都是对已有开发方法、新开发方法以及转变后的已有开发方法进行不同组合。但是它们都强调研发团队和业务专家之间的紧密协作、面对面的沟通（因为比文档更高效）、频繁地交付新的可部署的商业价值、紧密的自我管理的团队、精致开发代码和管理团队的方法，以使不可预见的需求不再是一场灾难。
敏捷开发的历史 2001年2月11日到13日，在美国犹他州Wasatch山的滑雪圣地Snowbird的一幢大楼里，17位轻量级过程专家通过这次会议形成了敏捷软件开发运动，其中包括了：极限编程（eXtremeProgramming, XP）、Scrum、动态系统开发方法（Dynamic SystemsDevelopment Method，DSDM）、自适应软件开发（AdaptiveSoftware Development，ASD）、Crystal方法、特性驱动方法（Feature-DrivenDevelopment，FDD）、实用程序设计等。这些业界专家概括出了一些可以让软件开发团队具有快速工作、响应变化能力的价值观和原则，目的是推进敏捷开发方法的研究和应用。会议的结果是17名与会者共同签署并发布了“敏捷软件开发宣言”（TheManifesto for Agile Software Development）,敏捷联盟（AgileAlliance）由此诞生。
敏捷开发的核心价值-特点和优势 个体和交互胜过过程和工具 人是获得成功的最为重要的因素。如果团队中没有优秀的成员，那么就是使用好的过程也不能从失败中挽救项目，但是，不好的过程却可以使最优秀的团队成员失去效用。如果不能作为一个团队进行工作，那么即使拥有一批优秀的成员也一样会惨败。团队的构建要比环境的构建重要得多。许多团队和管理者就犯了先构建环境，然后期望团队自动凝聚在一起的错误。相反，应该首先致力于构建团队，然后再让团队基于需要来配置环境。 可以工作的软件胜过面面俱到的文档 没有文档的软件是一种灾难。代码不是传达系统原理和结构的理想媒介。团队更需要编制易于阅读的文档，来对系统及其设计决策的依据进行描述。然而，过多的文档比过少的文档更糟。编制众多的文档需要花费大量的时间，并且要使这些文档和代码保持同步，就要花费更多的时间。如果文档和代码之间失去同步，那么文档就会变成庞大的、复杂的谎言，会造成重大的误导。虽然从代码中提取系统的原理和结构信息可能是困难的，但是代码是惟一没有二义性的信息源。在团队成员的头脑中，保存着时常变化的系统的脉络图（roadmap）。人和人之间的交互是把这份脉络图传授给他人的最快、最有效的方式。 客户合作胜过合同谈判 不能像订购日用品一样来订购软件。你不能够仅仅写下一份关于你想要的软件的描述，然后就让人在固定的时间内以固定的价格去开发它。所有用这种方式来对待软件项目的尝试都以失败而告终。有时，失败是惨重的。告诉开发团队想要的东西，然后期望开发团队消失一段时间后就能够交付一个满足需要的系统来，这对于公司的管理者来说是具有诱惑力的。然而，这种操作模式将导致低劣的质量和失败。成功的项目需要有序、频繁的客户反馈。项目的需求基本处于一个持续变化的状态。大的变更是很平常的。在这期间，也会出现整个功能块被减掉，而加进来另外一些功能块。然而，合同和项目都经受住了这些变更，并获得成功。成功的关键在于和客户之间真诚的协作，并且合同指导了这种协作，而不是试图去规定项目范围的细节和固定成本下的进度。 响应变化胜过遵循计划 响应变化的能力常常决定着一个软件项目的成败。当我们构建计划时，应该确保计划是灵活的并且易于适应商务和技术方面的变化。计划不能考虑得过远。 敏捷开发的十二条原则 我们最优先要做的是通过尽早地、持续地交付有价值的软件来使客户满意。 即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。 经常性地交付可以工作的软件，交付的间隔可以从几个星期到几个月，交付的时间间隔越短越好。 在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。 围绕被激励起来的个人来构建项目。给他们提供所需的环境和支持，并且信任他们能够完成工作。 在团队内部，最具有效果并富有效率的传递信息的方法，就是面对面的交谈。 可以工作的软件是首要的进度度量标准。 敏捷过程提倡可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。 不断地关注优秀的技能和好的设计会增强敏捷能力。 简单——把无需做的工作最大化的艺术——是最根本的。 最好的构架、需求和设计出于自我组织的团队。 每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整 敏捷开发的一些方法 完整团队XP项目的所有参与者（开发人员、客户、测试人员等）一起工作在一个开放的场所中，他们是同一个团队的成员。这个场所的墙壁上随意悬挂着大幅的、显著的图表以及其他一些显示他们进度的东西。 计划游戏计划是持续的、循序渐进的。每2周，开发人员就为下2周估算候选特性的成本，而客户则根据成本和商务价值来选择要实现的特性。 客户测试作为选择每个所期望的特性的一部分，客户可以根据脚本语言来定义出自动验收测试来表明该特性可以工作。 结对编程所有的产品软件都是由两个程序员、并排坐在一起在同一台机器上构建的。 测试驱动开发 编写单元测试是一个验证行为，更是一个设计行为。同样，它更是一种编写文档的行为。编写单元测试避免了相当数量的反馈循环，尤其是功能能验证方面的反馈循环。自动单元测试可以使研发工作和测试工作并行化。 改进设计随时利用重构方法改进已经腐化的代码，保持代码尽可能的干净、具有表达力。 持续集成团队总是使系统完整地被集成。只要有可能就进行代码集成，周期可以在几个小时，最好不要超过一天。持续集成可以避免错误的积累，可以增加可重用的代码。在一个结对小组认为适当的时候并通过了所有的单元测试，就可以进行集成，集成后的代码必须通过测试。 集体代码所有权任何结对的程序员都可以在任何时候改进任何代码。没有程序员对任何一个特定的模块或技术单独负责，每个人都可以参与任何其它方面的开发。 不要加班 尽可能不要加班，大多数加班并不能挽回已有的延迟，连续超过两个星期的加班说明有问题存在。向一个已经延迟的项目填加人员也不是一个好的选择。 附录-极限编程 1999年KentBeck提出的ExtremeProgramming（XP）是轻量级方法中最引人注目的一个。XP基于沟通、简单、反馈、勇气四个核心价值提出了完整团队（WholeTeam）、计划博弈（PlanningGame）、隐喻（Metaphor）、小规模交付（Smallrelease）、单元测试（Unittest）、简单设计（SimpleDesign）、结对开发（PairProgramming）、重构（Refactoring）、持续集成（ContinuousIntegration）、代码集体所有制（Collective codeOwnership）、编码标准（CodingStandard）、可持续步调（SustainablePace）等十二个核心实践。XP是目前发展应用得最活跃的方法，适用于需求模糊和挥发性强的场合。从2000年起，关于XP研究的年会年年召开，对XP方法的过程、原则、适用性等各方面的讨论大大丰富了XP的方法和理论。Mark C.Paulk提出XP是CMM的一个截面，LaurieWilliams在结对编程方面进行了深入的研究，Roy W.Miller对XP实践进行了修订，提出XP的19个实践。
附录-SCRUM 1993年KenSchwaber和JeffSutherland提出SCRUM，是对迭代式面向对象方法的改进。SCRUM提出的SCRUMMeeting、Sprint等模式。SCRUM将工业过程控制中的概念应用到软件开发中来，认为软件开发过程更多是经验性过程（EmpiricalProcess），而不是规约性过程（DefinedProcess）。
附录-Crystal 1999年Alistair Cockburn提出CrystalMethodologies。与其它敏捷方法的提出者不同，Cockburn的研究基于对IBM公司近四十个项目案例的调查。他认为不同的项目需采用不同的开发方法，并随着开发，进行连续不断的过程改进。据此他提出了一系列方法（CrystalClear、CrystalYellow、CrystalOrange、CrystalRed等）。Crystal方法强调以人和沟通为中心，强调对方法的选择和调整要考虑两个因素，一是充分发挥考虑人的特长，二是满足待开发软件的可靠性要求。刚好够用的方法论成为Crystal的基本原则之一。相对于人和团队，过程是第二位的，因此，过程应该被最小化，即“刚好够用”。
附录-DSDM 1994年DynamicSystems Development Methodology（DSDM）由英国16家公司的联盟发起，应用范围也不再限于IT行业。DSDM的基本观点是，任何事情都不可能一次性的圆满完成，在时间进度和可用资源预先固定的情况下，力争需求的最大化满足，提出了时间框（TimeBox）技术、MoSCoW（MustdO，Shoulddo，CoulddO，Won&amp;rsquo;tdo）优先级排序、工作间（Workshop）等方法。
附录-FDD Feature DrivenDevelopment（FDD）是由PeterCoad、Jeff deLuca、EricLefebvre共同开发的一套针对中小型软件开发项目的开发模式。所谓的特征点（Feature）是一些用户认为有用的小功能项，一个特征点能在两周或更短的时间内被实施，且产生可见的、能运行的代码。FDD将开发过程分为五个过程，每个过程指南采用ETVX（EntryCriteria，入口准则；Task，任务；Verification，评审确认；eXitCriteria，出口准则）方法描述，并明确了哪些角色参与哪些子任务，哪些子任务是可选的、哪些是必须的。
附录-自适应软件开发 1994年J.Holland在圣达菲（SantaFe Institute，SFI）研究所正式提出了比较完整的复杂自适应系统（ComplexAdaptive System，CAS）理论，认为在一定环境中的主体相互竞争和合作，导致系统产生突变。JimHighsmith基于复杂自适应系统理论提出了自适应软件开发（AdaptiveSoftware Development，ASD），旨在通过提高组织的自适应力以应对极度变化、难以预测的快速软件开发要求。开发组织的首要目标是快速响应变化，即提高适应力，而适应力只能孕育，不能通过命令和控制来获得，ASD提出“领导—协作”模型来提高组织的自适应力。Highsmith提出了基于有机原则的模式概念以区别于机械的过程，认为过程的实现方式必须能让项目团队成为一个有机的活跃的生态系统。他给出了一种过程分类方案：严密过程、灵活过程、问题求解过程，并强调问题求解过程是软件开发的创新核心。</description></item><item><title>面向对象设计的SOLID原则和设计模式</title><link>https://mryqu.github.io/post/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E7%9A%84solid%E5%8E%9F%E5%88%99%E5%92%8C%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link><pubDate>Fri, 23 Nov 2007 13:43:37 +0000</pubDate><guid>https://mryqu.github.io/post/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E7%9A%84solid%E5%8E%9F%E5%88%99%E5%92%8C%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid><description>S.O.L.I.D S.O.L.I.D是面向对象设计和编程(OOD&amp;amp;OOP)中几个重要编码原则(ProgrammingPrinciple)的首字母缩写。
SRP :The Single Responsibility Principle单一责任原则 OCP :The Open Closed Principle 开放封闭原则 LSP :The Loskop Substitution Principle里氏替换原则 DIP :The Dependency Inversion Principle依赖倒置原则 ISP :The Interface Segregation Principle接口分离原则 单一责任原则： 当需要修改某个类的时候原因有且只有一个（THERE SHOULD NEVER BE MORE THAN ONE REASONFOR A CLASS TOCHANGE）。换句话说就是让一个类只做一种类型责任，当这个类需要承当其他类型的责任的时候，就需要分解这个类。 比如：报表的内容和报表的格式都会变化改变，但是这两种变化的性质不同，一个是实质内在，一个是表面上的，SRP认为这是问题的两个方面，其实代表不同的职责，应该将它们分离放入不同的类或模块中，而不应该放在一起，否则的话，因为不同原因发生变化，导致对方变动，比如报表格式变新的样式，这个变化是不应该涉及到内容的。 反模式: 一个类处理的事情太多了, 应当进行分解
开放封闭原则 软件实体应该是可扩展，而不可修改的。也就是说，对扩展是开放的，而对修改是封闭的。这个原则是诸多面向对象编程原则中最抽象、最难理解的一个。 反模式: 一个模块的修改将导致其他模块的修改
里氏替换原则 当一个子类的实例应该能够替换任何其超类的实例时，它们之间才具有is-A关系 子类可以代替基类, 客户使用基类, 他们不需要知道派生类所做的事情. 反模式: if(a instanceof TypeA) {&amp;hellip;} 这是一个针对行为职责可替代的原则，如果S是T的子类型，那么S对象就应该在不改变任何抽象属性情况下替换所有T对象。这里的抽象属性是指对象的字段属性。
我们使用接口时经常碰到一个问题，需要使用接口子类中的方法，而接口中没有这个方法，那么只能要么修改接口，要么将接口downcast为具体子类。为什么会出现这个尴尬现象？有几种情况导致，其中一种情况是是将当前的类重构到接口时，没有将类中所有方法extract到接口中，可能因为这些被你漏掉的方法不属于当前接口，那么，它又违背了单一职责原理，说明你当前这个类的方法设计得又不合理。
所以，如果单一职责设计的足够好，那么LSP原则则是检验的方法。LSP原则是对对象职责和协作的一种检验约束方法，此外还有DBC(designby contract)原则，为了保证实现接口的子类职责行为的约束，DBC三要素都必须被重视满足：
Preconditions前置条件不能在子类中被强化。 Postconditions后置条件不能在子类中被弱化。 子类自身不变性Invariants必须在子类自己中封装满足。这也是前面“不改变任何抽象属性”的意思。 依赖倒置原则 高层模块不应该依赖于低层模块，二者都应该依赖于抽象 抽象不应该依赖于细节，细节应该依赖于抽象 要针对接口编程，不针对实现编程。
接口分离原则 不能强迫用户去依赖那些他们不使用的接口。换句话说，使用多个专门的接口比使用单一的总接口总要好。 反模式：肥类(fat class), 有成堆的方法, 而且用户很少使用 SOLID原则如今在DCI架构中能够得到真正实现和发展。</description></item></channel></rss>