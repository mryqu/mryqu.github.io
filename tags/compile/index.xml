<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Compile on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/compile/</link>
    <description>Recent content in Compile on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 30 Jul 2015 05:35:26 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/compile/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Hive] Hive JDBC实践</title>
      <link>https://mryqu.github.io/post/hive_hive_jdbc%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 30 Jul 2015 05:35:26 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hive_hive_jdbc%E5%AE%9E%E8%B7%B5/</guid>
      <description>HiveJdbcClient.java 使用参考一中的示例代码:
import java.sql.SQLException; import java.sql.Connection; import java.sql.ResultSet; import java.sql.Statement; import java.sql.DriverManager; public class HiveJdbcClient { private static String driverName = &amp;quot;org.apache.hive.jdbc.HiveDriver&amp;quot;; public static void main(String[] args) throws SQLException { try { Class.forName(driverName); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); System.exit(1); } //&amp;quot;hadoop&amp;quot; is the name of the user the queries should run as in my cluster. Connection con = DriverManager.getConnection( &amp;quot;jdbc:hive2://localhost:10000/default&amp;quot;, &amp;quot;hadoop&amp;quot;, &amp;quot;{PASSWORD_OF_USER_HADOOP}&amp;quot;); Statement stmt = con.</description>
    </item>
    
    <item>
      <title>[Hadoop] Failed to exec (compile-ms-winutils) on project hadoop-common</title>
      <link>https://mryqu.github.io/post/hadoop_failed_to_exec_compile-ms-winutils_on_project_hadoop-common/</link>
      <pubDate>Tue, 15 Apr 2014 22:16:23 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_failed_to_exec_compile-ms-winutils_on_project_hadoop-common/</guid>
      <description>在Windows平台编译Hadoop时遇到了compile-ms-winutils执行失败的问题。Hadoop默认需要用VS2010编译，但是我的环境只有VS2013。
问题及解决方案如下： - Cannot run program &amp;ldquo;msbuild&amp;rdquo; 将C:\Windows\Microsoft.NET\Framework\v4.0.30319放入PATH环境变量 - Command execution failed. Process exited with an error: 1(Exitvalue: 1) -&amp;gt; [Help 1] 打开hadoop-common\hadoop-hdfs-project\hadoop-hdfs\pom.xml，将&amp;rsquo;VisualStudio 10 Win64&amp;rsquo;改成&amp;rsquo;Visual Studio 12 Win64&amp;rsquo;。 将如下两个Visual Studio项目用VS2013打开，手动编译。 - hadoop-common\hadoop-common-project\hadoop-common\src\main\winutils\winutils.sln - hadoop-common\hadoop-common-project\hadoop-common\src\main\native\winutils.sln
重新执行：
C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\Tools\VsDevCmd.bat mvn install -DskipTests  上述问题不再出现。</description>
    </item>
    
    <item>
      <title>[C] GCC对UTF8 BOM的支持</title>
      <link>https://mryqu.github.io/post/c_gcc%E5%AF%B9utf8_bom%E7%9A%84%E6%94%AF%E6%8C%81/</link>
      <pubDate>Thu, 24 Oct 2013 20:31:28 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/c_gcc%E5%AF%B9utf8_bom%E7%9A%84%E6%94%AF%E6%8C%81/</guid>
      <description>最近玩些特俗字符，结果对yqutest.cpp源码文件编译时先碰到error:converting to execution character set: Illegal bytesequence错误。GCC的源码字符集与执行字符集默认是UTF-8编码，为了避免源码文件乱码，最好也是采用UTF-8编码来存储源码文件。将源码编码转成UTF-8，问题得以解决。 但是否需要UTF-8 BOM(byte-order mark)呢？ 我一时兴起添加了BOM，十六进制为EF BB BF，即对应八进制的357 273 277，编译结果如下：
mryqu&amp;gt; g++ yqutest.cpp -o yqutst123 yqutest.cpp:1: error: stray &#39;\357&#39; in program yqutest.cpp:1: error: stray &#39;\273&#39; in program yqutest.cpp:1: error: stray &#39;\277&#39; in program yqutest.cpp:1: error: stray &#39;#&#39; in program yqutest.cpp:1: error: expected constructor, destructor, or type conversion before &#39;&amp;lt;&#39; token mryqu&amp;gt; g++ -v Using built-in specs. Target: amd64-undermydesk-freebsd Configured with: FreeBSD/amd64 system compiler Thread model: posix gcc version 4.</description>
    </item>
    
  </channel>
</rss>