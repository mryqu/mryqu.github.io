<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sql on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/sql/</link>
    <description>Recent content in Sql on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 10 Jul 2018 05:50:35 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/sql/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Zeppelin] 尝试Zeppelin</title>
      <link>https://mryqu.github.io/post/zeppelin_%E5%B0%9D%E8%AF%95zeppelin/</link>
      <pubDate>Tue, 10 Jul 2018 05:50:35 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/zeppelin_%E5%B0%9D%E8%AF%95zeppelin/</guid>
      <description>Zeppelin简介 Apache Zeppelin是一个让交互式数据分析变得可行的基于网页的开源框架。Zeppelin提供了数据捏取、发现、分析、可视化与协作等功能。 Zeppelin 是一个提供交互数据分析且基于Web的笔记本。方便你做出可数据驱动的、可交互且可协作的精美文档，并且支持多种语言，包括 Scala(使用 Apache Spark)、Python(Apache Spark)、SparkSQL、 Hive、 Markdown、Shell等等。
试验环境搭建 跟之前的博文[Spark] 使用Spark2.30读写Hive2.3.3一样，本文的环境继续使用GitHub: martinprobson/vagrant-hadoop-hive-spark通过Vagrant搭建了一个Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0的虚拟机环境。不过当前scripts/common.sh中ZEPPELIN_VERSION=0.7.2，而Zeppelin 0.7.2已不可访问，需要改成最新版0.8.0。 按照GitHub: martinprobson/vagrant-hadoop-hive-spark说明执行zeppelin-daemon.sh start，结果说权限不足，因此我只好兜一圈开启Zeppelin守护进程。
vagrant@node1:~$ zeppelin-daemon.sh start find: File system loop detected; ‘/home/ubuntu/zeppelin/zeppelin-0.8.0-bin-netinst’ is part of the same file system loop as ‘/home/ubuntu/zeppelin’. Pid dir doesn&#39;t exist, create /home/ubuntu/zeppelin/run mkdir: cannot create directory ‘/home/ubuntu/zeppelin/run’: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.sh: line 187: /home/ubuntu/zeppelin/logs/zeppelin-vagrant-node1.out: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.sh: line 189: /home/ubuntu/zeppelin/logs/zeppelin-vagrant-node1.out: Permission denied /home/ubuntu/zeppelin/bin/zeppelin-daemon.</description>
    </item>
    
    <item>
      <title>[Spark] 使用Spark2.30读写MySQL</title>
      <link>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99mysql/</link>
      <pubDate>Wed, 04 Jul 2018 06:36:25 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99mysql/</guid>
      <description>本博文是[Spark] 使用Spark2.30读写Hive2.3.3的姊妹篇，环境及Java项目也是使用上一博文中的。
Spark项目 目录结构 vagrant@node1:~/HelloSparkHive$ ls build build.gradle src vagrant@node1:~/HelloSparkHive$ rm -rf build vagrant@node1:~/HelloSparkHive$ tree . ├── build.gradle └── src └── main └── java └── com └── yqu └── sparkhive ├── HelloSparkHiveDriver.java └── HelloSparkMysqlDriver.java 6 directories, 3 files  src/main/java/com/yqu/sparkhive/HelloSparkMysqlDriver.java 该范例加载Hive中的emp表，存储到MySQL的test数据库中，然后读取MySQL数据库加载emp表，由此完成MySQL读写示例。
package com.yqu.sparkhive; import org.apache.spark.sql.Dataset; import org.apache.spark.sql.Row; import org.apache.spark.sql.SparkSession; import java.io.File; import java.sql.*; public class HelloSparkMysqlDriver { private static boolean setup() { Connection conn = null; Statement stmt = null; try { Class.</description>
    </item>
    
    <item>
      <title>[Spark] 使用Spark2.30读写Hive2.3.3</title>
      <link>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99hive2.3.3/</link>
      <pubDate>Tue, 03 Jul 2018 06:04:31 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/spark_%E4%BD%BF%E7%94%A8spark2.30%E8%AF%BB%E5%86%99hive2.3.3/</guid>
      <description>试验环境搭建 安装Spark环境 犯懒，直接使用GitHub: martinprobson/vagrant-hadoop-hive-spark通过Vagrant搭建了一个Hadoop 2.7.6 + Hive 2.3.3 + Spark 2.3.0的虚拟机环境。
在Hive上加载emp表 hive&amp;gt; create table emp (empno int, ename string, job string, mgr int, hiredate string, salary double, comm double, deptno int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;|&#39; ; hive&amp;gt; LOAD DATA LOCAL INPATH &#39;/usr/local/hive/examples/files/emp2.txt&#39; OVERWRITE INTO TABLE emp;  安装Gradle 按照Gradle用户手册中的方式手工安装Gradle：
vagrant@node1:~$ export GRADLE_HOME=/opt/gradle/gradle-4.8.1 vagrant@node1:~$ export PATH=$PATH:$GRADLE_HOME/bin vagrant@node1:~$ gradle -v Welcome to Gradle 4.8.1! Here are the highlights of this release: - Dependency locking - Maven Publish and Ivy Publish plugins improved and marked stable - Incremental annotation processing enhancements - APIs to configure tasks at creation time For more details see https://docs.</description>
    </item>
    
    <item>
      <title>[MySQL] 将空返回值转换成NULL</title>
      <link>https://mryqu.github.io/post/mysql_%E5%B0%86%E7%A9%BA%E8%BF%94%E5%9B%9E%E5%80%BC%E8%BD%AC%E6%8D%A2%E6%88%90null/</link>
      <pubDate>Sat, 01 Apr 2017 06:17:43 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/mysql_%E5%B0%86%E7%A9%BA%E8%BF%94%E5%9B%9E%E5%80%BC%E8%BD%AC%E6%8D%A2%E6%88%90null/</guid>
      <description>当MySQL没有搜索到任何匹配行时，会返回空返回值，如何转换成NULL呢？
方法一 select (original_select_statement) as Alias  这种方法仅对一个单值有效，即： * 原语句返回单值，该值将被返回 * 原语句返回单列零行，将返回NULL * 原语句返回多列或多行，查询失败
方法二 使用IFNULL或COALESCE函数。</description>
    </item>
    
    <item>
      <title>SQL中的（稀疏）矩阵运算</title>
      <link>https://mryqu.github.io/post/sql%E4%B8%AD%E7%9A%84%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</link>
      <pubDate>Mon, 07 Jul 2014 21:16:01 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/sql%E4%B8%AD%E7%9A%84%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</guid>
      <description>前两天在一门课上看到SQL中（稀疏）矩阵的乘法，找到两篇相关帖子，介绍了SQL中的（稀疏）矩阵运算，包含矩阵相等判别、加法、乘法、转置。
Matrix Math in SQLMAD skills: new analysis practices for big data</description>
    </item>
    
  </channel>
</rss>