<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yarn on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/yarn/</link>
    <description>Recent content in Yarn on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 13 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/yarn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>折腾openui5-sample-app之使用Yarn替换Bower</title>
      <link>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8yarn%E6%9B%BF%E6%8D%A2bower/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/node_%E6%8A%98%E8%85%BEopenui5-sample-app%E4%B9%8B%E4%BD%BF%E7%94%A8yarn%E6%9B%BF%E6%8D%A2bower/</guid>
      <description>SAP/openui5-sample-app是使用npm下载依赖的后端开发和构建模块，使用bower下载依赖的前端openui5库。 在npm install的过程中提示&amp;rdquo;npm WARN deprecated bower@1.8.4: We don&amp;rsquo;t recommend using Bower for new projects. Please consider Yarn and Webpack or Parcel. You can read how to migrate legacy project here: https://bower.io/blog/2017/how-to-migrate-away-from-bower/&amp;quot;。 对于SAP这个小示例，区分前端和后端使用包管理器有点浪费！对于所有的依赖模块，可以要么使用npm，要么使用yarn。
 删除bower_components和dist目录
 安装yarn：
npm install yarn -g  去掉bower.json 不过其中依赖的openui5/packaged-sap.ui.core、openui5/packaged-sap.m、openui5/packaged-themelib_sap_belize仅仅bower能够获取，在npm仓库里是找不到的。
 修改package.json
 去除bower模块
 去除postinstall脚本
 增加@openui5/sap.m依赖
 增加@openui5/sap.ui.core依赖
 增加@openui5/themelib_sap_belize依赖  修改Gruntfile.js npm仓库里的@openui5/sap.m、@openui5/sap.ui.core、@openui5/themelib_sap_belize仅包含openui5/packaged-sap.ui.core、openui5/packaged-sap.m、openui5/packaged-themelib_sap_belize中resources的部分，而不包含test-resources的部分。 对于openui5_connect任务，我认为无需test-resources部分即可。
 将openui5库的定位从bower_components目录下改为node_modules目录下的相应位置  构建测试
yarn grunt build grunt serve   参考 SAP/grunt-openui5</description>
    </item>
    
    <item>
      <title>[Spark] Set spark.yarn.archive</title>
      <link>https://mryqu.github.io/post/spark_set_spark.yarn.archive/</link>
      <pubDate>Mon, 01 Aug 2016 05:30:15 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/spark_set_spark.yarn.archive/</guid>
      <description>提交Spark作业时，遇到没有设置spark.yarn.jars和spark.yarn.archive的告警：
16/08/01 05:01:19 INFO yarn.Client: Preparing resources for our AM container 16/08/01 05:01:20 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME. 16/08/01 05:01:23 INFO yarn.Client: Uploading resource file:/tmp/spark-AA-BB-CC-DD-EE/__spark_libs__XXX.zip -&amp;gt; hdfs://node50064.mryqu.com:9000/user/hadoop/.sparkStaging/application_1469998883123_0001/__spark_libs__XXX.zip  解决方案：
cd $SPARK_HOME zip spark-archive.zip jars/* hadoop fs -copyFromLocal spark-archive.zip echo &amp;quot;spark.yarn.archive=hdfs:///node50064.mryqu.com:9000/user/hadoop/spark-archive.zip&amp;quot; &amp;gt;&amp;gt; conf/spark-defaults.conf  如系统没有安装zip，可执行sudoapt-get install zip进行安装。 这样就不用每次上传Spark的jar文件到HDFS，YARN会找到Spark的库以用于运行作业。</description>
    </item>
    
    <item>
      <title>[Spark]Spark2集群安装实践</title>
      <link>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 28 Jul 2016 05:47:45 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</guid>
      <description>从Spark2.0.0开始，Spark使用Scala2.11构建，不再对Java7和Python2.6进行支持。当然不编译Spark源码的话，无需安装Scala。
Spark集群模型 Spark应用作为集群上一组独立进程运行，由你的主程序（即驱动程序）的SparkContext对象管理。为了在集群上运行，SparkContext可以与若干类型集群管理器（Spark自带的独立集群管理器、Mesos、YARN）连接，集群管理器为应用分配资源。Spark需要集群节点上的执行者（executor）为应用执行计算或存储数据。接下来，它将应用代码发送给执行者，最后SparkContext将人物发往执行者进行运行。准备工作 安装Scala # Scala Installation wget www.scala-lang.org/files/archive/scala-2.11.8.deb sudo dpkg -i scala-2.11.8.deb # sbt Installation echo &amp;quot;deb https://dl.bintray.com/sbt/debian /&amp;quot; | sudo tee -a /etc/apt/sources.list.d/sbt.list sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823 sudo apt-get update sudo apt-get install sbt  安装Java8 sudo apt-add-repository ppa:webupd8team/java -y sudo apt-get update -y sudo apt-get install oracle-java8-installer -y sudo apt-get install oracle-java8-set-default  环境变量设置 在~/.bashrc中添加：
# Set SPARK_HOME export SPARK_HOME=/usr/local/spark export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin  最后通过source~/.</description>
    </item>
    
    <item>
      <title>[Hadoop] YARN DistributedShell实践</title>
      <link>https://mryqu.github.io/post/hadoop_yarn_distributedshell%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 31 Jan 2016 06:20:46 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_yarn_distributedshell%E5%AE%9E%E8%B7%B5/</guid>
      <description>YARN DistributedShell介绍 Hadoop2的源代码中实现了两个基于YARN的应用，一个是MapReduce，另一个是非常简单的应用程序编程实例——DistributedShell。DistributedShell是一个构建在YARN之上的non-MapReduce应用示例。它的主要功能是在Hadoop集群中的多个节点，并行执行用户提供的shell命令或shell脚本（将用户提交的一串shell命令或者一个shell脚本，由ApplicationMaster控制，分配到不同的container中执行)。
YARN DistributedShell测试 执行下列命令进行测试：
hadoop jar /usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.X.jar -shell_command /bin/ls -shell_args /home/hadoop -jar /usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.X.jar  客户端日志显示执行成功：参考 如何运行YARN中的DistributedShell程序
YARN DistributedShell源码分析与修改
YARN Distributedshell解析</description>
    </item>
    
    <item>
      <title>[Hadoop] YARN中Application Manager和Application Master区别</title>
      <link>https://mryqu.github.io/post/hadoop_yarn%E4%B8%ADapplication_manager%E5%92%8Capplication_master%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Sat, 28 Nov 2015 05:56:33 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_yarn%E4%B8%ADapplication_manager%E5%92%8Capplication_master%E5%8C%BA%E5%88%AB/</guid>
      <description>术语Application Master和Application Manager经常被交换使用。其实，ApplicationMaster是一个主要的容器，用于请求、启动和监控应用特定资源；而ApplicationManager是资源管理器中的一个部件。 一个作业在YARN中启动流程如下： - 首先客户端向YARN资源管理器提交应用，包括请求容器启动上下文所需的信息。 - 接着资源管理器中的应用管理器协商好一个容器，为应用引导一个Application Master实例。 - 之后Application Master向资源管理器注册并请求容器。 - 当ApplicationMaster同节点管理器进行通信启动所授予的容器之后，为每个容器指定容器启动上下文描述（CLC，包括执行启动的命令、安全令牌、依赖[可执行文件、压缩包]、环境变量等等）。 - Application Master管理应用执行。在执行期间，应用向ApplicationMaster提供进度和状态信息。客户端通过查询资源管理器或直接与ApplicationMaster联系，可以监控应用的状态。 - Application Master向资源管理器报告应用结束。
应用管理器负责维护一系列已提交的应用。当应用提交后，它首先验证应用规格，为ApplicationMaster拒绝任何请求无法满足资源的应用（例如，集群中没有节点有足够资源运行ApplicationMaster自身）。之后确保没有已经运行的使用相同应用ID的其他应用，错误的客户端或恶意客户端有可能导致此类问题。最后，将提交的应用转给调度器。已结束应用从资源管理器内存完全清除之前，此部件也负责记录和管理这些已结束应用。当应用结束，它将应用汇总信息放在守护进程的日志文件。最后，应用管理器在应用完成用户请求后很久都会在缓存中保留该已结束应用。配置参数yarn.resourcemanager.max-completed-applications控制资源管理器在任意时刻可以记住的已结束应用的最大数量。该缓存是先入先出队列，为了存放最新的已结束应用，最老的应用将被移出。 参考 Difference between Application Manager and Application Master in YARN?
Application Master 启动流程与服务简介</description>
    </item>
    
    <item>
      <title>[Hadoop] 安装Hadoop 2.7.x 集群</title>
      <link>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 28 Apr 2015 23:37:27 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</guid>
      <description>集群规划 |节点|角色 |&amp;mdash;&amp;ndash; |node50064|NameNode RessourceManager |node50069|Datanode SecondNameNode |node51054|Datanade
准备工作 （在全部机器上）创建hadoop用户 $ sudo useradd -m hadoop -s /bin/bash $ sudo passwd hadoop $ sudo adduser hadoop sudo  （在全部机器上）配置/etc/hosts 10.120.12.135 node50064.mryqu.com node50064 10.120.11.201 node50069.mryqu.com node50069 10.120.14.226 node51054.mryqu.com node51054  （在全部机器上）禁止掉IPv6 参见之前的博文在Ubuntu中禁掉IPv6。
（在全部机器上）关闭防火墙 ufw disable //关闭 sudo apt-get remove ufw //卸载 sudo ufw status //查看  （在全部机器上）安装并配置Java JDK 安装Java JDK：
$ sudo apt-get update $ sudo apt-get install openjdk-7-jre openjdk-7-jdk  通过下列命令确定JDK安装路径为/usr/lib/jvm/java-7-openjdk-amd64： 通过sudovi /etc/profile添加如下内容：</description>
    </item>
    
    <item>
      <title>[Hadoop] YARN中的AuxiliaryService</title>
      <link>https://mryqu.github.io/post/hadoop_yarn%E4%B8%AD%E7%9A%84auxiliaryservice/</link>
      <pubDate>Sun, 01 Feb 2015 12:39:55 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_yarn%E4%B8%AD%E7%9A%84auxiliaryservice/</guid>
      <description>一个附属服务（AuxiliaryService）是由YARN中节点管理器（NM）启动的通用服务。该服务由YARN配置&amp;ldquo;yarn.nodemanager.aux-services&amp;rdquo;定义。默认值为mapreduce_shuffle，即MRv2中的ShuffleHandler。 AuxiliaryService是节点管理器内的服务，接收应用/容器初始化和停止事件并作相应处理。 MRv2提供了一个叫做org.apache.hadoop.mapred.ShuffleHandler的内建AuxiliaryService，用于将节点内map输出文件提供给reducer(上图中除ShuffleHandler之外的其他AuxiliaryService子类均为测试类)。 节点管理器可能有多个AuxiliaryService，类AuxServices用于处理此类服务集合。 当AuxServices对象启动，它从YarnConfiguration.NM_AUX_SERVICES（即&amp;rdquo;yarn.nodemanager.aux-services&amp;rdquo;）获得附属服务名，从YarnConfiguration.NM_AUX_SERVICE_FMT（即&amp;rdquo;yarn.nodemanager.aux-services.%s.class&amp;rdquo;）获得对应的服务类名。例如&amp;rdquo;yarn.nodemanager.aux-services.mapreduce_shuffle.class&amp;rdquo;对应ShuffleHandler类。之后它将服务置入serviceMap并调用init()方法对服务进行初始化。 Hadoop实现是一个事件驱动系统。AuxServices既是ServiceStateChangeListener也是EventHandler，用于处理AuxServicesEventType事件。
public enum AuxServicesEventType { APPLICATION_INIT, APPLICATION_STOP, CONTAINER_INIT, CONTAINER_STOP } public class AuxServicesEvent extends AbstractEvent { private final String user; private final String serviceId; private final ByteBuffer serviceData; private final ApplicationId appId; private final Container container; } public abstract class AbstractEvent&amp;gt; implements Event { private final TYPE type; private final long timestamp; }  在handle(AuxServicesEventevent)方法中，每个事件与AuxiliaryService中的一个API调用相关连。例如，只要AuxServices收到一个APPLICATION_INIT事件，对应AuxiliaryService的initializeApplication()方法就会被调用。 那一个事件如何被传递给AuxServices的？ NodeManager类包含一个ContainerManagerImpl对象变量，而ContainerManagerImpl类包含一个AuxServices对象变量。此外ContainerManagerImpl类有自己的AsyncDispatcher,它会向AuxServices分发所有AuxServicesEventType类型事件。 AuxServicesEventType.APPLICATION_STOP事件在ApplicationImpl类中被创建，节点管理器中应用表述的状态机触发。 其他三个的AuxServicesEventType事件，例如APPLICATION_INIT、CONTAINER_INIT和CONTAINER_STOP，在ContainerImpl类中随着容器的生命周期被创建。
参考 AuxiliaryService in Hadoop 2</description>
    </item>
    
    <item>
      <title>[Hadoop] hadoop job -list已废弃</title>
      <link>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</link>
      <pubDate>Sun, 20 Oct 2013 22:04:34 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</guid>
      <description>执行hadoop job -list，显示该命令已废弃，不过还能执行成功。
~$ hadoop job -list DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it.  看一下Hadoop 2.2.0的代码hadoop-common-project/hadoop-common/src/main/bin/hadoop：
#hdfs commands namenode|secondarynamenode|datanode|dfs|dfsadmin|fsck|balancer|fetchdt|oiv|dfsgroups|portmap|nfs3) echo &amp;quot;DEPRECATED: Use of this script to execute hdfs command is deprecated.&amp;quot; 1&amp;gt;&amp;amp;2 echo &amp;quot;Instead use the hdfs command for it.&amp;quot; 1&amp;gt;&amp;amp;2 echo &amp;quot;&amp;quot; 1&amp;gt;&amp;amp;2 #try to locate hdfs and if present, delegate to it. shift if [ -f &amp;quot;${HADOOP_HDFS_HOME}&amp;quot;/bin/hdfs ]; then exec &amp;quot;${HADOOP_HDFS_HOME}&amp;quot;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;quot;$@&amp;quot; elif [ -f &amp;quot;${HADOOP_PREFIX}&amp;quot;/bin/hdfs ]; then exec &amp;quot;${HADOOP_PREFIX}&amp;quot;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;quot;$@&amp;quot; else echo &amp;quot;HADOOP_HDFS_HOME not found!</description>
    </item>
    
  </channel>
</rss>