<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>下载 on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/%E4%B8%8B%E8%BD%BD/</link>
    <description>Recent content in 下载 on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 04 May 2014 22:03:49 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/%E4%B8%8B%E8%BD%BD/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>网络资源(主力书籍)</title>
      <link>https://mryqu.github.io/post/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E4%B8%BB%E5%8A%9B%E4%B9%A6%E7%B1%8D/</link>
      <pubDate>Sun, 04 May 2014 22:03:49 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90%E4%B8%BB%E5%8A%9B%E4%B9%A6%E7%B1%8D/</guid>
      <description> 外文书籍  Library Genesis
 BookZZ
 爱挖盘
 manybooks
 14个值得收藏可免费搜索/下载PDF电子图书（文档）的搜索引擎
  图书馆  全球免费开放的电子图书馆
  古籍  书格
  专利  史上最完整的专利信息数据库网址大全
  杂志  http://pdfmagazines.org/
 http://www.gqzzw.com/
 http://www.pdfzj.com/
 http://pdf-giant.com/
 http://www.magazine6.com/
  </description>
    </item>
    
    <item>
      <title>Wget笔记</title>
      <link>https://mryqu.github.io/post/wget%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 01 Dec 2013 08:35:14 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/wget%E7%AC%94%E8%AE%B0/</guid>
      <description>介绍 GNU Wget是一个命令行的下载工具，支持HTTP、HTTPS、FTP协议，支持断点续传。在宽带状态不佳的情况下，Wget能表现出很强的稳定性。
常用命令速查表 |操作|命令 |&amp;mdash;&amp;ndash; |下载文件|wget URL |恢复下载|wget -c URL |递归下载|以最大深度10级递归下载某链接：wget -r -l 10 URL |下载整个网站|wget -m URL-m等同于-r -N -l inf &amp;ndash;no-remove-listing |下载某个页面特定类型文件|仅下载pdf和mp3文件：wget -A &amp;ldquo;.pdf,.mp3&amp;rdquo; -r -l 1 -nd –np URL |下载某个页面特定类型之外的其他文件|下载pdf以外的文件：wget -R.pdf -r -l 1 -nd –np URL |忽略 robots.txt|wget -e robots=off URL |限制下载速率|wget –-limit-rate=20 URL |模拟firefox下载|wget -U Mozilla URL |不下载仅检查链接是否存在|wget &amp;ndash;spider &amp;ndash;force-html -i bookmarks.html |将输出写入文件|wget -O filepath URL |下载FTP文件|wget &amp;ndash;ftp-­use­r=yqu&amp;ndash;ftp-­pas­swo­rd=yqu URL |下载多个连接|wget URL1 URL2 URL3 |配置接收数据的限额大小|对单文件下载无效，对递归下载或从输入文件获取连接下载有效wget -Q2m -i URL当下载量超过限额后下载中断</description>
    </item>
    
  </channel>
</rss>