<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>classification on Mryqu's Notes</title><link>https://mryqu.github.io/tags/classification/</link><description>Recent content in classification on Mryqu's Notes</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 16 Jun 2013 22:44:54 +0000</lastBuildDate><atom:link href="https://mryqu.github.io/tags/classification/index.xml" rel="self" type="application/rss+xml"/><item><title>模型评估笔记</title><link>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 16 Jun 2013 22:44:54 +0000</pubDate><guid>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</guid><description>模型评估简介 模型评估是模型开发过程的不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。在数据挖掘中，使用训练集中的数据评估模型性能是不可接受的，因为这易于生成过于乐观和过拟合的模型。数据挖掘中有两种方法评估模型，验证（Hold-Out）和交叉验证（Cross-Validation）。为了避免过拟合，这两种方法都使用（模型没有遇到过的）测试集来评估模型性能。
验证（Hold-Out） 使用这种方法时，通常大的数据集会被_随机_分成三个子集：
训练集：用于构建预测模型。 验证集：用于评估训练阶段所得模型的性能。它为模型参数优化和选择最优模型提供了测试平台。不是所有模型算法都需要验证机。 测试集或之前未遇到的样本用于评估模型未来可能的性能。如果模型与训练集拟合的好于测试集，有可能是过拟合所致。 交叉验证（Cross-Validation） 当仅有有限数量的数据时，为了对模型性能进行无偏估计，我们可以使用_k_折交叉验证（k-foldcross-validation）。使用这种方法时，数据被分成_k_份数目相等的子集。我们构建_k_次模型，每次留一个子集做测试集，其他用作训练集。如果_k_等于样本大小，这也被称之为留一验证（leave-one-out）。
分类模型评估 混淆矩阵（Confusion Matrix） 混淆矩阵显示了分类模型相对数据的真实输出（目标值）的正确预测和不正确预测数目。矩阵为_N_x_N_，其中_N_为目标值（类）数目。这类模型的性能通常使用矩阵中的数据评估。下表为两个类别（阳性和阴性）的2x2混淆矩阵。
混淆矩阵目标&amp;nbsp;阳性阴性模型阳性TPFP阳性预测值
TP/(TP+FP)阴性FNTN阴性预测值
TN/(FN+TN)&amp;nbsp;灵敏度特异度准确度&amp;nbsp;=(TP+TN)/(TP+FP+FN+TN)
TP/(TP+FN)TN/(FP+TN) 术语：
阳性 (P, positive) 阴性 (N, Negative) 真阳性 (TP, true positive)：正确的肯定。又称：命中 (hit) 真阴性 (TN, true negative)：正确的否定。又称：正确拒绝 (correctrejection) 伪阳性 (FP, false positive)：错误的肯定，又称：假警报 (falsealarm)、第二型错误 伪阴性 (FN, false negative)：错误的否定，又称：未命中(miss)、第一型错误 灵敏度(sensitivity)或真阳性率(TPR, true positive rate)：又称：召回率（recall）、命中率 (hit rate)在阳性值中实际被预测正确所占的比例。TPR = TP / P = TP / (TP+FN) 伪阳性率(FPR, false positive rate)：又称：错误命中率，假警报率 (false alarm rate)FPR = FP / N = FP / (FP + TN) = 1-SPC 特异度 (SPC, Specificity)或真阴性率(TNR, true negativerate)：在阴性值中实现被预测正确所占的比例。SPC = TN / N = TN / (FP+TN) = 1-FPR 假发现率 (FDR, false discovery rate)：FDR = FP / (FP + TP) = 1-TPR 准确度 (ACC, accuracy）：预测正确的数占样本数的比例。ACC = (TP + TN) / (P + N) 阳性预测值 (PPV, positive predictive value)或精度(precision)：阳性预测值被预测正确的比例。PPV = TP / (TP + FP) 阴性预测值 (NPV, negative predictive value)：阴性预测值被预测正确的比例。NPV = TN / (TN + FN) F1评分：精度和灵敏度的调和平均数。F1 = 2 precision * recall / (precision+recall) =2TP/(2TP+FP+FN) Matthews相关系数 (MCC)，即 Phi相关系数：(TPTN - FPFN)/ sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)} 示例:</description></item></channel></rss>