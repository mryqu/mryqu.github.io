<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cluster on Mryqu's Notes</title><link>https://mryqu.github.io/tags/cluster/</link><description>Recent content in cluster on Mryqu's Notes</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 28 Jul 2016 05:47:45 +0000</lastBuildDate><atom:link href="https://mryqu.github.io/tags/cluster/index.xml" rel="self" type="application/rss+xml"/><item><title>[Spark]Spark2集群安装实践</title><link>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 28 Jul 2016 05:47:45 +0000</pubDate><guid>https://mryqu.github.io/post/spark_spark2%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%AE%9E%E8%B7%B5/</guid><description>从Spark2.0.0开始，Spark使用Scala2.11构建，不再对Java7和Python2.6进行支持。当然不编译Spark源码的话，无需安装Scala。
Spark集群模型 Spark应用作为集群上一组独立进程运行，由你的主程序（即驱动程序）的SparkContext对象管理。为了在集群上运行，SparkContext可以与若干类型集群管理器（Spark自带的独立集群管理器、Mesos、YARN）连接，集群管理器为应用分配资源。Spark需要集群节点上的执行者（executor）为应用执行计算或存储数据。接下来，它将应用代码发送给执行者，最后SparkContext将人物发往执行者进行运行。
准备工作 安装Scala # Scala Installation wget www.scala-lang.org/files/archive/scala-2.11.8.deb sudo dpkg -i scala-2.11.8.deb # sbt Installation echo &amp;#34;deb https://dl.bintray.com/sbt/debian /&amp;#34; | sudo tee -a /etc/apt/sources.list.d/sbt.list sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823 sudo apt-get update sudo apt-get install sbt 安装Java8 sudo apt-add-repository ppa:webupd8team/java -y sudo apt-get update -y sudo apt-get install oracle-java8-installer -y sudo apt-get install oracle-java8-set-default 环境变量设置 在~/.bashrc中添加：
# Set SPARK_HOME export SPARK_HOME=/usr/local/spark export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin 最后通过source~/.bashrc刷新配置文件。
安装Spark （在node50064上）下载并配置Spark wget http://d3kbcqa49mib13.</description></item><item><title>[Hadoop] 安装Hadoop 2.7.x 集群</title><link>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</link><pubDate>Tue, 28 Apr 2015 23:37:27 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_%E5%AE%89%E8%A3%85hadoop_2.7.x_%E9%9B%86%E7%BE%A4/</guid><description>集群规划 |节点|角色 |&amp;mdash;&amp;ndash; |node50064|NameNode RessourceManager |node50069|Datanode SecondNameNode |node51054|Datanade
准备工作 （在全部机器上）创建hadoop用户 $ sudo useradd -m hadoop -s /bin/bash $ sudo passwd hadoop $ sudo adduser hadoop sudo （在全部机器上）配置/etc/hosts 10.120.12.135 node50064.mryqu.com node50064 10.120.11.201 node50069.mryqu.com node50069 10.120.14.226 node51054.mryqu.com node51054 （在全部机器上）禁止掉IPv6 参见之前的博文在Ubuntu中禁掉IPv6。
（在全部机器上）关闭防火墙 ufw disable //关闭 sudo apt-get remove ufw //卸载 sudo ufw status //查看 （在全部机器上）安装并配置Java JDK 安装Java JDK：
$ sudo apt-get update $ sudo apt-get install openjdk-7-jre openjdk-7-jdk 通过下列命令确定JDK安装路径为/usr/lib/jvm/java-7-openjdk-amd64： 通过sudovi /etc/profile添加如下内容：
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64 export CLASSPATH=.</description></item></channel></rss>