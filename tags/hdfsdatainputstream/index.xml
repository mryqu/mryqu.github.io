<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hdfsdatainputstream on Mryqu's Notes</title><link>https://mryqu.github.io/tags/hdfsdatainputstream/</link><description>Recent content in hdfsdatainputstream on Mryqu's Notes</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Fri, 01 May 2015 01:15:35 +0000</lastBuildDate><atom:link href="https://mryqu.github.io/tags/hdfsdatainputstream/index.xml" rel="self" type="application/rss+xml"/><item><title>[Hadoop] check FSDataInputStream and its wrapped InputStream implementation</title><link>https://mryqu.github.io/post/hadoop_check_fsdatainputstream_and_its_wrapped_inputstream_implementation/</link><pubDate>Fri, 01 May 2015 01:15:35 +0000</pubDate><guid>https://mryqu.github.io/post/hadoop_check_fsdatainputstream_and_its_wrapped_inputstream_implementation/</guid><description>打开一个HDFS文件，获得一个FSDataInputStream对象，其实现类到底是什么？小小探究一下。
package com.yqu.hadoop; import java.io.IOException; import java.io.InputStream; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FSDataInputStream; import org.apache.hadoop.fs.FileSystem; import org.apache.hadoop.fs.Path; public class LearnFS { public static void main(String[] args) { Configuration config = new Configuration(); FSDataInputStream in = null; Path path = new Path(&amp;#34;/user/hadoop/input/access_log.txt&amp;#34;); try { FileSystem fs = FileSystem.get(config); System.out.println(&amp;#34;Scheme: &amp;#34; + fs.getScheme()); System.out.println(&amp;#34;Uri: &amp;#34; + fs.getUri().toString()); in = fs.open(path); if (in != null) { System.out.println(&amp;#34;FSDataInputStream impl:&amp;#34; + in.getClass().getCanonicalName()); InputStream is = in.getWrappedStream(); if (is !</description></item></channel></rss>