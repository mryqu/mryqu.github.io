<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datascience on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/categories/datascience/</link>
    <description>Recent content in Datascience on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 29 Aug 2016 06:09:47 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/categories/datascience/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>在Coursera上选了几门Tableau课程</title>
      <link>https://mryqu.github.io/post/%E5%9C%A8coursera%E4%B8%8A%E9%80%89%E4%BA%86%E5%87%A0%E9%97%A8tableau%E8%AF%BE%E7%A8%8B/</link>
      <pubDate>Mon, 29 Aug 2016 06:09:47 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E5%9C%A8coursera%E4%B8%8A%E9%80%89%E4%BA%86%E5%87%A0%E9%97%A8tableau%E8%AF%BE%E7%A8%8B/</guid>
      <description>今天在赤兔数据挖掘群里看到有人说Coursera上有Tableau课程，有机会学习一下我司竞争对手的课程，也是不错的。
有五门课程属于加州大学的使用Tableau可视化商业数据专业课系列： - Fundamentals of Visualization with Tableau - Essential Design Principles for Tableau - Explaining Your Data Using Tableau - Creating Dashboards and Storytelling with Tableau - Data Visualization with Tableau Project
有一门课程属于杜克大学的Excel到MySQL: 用于商业的分析技术专业课系列： - Data Visualization and Communication with Tableau
当然现在这些课只能听一听，不掏钱是没有分数的</description>
    </item>
    
    <item>
      <title>八卦一下H2O</title>
      <link>https://mryqu.github.io/post/%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bh2o/</link>
      <pubDate>Tue, 27 Oct 2015 06:05:39 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E5%85%AB%E5%8D%A6%E4%B8%80%E4%B8%8Bh2o/</guid>
      <description>H2O的对象是需要可伸缩的快速机器学习的数据科学家和业务分析师。H2O是开源预测性分析平台。H2O提供非凡的数学能力、高性能并发处理及无比的易用性。H2O处理数据科学语言，支持R、Python、Scala、Java和一套健壮的RESTAPI。智能业务应用由H2O的NanoFastTM评分引擎驱动。
H2O介绍 H2O使采用数学和预测性分析解决当今最有挑战的业务问题成为可能。它具有其他机器学习平台当前所没有的功能：
 最佳开源技术 –享受开源技术大数据科学所带来的自由。H2O通过最流行的开源产品ApacheTMHadoop和SparkTM使客户更加灵活方便地解决最有挑战性数据问题。 易于使用的WebUI和熟悉的接口 –使用H2O的基于Web的用户界面或熟悉的编程环境（例如R、Java、Scala、Python、JSON）可以快速设置并入门。 支持所有通用数据库和文件类型 – 对微软Excel、RStudio、Tableau等软件内的大数据可以轻松浏览和建模。能够连接HDFS、S3、SQL和NoSQL数据源。可在任何地方安装和部署。 海量大数据分析 –在全部数据集而不是小样本上训练模型，通过H2O快速in-memory分布平行处理实时迭代和开发模型。 实时数据评分 –为了精确预测，使用Nanofast评分引擎可在任何环境以纳秒级对模型进行数据评分。它比当前市场上最接近的技术（说的是谁？）在评分和预测上快十倍。  H2O.ai公司 h2o.ai公司（之前叫0xdata?）于2011年(Linkedin显示2012年？)成立于加州山景城，目前员工不到50人。 H2O.ai公司的创始人有两位：SriSatish Ambati和Cliff Click。 参考 H2O.ai公司网站
GitHub：h2oai/h2o-3
Oxdata研发H2O，打造大数据新蓝图
Oxdata获890万美元融资：推H2O开源机器学习项目</description>
    </item>
    
    <item>
      <title>SAS过程步支持的第三方编程语言</title>
      <link>https://mryqu.github.io/post/sas%E8%BF%87%E7%A8%8B%E6%AD%A5%E6%94%AF%E6%8C%81%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</link>
      <pubDate>Tue, 25 Aug 2015 05:58:04 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/sas%E8%BF%87%E7%A8%8B%E6%AD%A5%E6%94%AF%E6%8C%81%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/</guid>
      <description>编程语言接口描述C, C++PROC PROTOPROC PROTO可以以批处理模式注册以外部的C或C++程序。当C函数在PROC PROTO注册后，他们能被FCMP过程里声明的任何SAS函数或子程序调用, 也能被COMPILE过程里声明的任何SAS函数、子程序或方法块调用。PROC FCMPSAS函数编译器(FCMP)过程可以创建、测试和存储SAS函数和CALL子程序，这些SAS函数和CALL子程序之后可用于其它SAS过程步或数据步。PROC FCMP能够使用数据步语法创建存储在数据集内的SAS函数和CALL子程序。该过程步接受数据步语句的轻微变化，你可以使用PROC FCMP所创建的SAS函数和CALL子程序中SAS编程语言的大部分功能。GroovyPROC GROOVYPROC GROOVY是在SAS9.3引入，为特定Groovy内联代码提供提交快的SAS程序，也能运行存储在外部文件中的Groovy程序。 JavaJAVAOBJSAS9提供的数据步组件对象。示例： ``` data _null_; length s_out $200; declare JavaObj j1 (&#39;java/lang/String&#39;,&#39;KE&#39;); declare JavaObj j2 (&#39;java/lang/String&#39;,&#39;XIAO&#39;); j1.callStringMethod (&#39;concat&#39;, j2, s_out); put s_out=; j1.delete(); j2.delete(); run; ```  PROC JLAUNCHJLaunch过程步允许在SAS显示管理器系统（DMS）内启动Java GUI程序。示例： ``` proc jlaunch direct librefs debug app=&#39;com/sas/analytics/cmpfunceditor/app/FCmpFunctionEditorApp&#39;; picklist name=&#39;base/cmpedit.txt&#39;; run; ``` LuaPROC LUAPROC LUA是在SAS9.4引入，为特定Lua内联代码提供提交快的SAS程序，也能运行存储在外部文件中的Lua程序。RPROC IMLPROC IML提供了灵活的矩阵编程语言，可以与R集成。示例： ``` libname mmsamp &#34;!sasroot\mmcommon\sample&#34;; proc iml; run ExportDatasetToR(&#34;mmsamp.hmeq_train&#34; , &#34;mm_inds&#34;); submit /R; attach(mm_inds) # ----------------------------------------------- # FITTING THE LOGISTIC MODEL # ----------------------------------------------- logiten </description>
    </item>
    
    <item>
      <title>数据科学的战争：R vs Python</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%9A%84%E6%88%98%E4%BA%89r_vs_python/</link>
      <pubDate>Thu, 14 May 2015 05:48:20 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%9A%84%E6%88%98%E4%BA%89r_vs_python/</guid>
      <description>R和Python都是用于数据分析任务的流行编程语言，都有各自的拥拓者和反对者。Python经常作为语法简单易懂的通用编程语言广受赞誉。在人们心中，R的功能是由统计学家开发的，因此具有特定领域优势，例如数据可视化上具有的大量功能。 DataCamp上有一篇帖子Choosing R or Python for data analysis? An infographic以信息图的方式从数据科学和统计的角度详细对比了R和Python这两种编程语言。 </description>
    </item>
    
    <item>
      <title>[社交网络分析课] 数据集预处理及Gephi导入</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90%E8%AF%BE_%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8Agephi%E5%AF%BC%E5%85%A5/</link>
      <pubDate>Sun, 23 Nov 2014 23:24:33 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90%E8%AF%BE_%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8Agephi%E5%AF%BC%E5%85%A5/</guid>
      <description>紧赶慢赶忙完了社交网络分析课的编程大作业，选择的是经验性网络分析。
这次的大作业没有指定数据集，自己找数据集做分析。我在网上搜到以前一个同学做的移民分析，感觉很不错。然后，就茫然了。最怕这种自己找数据集的，以前有的课程介绍了一些比较好的开放数据集，可惜当时没觉得有什么太大的价值，没记呀！！！
费了半天，找了一个大不列颠的公路流量数据集，公路就是edge了，每个公路的两端就是node了，感觉还可以。数据集在线地址: http://data.dft.gov.uk/gb-traffic-matrix/Traffic-major-roads-miles.csv.数据集手册在线地址: http://data.dft.gov.uk/gb-traffic-matrix/all-traffic-data-metadata.pdf
这次作业主要使用Gephi对数据集进行分析，所以我先使用R语言对原始数据集进行预处理，然后使用Gephi导入生成的nodes.csv和edges.csv。
if (!file.exists(&amp;quot;./Traffic-major-roads-miles.csv&amp;quot;)) { download.file(&amp;quot;http://data.dft.gov.uk/gb-traffic-matrix/Traffic-major-roads-miles.csv&amp;quot;, destfile = &amp;quot;./Traffic-major-roads-miles.csv&amp;quot;) } data &amp;lt;- read.csv(&amp;quot;Traffic-major-roads-miles.csv&amp;quot;, sep = &amp;quot;,&amp;quot;) data2013 &amp;lt;- subset(data, Year == 2013 &amp;amp; AllMV &amp;gt; 0, select = c(A.Junction, B.Junction, AllMV)) data2013 &amp;lt;- data.frame(A.Junction = toupper(data2013$A.Junction), B.Junction = toupper(data2013$B.Junction), Weight = data2013$AllMV, stringsAsFactors = FALSE) A.junctions &amp;lt;- as.vector(data2013[, 1]) B.junctions &amp;lt;- as.vector(data2013[, 2]) junctions &amp;lt;- sort(unique(c(A.junctions, B.junctions))) # write nodes.csv nodes_print &amp;lt;- cbind(c(&amp;quot;Nodes&amp;quot;, junctions), c(&amp;quot;Id&amp;quot;, 1:length(junctions)), c(&amp;quot;Label&amp;quot;, junctions)) nodes_print &amp;lt;- t(nodes_print) write(nodes_print, file = &amp;quot;nodes.</description>
    </item>
    
    <item>
      <title>[社交网络分析课] 小世界网络</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E5%B0%8F%E4%B8%96%E7%95%8C%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Mon, 10 Nov 2014 20:35:52 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E5%B0%8F%E4%B8%96%E7%95%8C%E7%BD%91%E7%BB%9C/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna 。
小世界网络 在网络理论中，小世界网络是一类特殊的复杂网络结构，在这种网络中大部份的节点彼此并不相连，但绝大部份节点之间经过少数几布就可到达。 在日常生活中，有时你会发现，某些你觉得与你隔得很“遥远”的人，其实与你“很近”。小世界网络就是对这种现象（也称为小世界现象）的数学描述。用数学中图论的语言来说，小世界网络就是一个由大量顶点构成的图，其中任意两点之间的平均路径长度比顶点数量小得多。除了社会人际网络以外，小世界网络的例子在生物学、物理学、计算机科学等领域也有出现。 二十世纪60年代，美国哈佛大学社会心理学家斯坦利·米尔格伦（StanleyMilgram）做了一个连锁信实验。他将一些信件交给自愿的参加者，要求他们通过自己的熟人将信传到信封上指明的收信人手里，他发现，20%的信件最终送到了目标人物手中。而在成功传递的信件中，平均只需要6.5次转发，就能够到达目标。也就是说，在社会网络中，任意两个人之间的“距离”是6。这就是所谓的“六度分隔”理论。
全局集聚系数(Global Clustering Coefficient) 全局集聚系数基于节点的三点组。一个三点组由三个节点组成，其中可以两边连接(为闭三点组)或三边连接(开三点组)，统称连通三点组。 全局集聚系数是闭三点组个数(或三倍三角形个数)除以全部连通三点组个数。 该方法首次由Luce和Perry使用 (1949)。该指标指示了整个网络的集聚程度，可被用于无方向和有向网络。 定义： 局部集聚系数(Local Clustering Coefficient, Watts&amp;amp;Strogatz1998) 对于每个节点i，ni是节点i的邻居节点个数。 平均本地集聚系数： 示例1： 示例2： 示例3： 我用Gephi做了一个例子，Gephi不计算全局集聚系数，它会计算平均集聚系数和每个节点的局部集聚系数。 平均集聚系数 = (1+0.667+0.667+1)/4 = 0.833，同软件所得一致。
下面手动算一下全局集聚系数： 闭三点组有6个： B-&amp;gt;A&amp;lt;-C; A-&amp;gt;B&amp;lt;-C; A-&amp;gt;C&amp;lt;-B; C-&amp;gt;B&amp;lt;-D;B-&amp;gt;C&amp;lt;-D; B-&amp;gt;D&amp;lt;-C 开三点组有2个： A-&amp;gt;C&amp;lt;-D; A-&amp;gt;B&amp;lt;-D 全局集聚系数=6/(6+2)=3&amp;frasl;4=0.75
强联系(A strong tie)  联系频繁 亲密 许多共同的联系人  连接边嵌入性(edge embeddeness) 嵌入性(embeddeness)：两个端点所共同拥有的邻居节点个数。 邻居节点重叠(neighborhood overlap)： 分解局部结构：网络基序(Network motif) 网络的复杂性本质上就是关系的复杂性。但是，研究者通过对真实网络的分析，发现各种关系种类的出现频率是非随机性的。某些特定的关系种类在网络中反复出现，形成网络的典型连接方式；不同类型的网络具有不同的典型连接方式。研究者把这些特定的关系种类称为“网络基序”，认为它们是一个网络的基本构造单元。 基序是从功能的角度来分析网络的构成，着眼于网络内各种成分之间连接的模式或关系。 所有三节点基序 网络基序示例(三节点) 网络基序示例(四节点) 真实网络与随机网络的网络基序对比 网络基序探测 跟随机网络相比，一些网络基序更容易在真实网络中出现。
技术： 使用相同数量的节点和边构造随机网络(相同的节点度分布？) 计算图中的基序个数 计算Z-评分：给定基序个数偶然在真实网络出现的概率
基序软件 Uri AlonLab mfinder： 网络基序探测工具 Uri AlonLab mDraw： 网络基序可视化工具 FANMOD：网络基序快速探测工具(开发者S.</description>
    </item>
    
    <item>
      <title>又被Mining Massive Datasets的老师伤了！</title>
      <link>https://mryqu.github.io/post/%E5%8F%88%E8%A2%ABmining_massive_datasets%E7%9A%84%E8%80%81%E5%B8%88%E4%BC%A4%E4%BA%86/</link>
      <pubDate>Fri, 07 Nov 2014 20:42:31 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E5%8F%88%E8%A2%ABmining_massive_datasets%E7%9A%84%E8%80%81%E5%B8%88%E4%BC%A4%E4%BA%86/</guid>
      <description>Mining Massive Datasets这周的课讲聚类和计算广告学：二分图匹配。课后的作业好几个都是一眼看不出来，只好写程序算。
其中有一道题是这个样子： We wish to cluster the following set of points: into 10 clusters. We initially choose each of the green points(25,125), (44,105), (29,97), (35,63), (55,63), (42,57), (23,40),(64,37), (33,22), and (55,20) as a centroid. Assign each of thegold points to their nearest centroid. (Note: the scales of thehorizontal and vertical axes differ, so you really need to applythe formula for distance of points; you can&amp;rsquo;t just &amp;ldquo;eyeball&amp;rdquo; it.)Then, recompute the centroids of each of the clusters.</description>
    </item>
    
    <item>
      <title>[社交网络分析课] 社区结构</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%A4%BE%E5%8C%BA%E7%BB%93%E6%9E%84/</link>
      <pubDate>Mon, 03 Nov 2014 20:00:32 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%A4%BE%E5%8C%BA%E7%BB%93%E6%9E%84/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna 。
为什么关注群体凝聚力？ 观点的形成和一致性：如果节点采用邻居节点的主流观点，就有可能不同有凝聚力的子组有不同的观点。 什么导致社区的形成？  联系的相互关系(mutuality of ties)：组内每个人都认识其他人。 成员间联系的频率：组内每个人都同组内的其他人存在至少k个连接。 子组成员的亲密性或可达性：个体间被最多n跳分割。 子组成员间相对非成员的相对联系频率。  归属网络(Affiliation networks)  成员网络，例如董事会 超网络或超图(hypergraph) 二分图(bipartite graphs) 连锁网络?(interlocks)  小集团/帮派(cliques) 组内的每个成员都同其他成员有连接。小集团可以重叠。 小集团的意义  不健壮：缺失一个连接将毁掉小集团 无趣：每个人都同其他人连接；没有核心-边缘结构；无法使用中心性指标 小集团如何重叠比自身更有趣  k-cores 每个节点同组内k个其他节点相连。与小集团相比，简单且不那么严格。 即使如此，对于识别自然社区还是过于严苛的要求。 n – cliques 基于可达性和直径进行子组划分。子组内每两个节点最大距离为n。 问题： - 直径可能大于n - n-clique可能是断开的(路径通过子组外的节点进行)
解决方法：n-club:直径2的最大子图 {1,2,3,4},{1,2,3,5} and {2,3,4,5,6}
p-cliques 将网络分割成子组，其中节点至少有概率p的邻居节点在子组内。 有向加权网络的凝聚力 查找强连通分量 在查找强连通分量仅保留部分联系：相互的联系；边权重大于一定阀值。
分层聚类 处理流程： - 计算所有节点对的距离 - 从所有断开的n个节点开始 - 为了减少权重，为节点对逐个添加边 - 结果：递归分量，可在树的任一级切片
介数聚类 算法： - 计算所有边的介数 - 当(任一边的介数大于阀值)： - 移除带有最高介数的边 - 重新计算介数</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 多元线性回归</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Sat, 01 Nov 2014 11:17:53 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description> 本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
adjusted R squared 共线性(collinearity)：当两个预测变量彼此相关就可以说共线的。预测变量也称为独立变量，因此它们应该彼此独立。引入共线的预测变量(多重共线性，multicollinearity)使模型估计更加复杂。 简约法(parsimony)：避免添加互相关联的预测变量，因为这些变量不会带来新信息；优选最简单最好的模型，例如精简模型；加入共线的变量会导致回归参数有偏估计；当无法避免观察数据中的共线性，经常设计实验来控制关联的预测变量。
多元线性回归推断 模型选择 逐步模型选择 - 后向消除：从全模型(包含所有预测变量)开始，每次丢弃一个预测模型，直到获得精简模型 - 前向选择：从空模型开始，每次添加一个预测模型，直到获得精简模型
标准： 调整变量的标准有两种： 1. 使adjusted R square最大化； 2. 使p-value最小化
如果存在反映同一个性质的一组分类变量，要么全部保留，要么全部去除，不可以保留不完整的一部分 诊断 (1)(数字变量)x和y的线性关系 每个(数字)解释变量线性关联响应变量； 使用残差图检查残差是否随机分布0附近；不使用x和y的散点图，因为这样可以考虑模型内的其他变量，而不是仅仅x和y之间的二元变量关系。 (2)近似均值为0的正态分布残差 某些残差为正，某些为负；在残差图中残差随机分布0附近； 使用直方图或正态概率图检查是否近似均值为0的正态分布残差 (3)残差的恒定可变性 残差应该对预测的响应变量的低值和高值有相等的可变性 使用residuals vs. predicted残差图检查： residuals vs. predicted而不是residuals vs.x，允许一次考虑(带有所有解释变量的)整个模型；残差随机分布在0附件的常量带内；值得观察residuals vs.predicted的绝对值，轻松识别异常观察值。 (4)独立的残差 独立残差-&amp;gt;独立观察值 如果是可疑的时间序列结构，对比检查残差和数据采集顺序，否则，思考数据如何采样的。 </description>
    </item>
    
    <item>
      <title>igraph包的cliques函数总也不返回</title>
      <link>https://mryqu.github.io/post/igraph%E5%8C%85%E7%9A%84cliques%E5%87%BD%E6%95%B0%E6%80%BB%E4%B9%9F%E4%B8%8D%E8%BF%94%E5%9B%9E/</link>
      <pubDate>Wed, 29 Oct 2014 20:14:57 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/igraph%E5%8C%85%E7%9A%84cliques%E5%87%BD%E6%95%B0%E6%80%BB%E4%B9%9F%E4%B8%8D%E8%BF%94%E5%9B%9E/</guid>
      <description>做社交网络分析课的作业时碰到一个小麻烦，igraph包的cliques函数总也不返回，最后只能强行终止但是数据量也不大，而且largest.cliques和clique.number都是立刻返回，不解呀！
&amp;gt; library(igraph) &amp;gt; g = read.graph(&amp;quot;wikipedia.gml&amp;quot;,format=&amp;quot;gml&amp;quot;) &amp;gt; cliques(as.undirected(g)) &amp;gt; largest.cliques(as.undirected(g)) [[1]] [1] 26526 247 370 2119 6625 7826 8277 10019 11773 11801 13289 15758 [13] 16845 16885 16937 18925 22144 22644 23318 24585 24654 25487 &amp;gt; clique.number(as.undirected(g)) [1] 22  </description>
    </item>
    
    <item>
      <title>[社交网络分析课] 网络中心性</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%BF%83%E6%80%A7/</link>
      <pubDate>Tue, 28 Oct 2014 05:58:54 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%BF%83%E6%80%A7/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna 。
对于中心性(centrality)的不同观点 在下面每一个网络中，X都相对Y具有更高的中心性。 定量度中心性 在每个节点上标注节点度。例如，拥有朋友越多的节点其中心性越高。 其标准化就是用节点度除以最大的连接可能(N-1)。 集中度(centralization) 节点间的集中度分数存在多少差异？Freeman的集中度通用公式(可使用其他指标，如基尼系数或标准差) 度集中度示例： 介数(betweenness) 直观：多少个节点对必须经由本节点实现最小跳数互达。 定义： 非标准化版本示例1： 非标准化版本示例2： 非标准化版本示例3： 非标准化版本示例4： 经由B的最短路径有(A,C)、(A,E)、(A,D)，此外(C,D)的最短路径分配给B和E各0.5，因此B为3.5，E为0.5。
紧密性(closeness) 紧密性基于节点与网络所有其他节点的平均最短路径长度计算而得。 示例： 特征向量中心性(eigenvector centrality) 当前节点的中心性取决于邻居节点们的中心性。 Bonacich特征向量中心性 - a是一标准化常数 - b决定邻居节点对中心性的重要性 - A是相邻矩阵(可被权重) - I是单位矩阵 - 1是全一的矩阵
衰减因子b： 小b -&amp;gt; 高衰减：仅直接朋友起作用，且其重要性仅被考虑进去一点点。 高b -&amp;gt; 低衰减：全局网络(朋友，朋友的朋友等等)起作用 =0 产生简单的度中心性 如果b&amp;gt;0,节点连接其他中心节点具有更高中心性。 如果b&amp;lt;0, 节点连接其他非中心节点具有更高中心性。 示例： 有向网络的介数中心性 唯一的修改：当标准化时将使用(N-1)(N-2)而不是(N-1)(N-2)/2。 有向网络的紧密性中心性 选择一个方向：入紧密性、出紧密性。
有向网络的特征向量中心性 讲了pagerank和teleport。
中心性应用 以Java论坛为例，介绍了各种分析。
幂定律分布 在log-log图中是一条直线：ln(p(x))=c-aln(x) 参考 中心性(centrality)
Bonacich’s Centrality</description>
    </item>
    
    <item>
      <title>A Short Tutorial on Graph Laplacians, Laplacian Embedding, and Spectral Clustering</title>
      <link>https://mryqu.github.io/post/a_short_tutorial_on_graph_laplacians_laplacian_embedding_and_spectral_clustering/</link>
      <pubDate>Fri, 24 Oct 2014 20:12:08 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/a_short_tutorial_on_graph_laplacians_laplacian_embedding_and_spectral_clustering/</guid>
      <description>http://csustan.csustan.edu/~tom/Lecture-Notes/Clustering/GraphLaplacian-tutorial.pdf</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 线性回归</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Thu, 23 Oct 2014 20:39:16 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description> 本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics 。
相关性(correlation) 相关性描述了两个变量之间线性关联的强度，表示符号为R。属性： - 相关系数的幅度(绝对值)测量两个数字变量之间线性关联的强度 - 相关系数的正负指示关联的方向 - 相关系数总是介于-1(完美负线性关联)和1(完美正线性关联)之间，R=0指示没有线性关系 - 相关系数没有单位，不受变量中心点和比例变化的影响 - X与Y的相关性等同于Y与X的相关性 - 相关系数对异常点敏感
残差(residuals) 测量线性匹配度 方案1：最小化残差的幅度和 方案2：最小化残差平方和。更常使用，易于计算，残差增幅更大。 使用线性模型对解释变量给定值预测响应变量值称之为预测(prediction)。 使用模型估计原有数据域外的值称之为外推法(extrapolation)。优势预测可能是外推法。 线性回归条件 (1)线性 解释变量和响应变量值间的关系必须是线性的； 存在匹配非线性关系模型的方法； 使用数据散点图scatterplot或残差图residuals plot检查 (2)近似正态残差 残差必须近似正态分布，中心点为0；如果有异常观察值不遵循正常数据的趋势，有可能不满足该条件使用残差的直方图或正态概率图检查(3)恒定可变性 点围绕最小平方和线(the least squaresline)的可变性应该大概恒定，暗指残差围绕0的可变性应该大概恒定，这也称为同方差性(homoscedasticity)。 使用残差图residuals plot检查 R squared 评估线性模型拟合度更常使用，通过相关系数平方计算而得； 可以获知线性模型解释响应变量可变性的百分比，剩余可变性无法由模型解释； 介于0和1之间。
使用分类解释变量的回归 异常点类型 线性回归推断 由于我们经常检查解释变量和响应变量之间是否存在关系，对斜率虚假设值经常为0；很少对截距进行推断。 对线性回归的每个估计参数都会损失一个自由度。 我们必须了解所工作的数据：随机样本、非随机样本或总体。如果已有总体数据，假设推断及其p-value结果就毫无意义。如果样本是非随机（有偏）的，结果将不可信。 变异分解(variability partitioning) t检验是评估x和y线性关系斜率假设检验的证据力度的一种方式。将y可变性分解为可解释和无法解释的可变性，需要使用方差分析ANOVA。 再学习 R sqared Rsqared是模型可以解释y可变性的比例。很大，即x和y之间存在线性关系；小，则x和y之间存在线性关系的证据不令人信服。 两种结算方式：相关性，相关系数平方；定义，总可变性中可解释可变性的比例。 </description>
    </item>
    
    <item>
      <title>[社交网络分析课] 随机网络模型</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E9%9A%8F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 21 Oct 2014 20:07:15 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E9%9A%8F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna。
网络模型 为什么建立网络模型？ - 复杂网络的简单表达 - 可以通过数学推导出属性 - 可以预测属性和输出 - 可以对比真实网络与假设模型的不同之处，从中获得顿悟
随机图模型：Erdös-Renyi模型 假设  节点随机连接 网络是无向网络  除了节点数N之外的关键参数：p或M  p=任意两个节点连接的概率 M=图中边的总数  度分布 (N,p)模型：对每个潜在的边，概率p添加边，概率(1-p)不添加边。 每节点边数 每个节点最多可能（N-1）条边，每条边以概率p的可能性存在。二项分布提供了节点具有度K的概率： 度的平均数为：z = (n-1)*p度的方差为：s2=(n-1)p(1-p)近似值：ER图模型认知 社交中心(hub) 该模型下无法获得大的社交中心。
巨分量 上述实验中，每个点有可变的概率P表示渗透。当P等于1/2的时候，图中会出现一个明显的巨分量。
平均最短路径 每对节点的平均跳数是多少？假如你的朋友与z（=度平均值）个你的其他朋友相连，忽略回路的话与你距离l跳的人有zl个。 介绍模型(Introduction Model) 任意两个节点连接的概率prob-link仍然是p，此外增加了连接邻居节点的邻居节点概率prob-intro，不再完全随机。 与ER模型相比，介绍模型具有： - 更多的闭三点组（朋友将他的朋友介绍给你） - 更长的平均最短距离（边更局部连接） - 更多不均匀的度分布（有更多连接的节点更容易增加边） - 低概率p的情况更小的巨分量
静态地理模型(Static Geographical model) 每个节点与最接近的节点中的num-neighbors个相连。 与ER模型相比，静态地理模型具有： - 更窄的度分布(每个节点邻居节点目标一样，num-neighbors) - 更长的平均最短距离（地理局部连接） - 更小的巨分量(更少的机会进行随机连接)
随机遭遇模型(Random encounter) 节点随机移动，与偶遇的节点相连。 与ER模型相比，随机遭遇模型具有： - 更长的平均最短距离 - 更小的巨分量 - 更多的闭三点组</description>
    </item>
    
    <item>
      <title>[社交网络分析课] 网络介绍</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Thu, 16 Oct 2014 21:40:47 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna。
网络定义 网络就是由边(edge)所连接的一些点(node)。
&#34;网络&#34;≡&#34;图&#34;
点线verticesedges, arcs数学nodeslinks计算机科学sitesbonds物理学actorsties, relations社会学![社交网络分析：网络介绍](/images/2014/10/0026uWfMgy6O7qbbpnuec.png) 边 方向： - 单向的 A-&amp;gt;B (例如A likesB; A gave agift to B; Ais B’s child) - 双向的 A&amp;lt;-&amp;gt;B 或 A-B (例如A and Blike each other; A and B aresiblings; Aand B are co-authors)
属性： - 权重(例如通信频率) - 排名(第一好友、第二好友…) - 类型(朋友、亲戚、同事) - 取决于剩余图结构的属性：例如betweenness
图的数据表达方式 |相邻矩阵(adjacency matrix)|边列表
(edge list)|相邻列表(adjacency list) |&amp;mdash; ||2, 3
2, 4
3, 2
3, 4
4, 5
5, 2</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 分类变量推断</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F%E6%8E%A8%E6%96%AD/</link>
      <pubDate>Tue, 14 Oct 2014 20:59:27 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F%E6%8E%A8%E6%96%AD/</guid>
      <description> 本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
抽样可变性 用于概率的大树极限定理 概率的置信区间 计算符合误差幅度的样本个数 概率的假设检验 两个概率差的置信区间 两个概率差的假设检验 小样本概率 &amp;amp; 比较两个小样本概率 模拟方法进行假设检验： - 假设检验的最终目标是p-value，P(observed or more extreme outcome | H0true) - 假定虚假设为真，设计模拟方法 - 多次重复模拟，记录相关样本统计量 - 计算倾向备选假设的模拟概率作为p-value。
卡方拟合度检验(chi-square GOF test) 拟合度(goodness of fit)检验：评估观察数据有多拟合期望分布单个类别变量，变量值大于2级 卡方检验的p-value 用于卡方检验的p-value定义为高于计算的检验统计量的尾部区域由于检验统计量总是正数，更高的检验统计量意味着与虚假设偏离更大。 卡方独立检验 独立检验：评估两个类别变量之间的关系两个类别变量，类别值大于两级 </description>
    </item>
    
    <item>
      <title>[社交网络分析课] SNA工具</title>
      <link>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_sna%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Wed, 08 Oct 2014 20:57:50 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90_sna%E5%B7%A5%E5%85%B7/</guid>
      <description>本文为Social NetworkAnalysis学习笔记，课程地址为https://www.coursera.org/course/sna。
Gephi - https://gephi.github.io/ - 用于网络、复杂系统和动态封层图形的交互式可视化及研究平台，支持度、介数、紧密性等网络中心性指标以及密度、路径长度、网络直径、模块度、集聚系数等指标，支持GDF(GUESS)、GraphML (NodeXL)、GML、NET (Pajek)、GEXF等文件格式。 - 开源，支持Windows、Linux和Mac OS X平台 - Gephi指南 - 使用Gephi可视化twitter网络 - Twitter上的埃及革命
NetLogo - https://ccl.northwestern.edu/netlogo/index.shtml - 多主体仿真建模工具。可用于模拟各种社会现象和自然现象，通过设置个体行为并使多个个体自由运行来研究个体行为对于复杂系统的影响和变化。 - 开源，支持Windows、Linux和Mac平台 - NetLogo帮助文档 - Lada的多个特定网络属性演示
iGraph - http://igraph.org/ - 网络分析工具库，侧重于执行效率、可移植性和易用性，可被R、Python和C/C++调用。 - 开源，支持Windows、Linux和Mac OS X平台 - R iGraph帮助文档 - Python iGraph帮助文档 - C iGraph帮助文档
Pajek - http://pajek.imfm.si/doku.php - 网络分析和可视化工具，功能丰富，通过下拉菜单进行各种操作。 - 免费，支持Windows平台，也可以在Linux（64）和Mac平台上仿真（Wine）运行 - Pajek参考手册
UCINet - https://sites.google.com/site/ucinetsoftware/ - 社交网络数据分析软件包，功能丰富。 - 商业软件，支持Windows平台 - UCINet文档
NodeXL - http://nodexl.codeplex.com/ - 交互式网络可视化和分析工具，以MS Excel模板的形式利用MSExcel作为数据展示和分析平台。可以定制图像外观、无损缩放、移动图像，动态过滤顶点和边，提供多种布局方式，查找群和相关边，支持多种数据格式输入和输出。 - 开源，支持Windows Excel 2007/2010/2013 - NodeXL文档</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 数字变量推断</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E6%95%B0%E5%AD%97%E5%8F%98%E9%87%8F%E6%8E%A8%E6%96%AD/</link>
      <pubDate>Tue, 30 Sep 2014 06:47:20 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E6%95%B0%E5%AD%97%E5%8F%98%E9%87%8F%E6%8E%A8%E6%96%AD/</guid>
      <description>本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
两组数据比较 成对数据 独立数据 bootstrapping bootstrapping术语取自短句“pulling oneself up by one’sbootstraps”,暗指没有外力的情况下完成不可能实现的任务。统计中指使用给定样本中的数据估计总体参数。 1. 获得bootstrap样本 - 使用原样本有放回抽样获得相同大小的随机样本 2. 计算bootstrap统计量 - 通过bootstrap样本获得平均值、中值、概率等统计量 3. 多次重复步骤1和2以创建bootstrap分布 - bootstrap统计量的分布
估计方法： - 百分比方法：通过排除两端的数据，直接取bootstrap分布中间的95% - 标准差方法：先计算bootstrap分布的均值与标准差，再计算95%区间
限制： 没有类似于中心极限定理时的严格条件 如果bootstrap分布特别倾斜或稀疏，则可信度低需要一个可以概化的代表性样本。 若原样本有偏，则bootstrap结果很可能有偏
bootstrap vs. 抽样分布 抽样分布使用总体进行有放回抽样 Bootstrap分布使用样本进行有放回抽样 两者都是样本统计分布
t分布 当n比较小且方差σ未知，使用t分布解决标准差估计的不确定性。 t分布有一个参数：自由度(degrees of freedom, df)，决定分布尾部的厚度。自由度越大，越接近正态分布。 t统计用于推断σ未知且n &amp;lt; 30时的均值
基于小样本估计均值 R函数实例：
qt(0.025, df = 21) pt(2.30, df = 21, lower.tail = FALSE)  基于小样本比较均值 多均值比较 当比较两组均值时可以使用Z或T检验，当比较3+组均值时需要使用方差分析(analysis ofvariance,ANOVA)和F检验。 总平方和(sum of squares total, SST) 估量响应变量的总可变性，跟方差计算相似（除了不除以样本数） 组平方和(sum of squares groups, SSG) 估量组间可变性，可解释的可变性：组均值与总均值之间样本数加权的偏差 误差平方和(sum of squares error, SSE) 估量组内可变性，不可解释的可变性：组变量由于其他原因无法解释 自由度 总自由度：总样本量减一组自由度：组样本量减一误差自由度：前两者相减 平均平方和 F统计 p-value计算 pf(21.</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 大数极限定理与假设检验</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%A4%A7%E6%95%B0%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86%E4%B8%8E%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</link>
      <pubDate>Thu, 25 Sep 2014 20:54:19 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E5%A4%A7%E6%95%B0%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86%E4%B8%8E%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/</guid>
      <description>本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
采样可变性 中心极限定理 样本统计分布趋向于正态分布，其均值接近总体均值，标准差为原总体标准差除以样本量的平方根CLT条件： - 独立：样本观察值必须独立 - 随机抽样/分配 - 对于无放回抽样，样本个数n必须小于总体的10%，太大以后样本中的数据很难相互独立 - 样本大小/偏斜度：或者总体分布是正态分布，或者总体分布是偏斜的但样本很大(经验法则：n&amp;gt;30)
置信区间(confidence interval) 总体参数值的可能范围置信区间=点估计±误差幅度(误差边际,margin of error) 总体均值的置信区间
z*: 90% 1.65 95% 1.96 98% 2.33 99% 2.58  置信区间增大，宽度增大，准确度变大，精确度变小。唯有增加样本大小，可以获得高准确度和高精确度。 假设检验  基于置信区间的假设检验：判断现状是否存在于置信区间内 基于p-value的假设检验：p-value = P(observed or more extreme outcome | H0 true)使用测试统计计算p-value，虚假设为真的情况下当前数据集倾向备择假设的概率。如果p-value低（低于显著水平α，通常为5%），如果虚假设为真的情况下很难观测到（样本这样的）数据，因此拒绝H0。如果p-value高（高于α），即使虚假设为真也能观测到（样本这样的）数据，因此不拒绝H0。 双边检验(two-sided test):置信区间两边都纳入考虑单边与双边检验，p-value的定义相同，但计算方式有不同  决策失误：  第一类错误(Type 1 error)是当H0为真时拒绝H0 &amp;ndash; 错杀好人。 第二类错误(Type 2 error)是当HA为真时拒绝H0失败 &amp;ndash; 错放坏人。  P(Type 1 error | H0 true) = α，显著性水平(significance level,α)越高，犯第一类错误的可能性越大。 如果第一类错误代价高，选择小的显著水平(例如0.</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 概率分布</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</link>
      <pubDate>Tue, 16 Sep 2014 20:19:41 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</guid>
      <description>本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
概率规则  事件A或B发生概率： P(A or B) = P(A) + P(B) - P(A and B) 事件A和B同时发生概率： P(A and B) = P(A|B) x P(B) 条件概率：P(A|B) = P(A and B) / P(B) 不相交事件(disjoint, mutually exclusive)：事件A和B不会同时发生 p(A and B)=0,p(A or B)=p(A)+p(B), p(A|B)=0 互补事件(complementary)：概率和为1的不相交事件 p(A and B)=0, p(A|B)=0, p(A orB)=1, p(A)+p(B)=1 独立事件(independent)：事件A是否发生对事件B没有影响 p(A|B)=p(A), p(A andB)=p(A)p(B)  概率分布 列出样本空间所有输出及其概率
概率树 按照多个变量层层写出条件概率 贝叶斯推断 利用先验信息，例如以前发布的研究成果或物理模型当收集数据时自然集成，并更新先验信息避免反直觉的p-value定义：P(observed or more extreme outcome | H0 istrue)而是基于后验概率做判决：P(hypothesis is true | observed data)好的先验信息有帮助，坏的先验信息有损害。但是先验信息跟能收集到更多数据相比不重要。更高级的贝叶斯技术提供了频率模型无法表示的灵活度 过程： - 设定先验信息 - 收集数据 - 获得后验信息 - 使用后验信息更新先验信息</description>
    </item>
    
    <item>
      <title>[数据分析与统计推断] 介绍数据</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E4%BB%8B%E7%BB%8D%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Tue, 02 Sep 2014 21:43:48 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD_%E4%BB%8B%E7%BB%8D%E6%95%B0%E6%8D%AE/</guid>
      <description>本文为Data Analysis and StatisticalInference学习笔记，课程地址为https://www.coursera.org/course/statistics。
数据基础 观察值、变量、数据矩阵数据类型: - 数字变量：分为连续的和离散的 - 分类变量：分为有序（ordinal）的和普通无序的变量关系: - 关联Assocaited （Dependent）：分为正的和负的 - 独立Independent
研究方法  观察性研究Observational Study：直接取现实中的数据，探究变量间的相关性  retrospective：依赖以前的数据 prospective：在研究中收集新的数据  实验性研究Experiment: 随机分配对象到实验组；建立因果性连接观察性研究和实验性研究主要区别在于是否人为地施加了干预措施  观察性研究和抽样策略 为什么抽样？ - 某些个体很难定位和测量； - 统计总体很少保持不变抽样偏差源 - 便利样本Convenience sample：更易于被访问到的用户更可能被包含到采样中 - 无响应样本Non-response：仅部分被随机采样的被访者填写了调查问卷，这样的采样无法代表统计总体 - 自发性响应样本Voluntary response：对调查问卷中的问题更感兴趣的人积极主动填写调查问卷抽样方法 - 简单随机抽样Simple random sample (SRS)：不做控制随机地取样 - 分层抽样Stratified sample：对人群做分析，按相似性分成若干的阶层，在各阶层内取样 - 整群抽样cluster sample：随机将统计总体分成若干群，随机取一些群，再在这些群内取样混杂变量 Confounding/lurkvariable：对解释变量和响应变量都有影响的额外变量，使解释变量和响应变量看起来有关系
实验性研究 设计原则  control：比较实验组与对照组 randomize：保证对象在两个组分配的随机性 replicate：足够大的实验量或整个实验可复制 block：消除已知或可疑变量对输出的影响。例子:设计实验研究是否能量胶囊有助于奔跑更快： 实验组treatment：能量胶囊 对照组control:无能量胶囊能量胶囊可能对专业运动员和业余运动员影响不同消除专业状态： 将样本拆分为专业运动员和业余运动员 将专业运动员和业余运动员随机平均分配到实验组和对照组消除变量和解释变量的区别：  解释变量(factors)：施加于实验个体的条件 消除变量：我们需要控制的实验个体自带特征消除与分层很相似，区别在于： 在随机分配过程中消除，用于取得因果性 在随机抽样过程中分层，用于概化generalizability   术语  安慰剂：假处理，经常在药物研究中用作对照组 安慰剂效应：展示使用安慰剂的变化 盲 ：实验个体不知道其所在组 双盲：实验个体和研究者都不知道其所在组在需要从人的主观感受中剥离客观结论的社会性研究（比如药物实验）中，如果被试的主观感受会影响数据结果，就需要给予对照组无实质作用的安慰剂，并且对其隐藏其属于实验组还是对照组的信息，以区分实验组的变化和安慰剂效应，这就叫blindexperiment；更进一步，如果研究者的主观感受也会影响实验结果，则对研究者也隐藏实验与对照的分组信息，这就是通常说的双盲实验  随机抽样和随机分配 数值型数据的可视化 散点图scatterplot 可以从中归纳两个变量的相关性。相关性有几个性质：正/负相关、形状（线性、非线性）、强/弱相关，异常值直方图histogram 可以给出一个数据密度的视图，并且可以观察： - 偏度：描述了数据密度的左右分布，左偏/右偏/对称 - 形态（modality）：正态分布/均匀分布/双峰分布/多峰分布等等 - 区间划分不能过宽或过窄点阵图dotplot 当研究个体值时有用，样本量太大时不太适箱形图boxplot 在强调异常点、中位数、四分位距(Interquartile range，IQR，即Q3-Q1)时有用。强度图intensity map 用于空间分布。中心测量 均值mean、中位数median、众数mode分布性测量  范围range：最大值-最小值 方差variance： 标准差standard deviation： 四分位距Interquartile range：  健壮统计量 用于测评特异值是否作用较小数据转换： 通过函数对数据进行尺度变换，用于换一种数据观察角度；降低偏度；非线性转换为线性。示例为对数转换、平方根转换、倒数转换。1.</description>
    </item>
    
    <item>
      <title>数据科学：学习路径和图书</title>
      <link>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84%E5%92%8C%E5%9B%BE%E4%B9%A6/</link>
      <pubDate>Fri, 06 Jun 2014 20:02:21 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84%E5%92%8C%E5%9B%BE%E4%B9%A6/</guid>
      <description>转发网上的两个图片，时时对照学习。</description>
    </item>
    
    <item>
      <title>slidify</title>
      <link>https://mryqu.github.io/post/slidify/</link>
      <pubDate>Tue, 03 Jun 2014 21:19:22 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/slidify/</guid>
      <description>Slidify是使用RMarkdown创建、定制和发布（用于可重复性研究的）HTML幻灯片的工具包。 Slidify支持多种生成框架和主题：
|幻灯片生成框架|主题 |&amp;mdash;&amp;ndash; |io2012|&amp;nbsp; |html5slides|default, uulm |html5rocks|&amp;nbsp; |deck.js|web2.0, swiss, neon |dzslides|&amp;nbsp; |landslide|default, tango, clean |shower|ribbon |slidy|&amp;nbsp; |slideous|&amp;nbsp; |beamer|&amp;nbsp; |showoff|&amp;nbsp;
生成的幻灯片可以发布到Github、Dropbox和Rpubs上。命令集成了一些底层操作，所以很简单。见http://slidify.org/publish.html 前一段发布一个幻灯片碰到些麻烦，只好采用git命令行这种老方式。操作步骤参考如下链接： https://github.com/ramnathv/slidify/wiki/Publishing</description>
    </item>
    
    <item>
      <title>CRAN任务视图：机器学习与统计学习（2014-05-31版）</title>
      <link>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A02014-05-31%E7%89%88/</link>
      <pubDate>Tue, 03 Jun 2014 06:24:06 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A02014-05-31%E7%89%88/</guid>
      <description>我在CRAN任务视图使用一帖中学习CRAN中当前所有的任务视图，本帖学习机器学习与统计学习的任务视图，其原链接如下：http://cran.r-project.org/web/views/MachineLearning.html 机器学习是计算机科学和统计学的边缘交叉领域，R关于机器学习的扩展包大概包括以下几个方面： - 神经网络(Neural Networks) : 单隐含层神经网络在nnet 包(与R基础包一同发布)中实现。RSNNS 包提供斯图加特神经网络仿真软件(SNNS)的使用接口。 - 递归拆分（Recursive Partitioning） : 根据CART书中算法完成的用于回归、分类和生存分析的树形结构模型在rpart 包(与R基础包一同发布)和tree包中实现。rpart包推荐用于计算与分类回归树相类似的树结构。 Weka 拥有很多拆分算法的工具包，RWeka提供了Weka的C4.5（J4.8变种）和M5实现的使用接口。Cubist包通过在叶端使用线性回归模型、基于实例修正、boosting拟合基于规则的模型（与树类似）。C50包可以拟合C5.0分类树和基于规则的模型及其boosting版本。party包有两个带有无偏变量选择和统计停止准则的递归拆分算法实现。ctree()函数基于非参数条件推理过程，用于测试响应变量和每个输入变量的无关性；而mob()函数能用于拆分参数模型。party包也提供了用于可视化二叉树和响应变量节点分布的可扩展工具。用于多元响应变量的rpart改进版本在mvpart包提供。对于二元输入变量问题，LogicReg包实现了逻辑回归。maptree包提供了树的可视化工具。用于通过随机效应对纵向数据进行建模的树由REEMtree包提供。RPMM提供了对混合模型(Beta和高斯混合)的拆分。用于表达树的计算基础架构、预测和可视化的统一方法在partykit包内实现。oblique.tree包提供了用于分类数据的斜树。 - 随机森林（Random Forests） : randomForest包提供了用于回归和分类的随机森林算法参考实现。ipred包提供了用于回归、分类和生存分析的bagging（bootstrapaggregating的缩写）算法及通过集成学习对多个模型进行组合的bundling算法。此外，基于条件推断决策树（conditional inferencetree）的随机森林变体（其响应变量可以以任意比例估量）在party包中实现。randomSurvivalForest包提供用于删失数据的随机生存森林算法。分位数回归森林 quantregForest通过随机森林方式对探索变量的数值响应变量分位数进行回归。varSelRF和Boruta包专注于通过随机森林进行变量选择。对于大数据集，bigrf包以并行方式计算随机森林并使用大的内存对象存储数据。 - 正规化和收缩方法（Regularized and ShrinkageMethods） : 参数评估受限的回归模型可以使用lasso2和lars包进行拟合。grplasso包提供了群体LASSO（LeastAbsolute Shrinkage and Selection Operator）惩罚模型; grpreg包实现了一些其他群体惩罚模型，例如群体MCP（MinimaxConcave Penalty）和群体SCAD（Smoothly Clipped Absolute DeviationPenalty）。用于广义线性模型和Cox模型的L1正规化路径可以通过glmpath包里的函数获得，用于线性回归、逻辑回归和多项式回归模型的整个lasso或elastic-net正规化路径（也存在于elasticnet)可以通过glmnet包获得。penalized包提供了lasso(L1)和ridge (L2)惩罚回归模型(支持广义线性模型和Cox模型)的另一个替代实现。RXshrink包能用于标识和显示特定收缩路径的跟踪信息、判断合适的收缩程度。 使用lasso惩罚的半参数加法风险模型由ahaz包提供。一种用于线性回归的广义lasso收缩技术，relaxedlasso，由relaxo包提供。penalizedLDA包实现使用（可选的）LASSO惩罚的费舍尔线性判别分析，用于特征值p远大于观测值n的高维数据。pamr包实现了用于基因表达分析的缩小重心分类法和工具。earth包提供了一个多元自适应样条回归实现。penalizedSVM包提供了使用惩罚功能(SCAD或L1惩罚)的变量选择支持向量机。 各种惩罚判别分析在hda、rda、sda和SDDA包内实现。LiblineaR包提供了LIBLINEAR库的接口。ncvreg包使用坐标下降算法进行SCAD和MCP逻辑惩罚来拟合线性和逻辑回归模型。 bigRR包关注于高吞吐量岭回归(例如，对很多预测变量进行惩罚)和异方差效应模型。 bmrm包提供了一个用于正规化风险最小化的束方法实现。 - Boosting : 各种形式的梯度boosting在gbm包 (基于树的功能性梯度下降boosting)内实现。由boosting优化的Hinge-loss实现在bst包内. GAMBoost包可用于通过boosting算法拟合广义加法模型。mboost包提供一个用于广义线性、加法和非参数模型的可扩展boosting框架。 基于似然估计的boosting实现，用于Cox模型的在CoxBoost包内提供，用于混合模型的在GMMBoost包内提供。GAMLSS模型可以使用gamboostLSS提供的boosting进行拟合。 - 支持向量机（Support Vector Machines and KernelMethods） : e1071包中的svm()函数提供LIBSVM库的接口，包kernlab 为核学习（包括SVM、RVM和其他核学习算法）提供了一个灵活的框架。 klaR 包提供了用于SVMlight实现（仅one-against-all多类分类）的接口。 核特征空间的关联维可以使用rdetools包进行估计，rdetools也提供了用于模型选择和预测的程序。 - 贝叶斯方法（BayesianMethods） : tgp包提供了贝叶斯非稳半参数非线性回归和基于树的高斯过程（包括贝叶斯线性模型、分类和回归树、基于树的线性模型）设计. - 基于遗传算法的优化（Optimization using GeneticAlgorithms） : rgp和rgenoud包提供基于遗传算法的最优化程序。Rmalschains包实现了基于局部搜索链的模因算法（memeticalgorithm），该算法为一种特俗的演化算法类型，是稳态基因算法和用于实数参数优化的局部搜索的结合体。模因算法，又译为文化基因算法，全局搜索策略可以采用遗传算法、进化策略、进化规划等;局部搜索策略可以采用爬山搜索、模拟退火、贪婪算法、禁忌搜索等。 - 关联规则（Association Rules） arules包提供了有效处理稀疏二元数据的数据结构，以及为用于挖掘频繁项集、最大频繁项集、闭频繁项集和关联规则的Apriori和Eclat算法实现提供接口。 - _基于规则的_模糊系统（Fuzzy Rule-based Systems） :frbs包实现了许多用于回归和分类、从数据中学习模糊规则系统的标准方法。RoughSets包提供了粗糙集理论（RST）和模糊粗糙集理论（FRST）的完整实现。 - 模型选择和验证（Model selection andvalidation） :e1071包中用于超参数调优的tune()函数和ipred包中的errorest() 函数可被用于错误率估计。svmpath 包里的函数可用来选取支持向量机的代价参数C。ROCR 包提供了函数用于ROC分析和其他用于对比候选分类器的可视化技术。caret 包供了各种建立预测模型的函数，包括参数调优和变量重要性量度。这些包可被用于各种并行实现（例如MPI、NWS等）。 - 统计学习基础（Elements of StatisticalLearning） :《The Elements of Statistical Learning: Data Mining, Inference, and Prediction 》一书中的数据集、函数、例子都被打包放在ElemStatLearn包中。 - rattle 是R中用于数据挖掘的图形用户界面。CORElearn 包实现了很多机器学习算法，例如最近邻域算法、树、随机森林和一些特征选择方法。与之类似，rminer 包可以使用其他包的许多学习算法并计算多种性能度量。</description>
    </item>
    
    <item>
      <title>shiny练习</title>
      <link>https://mryqu.github.io/post/shiny%E7%BB%83%E4%B9%A0/</link>
      <pubDate>Mon, 02 Jun 2014 23:29:46 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/shiny%E7%BB%83%E4%B9%A0/</guid>
      <description>Shiny是RStudio公司开发的新包，有了它，无需web开发就可以用R语言轻松开发交互式web应用。
我参加数据科学专业课学习，使用shiny完成一个作业，虽然初学乍练，也能感觉到开发起来很快速。 参考 shiny tutorialshiny examplesLinear Regressions and Linear Models using the Iris Data</description>
    </item>
    
    <item>
      <title>在R作图系统中自定义坐标轴</title>
      <link>https://mryqu.github.io/post/%E5%9C%A8r%E4%BD%9C%E5%9B%BE%E7%B3%BB%E7%BB%9F%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%90%E6%A0%87%E8%BD%B4/</link>
      <pubDate>Tue, 15 Apr 2014 21:11:08 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E5%9C%A8r%E4%BD%9C%E5%9B%BE%E7%B3%BB%E7%BB%9F%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9D%90%E6%A0%87%E8%BD%B4/</guid>
      <description>在R作图系统中自定义坐标轴 R作图系统中坐标中的标签默认是等间隔，下列尝试是为了将少量数据的坐标显示在坐标轴上。
加载库并定义数据 library(lattice) library(ggplot2) library(grid) library(gridExtra) x &amp;lt;- c(1, 2, 3, 7, 8, 9) y &amp;lt;- c(1, 23, 12, 77, 14, 2) data &amp;lt;- data.frame(x = x, y = y) data  ## x y ## 1 1 1 ## 2 2 23 ## 3 3 12 ## 4 7 77 ## 5 8 14 ## 6 9 2  Base作图系统 opar &amp;lt;- par(mfrow = c(1, 2), mar = c(4, 6, 4, 2)) with(data, plot(x, y, type = &amp;quot;b&amp;quot;, main = &amp;quot;Default Axis&amp;quot;)) par(las = 1) with(data, plot(x, y, type = &amp;quot;b&amp;quot;, main = &amp;quot;customised Axis&amp;quot;, xaxt = &amp;quot;n&amp;quot;, yaxt = &amp;quot;n&amp;quot;)) axis(1, data$x) axis(2, data$y)  par(opar)  Lattice作图系统 plot1 &amp;lt;- xyplot(y ~ x, data, type = &amp;quot;b&amp;quot;, main = &amp;quot;Default Axis&amp;quot;) plot2 &amp;lt;- xyplot(y ~ x, data, type = &amp;quot;b&amp;quot;, main = &amp;quot;customised Axis&amp;quot;, scales = list(x = list(at = unlist(data$x)), y = list(at = unlist(data$y))), las = 1) grid.</description>
    </item>
    
    <item>
      <title>CRAN任务视图使用</title>
      <link>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 07 Jan 2014 19:59:22 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/cran%E4%BB%BB%E5%8A%A1%E8%A7%86%E5%9B%BE%E4%BD%BF%E7%94%A8/</guid>
      <description>一般都是从CRAN（Comprehensive R ArchiveNetwork）安装R的各种包（package）来满足我们的编程需求。CRAN将包按照应用范畴归类，并公布在如下链接：http://cran.r-project.org/web/views/我们可以通过安装视图的命令把所有同一应用范畴的包都安装上。
为了自动安装视图，需要安装ctv包。
install.packages(&amp;quot;ctv&amp;quot;) library(&amp;quot;ctv&amp;quot;)  通过如下命令安装或更新视图。
install.views(&amp;quot;Econometrics&amp;quot;) update.views(&amp;quot;MachineLearning&amp;quot;)  CRAN任务视图 |视图|说明 |&amp;mdash; |Bayesian|贝叶斯推断 |ChemPhys|化学计量学和计算物理学 |ClinicalTrials|临床试验设计、监控和分析 |Cluster|聚类分析和有限混合模型 |DifferentialEquations|微分方程 |Distributions|概率分布 |Econometrics|计量经济学 |Environmetrics|生态与环境数据分析 |ExperimentalDesign|实验设计和数据分析 |Finance|实证金融 |Genetics|统计遗传学 |Graphics|图形显示 &amp;amp; 动态图 &amp;amp; 图形设备 &amp;amp; 可视化 |HighPerformanceComputing|高性能计算和并行计算 |MachineLearning|机器学习与统计学习 |MedicalImaging|医学图像分析 |MetaAnalysis|元分析 |Multivariate|多元统计 |NaturalLanguageProcessing|自然语言处理 |NumericalMathematics|数值数学 |OfficialStatistics|官方统计和调查方法 |Optimization|优化和数学规划 |Pharmacokinetics|药物动力学数据分析 |Phylogenetics|系统发育、进化和遗传学分析 |Psychometrics|心理测量模型和方法 |ReproducibleResearch|可重复性研究 |Robust|稳健统计方法 |SocialSciences|社会科学统计 |Spatial|空间数据分析 |SpatioTemporal|时空数据处理和分析 |Survival|存活分析 |TimeSeries|时间序列分析 |WebC++nologies|Web技术与服务 |gR|图模型</description>
    </item>
    
    <item>
      <title>swirl介绍</title>
      <link>https://mryqu.github.io/post/swirl%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Sat, 28 Dec 2013 14:22:46 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/swirl%E4%BB%8B%E7%BB%8D/</guid>
      <description>swirl是在R命令行使用、用于R统计编程语言交互式教学的软件包。 swirl需要R3.0.2或更新版本。如果使用老版本R，需要更新R之后才能使用swirl。如果不清楚当前R版本，可以在R命令行敲入R.version.string获得当前的版本信息。 swirl可以通过如下命令安装：
install.packages(&amp;quot;swirl&amp;quot;)  每次使用前，通过如下命令加载包并执行：
library(swirl) swirl()  </description>
    </item>
    
    <item>
      <title>非概率抽样</title>
      <link>https://mryqu.github.io/post/%E9%9D%9E%E6%A6%82%E7%8E%87%E6%8A%BD%E6%A0%B7/</link>
      <pubDate>Sun, 29 Sep 2013 20:41:15 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E9%9D%9E%E6%A6%82%E7%8E%87%E6%8A%BD%E6%A0%B7/</guid>
      <description>非概率抽样：调查者根据自己的方便或主观判断抽取样本的方法。它不是严格按随机抽样原则来抽取样本，所以失去了大数定律的存在基础，也就无法确定抽样误差,无法正确地说明样本的统计值在多大程度上适合于总体。虽然根据样本调查的结果也可在一定程度上说明总体的性质，特征，但不能从数量上推断总体。非概率抽样主要有偶遇抽样，主观抽样，定额抽样，滚雪球抽样等类型。
定义 非概率抽样就是调查者根据自己的方便或主观判断抽取样本的方法。 它不是严格按随机抽样原则来抽取样本，所以失去了大数定律的存在基础，也就无法确定抽样误差，无法正确地说明样本的统计值在多大程度上适合于总体。虽然根据样本调查的结果也可在一定程度上说明总体的性质、特征，但不能从数量上推断总体。
分类 非概率抽样依抽样特点可分为方便抽样、定额抽样、立意抽样、滚雪球抽样和空间抽样。
方便抽样 样本限于总体中易于抽到的一部分。最常见的方便抽样是偶遇抽样，即研究者将在某一时间和环境中所遇到的每一总体单位均作为样本成员。“街头拦人法”就是一种偶遇抽样。某些调查对被调查者来说是不愉快的、麻烦的，这时为方便起见就采用以自愿被调查者为调查样本的方法。方便抽样是非随机抽样中最简单的方法，省时省钱，但样本代表性因受偶然因素的影响太大而得不到保证。
定额抽样 定额抽样也称配额抽样，是将总体依某种标准分层（群）；然后按照各层样本数与该层总体数成比例的原则主观抽取样本。定额抽样与分层概率抽样很接近，最大的不同是分层概率抽样的各层样本是随机抽取的，而定额抽样的各层样本是非随机的。总体也可按照多种标准的组合分层(群)，例如，在研究自杀问题时，考虑到婚姻与性别都可能对自杀有影响，可将研究对象分为未婚男性、已婚男性、未婚女性和已婚女性四个组，然后从各群非随机地抽样。定额抽样是通常使用的非概率抽样方法，样本除所选标识外无法保证代表性。
立意抽样 立意抽样又称判断抽样，研究人员从总体中选择那些被判断为最能代表总体的单位作样本的抽样方法。当研究者对自己的研究领域十分熟悉，对研究总体比较了解时采用这种抽样方法，可获代表性较高的样本。这种抽样方法多应用于总体小而内部差异大的情况，以及在总体边界无法确定或因研究者的时间与人力、物力有限时采用。
滚雪球抽样 以若干个具有所需特征的人为最初的调查对象，然后依靠他们提供认识的合格的调查对象，再由这些人提供第三批调查对象，……依次类推，样本如同滚雪球般由小变大。滚雪球抽样多用于总体单位的信息不足或观察性研究的情况。这种抽样中有些分子最后仍无法找到，有些分子被提供者漏而不提，两者都可能造成误差。
空间抽样 对非静止的、暂时性的空间相邻的群体的抽样方法。例如，游行与集会没有确定的总体，参加者从一地到另一地，一些人离去又有一些人进来，但这些事件是在一定范围内进行的。对这样的总体在同一时间内抽样十分重要，以便样本组成不会经历时间上的太大变化。具体作法是:若干调查员间隔均匀的距离,从某一方向开始，访问离他最近的人，然后每隔一定步数抽取一人为调查对象。
抽样列举 常用的非概率抽样有方便抽样、定额抽样、立意抽样、雪球抽样等。
方便抽样 方便抽样又称偶遇抽样。在这种抽样中，研究者选择那些最容易接近的人作为研究对象。此法常用于干预试验或预调查时，也可用于调查收尾时补缺。
立意抽样 立意抽样又称目的抽样和判断抽样。根据研究目的的需要和研究者的主观判断，选择研究对象。
雪球抽样 雪球抽样是指选择并调查几个具有研究目的所需要的特征的人，再依靠他们选择合乎研究需要的人，后者又可选择更多合乎研究需要的人，以此类推下去，样本就像滚雪球一样越来越大。
定额抽样 定额抽样是先将要研究的人群按某种特征划分成几个组别，然后，按照一定的比例，从每组人群中任意选择一定量的样本作为研究对象。由于抽样前先进行了分层处理，抽得的样本代表性比单纯的方便抽样要好。
优点 简单易行、成本低、省时间,在统计上也比概率抽样简单。但由于无法排除抽样者的主观性，无法控制和客观地测量样本代表性，因此样本不具有推论总体的性质。非概率抽样多用于探索性研究和预备性研究，以及总体边界不清难于实施概率抽样的研究。在实际应用中，非概率抽样往往与概率抽样结合使用。
方法 PPS抽样调查法;Q分类法;SEM模型;不重复抽样;专项调查;主观概率法;二手资料调研;二路焦点小组;产品留置测试;任意抽样;会议调查;典型调查法;分层抽样;分层最佳抽样;分层比例抽样;判断抽样;双重抽样;可行性研究;因果性调研;垃圾调研法;多维尺度法;多阶段抽样;威廉·戈塞;定性研究方法;定量研究方法;实地调研;家庭日记法;市场实验调查法;市场容量测定法;平衡量表法;投射研究;投影技法;抽样;抽样调查;抽签法;拐点调研;探索性调研;推销人员估计法;描述性调研;数值分配量表;整群抽样;文案调查法;文献调查法;无准备访问;案例研究法;案头调研;概率抽样;深层访谈法;滚雪球抽样;焦点访谈法;独立控制配额抽样;电话调查;留置调查;盲测;相互控制配额抽样;等比量表;等距抽样;等距量表;简单随机抽样;类别量表;经销商访谈;经验判断法;网上间接调查;网络调研;联合分析法;营销学术语英汉对照表;行踪分析;观察法;评价量表;询问法;辅助变量;辛迪加调研;逐户寻找法;邮寄调查;配对比较量表;配额抽样;重点调查;重置抽样;问卷调查法;随机号码表法;面谈访问法;顺序量表;&amp;hellip;</description>
    </item>
    
    <item>
      <title>R语言字符处理</title>
      <link>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E5%A4%84%E7%90%86/</link>
      <pubDate>Sat, 13 Jul 2013 22:36:49 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E5%A4%84%E7%90%86/</guid>
      <description>字符处理Encoding(x)
Encoding(x)  ## x is intended to be in latin1  x Encoding(x) [1] &#34;latin1&#34;  Encoding(x) xx Encoding(c(x, xx)) [1] &#34;latin1&#34; &#34;UTF-8&#34;  Encoding(xx) cat(&#34;xx = &#34;, xx, &#34;\n&#34;, sep = &#34;&#34;) xx = fa\xc3\xa7ilenchar(x, type = &#34;chars&#34;, allowNA = FALSE)
返回字符长度，在我的测试中allowNA参数没有作用？
nzchar(x) 判断是否空字符
对于缺失值NA，nchar和nzchar函数认为是字符数为2的字符串。
所以在对字符串进行测量之前，最好先使用is.na()函数判断一下是否是NA。
对于NULL，nchar和nzchar函数会忽略掉。 nchar(c(&#34;em&#34;,&#34;yqu&#34;,&#34;&#34;,NA)) [1] 2 3 0 2  nzchar(c(&#34;em&#34;,&#34;yqu&#34;,&#34;&#34;,NA)) [1] TRUE TRUE FALSE TRUE  nzchar(c(&#34;em&#34;,&#34;yqu&#34;,NULL,&#34;&#34;,NA)) [1] TRUE TRUE FALSE TRUE  nchar(c(&#34;</description>
    </item>
    
    <item>
      <title>R语言数值计算</title>
      <link>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Sat, 13 Jul 2013 21:14:49 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/r%E8%AF%AD%E8%A8%80%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</guid>
      <description>R中数值计算的对象一般是向量或列表，不同长度的对象进行计算时，短的对象元素将被循环使用。
运算操作符+ - * /
&amp; | ！
== !=  =  aba/b [1] 1.000000 7.000000 4.166667 4.000000 Warning message: In a/b : longer object length is not a multiple of shorter object length  2^5 [1] 32  25%%6 [1] 1  13%/%5 [1] 2  7&amp;8 [1] TRUE无归类的函数sign 取符号 sign(-2:2) [1] -1 -1 0 1 1abs 取绝对值sqrt 取平方根 sqrt(-2:2) [1] NaN NaN 0.000000 1.000000 1.414214 Warning message: In sqrt(-2:2) : NaNs produced对数与指数函数log(x, base = exp(1)) 取base为底的对数，base缺省的情况下取自然对数</description>
    </item>
    
    <item>
      <title>博客链接（搜索、统计、数据挖掘）</title>
      <link>https://mryqu.github.io/post/%E5%8D%9A%E5%AE%A2%E9%93%BE%E6%8E%A5%E6%90%9C%E7%B4%A2%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</link>
      <pubDate>Wed, 03 Jul 2013 10:37:49 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E5%8D%9A%E5%AE%A2%E9%93%BE%E6%8E%A5%E6%90%9C%E7%B4%A2%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</guid>
      <description>统计（侧重R） |Name|Blog|Weibo |&amp;mdash;- |R-bloggers|http://www.r-bloggers.com/| |statMethods blog|http://statmethods.wordpress.com/| |谢益辉|http://yihui.name/|Weibo：@谢益辉 |刘思喆|http://www.bjt.name/|Weibo：@刘思喆 |邓一硕|http://yishuo.org/|Weibo：@邓一硕 |陈堰平|http://yanping.me/|Weibo：@平沙落雁 |邱怡轩|http://yixuan.cos.name/|Weibo：@解名缰 |魏太云|http://blog.cos.name/taiyun/|Weibo：@cloud_wei |陈丽云|http://www.loyhome.com/|Weibo：@cloudly |肖楠|http://www.road2stat.com/|Weibo：@road2stat |肖凯|http://xccds.github.io/|Weibo：@xccds |高涛|http://joegaotao.github.io/cn|Weibo： @三水成海 |陈刚|http://gossipcoder.com/| |李舰|http://jliblog.com/|Weibo：@lijian001 |熊熹|http://blog.cos.name/tracy/|Weibo：@熊熹91 |范建|http://blog.cos.name/fan/|Weibo：@thinkfan
搜索 百度搜索研发部官方博客
淘宝搜索技术
量子恒道官方博客</description>
    </item>
    
    <item>
      <title>模型评估笔记</title>
      <link>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 16 Jun 2013 22:44:54 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AC%94%E8%AE%B0/</guid>
      <description>模型评估简介 模型评估是模型开发过程的不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。在数据挖掘中，使用训练集中的数据评估模型性能是不可接受的，因为这易于生成过于乐观和过拟合的模型。数据挖掘中有两种方法评估模型，验证（Hold-Out）和交叉验证（Cross-Validation）。为了避免过拟合，这两种方法都使用（模型没有遇到过的）测试集来评估模型性能。
验证（Hold-Out） 使用这种方法时，通常大的数据集会被_随机_分成三个子集： - 训练集：用于构建预测模型。 - 验证集：用于评估训练阶段所得模型的性能。它为模型参数优化和选择最优模型提供了测试平台。不是所有模型算法都需要验证机。 - 测试集或之前未遇到的样本用于评估模型未来可能的性能。如果模型与训练集拟合的好于测试集，有可能是过拟合所致。
交叉验证（Cross-Validation） 当仅有有限数量的数据时，为了对模型性能进行无偏估计，我们可以使用_k_折交叉验证（k-foldcross-validation）。使用这种方法时，数据被分成_k_份数目相等的子集。我们构建_k_次模型，每次留一个子集做测试集，其他用作训练集。如果_k_等于样本大小，这也被称之为留一验证（leave-one-out）。
分类模型评估 混淆矩阵（Confusion Matrix） 混淆矩阵显示了分类模型相对数据的真实输出（目标值）的正确预测和不正确预测数目。矩阵为_N_x_N_，其中_N_为目标值（类）数目。这类模型的性能通常使用矩阵中的数据评估。下表为两个类别（阳性和阴性）的2x2混淆矩阵。 混淆矩阵目标&amp;nbsp;阳性阴性模型阳性TPFP阳性预测值
TP/(TP+FP)阴性FNTN阴性预测值
TN/(FN+TN)&amp;nbsp;灵敏度特异度准确度&amp;nbsp;=(TP+TN)/(TP+FP+FN+TN)
TP/(TP+FN)TN/(FP+TN)
术语： - 阳性 (P, positive) - 阴性 (N, Negative) - 真阳性 (TP, true positive)：正确的肯定。又称：命中 (hit) - 真阴性 (TN, true negative)：正确的否定。又称：正确拒绝 (correctrejection) - 伪阳性 (FP, false positive)：错误的肯定，又称：假警报 (falsealarm)、第二型错误 - 伪阴性 (FN, false negative)：错误的否定，又称：未命中(miss)、第一型错误 - 灵敏度(sensitivity)或真阳性率(TPR, true positive rate)：又称：召回率（recall）、命中率 (hit rate)在阳性值中实际被预测正确所占的比例。TPR = TP / P = TP / (TP+FN) - 伪阳性率(FPR, false positive rate)：又称：错误命中率，假警报率 (false alarm rate)FPR = FP / N = FP / (FP + TN) = 1-SPC - 特异度 (SPC, Specificity)或真阴性率(TNR, true negativerate)：在阴性值中实现被预测正确所占的比例。SPC = TN / N = TN / (FP+TN) = 1-FPR - 假发现率 (FDR, false discovery rate)：FDR = FP / (FP + TP) = 1-TPR - 准确度 (ACC, accuracy）：预测正确的数占样本数的比例。ACC = (TP + TN) / (P + N) - 阳性预测值 (PPV, positive predictive value)或精度(precision)：阳性预测值被预测正确的比例。PPV = TP / (TP + FP) - 阴性预测值 (NPV, negative predictive value)：阴性预测值被预测正确的比例。NPV = TN / (TN + FN) - F1评分：精度和灵敏度的调和平均数。F1 = 2 precision * recall / (precision+recall) =2TP/(2TP+FP+FN) - Matthews相关系数 (MCC)，即 Phi相关系数：(TP*TN - FP*FN)/ sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}</description>
    </item>
    
    <item>
      <title>t分布的由来</title>
      <link>https://mryqu.github.io/post/t%E5%88%86%E5%B8%83%E7%9A%84%E7%94%B1%E6%9D%A5/</link>
      <pubDate>Sun, 16 Dec 2012 09:11:46 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/t%E5%88%86%E5%B8%83%E7%9A%84%E7%94%B1%E6%9D%A5/</guid>
      <description>一直对student分布的名字莫名其妙，搜了一下，原来t分布是由统计学家哥威廉·戈塞在都柏林的A.吉尼斯父子酿酒厂对小样本中平均数比例对其标准误差的分布所做的研究，由于吉尼斯酿酒厂的规定禁止戈塞发表关于酿酒过程变化性的研究成果，因此戈塞不得不于1908年，首次以“学生”(Student)为笔名，发表自己的研究成果。因此t分布又称为学生分布。 http://baike.baidu.com/view/1419652.htm
http://baike.baidu.com/view/1332600.htm</description>
    </item>
    
  </channel>
</rss>