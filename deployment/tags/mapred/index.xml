<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mapred on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/mapred/</link>
    <description>Recent content in Mapred on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 20 Oct 2013 22:04:34 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/mapred/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Hadoop] hadoop job -list已废弃</title>
      <link>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</link>
      <pubDate>Sun, 20 Oct 2013 22:04:34 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_hadoop_job_-list%E5%B7%B2%E5%BA%9F%E5%BC%83/</guid>
      <description>执行hadoop job -list，显示该命令已废弃，不过还能执行成功。
~$ hadoop job -list DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it.  看一下Hadoop 2.2.0的代码hadoop-common-project/hadoop-common/src/main/bin/hadoop：
#hdfs commands namenode|secondarynamenode|datanode|dfs|dfsadmin|fsck|balancer|fetchdt|oiv|dfsgroups|portmap|nfs3) echo &amp;quot;DEPRECATED: Use of this script to execute hdfs command is deprecated.&amp;quot; 1&amp;gt;&amp;amp;2 echo &amp;quot;Instead use the hdfs command for it.&amp;quot; 1&amp;gt;&amp;amp;2 echo &amp;quot;&amp;quot; 1&amp;gt;&amp;amp;2 #try to locate hdfs and if present, delegate to it. shift if [ -f &amp;quot;${HADOOP_HDFS_HOME}&amp;quot;/bin/hdfs ]; then exec &amp;quot;${HADOOP_HDFS_HOME}&amp;quot;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;quot;$@&amp;quot; elif [ -f &amp;quot;${HADOOP_PREFIX}&amp;quot;/bin/hdfs ]; then exec &amp;quot;${HADOOP_PREFIX}&amp;quot;/bin/hdfs ${COMMAND/dfsgroups/groups} &amp;quot;$@&amp;quot; else echo &amp;quot;HADOOP_HDFS_HOME not found!</description>
    </item>
    
    <item>
      <title>[Hadoop] mapred和mapreduce包的区别</title>
      <link>https://mryqu.github.io/post/hadoop_mapred%E5%92%8Cmapreduce%E5%8C%85%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Fri, 12 Jul 2013 16:55:48 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hadoop_mapred%E5%92%8Cmapreduce%E5%8C%85%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>背景介绍 在Hadoop的代码中，存在org.apache.hadoop.mapred和org.apache.hadoop.mapreduce两个包。mapred包下是老的API，在Hadoop0.20时被废弃了，引入了新包mapreduce，但是由于新的API迟迟没有完成，所以在Hadoop0.21中取消了mapred包的废弃状态。原来的设想中老包mapred在Hadoop0.22和1.0中将再次设成废弃状态，但时至今日也没有被废弃。
区别 本文将通过WordCount示例代码，介绍一下二者的区别。WordCount示例代码分别取自0.19和0.23.9版本的Hadoop源码。
0.19版WordCount示例 0.23.9版WordCount示例 区别新API老API包新API位于org.apache.hadoop.mapreduce包内老API位于org.apache.hadoop.mapred.包内Mapper和Reducer类型新API使用Mapper和Reducer抽象类
抽象类更容易扩展，Hadoop实现可以轻松向其抽象类中添加方法(用默认的实现)而不会对已有Hadoop应用造成影响老API使用Mapper和Reduceer接口使用对象新API使用Configuration和一些Helper类完成作业配置；
新API使用Job完成作业控制；
新API使用Context完成用户代码与MapReduce系统的通信。老API使用JobConf
完成作业配置，它是Configuration子类；
老API使用JobClient完成作业控制；
老API使用OutputCollector和Reporter完成用户代码与MapReduce系统的通信。
方法map() reduce() clearup() setup() run()；
所有方法可抛IOException或InterruptedException；
Reduce()输入值为java.lang.Iterable；键值对输出通过Context对象的write方法实现；
map() reduce()；
所有方法可抛IOException；
Reduce()输入值为java.lang.Iterator；
键值对输出通过OutputCollector对象的collect方法实现；输出文件part-m-nnnnn和part-r-nnnnn
(nnnnn为从0开始的整数)part-nnnnn
注意事项 尽量使用新API。在mapred和mapreduce两个包下存在FileInputFormat、FileOutputFormat等名字一样的类，如果引入错误的话，程序会无法通过编译。
参考 Upgrading To The New Map Reduce API
Difference between Hadoop OLD API and NEW API</description>
    </item>
    
  </channel>
</rss>