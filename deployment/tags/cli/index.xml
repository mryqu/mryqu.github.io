<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cli on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/tags/cli/</link>
    <description>Recent content in Cli on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 02 Jul 2018 05:40:10 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/tags/cli/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[AWS] 安装AWSCLI </title>
      <link>https://mryqu.github.io/post/aws_%E5%AE%89%E8%A3%85awscli/</link>
      <pubDate>Mon, 02 Jul 2018 05:40:10 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/aws_%E5%AE%89%E8%A3%85awscli/</guid>
      <description>想玩玩AWS CLI，就从https://aws.amazon.com/cli/装了一个，但是一执行就是出LookupError: unknown encoding: cp65001错误，查了一下据说是Python2.7导致的。 首先去https://www.python.org/下载了最新的Python3.7.0。然后重新安装AWS CLI，依旧出错，只好卸载。 查看是否安装pip，结果发现没有。根据https://packaging.python.org/tutorials/installing-packages/中的提示下载了get-pip.py，执行python get-pip.py，成功安装好pip。
C:\&amp;gt;pip --version pip 10.0.1 from c:\users\mryqu\appdata\local\programs\python\python37-32\lib\site-packages\pip (python 3.7  最后使用pip安装AWS CLI:
C:\&amp;gt;pip install awscli Collecting awscli Downloading https://files.pythonhosted.org/packages/1b/1b/7446d52820533164965f7e7d08cee70b170c78fbbcbd0c7a11ccb9187be6/awscli-1.15.49-py2.py3-none-any.whl (1.3MB) 100% |████████████████████████████████| 1.3MB 6.6MB/s Collecting docutils&amp;gt;=0.10 (from awscli) Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB) 100% |████████████████████████████████| 552kB 3.3MB/s Collecting s3transfer&amp;lt;0.2.0,&amp;gt;=0.1.12 (from awscli) Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB 100% |████████████████████████████████| 61kB 787kB/s Collecting botocore==1.10.48 (from awscli) Downloading https://files.pythonhosted.org/packages/0b/56/44067a8f0cae5f33007e7cbdbaac67cbd9fa598c733ad25eb8f252288fe9/botocore-1.10.48-py2.py3-none-any.whl (4.4MB 100% |████████████████████████████████| 4.4MB 6.6MB/s Collecting PyYAML&amp;lt;=3.12,&amp;gt;=3.10 (from awscli) Downloading https://files.</description>
    </item>
    
    <item>
      <title>[Hive] HCatalog和WebHCat学习</title>
      <link>https://mryqu.github.io/post/hive_hcatalog%E5%92%8Cwebhcat%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 29 Jul 2015 05:39:31 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hive_hcatalog%E5%92%8Cwebhcat%E5%AD%A6%E4%B9%A0/</guid>
      <description>HCatalog 访问数据的常见方法之一是通过表抽象，该方法通常用于访问关系型数据库，并且为许多开发者所熟知(和广泛采用)。一些流行的Hadoop系统，例如Hive和Pig，也采用了这种方法。这种抽象解除了数据如何存储(HDFS文件、HBase表)与应用程序如何处理数据(表格式)之间的耦合。此外，它允许从较大的数据语料库中&amp;rdquo;过滤&amp;rdquo;感兴趣的数据。 Hadoop的元数据服务HCatalog扩展了Hive的元存储，同时保留了HiveDDL中用于表定义的组件。其结果是，Hive的表抽象(当使用了HCatalog时)可以用于Pig和MapReduce应用程序，这带来了以下一些主要优势：
 它使得数据消费者不必知道其数据存储的位置和方式。 它允许数据生产者修改物理数据存储和数据模型，同时仍然支持以旧格式存储的现有数据，从而数据消费者不需要修改他们的处理流程。 它为Pig、Hive和MapReduce提供了共享的结构和数据模型。  HCatalog支持读写任何SerDe支持的文件格式。默认情况下，HCatalog支持RCFile、CSV、JSON、SequenceFile和ORC文件格式。如果使用订制格式，必须提供InputFormat、OutputFormat和SerDe。 WebHCat WebHCat是WebHCat的REST API。这样应用无需使用Hadoop API就可以通过HTTP请求访问HadoopMapReduce (或YARN)、Pig、Hive及HCatalog DDL。WebHCat所使用的代码和数据必须存放在HDFS中。HCatalogDDL命令在请求后即直接执行，MapReduce、Pig和Hive作业则放置在WebHCat(Templeton)服务器的队列中，并监控进展过程或按需停止。程序员指定Pig、Hive和MapReduce结果存放的HDFS位置。 使用 HCatalog和WebHCat都已随Hive安装，所以可以直接使用
使用HCatalog HCatalog CLI与Hive CLI功能大致一样：
cd $HIVE_HOME ./hcatalog/bin/hcat  使用WebHCat 在.bashrc中添加PYTHON_CMD：
export PYTHON_CMD=/usr/bin/python  启动WebHCat服务器：
cd $HIVE_HOME ./hcatalog/sbin/webhcat_server.sh start  参考 HCatalog
HCatalog CLI
WebHCat
GitHub: apache/hcatalog
GitHub: apache/hive/hcatalog
apache/hive/hcatalog/webhcat</description>
    </item>
    
    <item>
      <title>[Hive] Hive CLI和Beeline学习</title>
      <link>https://mryqu.github.io/post/hive_hive_cli%E5%92%8Cbeeline%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Tue, 28 Jul 2015 05:59:51 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hive_hive_cli%E5%92%8Cbeeline%E5%AD%A6%E4%B9%A0/</guid>
      <description>Hive CLI学习 Hive CLI使用手册很简单，但是看完了对有些参数还是不太理解，所以就翻翻Hive CLI源码对照学习吧。
-f和-i选项的区别 Hive CLI使用手册说-i指定的是初始化SQL文件，-f指定的是SQL脚本文件。 通过阅读源码可知，所谓的初始化SQL文件就是你期望每次执行HiveCLI都要在其他操作之前运行的一些SQL命令。执行完初始化SQL，可以接着执行-e选项中的SQL命令、-f选项中的SQL脚本文件或交互输入的命令；而-f选项和-e选项二者只能存在其一，执行完-f选项后退出CLI。
hiverc文件 当没有指定-i参数时，CLI会尝试加载$HIVE_HOME/bin/.hiverc、$HIVE_CONF_DIR/.hiverc和$HOME/.hiverc作为初始化文件。只要存在，这些.hiverc都会被加载执行。 通过CliDriver类的processInitFiles方法可知，执行初始化SQL时始终采用静默模式，即不显示执行进度信息，只显示最后结果；执行-f选项中SQL脚本时是否采用静默模式由-S选项控制。
Hive CLI如何处理shell命令、Hive命令和SQL的？ HiveCLI既可以处理一个SQL脚本文件、也可以处理多个SQL命令。它通过处理多行命令，以&amp;rdquo;;&amp;ldquo;为分隔符，获取单个命令列表。一个单个命令，即可能是&amp;ndash;开头的注释行，也可能是!开头的shell命令，此外SQL命令和Hive自身支持的命令。 - 对于shell命令，Hive CLI是通过ShellCmdExecutor执行的； - 对于SQL命令，Hive CLI是通过org.apache.hadoop.hive.ql.Driver执行的； - 对于Hive命令，HiveCLI通过SetProcessor、ResetProcessor、DfsProcessor、AddResourceProcessor、ListResourceProcessor、DeleteResourceProcessor、CompileProcessor、ReloadProcessor、CryptoProcessor这些处理进行执行。
&amp;ndash;hiveconf、&amp;ndash;define (-d)、&amp;ndash;hivevar之间的关系 首先我们看一下OptionsProcessor类，它通过Apache Commons CLI解析Hive CLI命令参数: - 其process_stage1方法将&amp;ndash;hiveconf参数置入系统属性中，将&amp;ndash;define和&amp;ndash;hivevar参数置入CliSessionState对象的hiveVariables字段 - 其process_stage2方法将&amp;ndash;hiveconf参数置入CliSessionState对象的cmdProperties字段
接下来看一下CliSessionState对象的hiveVariables字段和cmdProperties字段使用情况: - CliDriver.run方法将CliSessionState对象的cmdProperties字段中的键值对覆盖HiveConf对象，然后置入CliSessionState对象的overriddenConfigurations字段 - CliSessionState对象的hiveVariables字段主要用于变量替换，包括替换提示符（CliDriver.run）、替换source命令所跟文件路径及shell命令（CliDriver.processCmd）、替换SQL（Driver.compile）、替换Hive命令（DfsProcessor.run、&amp;hellip;&amp;hellip;）
总之： - &amp;ndash;hiveconf参数在命令行中设置Hive的运行时配置参数，优先级高于hive-site.xml,但低于Hive交互Shell中使用Set命令设置。 - &amp;ndash;define (-d)和&amp;ndash;hivevar没有区别，都是用于变量替换的。
hivehistory文件 Hive CLI会创建$HOME/.hivehistory文件，并在其中记录命令历史记录。
-v参数打印出的SQL语句是变量替换后的吗？ 不是，打印的是原始SQL语句。 看了Hive CLI源码后的疑惑  CliDriver类主函数实例化一个CliDriver对象，而在executeDriver方法中不用自身实例，偏偏又实例化一个CliDriver对象cli来，为啥？ &amp;ndash;hiveconf参数会被放入CliSessionState对象的cmdProperties字段和overriddenConfigurations字段，难道不能合并成一份么？  Hive Beeline学习 BeeLine类的dispatch负责将特定命令行分发给适合的CommandHandler。 - 其中以!起始的SQLLine命令由execCommandWithPrefix方法处理，具体实现见Commands类的同名方法。- 其他命令则由Commands类的sql方法处理
参考 Hive LanguageManual CLI
Hive LanguageManual VariableSubstitution
Hive CLI source code</description>
    </item>
    
  </channel>
</rss>