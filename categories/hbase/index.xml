<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hbase on Mryqu&#39;s Notes</title>
    <link>https://mryqu.github.io/categories/hbase/</link>
    <description>Recent content in Hbase on Mryqu&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 05 Mar 2016 06:21:09 +0000</lastBuildDate>
    
	<atom:link href="https://mryqu.github.io/categories/hbase/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[HBase] 使用HBase Shell时遇到ZooKeeper exists failed after 4 attempts错误</title>
      <link>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8hbase_shell%E6%97%B6%E9%81%87%E5%88%B0zookeeper_exists_failed_after_4_attempts%E9%94%99%E8%AF%AF/</link>
      <pubDate>Sat, 05 Mar 2016 06:21:09 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8hbase_shell%E6%97%B6%E9%81%87%E5%88%B0zookeeper_exists_failed_after_4_attempts%E9%94%99%E8%AF%AF/</guid>
      <description>今天打开HBase Shell就闪退，可是前两天还好好的。错误如下：
2016-03-05 00:32:23,597 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper exists failed after 4 attempts 2016-03-05 00:32:23,598 WARN [main] zookeeper.ZKUtil: hconnection-0x2dba911d0x0, quorum=node50064.mryqu.com:2181,node50069.mryqu.com:2181,node51054.mryqu.com:2181, baseZNode=/hbase Unable to set watcher on znode (/hbase/hbaseid) org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid at org.apache.zookeeper.KeeperException.create(KeeperException:99) at org.apache.zookeeper.KeeperException.create(KeeperException:51) at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper:1045) at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper:220) at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil:419) at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId:65) at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry:105) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager:905) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.&amp;lt;init&amp;gt;(ConnectionManager:648) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl:45) at at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:238) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:218) at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory:119) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.</description>
    </item>
    
    <item>
      <title>[HBase] 才发现HBase REST服务占用的是8080端口</title>
      <link>https://mryqu.github.io/post/hbase_%E6%89%8D%E5%8F%91%E7%8E%B0hbase_rest%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8%E7%9A%84%E6%98%AF8080%E7%AB%AF%E5%8F%A3/</link>
      <pubDate>Thu, 03 Mar 2016 05:43:11 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E6%89%8D%E5%8F%91%E7%8E%B0hbase_rest%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8%E7%9A%84%E6%98%AF8080%E7%AB%AF%E5%8F%A3/</guid>
      <description>今天用一下Tomcat，结果发现8080端口还被占了，谁呀？ 竟然是HBase REST服务占用的！！看了一下Ports Used by Components of CDH 5，发现ClouderaCDH里是这么用的： - 8080：Non- Cloudera Manager - managed HBase REST Service - 20550：Cloudera Manager - managed HBase REST Service - 8085：HBase REST UI
8080端口还是留着吧，对hbase-site.xml做如下修改：重启HBase REST服务：
hbase-daemon.sh stop rest hbase-daemon.sh start rest  通过HBase REST UI检查，REST服务端口改成了20550：另一种修改REST服务端口的方式是在启动HBase REST服务命令时通过-p选项直接指定端口。例如：
hbase-daemon.sh start rest -p 20550  参考 Linux – Which application is using port 8080
Configuring and Using the HBase REST API
Ports Used by Components of CDH 5</description>
    </item>
    
    <item>
      <title>[HBase] 安装HBase 1.2.x &#43; ZooKeeper 3.4.x 集群</title>
      <link>https://mryqu.github.io/post/hbase_%E5%AE%89%E8%A3%85hbase_1.2.x_&#43;_zookeeper_3.4.x_%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 29 Feb 2016 06:23:10 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E5%AE%89%E8%A3%85hbase_1.2.x_&#43;_zookeeper_3.4.x_%E9%9B%86%E7%BE%A4/</guid>
      <description>安装HBase，首先需要参考一下The versions of Hadoop supported with each version of HBase，以便确定Hadoop和HBase各自的版本。
集群规划 |节点|角色 |&amp;mdash;&amp;ndash; |node50064|NameNode RessourceManager QuorumPeerMain HMaster |node50069|Datanode SecondNameNode QuorumPeerMain HMasterHRegionServer |node51054|Datanade QuorumPeerMain HRegionServer
ZooKeeper在HBase集群中的作用  HBase regionserver向ZooKeeper注册，提供HBase regionserver状态信息（是否在线） HMaster启动时候会将HBase 系统表-ROOT-加载到ZooKeeper集群，通过zookeeper集群可以获取当前系统表.META.的存储所对应的regionserver信息。  HMaster主要作用在于，通过HMaster维护系统表-ROOT-,.META.，记录regionserver所对应region变化信息。此外还负责监控处理当前HBase集群中regionserver状态变化信息。
Zookeeper安装 （在node50064上）下载并配置ZooKeeper wget http://apache.mirrors.tds.net/zookeeper/zookeeper-3.4.x/zookeeper-3.4.x.tar.gz tar -xzf zookeeper-3.4.x.tar.gz sudo mv zookeeper-3.4.x /usr/local/zookeeper sudo chown -R &amp;quot;hadoop:hadoop&amp;quot; /usr/local/zookeeper sudo mkdir /var/log/zookeeper sudo chown -R &amp;quot;hadoop:hadoop&amp;quot; /var/log/zookeeper sudo mkdir /var/lib/zookeeper sudo chown -R &amp;quot;hadoop:hadoop&amp;quot; /var/lib/zookeeper cd /var/lib/zookeeper touch myid echo 1 &amp;gt; myid cd /usr/local/zookeeper/conf  通过cpzoo_sample.</description>
    </item>
    
    <item>
      <title>[HBase] 查看ZooKeeper服务器</title>
      <link>https://mryqu.github.io/post/hbase_%E6%9F%A5%E7%9C%8Bzookeeper%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Wed, 20 May 2015 06:10:22 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E6%9F%A5%E7%9C%8Bzookeeper%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>使用hbaseorg.apache.hadoop.hbase.zookeeper.ZKServerTool可以很方便查看HBase所使用的ZK服务器列表。 </description>
    </item>
    
    <item>
      <title>[HBase] 使用ImportTsv命令导入数据</title>
      <link>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8importtsv%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Mon, 16 Mar 2015 20:16:13 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E4%BD%BF%E7%94%A8importtsv%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/</guid>
      <description>ImportTsv简介 ImportTsv是一款用于将TSV格式数据导入HBase的工具。它有两种用法： - 通过Put将TSV格式数据导入HBase - 通过批量导入数据的方式生成用于加载进HBase的存储文件
下面看一下ImportTsv的使用说明： ImportTsv参数 -Dimporttsv.skip.bad.lines=false - 若遇到无效行则失败 &amp;lsquo;-Dimporttsv.separator=|&amp;rsquo; - 使用特定分隔符| -Dimporttsv.timestamp=currentTimeAsLong - 使用导入时的时间戳 -Dimporttsv.mapper.class=my.Mapper -使用用户自定义Mapper类替换TsvImporterMapper -Dmapreduce.job.name=jobName - 对导入使用特定mapreduce作业名 -Dcreate.table=no - 避免创建表，注：如设为为no，目标表必须存在于HBase中 -Dno.strict=true - 忽略HBase表列族检查。默认为false
ImportTsv测试 准备数据 hadoop@node50064:~$ hadoop fs -cat /user/hadoop/tsv_input/sales2013.csv Name,Sex,Age,Height,Weight Alfred,M,14,69,112.5 Alice,F,13,56.5,84 Barbara,F,13,65.3,98 Carol,F,14,62.8,102.5 Henry,M,14,63.5,102.5 James,M,12,57.3,83 Jane,F,12,59.8,84.5 Janet,F,15,62.5,112.5 Jeffrey,M,13,62.5,84 John,M,12,59,99.5 Joyce,F,11,51.3,50.5 Judy,F,14,64.3,90 Louise,F,12,56.3,77 Mary,F,15,66.5,112 Philip,M,16,72,150 Robert,M,12,64.8,128 Ronald,M,15,67,133 Thomas,M,11,57.5,85 William,M,15,66.5,112  准备目标表 hbase(main):001:0&amp;gt; create &#39;sales2013&#39;, &#39;info&#39; 0 row(s) in 4.5730 seconds =&amp;gt; Hbase::Table - sales2013 hbase(main):002:0&amp;gt; create &#39;sales2013bulk&#39;, &#39;info&#39; 0 row(s) in 2.</description>
    </item>
    
    <item>
      <title>[HBase] 启动内置ZooKeeper过程</title>
      <link>https://mryqu.github.io/post/hbase_%E5%90%AF%E5%8A%A8%E5%86%85%E7%BD%AEzookeeper%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Tue, 24 Feb 2015 07:00:09 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E5%90%AF%E5%8A%A8%E5%86%85%E7%BD%AEzookeeper%E8%BF%87%E7%A8%8B/</guid>
      <description> start-hbase.sh  hbase-daemons.sh start zookeeper zookeepers.sh --hosts /usr/local/hbase/conf/regionservers--config /usr/local/hbase/conf cd /usr/local/hbase;/usr/local/hbase/bin/hbase-daemon.sh --config /usr/local/hbase/confstart zookeeper 检查配置HBASE_MANAGES_ZK，若不为true则终止处理。  ssh node51054 cd /usr/local/hbase;/usr/local/hbase/bin/hbase-daemon.sh --config /usr/local/hbase/confstart zookeeper hbase zookeeper start  java org.apache.hadoop.hbase.zookeeper.HQuorumPeer     </description>
    </item>
    
    <item>
      <title>[HBase] HBase Shell中的put操作解析</title>
      <link>https://mryqu.github.io/post/hbase_hbase_shell%E4%B8%AD%E7%9A%84put%E6%93%8D%E4%BD%9C%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Fri, 03 Jan 2014 23:20:51 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_hbase_shell%E4%B8%AD%E7%9A%84put%E6%93%8D%E4%BD%9C%E8%A7%A3%E6%9E%90/</guid>
      <description>阅读了HBase Shell datatype conversion一贴，感觉下列两个操作结果中的单元格数据值都像是文本类型的：
put &#39;mytable&#39;, &#39;2342&#39;, &#39;cf:c1&#39;, &#39;67&#39; put &#39;mytable&#39;, &#39;2341&#39;, &#39;cf:c1&#39;, 23  预知真相，看来只好看HBase Shell代码了。HBase Shell是Ruby代码，首先找到这些代码的位置：
cd $HBASE_HOME find . -name &#39;*.rb&#39; -print  找到了$HBASE_HOME/lib/ruby/shell/commands/put.rb，其GitHub代码库位置为https://github.com/apache/hbase/commits/master/hbase-shell/src/main/ruby/shell/commands/put.rb：
def command(table, row, column, value, timestamp=nil, args = {}) put table(table), row, column, value, timestamp, args end def put(table, row, column, value, timestamp = nil, args = {}) format_simple_command do table._put_internal(row, column, value, timestamp, args) end end  继而找到了$HBASE_HOME/lib/ruby/hbase/table.rb，其GitHub代码库位置为https://github.com/apache/hbase/blob/master/hbase-shell/src/main/ruby/hbase/table.rb：
def _put_internal(row, column, value, timestamp = nil, args = {}) p = org.</description>
    </item>
    
    <item>
      <title>[HBase] Java客户端程序构建脚本</title>
      <link>https://mryqu.github.io/post/hbase_java%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%A8%8B%E5%BA%8F%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC/</link>
      <pubDate>Fri, 03 Jan 2014 00:05:34 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_java%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%A8%8B%E5%BA%8F%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC/</guid>
      <description>上一博文[HBase] 原始数据类型存储中所用到的构建脚本build.sh如下：
#!/bin/bash HADOOP_HOME=/usr/local/hadoop HBASE_HOME=/usr/local/hbase CLASSPATH=.:$HBASE_HOME/conf:$(hbase classpath) javac -cp $CLASSPATH HBasePrimitiveDataTypeTest.java java -cp $CLASSPATH HBasePrimitiveDataTypeTest  </description>
    </item>
    
    <item>
      <title>[HBase] 原始数据类型存储</title>
      <link>https://mryqu.github.io/post/hbase_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8/</link>
      <pubDate>Thu, 02 Jan 2014 22:37:53 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AD%98%E5%82%A8/</guid>
      <description>对原始数据类型如何在HBase中存储，如何在HBaseShell中如何显示尚不了解，做一下小实验满足一下好奇心。使用下列代码存放和读取原始数据类型：
byte[] cf = Bytes.toBytes(CF_DEFAULT); Put put = new Put(Bytes.toBytes(&amp;quot;test&amp;quot;)); byte[] val = Bytes.toBytes(&amp;quot;123&amp;quot;); System.out.println(&amp;quot;Bytes for str: &amp;quot;+ bytesToHex(val)+&amp;quot;,len=&amp;quot;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;quot;str&amp;quot;), val); short shortVal = 123; val = Bytes.toBytes(shortVal); System.out.println(&amp;quot;Bytes for short:&amp;quot;+ bytesToHex(val)+&amp;quot;,len=&amp;quot;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;quot;short&amp;quot;), val); int intVal = 123; val = Bytes.toBytes(intVal); System.out.println(&amp;quot;Bytes for int:&amp;quot;+ bytesToHex(val)+&amp;quot;,len=&amp;quot;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;quot;int&amp;quot;), val); long longVal = 123L; val = Bytes.toBytes(longVal); System.out.println(&amp;quot;Bytes for long:&amp;quot;+ bytesToHex(val)+&amp;quot;,len=&amp;quot;+val.length); put.addColumn(cf, Bytes.toBytes(&amp;quot;long&amp;quot;), val); float floatVal = 123; val = Bytes.</description>
    </item>
    
    <item>
      <title>[HBase] HBase Shell交互实践</title>
      <link>https://mryqu.github.io/post/hbase_hbase_shell%E4%BA%A4%E4%BA%92%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 25 Oct 2013 20:12:48 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_hbase_shell%E4%BA%A4%E4%BA%92%E5%AE%9E%E8%B7%B5/</guid>
      <description>HBase Shell是对HBase的脚本接口，是一个JRuby REPL(Read-Eval-PrintLoop，“读取-求值-输出”循环)，可以通过脚本访问所有HBase客户端API。
单列族练习 创建表friends $ hbase shell hbase(main):001:0&amp;gt; list TABLE customer 1 row(s) in 0.2050 seconds =&amp;gt; [&amp;quot;customer&amp;quot;, &amp;quot;student&amp;quot;] hbase(main):002:0&amp;gt; create &#39;friends&#39;, &#39;d&#39; 0 row(s) in 1.3350 seconds =&amp;gt; Hbase::Table - friends hbase(main):003:0&amp;gt; list TABLE customer friends 2 row(s) in 0.0060 seconds =&amp;gt; [&amp;quot;customer&amp;quot;, &amp;quot;friends&amp;quot;, &amp;quot;student&amp;quot;]  获得表friends的描述说明 hbase(main):004:0&amp;gt; describe &#39;friends&#39; Table friends is ENABLED friends COLUMN FAMILIES DESCRIPTION {NAME =&amp;gt; &#39;d&#39;, DATA_BLOCK_ENCODING =&amp;gt; &#39;NONE&#39;, BLOOMFILTER =&amp;gt; &#39;ROW&#39;, REPLICATION_SCO PE =&amp;gt; &#39;0&#39;, VERSIONS =&amp;gt; &#39;1&#39;, COMPRESSION =&amp;gt; &#39;NONE&#39;, MIN_VERSIONS =&amp;gt; &#39;0&#39;, TTL =&amp;gt; &#39;FO REVER&#39;, KEEP_DELETED_CELLS =&amp;gt; &#39;FALSE&#39;, BLOCKSIZE =&amp;gt; &#39;65536&#39;, IN_MEMORY =&amp;gt; &#39;false&#39;, BLOCKCACHE =&amp;gt; &#39;true&#39;} 1 row(s) in 0.</description>
    </item>
    
    <item>
      <title>[HBase] Shell命令</title>
      <link>https://mryqu.github.io/post/hbase_shell%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 27 Sep 2013 19:58:03 +0000</pubDate>
      
      <guid>https://mryqu.github.io/post/hbase_shell%E5%91%BD%E4%BB%A4/</guid>
      <description>HBase提供可扩展的基于jruby(JIRB)命令行已用于执行一些命令。HBase命令行主要归为六类。
1) 通用HBase命令 status 显示集群状态。可以为‘summary’、‘simple’或‘detailed’。默认为‘summary’。 用法:
hbase&amp;gt; status hbase&amp;gt; status ‘simple’ hbase&amp;gt; status ‘summary’ hbase&amp;gt; status ‘detailed’  version 输出HBase版本 用法:
hbase&amp;gt; version  whoami 显示当前HBase用户。 用法:
hbase&amp;gt; whoami  2) 表管理命令 alter 修改列族schema；提供表名和指定新列族schema的字典。字典必须包含所要修改的列族名。例如，
对表‘t1’修改或添加列族‘f1’从当前值到最大版本5：
hbase&amp;gt; alter ‘t1’, NAME =&amp;gt; ‘f1’, VERSIONS =&amp;gt; 5  对多个列族进行操作:
hbase&amp;gt; alter ‘t1’, ‘f1’, {NAME =&amp;gt; ‘f2’, IN_MEMORY =&amp;gt; true}, {NAME =&amp;gt; ‘f3’, VERSIONS =&amp;gt; 5}  删除表‘t1’中的列族‘f1’，使用下列方法之一：
hbase&amp;gt; alter ‘t1’, NAME =&amp;gt; ‘f1’, METHOD =&amp;gt; ‘delete’ hbase&amp;gt; alter ‘t1’, ‘delete’ =&amp;gt; ‘f1’  也可以修改诸如MAX_FILESIZE、READONLY、MEMSTORE_FLUSHSIZE、DEFERRED_LOG_FLUSH等表属性，例如将region最大容量设为128MB：</description>
    </item>
    
  </channel>
</rss>